{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Home-work detection",
   "id": "10abea4087e0bd6d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-19T10:51:14.873558Z",
     "start_time": "2025-06-19T10:51:14.807844Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd D:\\mobi-seg-net"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\mobi-seg-net\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T10:54:37.643648Z",
     "start_time": "2025-06-19T10:54:36.295298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import sqlalchemy\n",
    "from lib import workers as workers\n",
    "from howde import HoWDe_labelling\n",
    "from pyspark.sql.functions import col\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pickle"
   ],
   "id": "f2ce2d8a1de260ed",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T10:51:47.889784Z",
     "start_time": "2025-06-19T10:51:33.519172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pyspark set up\n",
    "os.environ['JAVA_HOME'] = r\"C:\\Program Files\\Eclipse Adoptium\\jdk-11.0.27.6-hotspot\"\n",
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "from pyspark import SparkConf\n",
    "# Set up pyspark\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "# Create new context\n",
    "mem=\"50g\"\n",
    "n_workers = 16\n",
    "spark = SparkSession.builder.config(\"spark.sql.files.ignoreCorruptFiles\",\"true\")\\\n",
    "                                            .config(\"spark.driver.memory\", mem) \\\n",
    "                                            .config(\"spark.driver.maxResultSize\", \"40g\") \\\n",
    "                                            .config(\"spark.executer.memory\", \"40g\") \\\n",
    "                                            .config(\"spark.sql.session.timeZone\",\"Europe/Stockholm\")\\\n",
    "                                            .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    "                                            .config(\"spark.driver.maxResultSize\", \"40g\")\\\n",
    "                                            .config(\"spark.kryoserializer.buffer.max\", \"128m\")\\\n",
    "                                            .config(\"spark.storage.memoryFraction\", \"0.5\")\\\n",
    "                                            .config(\"spark.sql.broadcastTimeout\", \"7200\")\\\n",
    "                                            .master(f\"local[{n_workers}]\").getOrCreate()\n",
    "java_version = spark._jvm.System.getProperty(\"java.version\")\n",
    "print(f\"Java version used by PySpark: {java_version}\")\n",
    "print('Web UI:', spark.sparkContext.uiWebUrl)"
   ],
   "id": "8d3b9edcc2145cf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java version used by PySpark: 11.0.27\n",
      "Web UI: http://C19YUEI.net.chalmers.se:4040\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T10:51:45.271523Z",
     "start_time": "2025-06-11T10:51:44.938392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data location\n",
    "user = workers.keys_manager['database']['user']\n",
    "password = workers.keys_manager['database']['password']\n",
    "port = workers.keys_manager['database']['port']\n",
    "db_name = workers.keys_manager['database']['name']\n",
    "engine = sqlalchemy.create_engine(f'postgresql://{user}:{password}@localhost:{port}/{db_name}?gssencmode=disable')"
   ],
   "id": "48a9a6b5a92e9aca",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T10:54:51.868960Z",
     "start_time": "2025-06-19T10:54:51.770822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def within_box(lat, lng):\n",
    "    if (lat >= workers.stockholm_box[1]) & (lat <= workers.stockholm_box[3]):\n",
    "        if (lng >= workers.stockholm_box[0]) & (lng <= workers.stockholm_box[2]):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def hw_extract(data):\n",
    "    if len(data[data['location_type'] == 'W']) > 0:\n",
    "        w_list = data.loc[data['location_type'] == 'W', 'loc'].tolist()\n",
    "        counter = Counter(w_list)\n",
    "        most_common_element, count = counter.most_common(1)[0]\n",
    "    else:\n",
    "        most_common_element, count = 0, 0\n",
    "    return pd.Series(dict(workplace_loc=most_common_element, workplace_count=count))"
   ],
   "id": "d4a3080eceab1ee1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Load data",
   "id": "69d945190fec4bd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T10:53:39.118911Z",
     "start_time": "2025-06-11T10:52:33.074356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols = ['device_aid', 'loc', 'localtime', 'l_localtime']\n",
    "uuid_dict = dict()\n",
    "df_list = []\n",
    "for i in tqdm(range(0, 50)):\n",
    "    # Align column names and timestamp format\n",
    "    df_stops = pd.read_parquet(f\"dbs/stops_pr/stops_pr_{i}.parquet\",\n",
    "                               columns=cols)\n",
    "    df_stops.columns = [\"useruuid\", \"loc\", \"start\", \"end\"]\n",
    "    b_dict = {x: y for x, y in zip(df_stops['useruuid'].unique(), range(1, df_stops['useruuid'].nunique() + 1))}\n",
    "    uuid_dict.update(b_dict)\n",
    "    df_stops['useruuid'] = df_stops['useruuid'].map(uuid_dict)\n",
    "    df_list.append(df_stops)\n",
    "df_stops = pd.concat(df_list)\n",
    "del df_list"
   ],
   "id": "c6db251887edeedb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:04<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T10:56:21.262840Z",
     "start_time": "2025-06-11T10:56:17.297705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "uuid_list = df_stops['useruuid'].unique()\n",
    "uuid_batch_dict = {x: random.randint(1, 200) for x in uuid_list}\n",
    "df_stops.loc[:, 'batch'] = df_stops['useruuid'].map(uuid_batch_dict)\n",
    "print(df_stops.loc[:, 'batch'].nunique())"
   ],
   "id": "7db935910c9844fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T10:57:30.645495Z",
     "start_time": "2025-06-11T10:57:30.551203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def write_group(data):\n",
    "    # Write it back with compatible timestamp type (MILLIS)\n",
    "    table = pa.Table.from_pandas(data)  # force timestamps to milliseconds\n",
    "    pq.write_table(table, f'dbs/temp/stops_pr_{data.name}_millis.parquet', coerce_timestamps='ms')"
   ],
   "id": "a2465aaf069ff84",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T10:59:05.906385Z",
     "start_time": "2025-06-11T10:58:15.389392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tqdm.pandas()\n",
    "df_stops.groupby('batch').progress_apply(lambda x: write_group(x))"
   ],
   "id": "ec20f2bbf1d729d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:48<00:00,  4.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T10:59:09.751594Z",
     "start_time": "2025-06-11T10:59:09.519514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# To test\n",
    "# df_stops = df_stops.loc[df_stops['useruuid'].isin(df_stops['useruuid'].unique()[:1000]), :]\n",
    "uuid_r_dict = {v: k for k, v in uuid_dict.items()}\n",
    "# Save to file\n",
    "with open('dbs/uuid_r_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(uuid_r_dict, f)"
   ],
   "id": "ac5f2bbfb64e6c9c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Convert data (50 batches) into correct time format",
   "id": "850343d1feead146"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T11:08:40.691307Z",
     "start_time": "2025-06-19T11:07:00.531969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols = ['device_aid', 'loc', 'localtime', 'l_localtime']\n",
    "uuid_dict = dict()\n",
    "df_list = []\n",
    "for i in tqdm(range(0, 50)):\n",
    "    # Align column names and timestamp format\n",
    "    df_stops = pd.read_parquet(f\"dbs/stops_pr/stops_pr_{i}.parquet\",\n",
    "                               columns=cols)\n",
    "    df_stops.columns = [\"useruuid\", \"loc\", \"start\", \"end\"]\n",
    "    # b_dict = {x: y for x, y in zip(df_stops['useruuid'].unique(), range(1, df_stops['useruuid'].nunique() + 1))}\n",
    "    # uuid_dict.update(b_dict)\n",
    "    # df_stops['useruuid'] = df_stops['useruuid'].map(uuid_dict)\n",
    "    table = pa.Table.from_pandas(df_stops)  # force timestamps to milliseconds\n",
    "    pq.write_table(table, f'dbs/hw_detection/stops_pr_{i}_millis.parquet', coerce_timestamps='ms')"
   ],
   "id": "944b2e5100d337b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:40<00:00,  2.00s/it]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Workplace detection",
   "id": "b6dfc4431a39512b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T11:08:40.878809Z",
     "start_time": "2025-06-19T11:08:40.750515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Home-work detection\n",
    "path2data = 'dbs/hw_detection'\n",
    "files = os.listdir('dbs/hw_detection')\n",
    "file_paths = [os.path.join(path2data, f) for f in files]"
   ],
   "id": "eacd8a19872aad24",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T11:18:21.936215Z",
     "start_time": "2025-06-19T11:18:19.317761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load your stop location data\n",
    "# input_data = spark.read.parquet(*file_paths)\n",
    "\n",
    "i = 42\n",
    "input_data = spark.read.parquet(f'dbs/hw_detection/stops_pr_{i}_millis.parquet')\n",
    "input_data = input_data.repartition('useruuid')\n",
    "input_data.orderBy(['useruuid', 'start']).show(5)"
   ],
   "id": "71f87bb9bb2b7cf7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+-------------------+-------------------+-----------------+\n",
      "|            useruuid|loc|              start|                end|__index_level_0__|\n",
      "+--------------------+---+-------------------+-------------------+-----------------+\n",
      "|00024acb-1397-459...| 13|2024-01-28 22:50:25|2024-01-29 03:44:04|          1303216|\n",
      "|00024acb-1397-459...|  3|2024-01-29 09:51:30|2024-01-29 10:11:17|           320442|\n",
      "|00024acb-1397-459...| 15|2024-01-29 12:08:35|2024-01-29 15:47:36|          1954576|\n",
      "|00024acb-1397-459...| 14|2024-01-29 17:53:07|2024-01-29 20:53:06|           974049|\n",
      "|00024acb-1397-459...|  3|2024-01-29 22:15:55|2024-01-30 06:19:16|          1630210|\n",
      "+--------------------+---+-------------------+-------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T11:18:33.501092Z",
     "start_time": "2025-06-19T11:18:33.408939Z"
    }
   },
   "cell_type": "code",
   "source": "input_data.printSchema()",
   "id": "be088dd3dd27b1ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- useruuid: string (nullable = true)\n",
      " |-- loc: integer (nullable = true)\n",
      " |-- start: timestamp (nullable = true)\n",
      " |-- end: timestamp (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T11:13:41.907722Z",
     "start_time": "2025-06-19T11:13:38.853475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run HoWDe labelling\n",
    "with open('dbs/uuid_r_dict.pkl', 'rb') as f:\n",
    "    uuid_r_dict = pickle.load(f)\n",
    "df_w_list = []\n",
    "i = 42\n",
    "print(f'File {i} is being processed...')\n",
    "# .limit(10000)\n",
    "input_data = spark.read.parquet(f'dbs/hw_detection/stops_pr_{i}_millis.parquet') \\\n",
    "    .select(\"useruuid\", \"loc\", \"start\", \"end\")\n",
    "\n",
    "labeled_data = HoWDe_labelling(\n",
    "    input_data,\n",
    "    edit_config_default=None,\n",
    "    range_window_home=28,\n",
    "    range_window_work=42,\n",
    "    dhn=3,\n",
    "    dn_H=0.7,\n",
    "    dn_W=0.5,\n",
    "    hf_H=0.7,\n",
    "    hf_W=0.4,\n",
    "    df_W=0.6,\n",
    "    output_format=\"stop\",\n",
    "    verbose=False,\n",
    ")"
   ],
   "id": "a722e322e5edd5cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 42 is being processed...\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T11:15:18.495729Z",
     "start_time": "2025-06-19T11:13:47.400726Z"
    }
   },
   "cell_type": "code",
   "source": "labeled_data.show(5)",
   "id": "6d84cc0b4b41a498",
   "outputs": [
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\anaconda3\\envs\\mobi\\Lib\\socket.py\", line 721, in readinto\n    raise\nTimeoutError: timed out\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPythonException\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m labeled_data\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m5\u001B[39m)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\mobi\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001B[0m, in \u001B[0;36mDataFrame.show\u001B[1;34m(self, n, truncate, vertical)\u001B[0m\n\u001B[0;32m    887\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshow\u001B[39m(\u001B[38;5;28mself\u001B[39m, n: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20\u001B[39m, truncate: Union[\u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, vertical: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    888\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001B[39;00m\n\u001B[0;32m    889\u001B[0m \n\u001B[0;32m    890\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    945\u001B[0m \u001B[38;5;124;03m    name | Bob\u001B[39;00m\n\u001B[0;32m    946\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_show_string(n, truncate, vertical))\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\mobi\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001B[0m, in \u001B[0;36mDataFrame._show_string\u001B[1;34m(self, n, truncate, vertical)\u001B[0m\n\u001B[0;32m    959\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[0;32m    960\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_BOOL\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    961\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvertical\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(vertical)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[0;32m    962\u001B[0m     )\n\u001B[0;32m    964\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(truncate, \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m truncate:\n\u001B[1;32m--> 965\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mshowString(n, \u001B[38;5;241m20\u001B[39m, vertical)\n\u001B[0;32m    966\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    967\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\mobi\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[0;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[1;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[0;32m   1323\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[0;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\mobi\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[1;34m(*a, **kw)\u001B[0m\n\u001B[0;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[1;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mPythonException\u001B[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\anaconda3\\envs\\mobi\\Lib\\socket.py\", line 721, in readinto\n    raise\nTimeoutError: timed out\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Show the results\n",
    "df_l = labeled_data.toPandas()\n",
    "df_l = df_l.loc[df_l['location_type'] == 'W', ['useruuid', 'loc', 'location_type']]\n",
    "# df_l['useruuid'] = df_l['useruuid'].map(uuid_r_dict)\n",
    "tqdm.pandas()\n",
    "df_l = df_l.groupby('useruuid').progress_apply(hw_extract).reset_index()\n",
    "print(f\"No. of commuters: {df_l.shape[0]}\")\n",
    "df_w_list.append(df_l)"
   ],
   "id": "efd124825e305e54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T11:02:04.464650Z",
     "start_time": "2025-06-11T11:02:04.293404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# input_data = input_data.repartition(\"useruuid\")\n",
    "input_data.rdd.getNumPartitions()"
   ],
   "id": "b60c0097b369272d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T10:30:50.187556Z",
     "start_time": "2025-06-11T10:30:47.435493Z"
    }
   },
   "cell_type": "code",
   "source": "input_data.orderBy(['useruuid', 'start']).show()",
   "id": "7a1e9e49522b4ebd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-------------------+-------------------+\n",
      "|useruuid|loc|              start|                end|\n",
      "+--------+---+-------------------+-------------------+\n",
      "|       1|  7|2024-02-22 03:34:06|2024-02-22 05:46:46|\n",
      "|       1| 52|2024-02-22 07:15:48|2024-02-22 10:15:47|\n",
      "|       1|  8|2024-02-22 13:38:52|2024-02-22 14:34:24|\n",
      "|       1|  8|2024-02-23 08:57:47|2024-02-23 16:31:42|\n",
      "|       1| 53|2024-02-24 20:37:38|2024-02-25 00:58:34|\n",
      "|       1|  8|2024-02-26 06:49:14|2024-02-26 15:13:41|\n",
      "|       1|  7|2024-02-26 17:19:34|2024-02-26 18:41:23|\n",
      "|       1|  7|2024-02-26 19:06:44|2024-02-27 06:26:28|\n",
      "|       1|  8|2024-02-27 07:51:55|2024-02-27 15:13:02|\n",
      "|       1|  8|2024-02-28 06:54:46|2024-02-28 09:51:41|\n",
      "|       1|  8|2024-02-28 13:20:08|2024-02-28 16:28:46|\n",
      "|       1|  7|2024-02-28 17:22:07|2024-02-28 23:55:15|\n",
      "|       1| 51|2024-03-21 11:48:49|2024-03-21 16:31:08|\n",
      "|       1| 54|2024-03-24 10:21:38|2024-03-24 13:21:37|\n",
      "|       1| 55|2024-03-24 14:36:12|2024-03-24 18:23:38|\n",
      "|       1|  1|2024-04-14 18:21:35|2024-04-14 18:54:07|\n",
      "|       1|  1|2024-04-15 15:15:30|2024-04-15 16:32:10|\n",
      "|       1|  1|2024-04-16 14:28:10|2024-04-16 19:53:12|\n",
      "|       1| 11|2024-04-16 20:26:38|2024-04-16 20:42:53|\n",
      "|       1|  1|2024-04-17 16:51:08|2024-04-17 18:47:20|\n",
      "+--------+---+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_w = pd.concat(df_w_list)\n",
    "df_w.to_sql('commuter_device', engine, schema='public', index=False,\n",
    "            if_exists='append', method='multi', chunksize=5000)"
   ],
   "id": "1d56be49847a4f0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T11:02:58.736275Z",
     "start_time": "2025-06-11T11:02:58.637025Z"
    }
   },
   "cell_type": "code",
   "source": "len(df_l)",
   "id": "22daec5d5bfe28fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T08:39:26.951629Z",
     "start_time": "2025-06-11T08:39:26.853887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clear temporal files\n",
    "folder = 'dbs/temp'\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted file: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting {file_path}: {e}\")"
   ],
   "id": "dd2aabf1854f8971",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted file: dbs/temp\\stops_pr_0_millis.parquet\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T16:24:54.842847Z",
     "start_time": "2025-06-11T16:24:52.658697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "pd.read_parquet(f'dbs/cities/stockholm_stops_1.parquet').head()"
   ],
   "id": "5ae4c84ff429511b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             device_aid            h3_id  loc   latitude  \\\n",
       "0  00071219-6ef6-4d98-ae3a-5a7d7da093e7  880886619bfffff    7  59.345862   \n",
       "1  00071219-6ef6-4d98-ae3a-5a7d7da093e7  880886619bfffff    7  59.345862   \n",
       "2  00071219-6ef6-4d98-ae3a-5a7d7da093e7  880886619bfffff    7  59.345862   \n",
       "3  00071219-6ef6-4d98-ae3a-5a7d7da093e7  88088662c5fffff    1  59.376227   \n",
       "4  00071219-6ef6-4d98-ae3a-5a7d7da093e7  8808866215fffff    2  59.358313   \n",
       "\n",
       "   longitude         dur                 localtime               l_localtime  \\\n",
       "0  18.099108  252.650000 2024-01-22 02:17:28+01:00 2024-01-22 06:30:07+01:00   \n",
       "1  18.099108  329.550000 2024-01-23 02:26:44+01:00 2024-01-23 07:56:17+01:00   \n",
       "2  18.099108   16.166667 2024-01-23 16:48:15+01:00 2024-01-23 17:04:25+01:00   \n",
       "3  17.921041   60.066667 2024-02-23 05:54:18+01:00 2024-02-23 06:54:22+01:00   \n",
       "4  17.899770  119.500000 2024-02-23 09:36:34+01:00 2024-02-23 11:36:04+01:00   \n",
       "\n",
       "         date  home  year  weekday  week  seq  batch  \n",
       "0  2024-01-22   0.0  2024        0     4    4      1  \n",
       "1  2024-01-23   0.0  2024        1     4    5      1  \n",
       "2  2024-01-23   0.0  2024        1     4    6      1  \n",
       "3  2024-02-23   1.0  2024        4     8    7      1  \n",
       "4  2024-02-23   0.0  2024        4     8    8      1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_aid</th>\n",
       "      <th>h3_id</th>\n",
       "      <th>loc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>dur</th>\n",
       "      <th>localtime</th>\n",
       "      <th>l_localtime</th>\n",
       "      <th>date</th>\n",
       "      <th>home</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>seq</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00071219-6ef6-4d98-ae3a-5a7d7da093e7</td>\n",
       "      <td>880886619bfffff</td>\n",
       "      <td>7</td>\n",
       "      <td>59.345862</td>\n",
       "      <td>18.099108</td>\n",
       "      <td>252.650000</td>\n",
       "      <td>2024-01-22 02:17:28+01:00</td>\n",
       "      <td>2024-01-22 06:30:07+01:00</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00071219-6ef6-4d98-ae3a-5a7d7da093e7</td>\n",
       "      <td>880886619bfffff</td>\n",
       "      <td>7</td>\n",
       "      <td>59.345862</td>\n",
       "      <td>18.099108</td>\n",
       "      <td>329.550000</td>\n",
       "      <td>2024-01-23 02:26:44+01:00</td>\n",
       "      <td>2024-01-23 07:56:17+01:00</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00071219-6ef6-4d98-ae3a-5a7d7da093e7</td>\n",
       "      <td>880886619bfffff</td>\n",
       "      <td>7</td>\n",
       "      <td>59.345862</td>\n",
       "      <td>18.099108</td>\n",
       "      <td>16.166667</td>\n",
       "      <td>2024-01-23 16:48:15+01:00</td>\n",
       "      <td>2024-01-23 17:04:25+01:00</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00071219-6ef6-4d98-ae3a-5a7d7da093e7</td>\n",
       "      <td>88088662c5fffff</td>\n",
       "      <td>1</td>\n",
       "      <td>59.376227</td>\n",
       "      <td>17.921041</td>\n",
       "      <td>60.066667</td>\n",
       "      <td>2024-02-23 05:54:18+01:00</td>\n",
       "      <td>2024-02-23 06:54:22+01:00</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00071219-6ef6-4d98-ae3a-5a7d7da093e7</td>\n",
       "      <td>8808866215fffff</td>\n",
       "      <td>2</td>\n",
       "      <td>59.358313</td>\n",
       "      <td>17.899770</td>\n",
       "      <td>119.500000</td>\n",
       "      <td>2024-02-23 09:36:34+01:00</td>\n",
       "      <td>2024-02-23 11:36:04+01:00</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
