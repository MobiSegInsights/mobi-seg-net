{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test the data requirement of metapath2vec\n",
    "Reference: example using hetero [[Link](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/metapath2vec.py)]."
   ],
   "id": "24991a853a562e01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T15:43:26.346902Z",
     "start_time": "2025-03-03T15:43:26.274966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd D:\\mobi-seg-net"
   ],
   "id": "55458596727b592a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\mobi-seg-net\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T15:43:36.039710Z",
     "start_time": "2025-03-03T15:43:26.876946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import MetaPath2Vec\n",
    "from torch_geometric.data import HeteroData\n",
    "import workers\n",
    "import sqlalchemy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import AMiner\n",
    "print(torch.__version__)"
   ],
   "id": "2752cecee9aa005b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T15:43:36.283564Z",
     "start_time": "2025-03-03T15:43:36.039710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data location\n",
    "user = workers.keys_manager['database']['user']\n",
    "password = workers.keys_manager['database']['password']\n",
    "port = workers.keys_manager['database']['port']\n",
    "db_name = workers.keys_manager['database']['name']\n",
    "engine = sqlalchemy.create_engine(f'postgresql://{user}:{password}@localhost:{port}/{db_name}?gssencmode=disable')"
   ],
   "id": "d8afa18beced1e18",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Prepare a subset of individuals",
   "id": "6ca6c43807e8d428"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:11:15.633309Z",
     "start_time": "2025-03-03T19:10:49.068228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_stops = pd.read_parquet(\"dbs/cities/stockholm.parquet\")\n",
    "print(f\"No of edges {len(df_stops)} from {df_stops['device_aid'].nunique()} unique devices\")"
   ],
   "id": "a228b04f09ffbcd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of edges 24609483 from 941746 unique devices\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:11:22.151855Z",
     "start_time": "2025-03-03T19:11:15.743068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_ib = pd.read_sql(\"\"\"SELECT device_aid, \"group\" FROM device_group;\"\"\", con=engine)\n",
    "df_ib = df_ib[df_ib['device_aid'].isin(df_stops['device_aid'].unique())]"
   ],
   "id": "c9aa2e55a65fac2c",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Get the edges",
   "id": "516b157fdff39fa1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:11:34.281004Z",
     "start_time": "2025-03-03T19:11:22.564045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_stops = df_stops[df_stops.device_aid.isin(df_ib['device_aid'].unique())]\n",
    "print(f\"No of edges {len(df_stops)} from {df_stops['device_aid'].nunique()} unique devices\")\n",
    "individuals_mapping = dict(zip(df_stops['device_aid'].unique(), range(0, df_stops['device_aid'].nunique())))\n",
    "h3_mapping = dict(zip(df_stops['h3_id'].unique(), range(0, df_stops['h3_id'].nunique())))"
   ],
   "id": "dbdd0aaebf52e0e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of edges 24532983 from 937937 unique devices\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 Process the H-F edges",
   "id": "9d3fbfb4f9a705b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:12:58.501453Z",
     "start_time": "2025-03-03T19:11:35.295787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_stops_h = df_stops[['h3_id', 'kind']].explode('kind')\n",
    "df_stops_h.dropna(inplace=True)\n",
    "df_stops_h = df_stops_h.groupby(['h3_id', 'kind']).size().rename('count').reset_index()\n",
    "print(df_stops_h.shape, df_stops_h['count'].max(), df_stops_h['count'].min())"
   ],
   "id": "69f4fe1ce4d967e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7100, 3) 1661358 1\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:13:00.125263Z",
     "start_time": "2025-03-03T19:12:59.031430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_norm(data):\n",
    "    data['count_n'] = np.ceil(data['count'] / data['count'].sum() * 10)\n",
    "    return data\n",
    "df_stops_hs = df_stops_h.groupby('h3_id').apply(lambda data: count_norm(data), include_groups=False).reset_index()"
   ],
   "id": "a6965a32d234d5b9",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:13:00.303477Z",
     "start_time": "2025-03-03T19:13:00.125263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_stops_hs['count_n'] = df_stops_hs['count_n'].astype(int)\n",
    "df_stops_hs['count_r'] = df_stops_hs['count_n'].apply(lambda x: [1]*x)\n",
    "df_stops_hs = df_stops_hs[['h3_id', 'kind', 'count_r']].explode('count_r').drop(columns=['count_r'])\n",
    "print(df_stops_hs.shape)"
   ],
   "id": "d4faca72e3d9a67a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27230, 2)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:13:00.977586Z",
     "start_time": "2025-03-03T19:13:00.819661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df_stops_h.drop_duplicates(['h3_id', 'kind'], inplace=True)\n",
    "poi_mapping = dict(zip(df_stops_hs['kind'].unique(), range(0, df_stops_hs['kind'].nunique())))"
   ],
   "id": "e5126e99e575c1f8",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:13:03.935875Z",
     "start_time": "2025-03-03T19:13:01.494746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_stops.loc[:, 'src_id'] = df_stops.loc[:, 'device_aid'].map(individuals_mapping)\n",
    "df_stops.loc[:, 'dst_id'] = df_stops.loc[:, 'h3_id'].map(h3_mapping)\n",
    "df_stops_hs.loc[:, 'src_id'] = df_stops_hs.loc[:, 'h3_id'].map(h3_mapping)\n",
    "df_stops_hs.loc[:, 'dst_id'] = df_stops_hs.loc[:, 'kind'].map(poi_mapping)"
   ],
   "id": "b206c15ccab6fc4b",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 Process the G-I edges",
   "id": "d6015b3e5cdbda54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:13:05.431475Z",
     "start_time": "2025-03-03T19:13:04.435086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_ib.loc[:, 'dst_id'] = df_ib.loc[:, 'device_aid'].map(individuals_mapping)\n",
    "df_ib.loc[:, 'src_id'] = df_ib.loc[:, 'group']"
   ],
   "id": "b9a59db4c8437d18",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:13:06.113997Z",
     "start_time": "2025-03-03T19:13:05.944580Z"
    }
   },
   "cell_type": "code",
   "source": "df_ib.groupby('group').size()",
   "id": "7dca6e09f30f5385",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "1    556165\n",
       "2     61536\n",
       "3    254354\n",
       "4     65882\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:13:06.795910Z",
     "start_time": "2025-03-03T19:13:06.647645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# path = 'dbs/AMiner'\n",
    "# dataset = AMiner(path)\n",
    "# data_eg = dataset[0]"
   ],
   "id": "cc672e2fd7daa872",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Convert to HeteroData object",
   "id": "119478d4bb034362"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:13:07.181188Z",
     "start_time": "2025-03-03T19:13:06.883414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = HeteroData()\n",
    "# Add node features\n",
    "data['individual'].y_index = torch.tensor([v for _, v in individuals_mapping.items()], dtype=torch.long)\n",
    "data['hexagon'].y_index = torch.tensor([v for _, v in h3_mapping.items()], dtype=torch.long)\n",
    "data['poi'].y_index = torch.tensor([v for _, v in poi_mapping.items()], dtype=torch.long)\n",
    "data['group'].y_index = torch.tensor([v for v in df_ib['group'].unique()], dtype=torch.long)"
   ],
   "id": "613ca8a51f5dbda3",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:13:08.333721Z",
     "start_time": "2025-03-03T19:13:07.409114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add edge - group includes individual\n",
    "edge_index = torch.tensor(df_ib[['src_id', 'dst_id']].values.T, dtype=torch.long)\n",
    "data['group', 'includes', 'individual'].edge_index = edge_index\n",
    "\n",
    "# Add edge - individual belongs_to group\n",
    "edge_index = torch.tensor(df_ib[['dst_id', 'src_id']].values.T, dtype=torch.long)\n",
    "data['individual', 'belongs_to', 'group'].edge_index = edge_index\n",
    "\n",
    "# Add edge - individual visits hexagon\n",
    "edge_index = torch.tensor(df_stops[['src_id', 'dst_id']].values.T, dtype=torch.long)\n",
    "data['individual', 'visits', 'hexagon'].edge_index = edge_index\n",
    "\n",
    "# Add edge - hexagon visited by individual\n",
    "edge_index = torch.tensor(df_stops[['dst_id', 'src_id']].values.T, dtype=torch.long)\n",
    "data['hexagon', 'visited_by', 'individual'].edge_index = edge_index\n",
    "\n",
    "# Add edge - hexagon contains poi\n",
    "edge_index = torch.tensor(df_stops_hs[['src_id', 'dst_id']].values.T, dtype=torch.long)\n",
    "data['hexagon', 'contains', 'poi'].edge_index = edge_index\n",
    "\n",
    "# Add edge - hexagon contains poi\n",
    "edge_index = torch.tensor(df_stops_hs[['dst_id', 'src_id']].values.T, dtype=torch.long)\n",
    "data['poi', 'located_in', 'hexagon'].edge_index = edge_index"
   ],
   "id": "6befd1aa646ad119",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:13:35.643771Z",
     "start_time": "2025-03-03T19:13:34.621533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For demonstration, we define an integer label for each author node.\n",
    "individual_group_dict = df_ib.set_index('device_aid')['group'].to_dict()\n",
    "individual_labels = [individual_group_dict[k] for k, _ in individuals_mapping.items()]\n",
    "data[\"individual\"].y = torch.tensor(individual_labels, dtype=torch.int32)\n",
    "# We'll store indices of these author nodes so we can access them for the classification test.\n",
    "print(\"Constructed HeteroData object:\", data)\n",
    "print(\"Individual labels:\", data[\"individual\"].y)"
   ],
   "id": "d907165076661350",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed HeteroData object: HeteroData(\n",
      "  individual={\n",
      "    y_index=[937937],\n",
      "    y=[937937],\n",
      "  },\n",
      "  hexagon={ y_index=[3146] },\n",
      "  poi={ y_index=[5] },\n",
      "  group={ y_index=[4] },\n",
      "  (group, includes, individual)={ edge_index=[2, 937937] },\n",
      "  (individual, belongs_to, group)={ edge_index=[2, 937937] },\n",
      "  (individual, visits, hexagon)={ edge_index=[2, 24532983] },\n",
      "  (hexagon, visited_by, individual)={ edge_index=[2, 24532983] },\n",
      "  (hexagon, contains, poi)={ edge_index=[2, 27230] },\n",
      "  (poi, located_in, hexagon)={ edge_index=[2, 27230] }\n",
      ")\n",
      "Individual labels: tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:13:18.006664Z",
     "start_time": "2025-03-03T19:13:10.222099Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(data, 'dbs/cities/graph_data_stockholm.pth')",
   "id": "d4f6894acb5084f",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Set up the model",
   "id": "ee4da18428744c53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:25:23.400789Z",
     "start_time": "2025-02-26T19:25:21.318387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metapath = [\n",
    "    ('group', 'includes', 'individual'),\n",
    "    ('individual', 'visits', 'hexagon'),\n",
    "    ('hexagon', 'contains', 'poi'),\n",
    "    ('poi', 'located_in', 'hexagon'),\n",
    "    ('hexagon', 'visited_by', 'individual'),\n",
    "    ('individual', 'belongs_to', 'group'),\n",
    "]\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch_geometric.is_xpu_available():\n",
    "    device = torch.device('xpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "model = MetaPath2Vec(\n",
    "    data.edge_index_dict,\n",
    "    embedding_dim=64,        # Smaller dimension for our toy data\n",
    "    metapath=metapath,\n",
    "    walk_length=100,\n",
    "    context_size=7,\n",
    "    walks_per_node=500,\n",
    "    num_negative_samples=5,\n",
    "    sparse=True  # Use a sparse embedding for memory efficiency\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)"
   ],
   "id": "7df55c00a0ee67dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Train the model to predict the individual residential segregation level\n",
    "1- Segregated towards foreign-born\n",
    "\n",
    "2- Non-segregated\n",
    "\n",
    "3- Segregted towards native-born"
   ],
   "id": "b7e30ff97f60e766"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:25:53.668307Z",
     "start_time": "2025-02-26T19:25:53.504954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loader = model.loader(batch_size=16, shuffle=True, num_workers=0)\n",
    "def train(epoch, log_steps=10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (i + 1) % log_steps == 0:\n",
    "            avg_loss = total_loss / log_steps\n",
    "            print(f'Epoch: {epoch}, Step: {i + 1:03d}/{len(loader)}, '\n",
    "                  f'Loss: {avg_loss:.4f}')\n",
    "            total_loss = 0\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(train_ratio=0.5):\n",
    "    \"\"\"Simple test: we embed individuals, then do a logistic regression on their labels.\"\"\"\n",
    "    model.eval()\n",
    "    z = model('individual', batch=data[\"individual\"].y_index.to(device))\n",
    "    y = data[\"individual\"].y\n",
    "\n",
    "    num_nodes = z.size(0)\n",
    "    perm = torch.randperm(num_nodes)\n",
    "    train_size = int(num_nodes * train_ratio)\n",
    "    train_mask = perm[:train_size]\n",
    "    test_mask = perm[train_size:]\n",
    "\n",
    "    # Fit a simple linear model on top of embeddings:\n",
    "    x_train = z[train_mask].cpu()\n",
    "    y_train = y[train_mask].cpu()\n",
    "    x_test = z[test_mask].cpu()\n",
    "    y_test = y[test_mask].cpu()\n",
    "\n",
    "    # We can do a tiny logistic regression or SVC, but here we use a\n",
    "    # built-in model test from MetaPath2Vec or do a manual approach:\n",
    "    return model.test(x_train, y_train, x_test, y_test, max_iter=50)\n",
    "\n",
    "#@torch.no_grad()\n",
    "def test_alternative(train_ratio=0.5, model_type='xgboost'):\n",
    "    \"\"\"\n",
    "    Advanced test: we embed individuals, then train a more advanced model (XGBoost or Random Forest) on their labels.\n",
    "\n",
    "    Args:\n",
    "        train_ratio (float): Ratio of training data.\n",
    "        model_type (str): Type of model to use ('xgboost' or 'random_forest').\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    z = model('individual', batch=data[\"individual\"].y_index.to(device))\n",
    "    y = data[\"individual\"].y\n",
    "\n",
    "    num_nodes = z.size(0)\n",
    "    perm = torch.randperm(num_nodes)\n",
    "    train_size = int(num_nodes * train_ratio)\n",
    "    train_mask = perm[:train_size]\n",
    "    test_mask = perm[train_size:]\n",
    "\n",
    "    # Prepare data\n",
    "    x_train = z[train_mask].detach().cpu().numpy()\n",
    "    y_train = y[train_mask].detach().cpu().numpy()\n",
    "    x_test = z[test_mask].detach().cpu().numpy()\n",
    "    y_test = y[test_mask].detach().cpu().numpy()\n",
    "\n",
    "    # Choose and train the model\n",
    "    if model_type == 'xgboost':\n",
    "        clf = XGBClassifier(\n",
    "            n_estimators=100,  # Number of boosting rounds\n",
    "            max_depth=6,       # Maximum depth of a tree\n",
    "            learning_rate=0.1, # Learning rate\n",
    "            objective='binary:logistic',  # For binary classification\n",
    "            random_state=42\n",
    "        )\n",
    "    elif model_type == 'random_forest':\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=100,  # Number of trees\n",
    "            max_depth=10,       # Maximum depth of a tree\n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type. Choose 'xgboost' or 'random_forest'.\")\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test Accuracy ({model_type}): {accuracy:.4f}\")\n",
    "    return accuracy"
   ],
   "id": "8316e6006f130da4",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:26:50.220802300Z",
     "start_time": "2025-02-26T19:25:57.949094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run Training\n",
    "for epoch in range(1, 6):\n",
    "    train(epoch)\n",
    "    # acc = test_alternative()\n",
    "    acc = test()\n",
    "    print(f'Epoch: {epoch}, Accuracy: {acc:.4f}')"
   ],
   "id": "e210ba47ec826e8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b36079339986eb08"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
