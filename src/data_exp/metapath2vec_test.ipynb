{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test the data requirement of metapath2vec\n",
    "Reference: example using hetero [[Link](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/metapath2vec.py)]."
   ],
   "id": "24991a853a562e01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:50:23.445027Z",
     "start_time": "2025-02-24T11:50:23.368784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd D:\\mobi-seg-net"
   ],
   "id": "55458596727b592a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\mobi-seg-net\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:50:33.369970Z",
     "start_time": "2025-02-24T11:50:24.097779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import MetaPath2Vec\n",
    "from torch_geometric.data import HeteroData\n",
    "import workers\n",
    "import sqlalchemy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import AMiner\n",
    "print(torch.__version__)"
   ],
   "id": "2752cecee9aa005b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:50:33.645690Z",
     "start_time": "2025-02-24T11:50:33.401606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data location\n",
    "user = workers.keys_manager['database']['user']\n",
    "password = workers.keys_manager['database']['password']\n",
    "port = workers.keys_manager['database']['port']\n",
    "db_name = workers.keys_manager['database']['name']\n",
    "engine = sqlalchemy.create_engine(f'postgresql://{user}:{password}@localhost:{port}/{db_name}?gssencmode=disable')"
   ],
   "id": "d8afa18beced1e18",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Prepare a subset of individuals",
   "id": "6ca6c43807e8d428"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:50:36.476262Z",
     "start_time": "2025-02-24T11:50:33.660784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_stops = pd.read_parquet(\"dbs/stops_pr/stops_pr_0.parquet\", columns=['device_aid', 'h3_id', 'home', 'kind'])\n",
    "df_stops = df_stops[df_stops['home']!=1]\n",
    "# df_stops.drop_duplicates(subset=['device_aid', 'h3_id'], inplace=True)\n",
    "print(f\"No of edges {len(df_stops)} from {df_stops['device_aid'].nunique()} unique devices\")"
   ],
   "id": "a228b04f09ffbcd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of edges 1709633 from 33317 unique devices\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:56:26.497349Z",
     "start_time": "2025-02-24T11:56:21.806242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_ib = pd.read_sql(\"\"\"SELECT device_aid, b_id FROM home_building;\"\"\", con=engine)\n",
    "df_ib = df_ib[df_ib['device_aid'].isin(df_stops['device_aid'].unique())]\n",
    "df_bd = pd.read_sql(\"\"\"SELECT * FROM building_data;\"\"\", con=engine)\n",
    "df_ib = pd.merge(df_ib, df_bd, on='b_id', how='left')\n",
    "df_ib.dropna(inplace=True)"
   ],
   "id": "c9aa2e55a65fac2c",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:52:16.693063Z",
     "start_time": "2025-02-24T11:52:16.521752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ice(ai=None, bi=None, popi=None, share_a=0.8044332515556147, share_b=0.11067529894925136):\n",
    "    oi = popi - ai - bi\n",
    "    share_o = 1 - share_a - share_b\n",
    "    return (ai / share_a - bi / share_b) / (ai / share_a + bi / share_b + oi / share_o)\n",
    "\n",
    "def ice_group(x):\n",
    "    if x < -0.2:\n",
    "        return 0\n",
    "    elif x < 0.2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ],
   "id": "6a834b4d4a923b58",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Birth background label",
   "id": "5d612bea747d8e30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:56:36.135525Z",
     "start_time": "2025-02-24T11:56:35.683205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_ib['pop_o'] = df_ib.loc[:, ['sweden', 'nordic', 'eu', 'other']].sum(axis=1)\n",
    "df_ib = df_ib[df_ib['pop_o'] > 0].copy()\n",
    "df_ib.loc[:, 'other_share'] = df_ib['other'] / df_ib['pop_o']\n",
    "df_ib.loc[:, 'ice'] = df_ib.apply(lambda x: ice(ai=x['sweden'], bi=x['other'], popi=x['pop_o']), axis=1)\n",
    "# workers.distr(df_ib, col_name='other_share', x_lb='Share of other', y_lb='Probability density', bin_num=100)"
   ],
   "id": "c697c6b91e7cab2b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:56:42.551443Z",
     "start_time": "2025-02-24T11:56:42.352999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_ib.loc[:, 'grp_o'] = pd.qcut(df_ib.loc[:, 'other_share'], q=4, labels=[1, 2, 3, 4])\n",
    "df_ib.loc[:, 'grp_ice_o'] = df_ib.loc[:, 'ice'].apply(lambda x: ice_group(x))"
   ],
   "id": "fe2cda5f72123b8e",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Income label",
   "id": "11b3c44b7d4fabe2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:56:43.762193Z",
     "start_time": "2025-02-24T11:56:43.264979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_ib['pop_i'] = df_ib.loc[:, ['Q1', 'Q2', 'Q3', 'Q4']].sum(axis=1)\n",
    "df_ib = df_ib[df_ib['pop_i'] > 0].copy()\n",
    "df_ib.loc[:, 'q1_share'] = df_ib.loc[:, 'Q1'] / df_ib.loc[:, ['Q1', 'Q2', 'Q3', 'Q4']].sum(axis=1)\n",
    "df_ib.loc[:, 'ice_i'] = df_ib.apply(lambda x: ice(ai=x['Q1'], bi=x['Q4'], popi=x['pop_i'], share_a=0.25, share_b=0.25), axis=1)\n",
    "# workers.distr(df_ib, col_name='q1_share', x_lb='Share of low-income quantile', y_lb='Probability density', bin_num=100)"
   ],
   "id": "6ca16d572f4cefa0",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:56:44.172238Z",
     "start_time": "2025-02-24T11:56:43.977190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_ib.loc[:, 'grp_i'] = pd.qcut(df_ib.loc[:, 'q1_share'], q=4, labels=[1, 2, 3, 4])\n",
    "df_ib.loc[:, 'grp_ice_i'] = df_ib.loc[:, 'ice_i'].apply(lambda x: ice_group(x))"
   ],
   "id": "e4e9d4c3e12b31a6",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:56:44.938925Z",
     "start_time": "2025-02-24T11:56:44.742257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_ib = df_ib[['device_aid', 'grp_o', 'grp_ice_o', 'grp_i', 'grp_ice_i']]\n",
    "print(len(df_ib), len(df_ib.dropna()))"
   ],
   "id": "ccf69f2a0a5114cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33163 33163\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:56:45.803754Z",
     "start_time": "2025-02-24T11:56:45.609291Z"
    }
   },
   "cell_type": "code",
   "source": "df_ib.groupby('grp_ice_o').size()",
   "id": "ada2afd4f73ffb6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grp_ice_o\n",
       "0    11018\n",
       "1    12900\n",
       "2     9245\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Get the edges",
   "id": "516b157fdff39fa1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:53:26.373934Z",
     "start_time": "2025-02-24T11:53:26.036745Z"
    }
   },
   "cell_type": "code",
   "source": "df_stops = df_stops[df_stops.device_aid.isin(df_ib['device_aid'])]",
   "id": "54668c969da5382d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:53:27.087362Z",
     "start_time": "2025-02-24T11:53:26.429360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "individuals_mapping = dict(zip(df_stops['device_aid'].unique(), range(0, df_stops['device_aid'].nunique())))\n",
    "h3_mapping = dict(zip(df_stops['h3_id'].unique(), range(0, df_stops['h3_id'].nunique())))"
   ],
   "id": "dbdd0aaebf52e0e2",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:53:31.860116Z",
     "start_time": "2025-02-24T11:53:27.087362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_stops_h = df_stops[['h3_id', 'kind']].explode('kind')\n",
    "df_stops_h.dropna(inplace=True)\n",
    "# df_stops_h.drop_duplicates(['h3_id', 'kind'], inplace=True)\n",
    "poi_mapping = dict(zip(df_stops_h['kind'].unique(), range(0, df_stops_h['kind'].nunique())))"
   ],
   "id": "b8289fc785744e19",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:53:32.867620Z",
     "start_time": "2025-02-24T11:53:31.923373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_stops.loc[:, 'src_id'] = df_stops.loc[:, 'device_aid'].map(individuals_mapping)\n",
    "df_stops.loc[:, 'dst_id'] = df_stops.loc[:, 'h3_id'].map(h3_mapping)\n",
    "df_stops_h.loc[:, 'src_id'] = df_stops_h.loc[:, 'h3_id'].map(h3_mapping)\n",
    "df_stops_h.loc[:, 'dst_id'] = df_stops_h.loc[:, 'kind'].map(poi_mapping)"
   ],
   "id": "b206c15ccab6fc4b",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:50:43.281182300Z",
     "start_time": "2025-02-24T11:44:23.604507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# path = 'dbs/AMiner'\n",
    "# dataset = AMiner(path)\n",
    "# data_eg = dataset[0]"
   ],
   "id": "cc672e2fd7daa872",
   "outputs": [],
   "execution_count": 221
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Convert to HeteroData object",
   "id": "119478d4bb034362"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:56:55.196860Z",
     "start_time": "2025-02-24T11:56:55.014438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = HeteroData()\n",
    "# Add node features\n",
    "data['individual'].y_index = torch.tensor([v for _, v in individuals_mapping.items()], dtype=torch.long)\n",
    "data['hexagon'].y_index = torch.tensor([v for _, v in h3_mapping.items()], dtype=torch.long)\n",
    "data['poi'].y_index = torch.tensor([v for _, v in poi_mapping.items()], dtype=torch.long)"
   ],
   "id": "613ca8a51f5dbda3",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:56:55.961937Z",
     "start_time": "2025-02-24T11:56:55.354521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add edge - individual visits hexagon\n",
    "edge_index = torch.tensor(df_stops[['src_id', 'dst_id']].values.T, dtype=torch.long)\n",
    "data['individual', 'visits', 'hexagon'].edge_index = edge_index\n",
    "\n",
    "# Add edge - individual visits hexagon\n",
    "edge_index = torch.tensor(df_stops[['dst_id', 'src_id']].values.T, dtype=torch.long)\n",
    "data['hexagon', 'visited_by', 'individual'].edge_index = edge_index\n",
    "\n",
    "# Add edge - hexagon contains poi\n",
    "edge_index = torch.tensor(df_stops_h[['src_id', 'dst_id']].values.T, dtype=torch.long)\n",
    "data['hexagon', 'contains', 'poi'].edge_index = edge_index\n",
    "\n",
    "# Add edge - hexagon contains poi\n",
    "edge_index = torch.tensor(df_stops_h[['dst_id', 'src_id']].values.T, dtype=torch.long)\n",
    "data['poi', 'located_in', 'hexagon'].edge_index = edge_index"
   ],
   "id": "6befd1aa646ad119",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:56:57.255229Z",
     "start_time": "2025-02-24T11:56:57.045098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For demonstration, we define an integer label for each author node.\n",
    "individual_group_dict = df_ib.set_index('device_aid')['grp_ice_o'].to_dict()\n",
    "individual_labels = [individual_group_dict[k] for k, _ in individuals_mapping.items()]\n",
    "data[\"individual\"].y = torch.tensor(individual_labels, dtype=torch.int32)\n",
    "# We'll store indices of these author nodes so we can access them for the classification test.\n",
    "print(\"Constructed HeteroData object:\", data)\n",
    "print(\"Author labels:\", data[\"individual\"].y)"
   ],
   "id": "eccdd8b001f07942",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed HeteroData object: HeteroData(\n",
      "  individual={\n",
      "    y_index=[33163],\n",
      "    y=[33163],\n",
      "  },\n",
      "  hexagon={ y_index=[47171] },\n",
      "  poi={ y_index=[5] },\n",
      "  (individual, visits, hexagon)={ edge_index=[2, 1701194] },\n",
      "  (hexagon, visited_by, individual)={ edge_index=[2, 1701194] },\n",
      "  (hexagon, contains, poi)={ edge_index=[2, 12401609] },\n",
      "  (poi, located_in, hexagon)={ edge_index=[2, 12401609] }\n",
      ")\n",
      "Author labels: tensor([2, 1, 1,  ..., 1, 1, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Set up the model",
   "id": "ee4da18428744c53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:57:05.335488Z",
     "start_time": "2025-02-24T11:57:04.548673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metapath = [\n",
    "    ('hexagon', 'visited_by', 'individual'),\n",
    "    ('individual', 'visits', 'hexagon'),\n",
    "    ('hexagon', 'contains', 'poi'),\n",
    "    ('poi', 'located_in', 'hexagon'),\n",
    "]\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch_geometric.is_xpu_available():\n",
    "    device = torch.device('xpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "model = MetaPath2Vec(\n",
    "    data.edge_index_dict,\n",
    "    embedding_dim=64,        # Smaller dimension for our toy data\n",
    "    metapath=metapath,\n",
    "    walk_length=20,\n",
    "    context_size=4,\n",
    "    walks_per_node=2,\n",
    "    num_negative_samples=2,\n",
    "    sparse=True  # Use a sparse embedding for memory efficiency\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)"
   ],
   "id": "7df55c00a0ee67dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Train the model to predict the individual residential segregation level\n",
    "1- Segregated towards foreign-born\n",
    "\n",
    "2- Non-segregated\n",
    "\n",
    "3- Segregted towards native-born"
   ],
   "id": "b7e30ff97f60e766"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T12:00:31.228946Z",
     "start_time": "2025-02-24T12:00:31.025995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loader = model.loader(batch_size=16, shuffle=True, num_workers=0)\n",
    "def train(epoch, log_steps=1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (i + 1) % log_steps == 0:\n",
    "            avg_loss = total_loss / log_steps\n",
    "            print(f'Epoch: {epoch}, Step: {i + 1:03d}/{len(loader)}, '\n",
    "                  f'Loss: {avg_loss:.4f}')\n",
    "            total_loss = 0\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(train_ratio=0.5):\n",
    "    \"\"\"Simple test: we embed individuals, then do a logistic regression on their labels.\"\"\"\n",
    "    model.eval()\n",
    "    z = model('individual', batch=data[\"individual\"].y_index.to(device))\n",
    "    y = data[\"individual\"].y\n",
    "\n",
    "    num_nodes = z.size(0)\n",
    "    perm = torch.randperm(num_nodes)\n",
    "    train_size = int(num_nodes * train_ratio)\n",
    "    train_mask = perm[:train_size]\n",
    "    test_mask = perm[train_size:]\n",
    "\n",
    "    # Fit a simple linear model on top of embeddings:\n",
    "    x_train = z[train_mask].cpu()\n",
    "    y_train = y[train_mask].cpu()\n",
    "    x_test = z[test_mask].cpu()\n",
    "    y_test = y[test_mask].cpu()\n",
    "\n",
    "    # We can do a tiny logistic regression or SVC, but here we use a\n",
    "    # built-in model test from MetaPath2Vec or do a manual approach:\n",
    "    return model.test(x_train, y_train, x_test, y_test, max_iter=50)\n",
    "\n",
    "#@torch.no_grad()\n",
    "def test_alternative(train_ratio=0.5, model_type='xgboost'):\n",
    "    \"\"\"\n",
    "    Advanced test: we embed individuals, then train a more advanced model (XGBoost or Random Forest) on their labels.\n",
    "\n",
    "    Args:\n",
    "        train_ratio (float): Ratio of training data.\n",
    "        model_type (str): Type of model to use ('xgboost' or 'random_forest').\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    z = model('individual', batch=data[\"individual\"].y_index.to(device))\n",
    "    y = data[\"individual\"].y\n",
    "\n",
    "    num_nodes = z.size(0)\n",
    "    perm = torch.randperm(num_nodes)\n",
    "    train_size = int(num_nodes * train_ratio)\n",
    "    train_mask = perm[:train_size]\n",
    "    test_mask = perm[train_size:]\n",
    "\n",
    "    # Prepare data\n",
    "    x_train = z[train_mask].detach().cpu().numpy()\n",
    "    y_train = y[train_mask].detach().cpu().numpy()\n",
    "    x_test = z[test_mask].detach().cpu().numpy()\n",
    "    y_test = y[test_mask].detach().cpu().numpy()\n",
    "\n",
    "    # Choose and train the model\n",
    "    if model_type == 'xgboost':\n",
    "        clf = XGBClassifier(\n",
    "            n_estimators=100,  # Number of boosting rounds\n",
    "            max_depth=6,       # Maximum depth of a tree\n",
    "            learning_rate=0.1, # Learning rate\n",
    "            objective='binary:logistic',  # For binary classification\n",
    "            random_state=42\n",
    "        )\n",
    "    elif model_type == 'random_forest':\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=100,  # Number of trees\n",
    "            max_depth=10,       # Maximum depth of a tree\n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type. Choose 'xgboost' or 'random_forest'.\")\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test Accuracy ({model_type}): {accuracy:.4f}\")\n",
    "    return accuracy"
   ],
   "id": "8316e6006f130da4",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T12:02:58.264399Z",
     "start_time": "2025-02-24T12:00:39.720940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run Training\n",
    "for epoch in range(1, 6):\n",
    "    train(epoch)\n",
    "    acc = test_alternative()\n",
    "    # acc = test()\n",
    "    print(f'Epoch: {epoch}, Accuracy: {acc:.4f}')"
   ],
   "id": "e210ba47ec826e8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 001/2949, Loss: 0.9206\n",
      "Epoch: 1, Step: 002/2949, Loss: 0.8994\n",
      "Epoch: 1, Step: 003/2949, Loss: 0.8915\n",
      "Epoch: 1, Step: 004/2949, Loss: 0.9089\n",
      "Epoch: 1, Step: 005/2949, Loss: 0.8435\n",
      "Epoch: 1, Step: 006/2949, Loss: 0.9167\n",
      "Epoch: 1, Step: 007/2949, Loss: 0.9073\n",
      "Epoch: 1, Step: 008/2949, Loss: 0.9114\n",
      "Epoch: 1, Step: 009/2949, Loss: 0.8869\n",
      "Epoch: 1, Step: 010/2949, Loss: 0.8480\n",
      "Epoch: 1, Step: 011/2949, Loss: 0.9537\n",
      "Epoch: 1, Step: 012/2949, Loss: 0.8660\n",
      "Epoch: 1, Step: 013/2949, Loss: 0.8593\n",
      "Epoch: 1, Step: 014/2949, Loss: 0.8359\n",
      "Epoch: 1, Step: 015/2949, Loss: 0.8936\n",
      "Epoch: 1, Step: 016/2949, Loss: 0.9069\n",
      "Epoch: 1, Step: 017/2949, Loss: 0.8478\n",
      "Epoch: 1, Step: 018/2949, Loss: 0.8746\n",
      "Epoch: 1, Step: 019/2949, Loss: 0.8895\n",
      "Epoch: 1, Step: 020/2949, Loss: 0.8255\n",
      "Epoch: 1, Step: 021/2949, Loss: 0.8640\n",
      "Epoch: 1, Step: 022/2949, Loss: 0.9123\n",
      "Epoch: 1, Step: 023/2949, Loss: 0.8641\n",
      "Epoch: 1, Step: 024/2949, Loss: 0.8651\n",
      "Epoch: 1, Step: 025/2949, Loss: 0.8892\n",
      "Epoch: 1, Step: 026/2949, Loss: 0.8778\n",
      "Epoch: 1, Step: 027/2949, Loss: 0.9154\n",
      "Epoch: 1, Step: 028/2949, Loss: 0.8645\n",
      "Epoch: 1, Step: 029/2949, Loss: 0.8905\n",
      "Epoch: 1, Step: 030/2949, Loss: 0.8568\n",
      "Epoch: 1, Step: 031/2949, Loss: 0.8835\n",
      "Epoch: 1, Step: 032/2949, Loss: 0.8687\n",
      "Epoch: 1, Step: 033/2949, Loss: 0.8861\n",
      "Epoch: 1, Step: 034/2949, Loss: 0.8906\n",
      "Epoch: 1, Step: 035/2949, Loss: 0.8731\n",
      "Epoch: 1, Step: 036/2949, Loss: 0.9342\n",
      "Epoch: 1, Step: 037/2949, Loss: 0.8724\n",
      "Epoch: 1, Step: 038/2949, Loss: 0.8870\n",
      "Epoch: 1, Step: 039/2949, Loss: 0.9001\n",
      "Epoch: 1, Step: 040/2949, Loss: 0.9104\n",
      "Epoch: 1, Step: 041/2949, Loss: 0.8639\n",
      "Epoch: 1, Step: 042/2949, Loss: 0.8695\n",
      "Epoch: 1, Step: 043/2949, Loss: 0.9268\n",
      "Epoch: 1, Step: 044/2949, Loss: 0.8476\n",
      "Epoch: 1, Step: 045/2949, Loss: 0.8478\n",
      "Epoch: 1, Step: 046/2949, Loss: 0.8759\n",
      "Epoch: 1, Step: 047/2949, Loss: 0.8913\n",
      "Epoch: 1, Step: 048/2949, Loss: 0.8254\n",
      "Epoch: 1, Step: 049/2949, Loss: 0.8864\n",
      "Epoch: 1, Step: 050/2949, Loss: 0.9004\n",
      "Epoch: 1, Step: 051/2949, Loss: 0.8628\n",
      "Epoch: 1, Step: 052/2949, Loss: 0.8579\n",
      "Epoch: 1, Step: 053/2949, Loss: 0.9065\n",
      "Epoch: 1, Step: 054/2949, Loss: 0.8838\n",
      "Epoch: 1, Step: 055/2949, Loss: 0.9016\n",
      "Epoch: 1, Step: 056/2949, Loss: 0.9287\n",
      "Epoch: 1, Step: 057/2949, Loss: 0.9034\n",
      "Epoch: 1, Step: 058/2949, Loss: 0.8776\n",
      "Epoch: 1, Step: 059/2949, Loss: 0.9360\n",
      "Epoch: 1, Step: 060/2949, Loss: 0.8809\n",
      "Epoch: 1, Step: 061/2949, Loss: 0.8881\n",
      "Epoch: 1, Step: 062/2949, Loss: 0.8555\n",
      "Epoch: 1, Step: 063/2949, Loss: 0.8884\n",
      "Epoch: 1, Step: 064/2949, Loss: 0.9231\n",
      "Epoch: 1, Step: 065/2949, Loss: 0.8330\n",
      "Epoch: 1, Step: 066/2949, Loss: 0.8471\n",
      "Epoch: 1, Step: 067/2949, Loss: 0.8564\n",
      "Epoch: 1, Step: 068/2949, Loss: 0.8321\n",
      "Epoch: 1, Step: 069/2949, Loss: 0.8645\n",
      "Epoch: 1, Step: 070/2949, Loss: 0.8912\n",
      "Epoch: 1, Step: 071/2949, Loss: 0.8502\n",
      "Epoch: 1, Step: 072/2949, Loss: 0.8433\n",
      "Epoch: 1, Step: 073/2949, Loss: 0.8781\n",
      "Epoch: 1, Step: 074/2949, Loss: 0.8516\n",
      "Epoch: 1, Step: 075/2949, Loss: 0.9163\n",
      "Epoch: 1, Step: 076/2949, Loss: 0.8787\n",
      "Epoch: 1, Step: 077/2949, Loss: 0.9174\n",
      "Epoch: 1, Step: 078/2949, Loss: 0.8456\n",
      "Epoch: 1, Step: 079/2949, Loss: 0.8938\n",
      "Epoch: 1, Step: 080/2949, Loss: 0.8726\n",
      "Epoch: 1, Step: 081/2949, Loss: 0.9014\n",
      "Epoch: 1, Step: 082/2949, Loss: 0.8278\n",
      "Epoch: 1, Step: 083/2949, Loss: 0.8998\n",
      "Epoch: 1, Step: 084/2949, Loss: 0.8821\n",
      "Epoch: 1, Step: 085/2949, Loss: 0.8940\n",
      "Epoch: 1, Step: 086/2949, Loss: 0.8552\n",
      "Epoch: 1, Step: 087/2949, Loss: 0.8788\n",
      "Epoch: 1, Step: 088/2949, Loss: 0.9266\n",
      "Epoch: 1, Step: 089/2949, Loss: 0.8998\n",
      "Epoch: 1, Step: 090/2949, Loss: 0.8822\n",
      "Epoch: 1, Step: 091/2949, Loss: 0.8448\n",
      "Epoch: 1, Step: 092/2949, Loss: 0.9075\n",
      "Epoch: 1, Step: 093/2949, Loss: 0.9052\n",
      "Epoch: 1, Step: 094/2949, Loss: 0.9286\n",
      "Epoch: 1, Step: 095/2949, Loss: 0.9189\n",
      "Epoch: 1, Step: 096/2949, Loss: 0.8925\n",
      "Epoch: 1, Step: 097/2949, Loss: 0.8889\n",
      "Epoch: 1, Step: 098/2949, Loss: 0.8797\n",
      "Epoch: 1, Step: 099/2949, Loss: 0.8609\n",
      "Epoch: 1, Step: 100/2949, Loss: 0.9089\n",
      "Epoch: 1, Step: 101/2949, Loss: 0.8938\n",
      "Epoch: 1, Step: 102/2949, Loss: 0.8997\n",
      "Epoch: 1, Step: 103/2949, Loss: 0.8859\n",
      "Epoch: 1, Step: 104/2949, Loss: 0.8765\n",
      "Epoch: 1, Step: 105/2949, Loss: 0.8683\n",
      "Epoch: 1, Step: 106/2949, Loss: 0.8721\n",
      "Epoch: 1, Step: 107/2949, Loss: 0.8649\n",
      "Epoch: 1, Step: 108/2949, Loss: 0.8672\n",
      "Epoch: 1, Step: 109/2949, Loss: 0.9196\n",
      "Epoch: 1, Step: 110/2949, Loss: 0.8412\n",
      "Epoch: 1, Step: 111/2949, Loss: 0.9345\n",
      "Epoch: 1, Step: 112/2949, Loss: 0.9516\n",
      "Epoch: 1, Step: 113/2949, Loss: 0.8758\n",
      "Epoch: 1, Step: 114/2949, Loss: 0.8881\n",
      "Epoch: 1, Step: 115/2949, Loss: 0.9015\n",
      "Epoch: 1, Step: 116/2949, Loss: 0.8580\n",
      "Epoch: 1, Step: 117/2949, Loss: 0.8725\n",
      "Epoch: 1, Step: 118/2949, Loss: 0.8599\n",
      "Epoch: 1, Step: 119/2949, Loss: 0.8739\n",
      "Epoch: 1, Step: 120/2949, Loss: 0.8888\n",
      "Epoch: 1, Step: 121/2949, Loss: 0.8462\n",
      "Epoch: 1, Step: 122/2949, Loss: 0.8859\n",
      "Epoch: 1, Step: 123/2949, Loss: 0.8495\n",
      "Epoch: 1, Step: 124/2949, Loss: 0.8811\n",
      "Epoch: 1, Step: 125/2949, Loss: 0.9143\n",
      "Epoch: 1, Step: 126/2949, Loss: 0.9190\n",
      "Epoch: 1, Step: 127/2949, Loss: 0.8889\n",
      "Epoch: 1, Step: 128/2949, Loss: 0.8912\n",
      "Epoch: 1, Step: 129/2949, Loss: 0.8689\n",
      "Epoch: 1, Step: 130/2949, Loss: 0.8595\n",
      "Epoch: 1, Step: 131/2949, Loss: 0.8578\n",
      "Epoch: 1, Step: 132/2949, Loss: 0.8122\n",
      "Epoch: 1, Step: 133/2949, Loss: 0.8841\n",
      "Epoch: 1, Step: 134/2949, Loss: 0.8650\n",
      "Epoch: 1, Step: 135/2949, Loss: 0.8873\n",
      "Epoch: 1, Step: 136/2949, Loss: 0.9215\n",
      "Epoch: 1, Step: 137/2949, Loss: 0.8850\n",
      "Epoch: 1, Step: 138/2949, Loss: 0.8401\n",
      "Epoch: 1, Step: 139/2949, Loss: 0.9228\n",
      "Epoch: 1, Step: 140/2949, Loss: 0.8561\n",
      "Epoch: 1, Step: 141/2949, Loss: 0.8764\n",
      "Epoch: 1, Step: 142/2949, Loss: 0.8648\n",
      "Epoch: 1, Step: 143/2949, Loss: 0.8981\n",
      "Epoch: 1, Step: 144/2949, Loss: 0.8665\n",
      "Epoch: 1, Step: 145/2949, Loss: 0.9179\n",
      "Epoch: 1, Step: 146/2949, Loss: 0.9046\n",
      "Epoch: 1, Step: 147/2949, Loss: 0.8966\n",
      "Epoch: 1, Step: 148/2949, Loss: 0.8771\n",
      "Epoch: 1, Step: 149/2949, Loss: 0.8809\n",
      "Epoch: 1, Step: 150/2949, Loss: 0.8985\n",
      "Epoch: 1, Step: 151/2949, Loss: 0.9014\n",
      "Epoch: 1, Step: 152/2949, Loss: 0.8059\n",
      "Epoch: 1, Step: 153/2949, Loss: 0.8574\n",
      "Epoch: 1, Step: 154/2949, Loss: 0.8558\n",
      "Epoch: 1, Step: 155/2949, Loss: 0.8629\n",
      "Epoch: 1, Step: 156/2949, Loss: 0.8938\n",
      "Epoch: 1, Step: 157/2949, Loss: 0.8813\n",
      "Epoch: 1, Step: 158/2949, Loss: 0.8679\n",
      "Epoch: 1, Step: 159/2949, Loss: 0.9042\n",
      "Epoch: 1, Step: 160/2949, Loss: 0.8773\n",
      "Epoch: 1, Step: 161/2949, Loss: 0.8643\n",
      "Epoch: 1, Step: 162/2949, Loss: 0.8728\n",
      "Epoch: 1, Step: 163/2949, Loss: 0.8715\n",
      "Epoch: 1, Step: 164/2949, Loss: 0.8806\n",
      "Epoch: 1, Step: 165/2949, Loss: 0.8385\n",
      "Epoch: 1, Step: 166/2949, Loss: 0.8831\n",
      "Epoch: 1, Step: 167/2949, Loss: 0.8922\n",
      "Epoch: 1, Step: 168/2949, Loss: 0.8886\n",
      "Epoch: 1, Step: 169/2949, Loss: 0.8888\n",
      "Epoch: 1, Step: 170/2949, Loss: 0.8879\n",
      "Epoch: 1, Step: 171/2949, Loss: 0.8980\n",
      "Epoch: 1, Step: 172/2949, Loss: 0.8704\n",
      "Epoch: 1, Step: 173/2949, Loss: 0.8806\n",
      "Epoch: 1, Step: 174/2949, Loss: 0.9101\n",
      "Epoch: 1, Step: 175/2949, Loss: 0.8715\n",
      "Epoch: 1, Step: 176/2949, Loss: 0.8751\n",
      "Epoch: 1, Step: 177/2949, Loss: 0.8939\n",
      "Epoch: 1, Step: 178/2949, Loss: 0.9296\n",
      "Epoch: 1, Step: 179/2949, Loss: 0.8687\n",
      "Epoch: 1, Step: 180/2949, Loss: 0.8294\n",
      "Epoch: 1, Step: 181/2949, Loss: 0.8755\n",
      "Epoch: 1, Step: 182/2949, Loss: 0.8655\n",
      "Epoch: 1, Step: 183/2949, Loss: 0.9157\n",
      "Epoch: 1, Step: 184/2949, Loss: 0.8632\n",
      "Epoch: 1, Step: 185/2949, Loss: 0.9089\n",
      "Epoch: 1, Step: 186/2949, Loss: 0.9380\n",
      "Epoch: 1, Step: 187/2949, Loss: 0.8922\n",
      "Epoch: 1, Step: 188/2949, Loss: 0.8470\n",
      "Epoch: 1, Step: 189/2949, Loss: 0.8678\n",
      "Epoch: 1, Step: 190/2949, Loss: 0.8769\n",
      "Epoch: 1, Step: 191/2949, Loss: 0.8448\n",
      "Epoch: 1, Step: 192/2949, Loss: 0.8792\n",
      "Epoch: 1, Step: 193/2949, Loss: 0.9069\n",
      "Epoch: 1, Step: 194/2949, Loss: 0.8963\n",
      "Epoch: 1, Step: 195/2949, Loss: 0.8634\n",
      "Epoch: 1, Step: 196/2949, Loss: 0.8474\n",
      "Epoch: 1, Step: 197/2949, Loss: 0.9083\n",
      "Epoch: 1, Step: 198/2949, Loss: 0.8971\n",
      "Epoch: 1, Step: 199/2949, Loss: 0.9201\n",
      "Epoch: 1, Step: 200/2949, Loss: 0.8655\n",
      "Epoch: 1, Step: 201/2949, Loss: 0.8972\n",
      "Epoch: 1, Step: 202/2949, Loss: 0.8674\n",
      "Epoch: 1, Step: 203/2949, Loss: 0.8781\n",
      "Epoch: 1, Step: 204/2949, Loss: 0.9170\n",
      "Epoch: 1, Step: 205/2949, Loss: 0.8614\n",
      "Epoch: 1, Step: 206/2949, Loss: 0.9146\n",
      "Epoch: 1, Step: 207/2949, Loss: 0.8886\n",
      "Epoch: 1, Step: 208/2949, Loss: 0.8354\n",
      "Epoch: 1, Step: 209/2949, Loss: 0.8662\n",
      "Epoch: 1, Step: 210/2949, Loss: 0.8986\n",
      "Epoch: 1, Step: 211/2949, Loss: 0.8663\n",
      "Epoch: 1, Step: 212/2949, Loss: 0.8779\n",
      "Epoch: 1, Step: 213/2949, Loss: 0.8595\n",
      "Epoch: 1, Step: 214/2949, Loss: 0.8545\n",
      "Epoch: 1, Step: 215/2949, Loss: 0.8738\n",
      "Epoch: 1, Step: 216/2949, Loss: 0.8665\n",
      "Epoch: 1, Step: 217/2949, Loss: 0.8538\n",
      "Epoch: 1, Step: 218/2949, Loss: 0.8549\n",
      "Epoch: 1, Step: 219/2949, Loss: 0.8832\n",
      "Epoch: 1, Step: 220/2949, Loss: 0.8686\n",
      "Epoch: 1, Step: 221/2949, Loss: 0.8690\n",
      "Epoch: 1, Step: 222/2949, Loss: 0.9099\n",
      "Epoch: 1, Step: 223/2949, Loss: 0.8062\n",
      "Epoch: 1, Step: 224/2949, Loss: 0.8878\n",
      "Epoch: 1, Step: 225/2949, Loss: 0.9092\n",
      "Epoch: 1, Step: 226/2949, Loss: 0.8425\n",
      "Epoch: 1, Step: 227/2949, Loss: 0.8547\n",
      "Epoch: 1, Step: 228/2949, Loss: 0.9525\n",
      "Epoch: 1, Step: 229/2949, Loss: 0.8796\n",
      "Epoch: 1, Step: 230/2949, Loss: 0.8444\n",
      "Epoch: 1, Step: 231/2949, Loss: 0.8509\n",
      "Epoch: 1, Step: 232/2949, Loss: 0.8877\n",
      "Epoch: 1, Step: 233/2949, Loss: 0.8746\n",
      "Epoch: 1, Step: 234/2949, Loss: 0.8455\n",
      "Epoch: 1, Step: 235/2949, Loss: 0.8516\n",
      "Epoch: 1, Step: 236/2949, Loss: 0.8178\n",
      "Epoch: 1, Step: 237/2949, Loss: 0.8842\n",
      "Epoch: 1, Step: 238/2949, Loss: 0.8761\n",
      "Epoch: 1, Step: 239/2949, Loss: 0.8870\n",
      "Epoch: 1, Step: 240/2949, Loss: 0.8499\n",
      "Epoch: 1, Step: 241/2949, Loss: 0.8378\n",
      "Epoch: 1, Step: 242/2949, Loss: 0.8756\n",
      "Epoch: 1, Step: 243/2949, Loss: 0.8469\n",
      "Epoch: 1, Step: 244/2949, Loss: 0.9165\n",
      "Epoch: 1, Step: 245/2949, Loss: 0.8824\n",
      "Epoch: 1, Step: 246/2949, Loss: 0.8929\n",
      "Epoch: 1, Step: 247/2949, Loss: 0.8689\n",
      "Epoch: 1, Step: 248/2949, Loss: 0.8693\n",
      "Epoch: 1, Step: 249/2949, Loss: 0.8520\n",
      "Epoch: 1, Step: 250/2949, Loss: 0.9464\n",
      "Epoch: 1, Step: 251/2949, Loss: 0.9001\n",
      "Epoch: 1, Step: 252/2949, Loss: 0.9285\n",
      "Epoch: 1, Step: 253/2949, Loss: 0.8566\n",
      "Epoch: 1, Step: 254/2949, Loss: 0.8740\n",
      "Epoch: 1, Step: 255/2949, Loss: 0.8762\n",
      "Epoch: 1, Step: 256/2949, Loss: 0.9144\n",
      "Epoch: 1, Step: 257/2949, Loss: 0.8992\n",
      "Epoch: 1, Step: 258/2949, Loss: 0.9167\n",
      "Epoch: 1, Step: 259/2949, Loss: 0.8829\n",
      "Epoch: 1, Step: 260/2949, Loss: 0.8578\n",
      "Epoch: 1, Step: 261/2949, Loss: 0.8911\n",
      "Epoch: 1, Step: 262/2949, Loss: 0.8669\n",
      "Epoch: 1, Step: 263/2949, Loss: 0.8369\n",
      "Epoch: 1, Step: 264/2949, Loss: 0.8905\n",
      "Epoch: 1, Step: 265/2949, Loss: 0.8556\n",
      "Epoch: 1, Step: 266/2949, Loss: 0.9345\n",
      "Epoch: 1, Step: 267/2949, Loss: 0.8358\n",
      "Epoch: 1, Step: 268/2949, Loss: 0.8681\n",
      "Epoch: 1, Step: 269/2949, Loss: 0.9002\n",
      "Epoch: 1, Step: 270/2949, Loss: 0.9229\n",
      "Epoch: 1, Step: 271/2949, Loss: 0.8491\n",
      "Epoch: 1, Step: 272/2949, Loss: 0.9075\n",
      "Epoch: 1, Step: 273/2949, Loss: 0.8607\n",
      "Epoch: 1, Step: 274/2949, Loss: 0.8706\n",
      "Epoch: 1, Step: 275/2949, Loss: 0.9069\n",
      "Epoch: 1, Step: 276/2949, Loss: 0.8928\n",
      "Epoch: 1, Step: 277/2949, Loss: 0.8141\n",
      "Epoch: 1, Step: 278/2949, Loss: 0.8542\n",
      "Epoch: 1, Step: 279/2949, Loss: 0.9244\n",
      "Epoch: 1, Step: 280/2949, Loss: 0.8825\n",
      "Epoch: 1, Step: 281/2949, Loss: 0.8900\n",
      "Epoch: 1, Step: 282/2949, Loss: 0.8725\n",
      "Epoch: 1, Step: 283/2949, Loss: 0.8746\n",
      "Epoch: 1, Step: 284/2949, Loss: 0.8487\n",
      "Epoch: 1, Step: 285/2949, Loss: 0.9345\n",
      "Epoch: 1, Step: 286/2949, Loss: 0.8947\n",
      "Epoch: 1, Step: 287/2949, Loss: 0.8813\n",
      "Epoch: 1, Step: 288/2949, Loss: 0.8348\n",
      "Epoch: 1, Step: 289/2949, Loss: 0.8107\n",
      "Epoch: 1, Step: 290/2949, Loss: 0.8994\n",
      "Epoch: 1, Step: 291/2949, Loss: 0.8553\n",
      "Epoch: 1, Step: 292/2949, Loss: 0.8791\n",
      "Epoch: 1, Step: 293/2949, Loss: 0.9013\n",
      "Epoch: 1, Step: 294/2949, Loss: 0.8869\n",
      "Epoch: 1, Step: 295/2949, Loss: 0.8372\n",
      "Epoch: 1, Step: 296/2949, Loss: 0.9118\n",
      "Epoch: 1, Step: 297/2949, Loss: 0.8186\n",
      "Epoch: 1, Step: 298/2949, Loss: 0.8482\n",
      "Epoch: 1, Step: 299/2949, Loss: 0.9216\n",
      "Epoch: 1, Step: 300/2949, Loss: 0.8937\n",
      "Epoch: 1, Step: 301/2949, Loss: 0.8875\n",
      "Epoch: 1, Step: 302/2949, Loss: 0.9093\n",
      "Epoch: 1, Step: 303/2949, Loss: 0.8339\n",
      "Epoch: 1, Step: 304/2949, Loss: 0.8601\n",
      "Epoch: 1, Step: 305/2949, Loss: 0.9008\n",
      "Epoch: 1, Step: 306/2949, Loss: 0.8790\n",
      "Epoch: 1, Step: 307/2949, Loss: 0.8946\n",
      "Epoch: 1, Step: 308/2949, Loss: 0.8997\n",
      "Epoch: 1, Step: 309/2949, Loss: 0.9369\n",
      "Epoch: 1, Step: 310/2949, Loss: 0.9060\n",
      "Epoch: 1, Step: 311/2949, Loss: 0.8414\n",
      "Epoch: 1, Step: 312/2949, Loss: 0.9299\n",
      "Epoch: 1, Step: 313/2949, Loss: 0.8382\n",
      "Epoch: 1, Step: 314/2949, Loss: 0.9256\n",
      "Epoch: 1, Step: 315/2949, Loss: 0.8747\n",
      "Epoch: 1, Step: 316/2949, Loss: 0.9077\n",
      "Epoch: 1, Step: 317/2949, Loss: 0.8313\n",
      "Epoch: 1, Step: 318/2949, Loss: 0.8486\n",
      "Epoch: 1, Step: 319/2949, Loss: 0.8900\n",
      "Epoch: 1, Step: 320/2949, Loss: 0.8944\n",
      "Epoch: 1, Step: 321/2949, Loss: 0.8645\n",
      "Epoch: 1, Step: 322/2949, Loss: 0.8293\n",
      "Epoch: 1, Step: 323/2949, Loss: 0.8646\n",
      "Epoch: 1, Step: 324/2949, Loss: 0.8670\n",
      "Epoch: 1, Step: 325/2949, Loss: 0.8823\n",
      "Epoch: 1, Step: 326/2949, Loss: 0.8373\n",
      "Epoch: 1, Step: 327/2949, Loss: 0.8941\n",
      "Epoch: 1, Step: 328/2949, Loss: 0.9309\n",
      "Epoch: 1, Step: 329/2949, Loss: 0.8443\n",
      "Epoch: 1, Step: 330/2949, Loss: 0.8395\n",
      "Epoch: 1, Step: 331/2949, Loss: 0.9024\n",
      "Epoch: 1, Step: 332/2949, Loss: 0.8478\n",
      "Epoch: 1, Step: 333/2949, Loss: 0.8910\n",
      "Epoch: 1, Step: 334/2949, Loss: 0.8865\n",
      "Epoch: 1, Step: 335/2949, Loss: 0.9064\n",
      "Epoch: 1, Step: 336/2949, Loss: 0.8886\n",
      "Epoch: 1, Step: 337/2949, Loss: 0.9225\n",
      "Epoch: 1, Step: 338/2949, Loss: 0.8816\n",
      "Epoch: 1, Step: 339/2949, Loss: 0.9060\n",
      "Epoch: 1, Step: 340/2949, Loss: 0.8557\n",
      "Epoch: 1, Step: 341/2949, Loss: 0.8837\n",
      "Epoch: 1, Step: 342/2949, Loss: 0.8431\n",
      "Epoch: 1, Step: 343/2949, Loss: 0.9326\n",
      "Epoch: 1, Step: 344/2949, Loss: 0.8424\n",
      "Epoch: 1, Step: 345/2949, Loss: 0.8993\n",
      "Epoch: 1, Step: 346/2949, Loss: 0.8806\n",
      "Epoch: 1, Step: 347/2949, Loss: 0.8360\n",
      "Epoch: 1, Step: 348/2949, Loss: 0.8422\n",
      "Epoch: 1, Step: 349/2949, Loss: 0.8794\n",
      "Epoch: 1, Step: 350/2949, Loss: 0.8786\n",
      "Epoch: 1, Step: 351/2949, Loss: 0.8438\n",
      "Epoch: 1, Step: 352/2949, Loss: 0.9277\n",
      "Epoch: 1, Step: 353/2949, Loss: 0.8724\n",
      "Epoch: 1, Step: 354/2949, Loss: 0.8929\n",
      "Epoch: 1, Step: 355/2949, Loss: 0.8780\n",
      "Epoch: 1, Step: 356/2949, Loss: 0.8715\n",
      "Epoch: 1, Step: 357/2949, Loss: 0.8280\n",
      "Epoch: 1, Step: 358/2949, Loss: 0.8862\n",
      "Epoch: 1, Step: 359/2949, Loss: 0.9046\n",
      "Epoch: 1, Step: 360/2949, Loss: 0.8502\n",
      "Epoch: 1, Step: 361/2949, Loss: 0.8646\n",
      "Epoch: 1, Step: 362/2949, Loss: 0.8973\n",
      "Epoch: 1, Step: 363/2949, Loss: 0.8842\n",
      "Epoch: 1, Step: 364/2949, Loss: 0.8678\n",
      "Epoch: 1, Step: 365/2949, Loss: 0.8941\n",
      "Epoch: 1, Step: 366/2949, Loss: 0.8609\n",
      "Epoch: 1, Step: 367/2949, Loss: 0.8758\n",
      "Epoch: 1, Step: 368/2949, Loss: 0.8488\n",
      "Epoch: 1, Step: 369/2949, Loss: 0.8920\n",
      "Epoch: 1, Step: 370/2949, Loss: 0.8359\n",
      "Epoch: 1, Step: 371/2949, Loss: 0.8841\n",
      "Epoch: 1, Step: 372/2949, Loss: 0.9056\n",
      "Epoch: 1, Step: 373/2949, Loss: 0.8332\n",
      "Epoch: 1, Step: 374/2949, Loss: 0.9023\n",
      "Epoch: 1, Step: 375/2949, Loss: 0.8822\n",
      "Epoch: 1, Step: 376/2949, Loss: 0.8354\n",
      "Epoch: 1, Step: 377/2949, Loss: 0.9260\n",
      "Epoch: 1, Step: 378/2949, Loss: 0.8557\n",
      "Epoch: 1, Step: 379/2949, Loss: 0.9015\n",
      "Epoch: 1, Step: 380/2949, Loss: 0.8642\n",
      "Epoch: 1, Step: 381/2949, Loss: 0.8628\n",
      "Epoch: 1, Step: 382/2949, Loss: 0.8786\n",
      "Epoch: 1, Step: 383/2949, Loss: 0.8556\n",
      "Epoch: 1, Step: 384/2949, Loss: 0.8130\n",
      "Epoch: 1, Step: 385/2949, Loss: 0.9262\n",
      "Epoch: 1, Step: 386/2949, Loss: 0.8857\n",
      "Epoch: 1, Step: 387/2949, Loss: 0.8887\n",
      "Epoch: 1, Step: 388/2949, Loss: 0.7994\n",
      "Epoch: 1, Step: 389/2949, Loss: 0.8882\n",
      "Epoch: 1, Step: 390/2949, Loss: 0.8571\n",
      "Epoch: 1, Step: 391/2949, Loss: 0.9162\n",
      "Epoch: 1, Step: 392/2949, Loss: 0.8138\n",
      "Epoch: 1, Step: 393/2949, Loss: 0.9320\n",
      "Epoch: 1, Step: 394/2949, Loss: 0.8619\n",
      "Epoch: 1, Step: 395/2949, Loss: 0.8667\n",
      "Epoch: 1, Step: 396/2949, Loss: 0.7945\n",
      "Epoch: 1, Step: 397/2949, Loss: 0.9525\n",
      "Epoch: 1, Step: 398/2949, Loss: 0.8036\n",
      "Epoch: 1, Step: 399/2949, Loss: 0.8513\n",
      "Epoch: 1, Step: 400/2949, Loss: 0.8891\n",
      "Epoch: 1, Step: 401/2949, Loss: 0.8485\n",
      "Epoch: 1, Step: 402/2949, Loss: 0.9125\n",
      "Epoch: 1, Step: 403/2949, Loss: 0.8405\n",
      "Epoch: 1, Step: 404/2949, Loss: 0.8398\n",
      "Epoch: 1, Step: 405/2949, Loss: 0.9587\n",
      "Epoch: 1, Step: 406/2949, Loss: 0.8522\n",
      "Epoch: 1, Step: 407/2949, Loss: 0.9017\n",
      "Epoch: 1, Step: 408/2949, Loss: 0.8755\n",
      "Epoch: 1, Step: 409/2949, Loss: 0.8620\n",
      "Epoch: 1, Step: 410/2949, Loss: 0.8762\n",
      "Epoch: 1, Step: 411/2949, Loss: 0.9189\n",
      "Epoch: 1, Step: 412/2949, Loss: 0.9142\n",
      "Epoch: 1, Step: 413/2949, Loss: 0.8563\n",
      "Epoch: 1, Step: 414/2949, Loss: 0.8745\n",
      "Epoch: 1, Step: 415/2949, Loss: 0.8424\n",
      "Epoch: 1, Step: 416/2949, Loss: 0.8915\n",
      "Epoch: 1, Step: 417/2949, Loss: 0.8915\n",
      "Epoch: 1, Step: 418/2949, Loss: 0.8796\n",
      "Epoch: 1, Step: 419/2949, Loss: 0.8627\n",
      "Epoch: 1, Step: 420/2949, Loss: 0.9177\n",
      "Epoch: 1, Step: 421/2949, Loss: 0.8333\n",
      "Epoch: 1, Step: 422/2949, Loss: 0.8510\n",
      "Epoch: 1, Step: 423/2949, Loss: 0.8595\n",
      "Epoch: 1, Step: 424/2949, Loss: 0.8867\n",
      "Epoch: 1, Step: 425/2949, Loss: 0.8650\n",
      "Epoch: 1, Step: 426/2949, Loss: 0.9160\n",
      "Epoch: 1, Step: 427/2949, Loss: 0.8841\n",
      "Epoch: 1, Step: 428/2949, Loss: 0.8811\n",
      "Epoch: 1, Step: 429/2949, Loss: 0.8211\n",
      "Epoch: 1, Step: 430/2949, Loss: 0.7654\n",
      "Epoch: 1, Step: 431/2949, Loss: 0.8681\n",
      "Epoch: 1, Step: 432/2949, Loss: 0.8995\n",
      "Epoch: 1, Step: 433/2949, Loss: 0.8118\n",
      "Epoch: 1, Step: 434/2949, Loss: 0.8638\n",
      "Epoch: 1, Step: 435/2949, Loss: 0.8915\n",
      "Epoch: 1, Step: 436/2949, Loss: 0.8412\n",
      "Epoch: 1, Step: 437/2949, Loss: 0.8372\n",
      "Epoch: 1, Step: 438/2949, Loss: 0.8595\n",
      "Epoch: 1, Step: 439/2949, Loss: 0.8706\n",
      "Epoch: 1, Step: 440/2949, Loss: 0.8805\n",
      "Epoch: 1, Step: 441/2949, Loss: 0.8391\n",
      "Epoch: 1, Step: 442/2949, Loss: 0.8608\n",
      "Epoch: 1, Step: 443/2949, Loss: 0.8993\n",
      "Epoch: 1, Step: 444/2949, Loss: 0.9357\n",
      "Epoch: 1, Step: 445/2949, Loss: 0.8214\n",
      "Epoch: 1, Step: 446/2949, Loss: 0.8959\n",
      "Epoch: 1, Step: 447/2949, Loss: 0.8346\n",
      "Epoch: 1, Step: 448/2949, Loss: 0.8954\n",
      "Epoch: 1, Step: 449/2949, Loss: 0.8424\n",
      "Epoch: 1, Step: 450/2949, Loss: 0.8169\n",
      "Epoch: 1, Step: 451/2949, Loss: 0.8721\n",
      "Epoch: 1, Step: 452/2949, Loss: 0.8767\n",
      "Epoch: 1, Step: 453/2949, Loss: 0.8832\n",
      "Epoch: 1, Step: 454/2949, Loss: 0.8789\n",
      "Epoch: 1, Step: 455/2949, Loss: 0.8850\n",
      "Epoch: 1, Step: 456/2949, Loss: 0.9002\n",
      "Epoch: 1, Step: 457/2949, Loss: 0.8571\n",
      "Epoch: 1, Step: 458/2949, Loss: 0.8400\n",
      "Epoch: 1, Step: 459/2949, Loss: 0.8379\n",
      "Epoch: 1, Step: 460/2949, Loss: 0.8463\n",
      "Epoch: 1, Step: 461/2949, Loss: 0.8229\n",
      "Epoch: 1, Step: 462/2949, Loss: 0.8437\n",
      "Epoch: 1, Step: 463/2949, Loss: 0.8806\n",
      "Epoch: 1, Step: 464/2949, Loss: 0.9054\n",
      "Epoch: 1, Step: 465/2949, Loss: 0.8890\n",
      "Epoch: 1, Step: 466/2949, Loss: 0.9632\n",
      "Epoch: 1, Step: 467/2949, Loss: 0.8950\n",
      "Epoch: 1, Step: 468/2949, Loss: 0.9220\n",
      "Epoch: 1, Step: 469/2949, Loss: 0.9120\n",
      "Epoch: 1, Step: 470/2949, Loss: 0.8721\n",
      "Epoch: 1, Step: 471/2949, Loss: 0.9069\n",
      "Epoch: 1, Step: 472/2949, Loss: 0.8676\n",
      "Epoch: 1, Step: 473/2949, Loss: 0.9322\n",
      "Epoch: 1, Step: 474/2949, Loss: 0.8311\n",
      "Epoch: 1, Step: 475/2949, Loss: 0.8895\n",
      "Epoch: 1, Step: 476/2949, Loss: 0.9442\n",
      "Epoch: 1, Step: 477/2949, Loss: 0.8577\n",
      "Epoch: 1, Step: 478/2949, Loss: 0.8276\n",
      "Epoch: 1, Step: 479/2949, Loss: 0.9000\n",
      "Epoch: 1, Step: 480/2949, Loss: 0.8279\n",
      "Epoch: 1, Step: 481/2949, Loss: 0.8421\n",
      "Epoch: 1, Step: 482/2949, Loss: 0.8941\n",
      "Epoch: 1, Step: 483/2949, Loss: 0.9189\n",
      "Epoch: 1, Step: 484/2949, Loss: 0.8860\n",
      "Epoch: 1, Step: 485/2949, Loss: 0.9268\n",
      "Epoch: 1, Step: 486/2949, Loss: 0.8725\n",
      "Epoch: 1, Step: 487/2949, Loss: 0.8763\n",
      "Epoch: 1, Step: 488/2949, Loss: 0.8474\n",
      "Epoch: 1, Step: 489/2949, Loss: 0.8738\n",
      "Epoch: 1, Step: 490/2949, Loss: 0.8724\n",
      "Epoch: 1, Step: 491/2949, Loss: 0.8826\n",
      "Epoch: 1, Step: 492/2949, Loss: 0.8824\n",
      "Epoch: 1, Step: 493/2949, Loss: 0.8898\n",
      "Epoch: 1, Step: 494/2949, Loss: 0.9285\n",
      "Epoch: 1, Step: 495/2949, Loss: 0.8834\n",
      "Epoch: 1, Step: 496/2949, Loss: 0.8361\n",
      "Epoch: 1, Step: 497/2949, Loss: 0.8441\n",
      "Epoch: 1, Step: 498/2949, Loss: 0.8390\n",
      "Epoch: 1, Step: 499/2949, Loss: 0.8821\n",
      "Epoch: 1, Step: 500/2949, Loss: 0.8767\n",
      "Epoch: 1, Step: 501/2949, Loss: 0.8628\n",
      "Epoch: 1, Step: 502/2949, Loss: 0.8399\n",
      "Epoch: 1, Step: 503/2949, Loss: 0.9129\n",
      "Epoch: 1, Step: 504/2949, Loss: 0.8462\n",
      "Epoch: 1, Step: 505/2949, Loss: 0.8705\n",
      "Epoch: 1, Step: 506/2949, Loss: 0.8593\n",
      "Epoch: 1, Step: 507/2949, Loss: 0.8696\n",
      "Epoch: 1, Step: 508/2949, Loss: 0.8392\n",
      "Epoch: 1, Step: 509/2949, Loss: 0.8385\n",
      "Epoch: 1, Step: 510/2949, Loss: 0.8644\n",
      "Epoch: 1, Step: 511/2949, Loss: 0.8799\n",
      "Epoch: 1, Step: 512/2949, Loss: 0.8991\n",
      "Epoch: 1, Step: 513/2949, Loss: 0.8160\n",
      "Epoch: 1, Step: 514/2949, Loss: 0.8575\n",
      "Epoch: 1, Step: 515/2949, Loss: 0.8613\n",
      "Epoch: 1, Step: 516/2949, Loss: 0.8630\n",
      "Epoch: 1, Step: 517/2949, Loss: 0.8925\n",
      "Epoch: 1, Step: 518/2949, Loss: 0.8630\n",
      "Epoch: 1, Step: 519/2949, Loss: 0.8532\n",
      "Epoch: 1, Step: 520/2949, Loss: 0.8378\n",
      "Epoch: 1, Step: 521/2949, Loss: 0.8696\n",
      "Epoch: 1, Step: 522/2949, Loss: 0.8592\n",
      "Epoch: 1, Step: 523/2949, Loss: 0.8328\n",
      "Epoch: 1, Step: 524/2949, Loss: 0.9291\n",
      "Epoch: 1, Step: 525/2949, Loss: 0.8921\n",
      "Epoch: 1, Step: 526/2949, Loss: 0.8792\n",
      "Epoch: 1, Step: 527/2949, Loss: 0.8671\n",
      "Epoch: 1, Step: 528/2949, Loss: 0.8498\n",
      "Epoch: 1, Step: 529/2949, Loss: 0.8754\n",
      "Epoch: 1, Step: 530/2949, Loss: 0.8544\n",
      "Epoch: 1, Step: 531/2949, Loss: 0.8939\n",
      "Epoch: 1, Step: 532/2949, Loss: 0.8639\n",
      "Epoch: 1, Step: 533/2949, Loss: 0.8277\n",
      "Epoch: 1, Step: 534/2949, Loss: 0.8597\n",
      "Epoch: 1, Step: 535/2949, Loss: 0.8625\n",
      "Epoch: 1, Step: 536/2949, Loss: 0.9297\n",
      "Epoch: 1, Step: 537/2949, Loss: 0.8479\n",
      "Epoch: 1, Step: 538/2949, Loss: 0.8887\n",
      "Epoch: 1, Step: 539/2949, Loss: 0.8514\n",
      "Epoch: 1, Step: 540/2949, Loss: 0.8562\n",
      "Epoch: 1, Step: 541/2949, Loss: 0.9069\n",
      "Epoch: 1, Step: 542/2949, Loss: 0.8667\n",
      "Epoch: 1, Step: 543/2949, Loss: 0.8725\n",
      "Epoch: 1, Step: 544/2949, Loss: 0.8311\n",
      "Epoch: 1, Step: 545/2949, Loss: 0.8461\n",
      "Epoch: 1, Step: 546/2949, Loss: 0.8394\n",
      "Epoch: 1, Step: 547/2949, Loss: 0.8684\n",
      "Epoch: 1, Step: 548/2949, Loss: 0.8467\n",
      "Epoch: 1, Step: 549/2949, Loss: 0.8342\n",
      "Epoch: 1, Step: 550/2949, Loss: 0.8933\n",
      "Epoch: 1, Step: 551/2949, Loss: 0.8754\n",
      "Epoch: 1, Step: 552/2949, Loss: 0.8804\n",
      "Epoch: 1, Step: 553/2949, Loss: 0.8388\n",
      "Epoch: 1, Step: 554/2949, Loss: 0.8454\n",
      "Epoch: 1, Step: 555/2949, Loss: 0.8222\n",
      "Epoch: 1, Step: 556/2949, Loss: 0.8734\n",
      "Epoch: 1, Step: 557/2949, Loss: 0.8906\n",
      "Epoch: 1, Step: 558/2949, Loss: 0.8130\n",
      "Epoch: 1, Step: 559/2949, Loss: 0.8824\n",
      "Epoch: 1, Step: 560/2949, Loss: 0.9187\n",
      "Epoch: 1, Step: 561/2949, Loss: 0.8873\n",
      "Epoch: 1, Step: 562/2949, Loss: 0.8903\n",
      "Epoch: 1, Step: 563/2949, Loss: 0.8842\n",
      "Epoch: 1, Step: 564/2949, Loss: 0.8455\n",
      "Epoch: 1, Step: 565/2949, Loss: 0.8721\n",
      "Epoch: 1, Step: 566/2949, Loss: 0.8981\n",
      "Epoch: 1, Step: 567/2949, Loss: 0.9000\n",
      "Epoch: 1, Step: 568/2949, Loss: 0.8707\n",
      "Epoch: 1, Step: 569/2949, Loss: 0.8421\n",
      "Epoch: 1, Step: 570/2949, Loss: 0.8628\n",
      "Epoch: 1, Step: 571/2949, Loss: 0.8920\n",
      "Epoch: 1, Step: 572/2949, Loss: 0.9192\n",
      "Epoch: 1, Step: 573/2949, Loss: 0.8893\n",
      "Epoch: 1, Step: 574/2949, Loss: 0.8308\n",
      "Epoch: 1, Step: 575/2949, Loss: 0.8909\n",
      "Epoch: 1, Step: 576/2949, Loss: 0.9113\n",
      "Epoch: 1, Step: 577/2949, Loss: 0.8792\n",
      "Epoch: 1, Step: 578/2949, Loss: 0.8299\n",
      "Epoch: 1, Step: 579/2949, Loss: 0.9060\n",
      "Epoch: 1, Step: 580/2949, Loss: 0.8740\n",
      "Epoch: 1, Step: 581/2949, Loss: 0.8866\n",
      "Epoch: 1, Step: 582/2949, Loss: 0.8960\n",
      "Epoch: 1, Step: 583/2949, Loss: 0.8640\n",
      "Epoch: 1, Step: 584/2949, Loss: 0.9020\n",
      "Epoch: 1, Step: 585/2949, Loss: 0.8799\n",
      "Epoch: 1, Step: 586/2949, Loss: 0.8679\n",
      "Epoch: 1, Step: 587/2949, Loss: 0.8464\n",
      "Epoch: 1, Step: 588/2949, Loss: 0.9102\n",
      "Epoch: 1, Step: 589/2949, Loss: 0.8512\n",
      "Epoch: 1, Step: 590/2949, Loss: 0.8261\n",
      "Epoch: 1, Step: 591/2949, Loss: 0.8509\n",
      "Epoch: 1, Step: 592/2949, Loss: 0.9075\n",
      "Epoch: 1, Step: 593/2949, Loss: 0.8779\n",
      "Epoch: 1, Step: 594/2949, Loss: 0.8576\n",
      "Epoch: 1, Step: 595/2949, Loss: 0.8143\n",
      "Epoch: 1, Step: 596/2949, Loss: 0.9032\n",
      "Epoch: 1, Step: 597/2949, Loss: 0.8590\n",
      "Epoch: 1, Step: 598/2949, Loss: 0.8945\n",
      "Epoch: 1, Step: 599/2949, Loss: 0.8567\n",
      "Epoch: 1, Step: 600/2949, Loss: 0.9282\n",
      "Epoch: 1, Step: 601/2949, Loss: 0.8709\n",
      "Epoch: 1, Step: 602/2949, Loss: 0.8987\n",
      "Epoch: 1, Step: 603/2949, Loss: 0.8555\n",
      "Epoch: 1, Step: 604/2949, Loss: 0.8349\n",
      "Epoch: 1, Step: 605/2949, Loss: 0.8076\n",
      "Epoch: 1, Step: 606/2949, Loss: 0.8434\n",
      "Epoch: 1, Step: 607/2949, Loss: 0.8678\n",
      "Epoch: 1, Step: 608/2949, Loss: 0.8170\n",
      "Epoch: 1, Step: 609/2949, Loss: 0.9092\n",
      "Epoch: 1, Step: 610/2949, Loss: 0.8279\n",
      "Epoch: 1, Step: 611/2949, Loss: 0.8799\n",
      "Epoch: 1, Step: 612/2949, Loss: 0.8543\n",
      "Epoch: 1, Step: 613/2949, Loss: 0.9134\n",
      "Epoch: 1, Step: 614/2949, Loss: 0.8811\n",
      "Epoch: 1, Step: 615/2949, Loss: 0.8898\n",
      "Epoch: 1, Step: 616/2949, Loss: 0.8914\n",
      "Epoch: 1, Step: 617/2949, Loss: 0.8767\n",
      "Epoch: 1, Step: 618/2949, Loss: 0.8792\n",
      "Epoch: 1, Step: 619/2949, Loss: 0.8757\n",
      "Epoch: 1, Step: 620/2949, Loss: 0.9008\n",
      "Epoch: 1, Step: 621/2949, Loss: 0.8252\n",
      "Epoch: 1, Step: 622/2949, Loss: 0.8234\n",
      "Epoch: 1, Step: 623/2949, Loss: 0.9294\n",
      "Epoch: 1, Step: 624/2949, Loss: 0.8699\n",
      "Epoch: 1, Step: 625/2949, Loss: 0.8108\n",
      "Epoch: 1, Step: 626/2949, Loss: 0.9032\n",
      "Epoch: 1, Step: 627/2949, Loss: 0.8615\n",
      "Epoch: 1, Step: 628/2949, Loss: 0.8758\n",
      "Epoch: 1, Step: 629/2949, Loss: 0.9098\n",
      "Epoch: 1, Step: 630/2949, Loss: 0.8904\n",
      "Epoch: 1, Step: 631/2949, Loss: 0.8902\n",
      "Epoch: 1, Step: 632/2949, Loss: 0.8687\n",
      "Epoch: 1, Step: 633/2949, Loss: 0.8458\n",
      "Epoch: 1, Step: 634/2949, Loss: 0.8253\n",
      "Epoch: 1, Step: 635/2949, Loss: 0.8507\n",
      "Epoch: 1, Step: 636/2949, Loss: 0.9224\n",
      "Epoch: 1, Step: 637/2949, Loss: 0.9263\n",
      "Epoch: 1, Step: 638/2949, Loss: 0.8892\n",
      "Epoch: 1, Step: 639/2949, Loss: 0.8799\n",
      "Epoch: 1, Step: 640/2949, Loss: 0.8979\n",
      "Epoch: 1, Step: 641/2949, Loss: 0.8727\n",
      "Epoch: 1, Step: 642/2949, Loss: 0.9063\n",
      "Epoch: 1, Step: 643/2949, Loss: 0.9226\n",
      "Epoch: 1, Step: 644/2949, Loss: 0.8269\n",
      "Epoch: 1, Step: 645/2949, Loss: 0.8425\n",
      "Epoch: 1, Step: 646/2949, Loss: 0.8635\n",
      "Epoch: 1, Step: 647/2949, Loss: 0.8351\n",
      "Epoch: 1, Step: 648/2949, Loss: 0.8173\n",
      "Epoch: 1, Step: 649/2949, Loss: 0.8900\n",
      "Epoch: 1, Step: 650/2949, Loss: 0.8241\n",
      "Epoch: 1, Step: 651/2949, Loss: 0.8570\n",
      "Epoch: 1, Step: 652/2949, Loss: 0.9048\n",
      "Epoch: 1, Step: 653/2949, Loss: 0.8850\n",
      "Epoch: 1, Step: 654/2949, Loss: 0.8702\n",
      "Epoch: 1, Step: 655/2949, Loss: 0.8213\n",
      "Epoch: 1, Step: 656/2949, Loss: 0.8481\n",
      "Epoch: 1, Step: 657/2949, Loss: 0.8509\n",
      "Epoch: 1, Step: 658/2949, Loss: 0.7938\n",
      "Epoch: 1, Step: 659/2949, Loss: 0.8790\n",
      "Epoch: 1, Step: 660/2949, Loss: 0.8285\n",
      "Epoch: 1, Step: 661/2949, Loss: 0.8760\n",
      "Epoch: 1, Step: 662/2949, Loss: 0.8525\n",
      "Epoch: 1, Step: 663/2949, Loss: 0.8648\n",
      "Epoch: 1, Step: 664/2949, Loss: 0.8494\n",
      "Epoch: 1, Step: 665/2949, Loss: 0.9012\n",
      "Epoch: 1, Step: 666/2949, Loss: 0.8368\n",
      "Epoch: 1, Step: 667/2949, Loss: 0.8609\n",
      "Epoch: 1, Step: 668/2949, Loss: 0.8687\n",
      "Epoch: 1, Step: 669/2949, Loss: 0.8831\n",
      "Epoch: 1, Step: 670/2949, Loss: 0.8926\n",
      "Epoch: 1, Step: 671/2949, Loss: 0.8760\n",
      "Epoch: 1, Step: 672/2949, Loss: 0.8147\n",
      "Epoch: 1, Step: 673/2949, Loss: 0.8399\n",
      "Epoch: 1, Step: 674/2949, Loss: 0.8749\n",
      "Epoch: 1, Step: 675/2949, Loss: 0.8379\n",
      "Epoch: 1, Step: 676/2949, Loss: 0.8925\n",
      "Epoch: 1, Step: 677/2949, Loss: 0.8900\n",
      "Epoch: 1, Step: 678/2949, Loss: 0.8485\n",
      "Epoch: 1, Step: 679/2949, Loss: 0.8132\n",
      "Epoch: 1, Step: 680/2949, Loss: 0.8496\n",
      "Epoch: 1, Step: 681/2949, Loss: 0.8781\n",
      "Epoch: 1, Step: 682/2949, Loss: 0.8688\n",
      "Epoch: 1, Step: 683/2949, Loss: 0.8995\n",
      "Epoch: 1, Step: 684/2949, Loss: 0.8858\n",
      "Epoch: 1, Step: 685/2949, Loss: 0.9362\n",
      "Epoch: 1, Step: 686/2949, Loss: 0.8797\n",
      "Epoch: 1, Step: 687/2949, Loss: 0.8338\n",
      "Epoch: 1, Step: 688/2949, Loss: 0.8800\n",
      "Epoch: 1, Step: 689/2949, Loss: 0.8208\n",
      "Epoch: 1, Step: 690/2949, Loss: 0.8367\n",
      "Epoch: 1, Step: 691/2949, Loss: 0.9214\n",
      "Epoch: 1, Step: 692/2949, Loss: 0.8821\n",
      "Epoch: 1, Step: 693/2949, Loss: 0.8746\n",
      "Epoch: 1, Step: 694/2949, Loss: 0.8611\n",
      "Epoch: 1, Step: 695/2949, Loss: 0.8557\n",
      "Epoch: 1, Step: 696/2949, Loss: 0.8155\n",
      "Epoch: 1, Step: 697/2949, Loss: 0.8885\n",
      "Epoch: 1, Step: 698/2949, Loss: 0.8904\n",
      "Epoch: 1, Step: 699/2949, Loss: 0.9175\n",
      "Epoch: 1, Step: 700/2949, Loss: 0.8948\n",
      "Epoch: 1, Step: 701/2949, Loss: 0.8561\n",
      "Epoch: 1, Step: 702/2949, Loss: 0.8048\n",
      "Epoch: 1, Step: 703/2949, Loss: 0.9007\n",
      "Epoch: 1, Step: 704/2949, Loss: 0.8299\n",
      "Epoch: 1, Step: 705/2949, Loss: 0.8552\n",
      "Epoch: 1, Step: 706/2949, Loss: 0.8661\n",
      "Epoch: 1, Step: 707/2949, Loss: 0.8703\n",
      "Epoch: 1, Step: 708/2949, Loss: 0.8629\n",
      "Epoch: 1, Step: 709/2949, Loss: 0.8740\n",
      "Epoch: 1, Step: 710/2949, Loss: 0.8872\n",
      "Epoch: 1, Step: 711/2949, Loss: 0.8129\n",
      "Epoch: 1, Step: 712/2949, Loss: 0.8338\n",
      "Epoch: 1, Step: 713/2949, Loss: 0.9189\n",
      "Epoch: 1, Step: 714/2949, Loss: 0.8439\n",
      "Epoch: 1, Step: 715/2949, Loss: 0.8387\n",
      "Epoch: 1, Step: 716/2949, Loss: 0.8553\n",
      "Epoch: 1, Step: 717/2949, Loss: 0.8862\n",
      "Epoch: 1, Step: 718/2949, Loss: 0.8905\n",
      "Epoch: 1, Step: 719/2949, Loss: 0.8594\n",
      "Epoch: 1, Step: 720/2949, Loss: 0.9177\n",
      "Epoch: 1, Step: 721/2949, Loss: 0.9477\n",
      "Epoch: 1, Step: 722/2949, Loss: 0.8826\n",
      "Epoch: 1, Step: 723/2949, Loss: 0.8918\n",
      "Epoch: 1, Step: 724/2949, Loss: 0.8789\n",
      "Epoch: 1, Step: 725/2949, Loss: 0.8068\n",
      "Epoch: 1, Step: 726/2949, Loss: 0.9332\n",
      "Epoch: 1, Step: 727/2949, Loss: 0.8402\n",
      "Epoch: 1, Step: 728/2949, Loss: 0.8223\n",
      "Epoch: 1, Step: 729/2949, Loss: 0.8416\n",
      "Epoch: 1, Step: 730/2949, Loss: 0.8703\n",
      "Epoch: 1, Step: 731/2949, Loss: 0.8496\n",
      "Epoch: 1, Step: 732/2949, Loss: 0.8624\n",
      "Epoch: 1, Step: 733/2949, Loss: 0.8760\n",
      "Epoch: 1, Step: 734/2949, Loss: 0.8965\n",
      "Epoch: 1, Step: 735/2949, Loss: 0.8488\n",
      "Epoch: 1, Step: 736/2949, Loss: 0.8918\n",
      "Epoch: 1, Step: 737/2949, Loss: 0.8241\n",
      "Epoch: 1, Step: 738/2949, Loss: 0.8646\n",
      "Epoch: 1, Step: 739/2949, Loss: 0.9124\n",
      "Epoch: 1, Step: 740/2949, Loss: 0.9081\n",
      "Epoch: 1, Step: 741/2949, Loss: 0.8943\n",
      "Epoch: 1, Step: 742/2949, Loss: 0.8603\n",
      "Epoch: 1, Step: 743/2949, Loss: 0.8397\n",
      "Epoch: 1, Step: 744/2949, Loss: 0.8642\n",
      "Epoch: 1, Step: 745/2949, Loss: 0.8557\n",
      "Epoch: 1, Step: 746/2949, Loss: 0.8442\n",
      "Epoch: 1, Step: 747/2949, Loss: 0.8823\n",
      "Epoch: 1, Step: 748/2949, Loss: 0.8438\n",
      "Epoch: 1, Step: 749/2949, Loss: 0.9366\n",
      "Epoch: 1, Step: 750/2949, Loss: 0.8644\n",
      "Epoch: 1, Step: 751/2949, Loss: 0.8818\n",
      "Epoch: 1, Step: 752/2949, Loss: 0.8250\n",
      "Epoch: 1, Step: 753/2949, Loss: 0.9138\n",
      "Epoch: 1, Step: 754/2949, Loss: 0.8168\n",
      "Epoch: 1, Step: 755/2949, Loss: 0.7993\n",
      "Epoch: 1, Step: 756/2949, Loss: 0.8553\n",
      "Epoch: 1, Step: 757/2949, Loss: 0.8907\n",
      "Epoch: 1, Step: 758/2949, Loss: 0.8385\n",
      "Epoch: 1, Step: 759/2949, Loss: 0.8522\n",
      "Epoch: 1, Step: 760/2949, Loss: 0.8403\n",
      "Epoch: 1, Step: 761/2949, Loss: 0.8200\n",
      "Epoch: 1, Step: 762/2949, Loss: 0.8468\n",
      "Epoch: 1, Step: 763/2949, Loss: 0.8878\n",
      "Epoch: 1, Step: 764/2949, Loss: 0.8963\n",
      "Epoch: 1, Step: 765/2949, Loss: 0.8403\n",
      "Epoch: 1, Step: 766/2949, Loss: 0.8422\n",
      "Epoch: 1, Step: 767/2949, Loss: 0.8396\n",
      "Epoch: 1, Step: 768/2949, Loss: 0.8752\n",
      "Epoch: 1, Step: 769/2949, Loss: 0.8466\n",
      "Epoch: 1, Step: 770/2949, Loss: 0.8800\n",
      "Epoch: 1, Step: 771/2949, Loss: 0.9044\n",
      "Epoch: 1, Step: 772/2949, Loss: 0.8878\n",
      "Epoch: 1, Step: 773/2949, Loss: 0.8200\n",
      "Epoch: 1, Step: 774/2949, Loss: 0.8710\n",
      "Epoch: 1, Step: 775/2949, Loss: 0.8381\n",
      "Epoch: 1, Step: 776/2949, Loss: 0.8069\n",
      "Epoch: 1, Step: 777/2949, Loss: 0.8322\n",
      "Epoch: 1, Step: 778/2949, Loss: 0.8579\n",
      "Epoch: 1, Step: 779/2949, Loss: 0.8907\n",
      "Epoch: 1, Step: 780/2949, Loss: 0.8959\n",
      "Epoch: 1, Step: 781/2949, Loss: 0.8253\n",
      "Epoch: 1, Step: 782/2949, Loss: 0.8633\n",
      "Epoch: 1, Step: 783/2949, Loss: 0.8891\n",
      "Epoch: 1, Step: 784/2949, Loss: 0.8518\n",
      "Epoch: 1, Step: 785/2949, Loss: 0.9225\n",
      "Epoch: 1, Step: 786/2949, Loss: 0.8558\n",
      "Epoch: 1, Step: 787/2949, Loss: 0.8922\n",
      "Epoch: 1, Step: 788/2949, Loss: 0.8308\n",
      "Epoch: 1, Step: 789/2949, Loss: 0.8194\n",
      "Epoch: 1, Step: 790/2949, Loss: 0.8986\n",
      "Epoch: 1, Step: 791/2949, Loss: 0.8348\n",
      "Epoch: 1, Step: 792/2949, Loss: 0.8654\n",
      "Epoch: 1, Step: 793/2949, Loss: 0.9181\n",
      "Epoch: 1, Step: 794/2949, Loss: 0.8604\n",
      "Epoch: 1, Step: 795/2949, Loss: 0.8819\n",
      "Epoch: 1, Step: 796/2949, Loss: 0.8791\n",
      "Epoch: 1, Step: 797/2949, Loss: 0.8908\n",
      "Epoch: 1, Step: 798/2949, Loss: 0.7617\n",
      "Epoch: 1, Step: 799/2949, Loss: 0.9080\n",
      "Epoch: 1, Step: 800/2949, Loss: 0.8884\n",
      "Epoch: 1, Step: 801/2949, Loss: 0.8188\n",
      "Epoch: 1, Step: 802/2949, Loss: 0.8239\n",
      "Epoch: 1, Step: 803/2949, Loss: 0.8313\n",
      "Epoch: 1, Step: 804/2949, Loss: 0.8450\n",
      "Epoch: 1, Step: 805/2949, Loss: 0.8785\n",
      "Epoch: 1, Step: 806/2949, Loss: 0.8458\n",
      "Epoch: 1, Step: 807/2949, Loss: 0.8222\n",
      "Epoch: 1, Step: 808/2949, Loss: 0.8761\n",
      "Epoch: 1, Step: 809/2949, Loss: 0.8345\n",
      "Epoch: 1, Step: 810/2949, Loss: 0.8958\n",
      "Epoch: 1, Step: 811/2949, Loss: 0.8766\n",
      "Epoch: 1, Step: 812/2949, Loss: 0.8723\n",
      "Epoch: 1, Step: 813/2949, Loss: 0.8809\n",
      "Epoch: 1, Step: 814/2949, Loss: 0.8287\n",
      "Epoch: 1, Step: 815/2949, Loss: 0.8379\n",
      "Epoch: 1, Step: 816/2949, Loss: 0.8082\n",
      "Epoch: 1, Step: 817/2949, Loss: 0.8769\n",
      "Epoch: 1, Step: 818/2949, Loss: 0.9161\n",
      "Epoch: 1, Step: 819/2949, Loss: 0.8301\n",
      "Epoch: 1, Step: 820/2949, Loss: 0.8727\n",
      "Epoch: 1, Step: 821/2949, Loss: 0.8319\n",
      "Epoch: 1, Step: 822/2949, Loss: 0.8692\n",
      "Epoch: 1, Step: 823/2949, Loss: 0.8504\n",
      "Epoch: 1, Step: 824/2949, Loss: 0.8124\n",
      "Epoch: 1, Step: 825/2949, Loss: 0.8296\n",
      "Epoch: 1, Step: 826/2949, Loss: 0.8410\n",
      "Epoch: 1, Step: 827/2949, Loss: 0.8345\n",
      "Epoch: 1, Step: 828/2949, Loss: 0.8577\n",
      "Epoch: 1, Step: 829/2949, Loss: 0.8720\n",
      "Epoch: 1, Step: 830/2949, Loss: 0.8635\n",
      "Epoch: 1, Step: 831/2949, Loss: 0.8890\n",
      "Epoch: 1, Step: 832/2949, Loss: 0.8451\n",
      "Epoch: 1, Step: 833/2949, Loss: 0.8487\n",
      "Epoch: 1, Step: 834/2949, Loss: 0.8574\n",
      "Epoch: 1, Step: 835/2949, Loss: 0.9193\n",
      "Epoch: 1, Step: 836/2949, Loss: 0.8473\n",
      "Epoch: 1, Step: 837/2949, Loss: 0.8852\n",
      "Epoch: 1, Step: 838/2949, Loss: 0.7977\n",
      "Epoch: 1, Step: 839/2949, Loss: 0.9101\n",
      "Epoch: 1, Step: 840/2949, Loss: 0.8352\n",
      "Epoch: 1, Step: 841/2949, Loss: 0.8374\n",
      "Epoch: 1, Step: 842/2949, Loss: 0.8065\n",
      "Epoch: 1, Step: 843/2949, Loss: 0.8706\n",
      "Epoch: 1, Step: 844/2949, Loss: 0.8972\n",
      "Epoch: 1, Step: 845/2949, Loss: 0.8536\n",
      "Epoch: 1, Step: 846/2949, Loss: 0.8592\n",
      "Epoch: 1, Step: 847/2949, Loss: 0.8480\n",
      "Epoch: 1, Step: 848/2949, Loss: 0.8597\n",
      "Epoch: 1, Step: 849/2949, Loss: 0.8117\n",
      "Epoch: 1, Step: 850/2949, Loss: 0.9049\n",
      "Epoch: 1, Step: 851/2949, Loss: 0.8446\n",
      "Epoch: 1, Step: 852/2949, Loss: 0.8567\n",
      "Epoch: 1, Step: 853/2949, Loss: 0.8511\n",
      "Epoch: 1, Step: 854/2949, Loss: 0.8690\n",
      "Epoch: 1, Step: 855/2949, Loss: 0.8605\n",
      "Epoch: 1, Step: 856/2949, Loss: 0.8693\n",
      "Epoch: 1, Step: 857/2949, Loss: 0.8314\n",
      "Epoch: 1, Step: 858/2949, Loss: 0.8370\n",
      "Epoch: 1, Step: 859/2949, Loss: 0.8720\n",
      "Epoch: 1, Step: 860/2949, Loss: 0.8159\n",
      "Epoch: 1, Step: 861/2949, Loss: 0.8669\n",
      "Epoch: 1, Step: 862/2949, Loss: 0.8499\n",
      "Epoch: 1, Step: 863/2949, Loss: 0.8923\n",
      "Epoch: 1, Step: 864/2949, Loss: 0.8885\n",
      "Epoch: 1, Step: 865/2949, Loss: 0.8276\n",
      "Epoch: 1, Step: 866/2949, Loss: 0.8617\n",
      "Epoch: 1, Step: 867/2949, Loss: 0.8658\n",
      "Epoch: 1, Step: 868/2949, Loss: 0.8931\n",
      "Epoch: 1, Step: 869/2949, Loss: 0.8421\n",
      "Epoch: 1, Step: 870/2949, Loss: 0.8400\n",
      "Epoch: 1, Step: 871/2949, Loss: 0.8561\n",
      "Epoch: 1, Step: 872/2949, Loss: 0.8637\n",
      "Epoch: 1, Step: 873/2949, Loss: 0.8809\n",
      "Epoch: 1, Step: 874/2949, Loss: 0.8613\n",
      "Epoch: 1, Step: 875/2949, Loss: 0.8493\n",
      "Epoch: 1, Step: 876/2949, Loss: 0.8707\n",
      "Epoch: 1, Step: 877/2949, Loss: 0.8715\n",
      "Epoch: 1, Step: 878/2949, Loss: 0.8889\n",
      "Epoch: 1, Step: 879/2949, Loss: 0.8293\n",
      "Epoch: 1, Step: 880/2949, Loss: 0.9384\n",
      "Epoch: 1, Step: 881/2949, Loss: 0.8904\n",
      "Epoch: 1, Step: 882/2949, Loss: 0.8557\n",
      "Epoch: 1, Step: 883/2949, Loss: 0.8062\n",
      "Epoch: 1, Step: 884/2949, Loss: 0.8995\n",
      "Epoch: 1, Step: 885/2949, Loss: 0.8217\n",
      "Epoch: 1, Step: 886/2949, Loss: 0.8720\n",
      "Epoch: 1, Step: 887/2949, Loss: 0.8521\n",
      "Epoch: 1, Step: 888/2949, Loss: 0.9053\n",
      "Epoch: 1, Step: 889/2949, Loss: 0.9057\n",
      "Epoch: 1, Step: 890/2949, Loss: 0.8379\n",
      "Epoch: 1, Step: 891/2949, Loss: 0.8295\n",
      "Epoch: 1, Step: 892/2949, Loss: 0.8983\n",
      "Epoch: 1, Step: 893/2949, Loss: 0.8505\n",
      "Epoch: 1, Step: 894/2949, Loss: 0.8546\n",
      "Epoch: 1, Step: 895/2949, Loss: 0.8489\n",
      "Epoch: 1, Step: 896/2949, Loss: 0.8806\n",
      "Epoch: 1, Step: 897/2949, Loss: 0.9075\n",
      "Epoch: 1, Step: 898/2949, Loss: 0.8625\n",
      "Epoch: 1, Step: 899/2949, Loss: 0.8953\n",
      "Epoch: 1, Step: 900/2949, Loss: 0.8665\n",
      "Epoch: 1, Step: 901/2949, Loss: 0.8669\n",
      "Epoch: 1, Step: 902/2949, Loss: 0.8890\n",
      "Epoch: 1, Step: 903/2949, Loss: 0.8372\n",
      "Epoch: 1, Step: 904/2949, Loss: 0.8844\n",
      "Epoch: 1, Step: 905/2949, Loss: 0.7942\n",
      "Epoch: 1, Step: 906/2949, Loss: 0.8408\n",
      "Epoch: 1, Step: 907/2949, Loss: 0.9003\n",
      "Epoch: 1, Step: 908/2949, Loss: 0.8968\n",
      "Epoch: 1, Step: 909/2949, Loss: 0.8946\n",
      "Epoch: 1, Step: 910/2949, Loss: 0.8954\n",
      "Epoch: 1, Step: 911/2949, Loss: 0.8705\n",
      "Epoch: 1, Step: 912/2949, Loss: 0.8246\n",
      "Epoch: 1, Step: 913/2949, Loss: 0.8773\n",
      "Epoch: 1, Step: 914/2949, Loss: 0.8822\n",
      "Epoch: 1, Step: 915/2949, Loss: 0.8179\n",
      "Epoch: 1, Step: 916/2949, Loss: 0.8853\n",
      "Epoch: 1, Step: 917/2949, Loss: 0.8772\n",
      "Epoch: 1, Step: 918/2949, Loss: 0.8843\n",
      "Epoch: 1, Step: 919/2949, Loss: 0.8873\n",
      "Epoch: 1, Step: 920/2949, Loss: 0.8408\n",
      "Epoch: 1, Step: 921/2949, Loss: 0.8829\n",
      "Epoch: 1, Step: 922/2949, Loss: 0.8662\n",
      "Epoch: 1, Step: 923/2949, Loss: 0.8156\n",
      "Epoch: 1, Step: 924/2949, Loss: 0.8539\n",
      "Epoch: 1, Step: 925/2949, Loss: 0.8633\n",
      "Epoch: 1, Step: 926/2949, Loss: 0.9241\n",
      "Epoch: 1, Step: 927/2949, Loss: 0.8436\n",
      "Epoch: 1, Step: 928/2949, Loss: 0.8628\n",
      "Epoch: 1, Step: 929/2949, Loss: 0.8445\n",
      "Epoch: 1, Step: 930/2949, Loss: 0.8910\n",
      "Epoch: 1, Step: 931/2949, Loss: 0.8401\n",
      "Epoch: 1, Step: 932/2949, Loss: 0.8371\n",
      "Epoch: 1, Step: 933/2949, Loss: 0.8546\n",
      "Epoch: 1, Step: 934/2949, Loss: 0.9238\n",
      "Epoch: 1, Step: 935/2949, Loss: 0.9174\n",
      "Epoch: 1, Step: 936/2949, Loss: 0.8746\n",
      "Epoch: 1, Step: 937/2949, Loss: 0.8158\n",
      "Epoch: 1, Step: 938/2949, Loss: 0.8737\n",
      "Epoch: 1, Step: 939/2949, Loss: 0.8559\n",
      "Epoch: 1, Step: 940/2949, Loss: 0.8202\n",
      "Epoch: 1, Step: 941/2949, Loss: 0.8637\n",
      "Epoch: 1, Step: 942/2949, Loss: 0.8888\n",
      "Epoch: 1, Step: 943/2949, Loss: 0.8558\n",
      "Epoch: 1, Step: 944/2949, Loss: 0.8574\n",
      "Epoch: 1, Step: 945/2949, Loss: 0.8698\n",
      "Epoch: 1, Step: 946/2949, Loss: 0.8532\n",
      "Epoch: 1, Step: 947/2949, Loss: 0.8556\n",
      "Epoch: 1, Step: 948/2949, Loss: 0.8944\n",
      "Epoch: 1, Step: 949/2949, Loss: 0.8588\n",
      "Epoch: 1, Step: 950/2949, Loss: 0.8366\n",
      "Epoch: 1, Step: 951/2949, Loss: 0.8669\n",
      "Epoch: 1, Step: 952/2949, Loss: 0.8772\n",
      "Epoch: 1, Step: 953/2949, Loss: 0.8542\n",
      "Epoch: 1, Step: 954/2949, Loss: 0.8976\n",
      "Epoch: 1, Step: 955/2949, Loss: 0.8921\n",
      "Epoch: 1, Step: 956/2949, Loss: 0.8957\n",
      "Epoch: 1, Step: 957/2949, Loss: 0.8952\n",
      "Epoch: 1, Step: 958/2949, Loss: 0.7941\n",
      "Epoch: 1, Step: 959/2949, Loss: 0.8559\n",
      "Epoch: 1, Step: 960/2949, Loss: 0.8434\n",
      "Epoch: 1, Step: 961/2949, Loss: 0.8607\n",
      "Epoch: 1, Step: 962/2949, Loss: 0.8856\n",
      "Epoch: 1, Step: 963/2949, Loss: 0.8999\n",
      "Epoch: 1, Step: 964/2949, Loss: 0.9078\n",
      "Epoch: 1, Step: 965/2949, Loss: 0.8635\n",
      "Epoch: 1, Step: 966/2949, Loss: 0.8210\n",
      "Epoch: 1, Step: 967/2949, Loss: 0.8604\n",
      "Epoch: 1, Step: 968/2949, Loss: 0.8560\n",
      "Epoch: 1, Step: 969/2949, Loss: 0.8842\n",
      "Epoch: 1, Step: 970/2949, Loss: 0.8043\n",
      "Epoch: 1, Step: 971/2949, Loss: 0.8788\n",
      "Epoch: 1, Step: 972/2949, Loss: 0.8472\n",
      "Epoch: 1, Step: 973/2949, Loss: 0.8430\n",
      "Epoch: 1, Step: 974/2949, Loss: 0.8358\n",
      "Epoch: 1, Step: 975/2949, Loss: 0.8682\n",
      "Epoch: 1, Step: 976/2949, Loss: 0.8283\n",
      "Epoch: 1, Step: 977/2949, Loss: 0.8285\n",
      "Epoch: 1, Step: 978/2949, Loss: 0.8524\n",
      "Epoch: 1, Step: 979/2949, Loss: 0.8886\n",
      "Epoch: 1, Step: 980/2949, Loss: 0.9294\n",
      "Epoch: 1, Step: 981/2949, Loss: 0.8905\n",
      "Epoch: 1, Step: 982/2949, Loss: 0.8580\n",
      "Epoch: 1, Step: 983/2949, Loss: 0.8444\n",
      "Epoch: 1, Step: 984/2949, Loss: 0.8877\n",
      "Epoch: 1, Step: 985/2949, Loss: 0.9274\n",
      "Epoch: 1, Step: 986/2949, Loss: 0.8910\n",
      "Epoch: 1, Step: 987/2949, Loss: 0.8192\n",
      "Epoch: 1, Step: 988/2949, Loss: 0.8882\n",
      "Epoch: 1, Step: 989/2949, Loss: 0.8678\n",
      "Epoch: 1, Step: 990/2949, Loss: 0.8578\n",
      "Epoch: 1, Step: 991/2949, Loss: 0.8495\n",
      "Epoch: 1, Step: 992/2949, Loss: 0.8751\n",
      "Epoch: 1, Step: 993/2949, Loss: 0.8923\n",
      "Epoch: 1, Step: 994/2949, Loss: 0.9133\n",
      "Epoch: 1, Step: 995/2949, Loss: 0.8555\n",
      "Epoch: 1, Step: 996/2949, Loss: 0.8870\n",
      "Epoch: 1, Step: 997/2949, Loss: 0.8162\n",
      "Epoch: 1, Step: 998/2949, Loss: 0.8457\n",
      "Epoch: 1, Step: 999/2949, Loss: 0.8400\n",
      "Epoch: 1, Step: 1000/2949, Loss: 0.9356\n",
      "Epoch: 1, Step: 1001/2949, Loss: 0.9312\n",
      "Epoch: 1, Step: 1002/2949, Loss: 0.8510\n",
      "Epoch: 1, Step: 1003/2949, Loss: 0.8723\n",
      "Epoch: 1, Step: 1004/2949, Loss: 0.8618\n",
      "Epoch: 1, Step: 1005/2949, Loss: 0.8756\n",
      "Epoch: 1, Step: 1006/2949, Loss: 0.8413\n",
      "Epoch: 1, Step: 1007/2949, Loss: 0.8911\n",
      "Epoch: 1, Step: 1008/2949, Loss: 0.7916\n",
      "Epoch: 1, Step: 1009/2949, Loss: 0.8427\n",
      "Epoch: 1, Step: 1010/2949, Loss: 0.8567\n",
      "Epoch: 1, Step: 1011/2949, Loss: 0.8570\n",
      "Epoch: 1, Step: 1012/2949, Loss: 0.8773\n",
      "Epoch: 1, Step: 1013/2949, Loss: 0.8784\n",
      "Epoch: 1, Step: 1014/2949, Loss: 0.8410\n",
      "Epoch: 1, Step: 1015/2949, Loss: 0.8639\n",
      "Epoch: 1, Step: 1016/2949, Loss: 0.9012\n",
      "Epoch: 1, Step: 1017/2949, Loss: 0.8975\n",
      "Epoch: 1, Step: 1018/2949, Loss: 0.8136\n",
      "Epoch: 1, Step: 1019/2949, Loss: 0.8561\n",
      "Epoch: 1, Step: 1020/2949, Loss: 0.8495\n",
      "Epoch: 1, Step: 1021/2949, Loss: 0.8092\n",
      "Epoch: 1, Step: 1022/2949, Loss: 0.8468\n",
      "Epoch: 1, Step: 1023/2949, Loss: 0.8018\n",
      "Epoch: 1, Step: 1024/2949, Loss: 0.8694\n",
      "Epoch: 1, Step: 1025/2949, Loss: 0.8764\n",
      "Epoch: 1, Step: 1026/2949, Loss: 0.8620\n",
      "Epoch: 1, Step: 1027/2949, Loss: 0.8908\n",
      "Epoch: 1, Step: 1028/2949, Loss: 0.7749\n",
      "Epoch: 1, Step: 1029/2949, Loss: 0.8671\n",
      "Epoch: 1, Step: 1030/2949, Loss: 0.8932\n",
      "Epoch: 1, Step: 1031/2949, Loss: 0.8415\n",
      "Epoch: 1, Step: 1032/2949, Loss: 0.8356\n",
      "Epoch: 1, Step: 1033/2949, Loss: 0.8677\n",
      "Epoch: 1, Step: 1034/2949, Loss: 0.8621\n",
      "Epoch: 1, Step: 1035/2949, Loss: 0.9125\n",
      "Epoch: 1, Step: 1036/2949, Loss: 0.8160\n",
      "Epoch: 1, Step: 1037/2949, Loss: 0.8593\n",
      "Epoch: 1, Step: 1038/2949, Loss: 0.8625\n",
      "Epoch: 1, Step: 1039/2949, Loss: 0.8226\n",
      "Epoch: 1, Step: 1040/2949, Loss: 0.8857\n",
      "Epoch: 1, Step: 1041/2949, Loss: 0.8743\n",
      "Epoch: 1, Step: 1042/2949, Loss: 0.8368\n",
      "Epoch: 1, Step: 1043/2949, Loss: 0.8268\n",
      "Epoch: 1, Step: 1044/2949, Loss: 0.8769\n",
      "Epoch: 1, Step: 1045/2949, Loss: 0.7738\n",
      "Epoch: 1, Step: 1046/2949, Loss: 0.8620\n",
      "Epoch: 1, Step: 1047/2949, Loss: 0.8739\n",
      "Epoch: 1, Step: 1048/2949, Loss: 0.8575\n",
      "Epoch: 1, Step: 1049/2949, Loss: 0.8461\n",
      "Epoch: 1, Step: 1050/2949, Loss: 0.8123\n",
      "Epoch: 1, Step: 1051/2949, Loss: 0.8488\n",
      "Epoch: 1, Step: 1052/2949, Loss: 0.8293\n",
      "Epoch: 1, Step: 1053/2949, Loss: 0.8393\n",
      "Epoch: 1, Step: 1054/2949, Loss: 0.8846\n",
      "Epoch: 1, Step: 1055/2949, Loss: 0.8849\n",
      "Epoch: 1, Step: 1056/2949, Loss: 0.8897\n",
      "Epoch: 1, Step: 1057/2949, Loss: 0.8775\n",
      "Epoch: 1, Step: 1058/2949, Loss: 0.8563\n",
      "Epoch: 1, Step: 1059/2949, Loss: 0.8617\n",
      "Epoch: 1, Step: 1060/2949, Loss: 0.8762\n",
      "Epoch: 1, Step: 1061/2949, Loss: 0.8642\n",
      "Epoch: 1, Step: 1062/2949, Loss: 0.8620\n",
      "Epoch: 1, Step: 1063/2949, Loss: 0.8120\n",
      "Epoch: 1, Step: 1064/2949, Loss: 0.8130\n",
      "Epoch: 1, Step: 1065/2949, Loss: 0.8119\n",
      "Epoch: 1, Step: 1066/2949, Loss: 0.8787\n",
      "Epoch: 1, Step: 1067/2949, Loss: 0.8846\n",
      "Epoch: 1, Step: 1068/2949, Loss: 0.8214\n",
      "Epoch: 1, Step: 1069/2949, Loss: 0.8335\n",
      "Epoch: 1, Step: 1070/2949, Loss: 0.8523\n",
      "Epoch: 1, Step: 1071/2949, Loss: 0.8625\n",
      "Epoch: 1, Step: 1072/2949, Loss: 0.8707\n",
      "Epoch: 1, Step: 1073/2949, Loss: 0.8931\n",
      "Epoch: 1, Step: 1074/2949, Loss: 0.8577\n",
      "Epoch: 1, Step: 1075/2949, Loss: 0.8642\n",
      "Epoch: 1, Step: 1076/2949, Loss: 0.8873\n",
      "Epoch: 1, Step: 1077/2949, Loss: 0.8443\n",
      "Epoch: 1, Step: 1078/2949, Loss: 0.8442\n",
      "Epoch: 1, Step: 1079/2949, Loss: 0.8657\n",
      "Epoch: 1, Step: 1080/2949, Loss: 0.8573\n",
      "Epoch: 1, Step: 1081/2949, Loss: 0.8683\n",
      "Epoch: 1, Step: 1082/2949, Loss: 0.8231\n",
      "Epoch: 1, Step: 1083/2949, Loss: 0.8495\n",
      "Epoch: 1, Step: 1084/2949, Loss: 0.8811\n",
      "Epoch: 1, Step: 1085/2949, Loss: 0.8937\n",
      "Epoch: 1, Step: 1086/2949, Loss: 0.8654\n",
      "Epoch: 1, Step: 1087/2949, Loss: 0.8538\n",
      "Epoch: 1, Step: 1088/2949, Loss: 0.8492\n",
      "Epoch: 1, Step: 1089/2949, Loss: 0.8381\n",
      "Epoch: 1, Step: 1090/2949, Loss: 0.8768\n",
      "Epoch: 1, Step: 1091/2949, Loss: 0.8405\n",
      "Epoch: 1, Step: 1092/2949, Loss: 0.8028\n",
      "Epoch: 1, Step: 1093/2949, Loss: 0.8700\n",
      "Epoch: 1, Step: 1094/2949, Loss: 0.8655\n",
      "Epoch: 1, Step: 1095/2949, Loss: 0.8990\n",
      "Epoch: 1, Step: 1096/2949, Loss: 0.8843\n",
      "Epoch: 1, Step: 1097/2949, Loss: 0.8759\n",
      "Epoch: 1, Step: 1098/2949, Loss: 0.8976\n",
      "Epoch: 1, Step: 1099/2949, Loss: 0.8896\n",
      "Epoch: 1, Step: 1100/2949, Loss: 0.8537\n",
      "Epoch: 1, Step: 1101/2949, Loss: 0.8470\n",
      "Epoch: 1, Step: 1102/2949, Loss: 0.8234\n",
      "Epoch: 1, Step: 1103/2949, Loss: 0.8498\n",
      "Epoch: 1, Step: 1104/2949, Loss: 0.8942\n",
      "Epoch: 1, Step: 1105/2949, Loss: 0.8584\n",
      "Epoch: 1, Step: 1106/2949, Loss: 0.9040\n",
      "Epoch: 1, Step: 1107/2949, Loss: 0.8527\n",
      "Epoch: 1, Step: 1108/2949, Loss: 0.8918\n",
      "Epoch: 1, Step: 1109/2949, Loss: 0.8579\n",
      "Epoch: 1, Step: 1110/2949, Loss: 0.8825\n",
      "Epoch: 1, Step: 1111/2949, Loss: 0.8546\n",
      "Epoch: 1, Step: 1112/2949, Loss: 0.8478\n",
      "Epoch: 1, Step: 1113/2949, Loss: 0.8029\n",
      "Epoch: 1, Step: 1114/2949, Loss: 0.8573\n",
      "Epoch: 1, Step: 1115/2949, Loss: 0.8469\n",
      "Epoch: 1, Step: 1116/2949, Loss: 0.8614\n",
      "Epoch: 1, Step: 1117/2949, Loss: 0.8710\n",
      "Epoch: 1, Step: 1118/2949, Loss: 0.8743\n",
      "Epoch: 1, Step: 1119/2949, Loss: 0.8036\n",
      "Epoch: 1, Step: 1120/2949, Loss: 0.8508\n",
      "Epoch: 1, Step: 1121/2949, Loss: 0.9080\n",
      "Epoch: 1, Step: 1122/2949, Loss: 0.8821\n",
      "Epoch: 1, Step: 1123/2949, Loss: 0.8974\n",
      "Epoch: 1, Step: 1124/2949, Loss: 0.8656\n",
      "Epoch: 1, Step: 1125/2949, Loss: 0.8392\n",
      "Epoch: 1, Step: 1126/2949, Loss: 0.8325\n",
      "Epoch: 1, Step: 1127/2949, Loss: 0.8843\n",
      "Epoch: 1, Step: 1128/2949, Loss: 0.8371\n",
      "Epoch: 1, Step: 1129/2949, Loss: 0.8677\n",
      "Epoch: 1, Step: 1130/2949, Loss: 0.8606\n",
      "Epoch: 1, Step: 1131/2949, Loss: 0.8888\n",
      "Epoch: 1, Step: 1132/2949, Loss: 0.8522\n",
      "Epoch: 1, Step: 1133/2949, Loss: 0.8943\n",
      "Epoch: 1, Step: 1134/2949, Loss: 0.9071\n",
      "Epoch: 1, Step: 1135/2949, Loss: 0.8725\n",
      "Epoch: 1, Step: 1136/2949, Loss: 0.8520\n",
      "Epoch: 1, Step: 1137/2949, Loss: 0.8397\n",
      "Epoch: 1, Step: 1138/2949, Loss: 0.8562\n",
      "Epoch: 1, Step: 1139/2949, Loss: 0.8551\n",
      "Epoch: 1, Step: 1140/2949, Loss: 0.8215\n",
      "Epoch: 1, Step: 1141/2949, Loss: 0.8895\n",
      "Epoch: 1, Step: 1142/2949, Loss: 0.8396\n",
      "Epoch: 1, Step: 1143/2949, Loss: 0.8234\n",
      "Epoch: 1, Step: 1144/2949, Loss: 0.8185\n",
      "Epoch: 1, Step: 1145/2949, Loss: 0.8376\n",
      "Epoch: 1, Step: 1146/2949, Loss: 0.9021\n",
      "Epoch: 1, Step: 1147/2949, Loss: 0.8442\n",
      "Epoch: 1, Step: 1148/2949, Loss: 0.8840\n",
      "Epoch: 1, Step: 1149/2949, Loss: 0.8046\n",
      "Epoch: 1, Step: 1150/2949, Loss: 0.8512\n",
      "Epoch: 1, Step: 1151/2949, Loss: 0.8147\n",
      "Epoch: 1, Step: 1152/2949, Loss: 0.8536\n",
      "Epoch: 1, Step: 1153/2949, Loss: 0.8017\n",
      "Epoch: 1, Step: 1154/2949, Loss: 0.8731\n",
      "Epoch: 1, Step: 1155/2949, Loss: 0.8486\n",
      "Epoch: 1, Step: 1156/2949, Loss: 0.8879\n",
      "Epoch: 1, Step: 1157/2949, Loss: 0.8453\n",
      "Epoch: 1, Step: 1158/2949, Loss: 0.8650\n",
      "Epoch: 1, Step: 1159/2949, Loss: 0.8591\n",
      "Epoch: 1, Step: 1160/2949, Loss: 0.9015\n",
      "Epoch: 1, Step: 1161/2949, Loss: 0.8319\n",
      "Epoch: 1, Step: 1162/2949, Loss: 0.8243\n",
      "Epoch: 1, Step: 1163/2949, Loss: 0.8364\n",
      "Epoch: 1, Step: 1164/2949, Loss: 0.9267\n",
      "Epoch: 1, Step: 1165/2949, Loss: 0.8635\n",
      "Epoch: 1, Step: 1166/2949, Loss: 0.9151\n",
      "Epoch: 1, Step: 1167/2949, Loss: 0.8454\n",
      "Epoch: 1, Step: 1168/2949, Loss: 0.8063\n",
      "Epoch: 1, Step: 1169/2949, Loss: 0.8302\n",
      "Epoch: 1, Step: 1170/2949, Loss: 0.8778\n",
      "Epoch: 1, Step: 1171/2949, Loss: 0.8104\n",
      "Epoch: 1, Step: 1172/2949, Loss: 0.9177\n",
      "Epoch: 1, Step: 1173/2949, Loss: 0.8764\n",
      "Epoch: 1, Step: 1174/2949, Loss: 0.8466\n",
      "Epoch: 1, Step: 1175/2949, Loss: 0.8449\n",
      "Epoch: 1, Step: 1176/2949, Loss: 0.9304\n",
      "Epoch: 1, Step: 1177/2949, Loss: 0.8052\n",
      "Epoch: 1, Step: 1178/2949, Loss: 0.7864\n",
      "Epoch: 1, Step: 1179/2949, Loss: 0.8319\n",
      "Epoch: 1, Step: 1180/2949, Loss: 0.8226\n",
      "Epoch: 1, Step: 1181/2949, Loss: 0.8578\n",
      "Epoch: 1, Step: 1182/2949, Loss: 0.8599\n",
      "Epoch: 1, Step: 1183/2949, Loss: 0.8884\n",
      "Epoch: 1, Step: 1184/2949, Loss: 0.8800\n",
      "Epoch: 1, Step: 1185/2949, Loss: 0.8541\n",
      "Epoch: 1, Step: 1186/2949, Loss: 0.8336\n",
      "Epoch: 1, Step: 1187/2949, Loss: 0.8650\n",
      "Epoch: 1, Step: 1188/2949, Loss: 0.8726\n",
      "Epoch: 1, Step: 1189/2949, Loss: 0.8661\n",
      "Epoch: 1, Step: 1190/2949, Loss: 0.8414\n",
      "Epoch: 1, Step: 1191/2949, Loss: 0.8884\n",
      "Epoch: 1, Step: 1192/2949, Loss: 0.8513\n",
      "Epoch: 1, Step: 1193/2949, Loss: 0.8797\n",
      "Epoch: 1, Step: 1194/2949, Loss: 0.8217\n",
      "Epoch: 1, Step: 1195/2949, Loss: 0.8726\n",
      "Epoch: 1, Step: 1196/2949, Loss: 0.8630\n",
      "Epoch: 1, Step: 1197/2949, Loss: 0.8371\n",
      "Epoch: 1, Step: 1198/2949, Loss: 0.8804\n",
      "Epoch: 1, Step: 1199/2949, Loss: 0.8591\n",
      "Epoch: 1, Step: 1200/2949, Loss: 0.8515\n",
      "Epoch: 1, Step: 1201/2949, Loss: 0.8906\n",
      "Epoch: 1, Step: 1202/2949, Loss: 0.8701\n",
      "Epoch: 1, Step: 1203/2949, Loss: 0.9038\n",
      "Epoch: 1, Step: 1204/2949, Loss: 0.7981\n",
      "Epoch: 1, Step: 1205/2949, Loss: 0.7871\n",
      "Epoch: 1, Step: 1206/2949, Loss: 0.8613\n",
      "Epoch: 1, Step: 1207/2949, Loss: 0.8628\n",
      "Epoch: 1, Step: 1208/2949, Loss: 0.8142\n",
      "Epoch: 1, Step: 1209/2949, Loss: 0.8548\n",
      "Epoch: 1, Step: 1210/2949, Loss: 0.8883\n",
      "Epoch: 1, Step: 1211/2949, Loss: 0.8584\n",
      "Epoch: 1, Step: 1212/2949, Loss: 0.8848\n",
      "Epoch: 1, Step: 1213/2949, Loss: 0.9049\n",
      "Epoch: 1, Step: 1214/2949, Loss: 0.8145\n",
      "Epoch: 1, Step: 1215/2949, Loss: 0.8272\n",
      "Epoch: 1, Step: 1216/2949, Loss: 0.8789\n",
      "Epoch: 1, Step: 1217/2949, Loss: 0.8548\n",
      "Epoch: 1, Step: 1218/2949, Loss: 0.8385\n",
      "Epoch: 1, Step: 1219/2949, Loss: 0.8522\n",
      "Epoch: 1, Step: 1220/2949, Loss: 0.7893\n",
      "Epoch: 1, Step: 1221/2949, Loss: 0.8307\n",
      "Epoch: 1, Step: 1222/2949, Loss: 0.8585\n",
      "Epoch: 1, Step: 1223/2949, Loss: 0.8516\n",
      "Epoch: 1, Step: 1224/2949, Loss: 0.8826\n",
      "Epoch: 1, Step: 1225/2949, Loss: 0.8792\n",
      "Epoch: 1, Step: 1226/2949, Loss: 0.8806\n",
      "Epoch: 1, Step: 1227/2949, Loss: 0.8568\n",
      "Epoch: 1, Step: 1228/2949, Loss: 0.8953\n",
      "Epoch: 1, Step: 1229/2949, Loss: 0.8560\n",
      "Epoch: 1, Step: 1230/2949, Loss: 0.8160\n",
      "Epoch: 1, Step: 1231/2949, Loss: 0.8663\n",
      "Epoch: 1, Step: 1232/2949, Loss: 0.8467\n",
      "Epoch: 1, Step: 1233/2949, Loss: 0.8545\n",
      "Epoch: 1, Step: 1234/2949, Loss: 0.8541\n",
      "Epoch: 1, Step: 1235/2949, Loss: 0.8252\n",
      "Epoch: 1, Step: 1236/2949, Loss: 0.8692\n",
      "Epoch: 1, Step: 1237/2949, Loss: 0.9079\n",
      "Epoch: 1, Step: 1238/2949, Loss: 0.8808\n",
      "Epoch: 1, Step: 1239/2949, Loss: 0.8377\n",
      "Epoch: 1, Step: 1240/2949, Loss: 0.8648\n",
      "Epoch: 1, Step: 1241/2949, Loss: 0.8403\n",
      "Epoch: 1, Step: 1242/2949, Loss: 0.8668\n",
      "Epoch: 1, Step: 1243/2949, Loss: 0.8195\n",
      "Epoch: 1, Step: 1244/2949, Loss: 0.8585\n",
      "Epoch: 1, Step: 1245/2949, Loss: 0.8459\n",
      "Epoch: 1, Step: 1246/2949, Loss: 0.8678\n",
      "Epoch: 1, Step: 1247/2949, Loss: 0.8197\n",
      "Epoch: 1, Step: 1248/2949, Loss: 0.8897\n",
      "Epoch: 1, Step: 1249/2949, Loss: 0.8462\n",
      "Epoch: 1, Step: 1250/2949, Loss: 0.8828\n",
      "Epoch: 1, Step: 1251/2949, Loss: 0.8596\n",
      "Epoch: 1, Step: 1252/2949, Loss: 0.8526\n",
      "Epoch: 1, Step: 1253/2949, Loss: 0.8069\n",
      "Epoch: 1, Step: 1254/2949, Loss: 0.7978\n",
      "Epoch: 1, Step: 1255/2949, Loss: 0.8344\n",
      "Epoch: 1, Step: 1256/2949, Loss: 0.8414\n",
      "Epoch: 1, Step: 1257/2949, Loss: 0.8629\n",
      "Epoch: 1, Step: 1258/2949, Loss: 0.8940\n",
      "Epoch: 1, Step: 1259/2949, Loss: 0.8924\n",
      "Epoch: 1, Step: 1260/2949, Loss: 0.8305\n",
      "Epoch: 1, Step: 1261/2949, Loss: 0.8277\n",
      "Epoch: 1, Step: 1262/2949, Loss: 0.8897\n",
      "Epoch: 1, Step: 1263/2949, Loss: 0.7691\n",
      "Epoch: 1, Step: 1264/2949, Loss: 0.8037\n",
      "Epoch: 1, Step: 1265/2949, Loss: 0.8500\n",
      "Epoch: 1, Step: 1266/2949, Loss: 0.8295\n",
      "Epoch: 1, Step: 1267/2949, Loss: 0.8067\n",
      "Epoch: 1, Step: 1268/2949, Loss: 0.8396\n",
      "Epoch: 1, Step: 1269/2949, Loss: 0.8300\n",
      "Epoch: 1, Step: 1270/2949, Loss: 0.9088\n",
      "Epoch: 1, Step: 1271/2949, Loss: 0.7849\n",
      "Epoch: 1, Step: 1272/2949, Loss: 0.8586\n",
      "Epoch: 1, Step: 1273/2949, Loss: 0.8528\n",
      "Epoch: 1, Step: 1274/2949, Loss: 0.8287\n",
      "Epoch: 1, Step: 1275/2949, Loss: 0.8548\n",
      "Epoch: 1, Step: 1276/2949, Loss: 0.8622\n",
      "Epoch: 1, Step: 1277/2949, Loss: 0.8524\n",
      "Epoch: 1, Step: 1278/2949, Loss: 0.8647\n",
      "Epoch: 1, Step: 1279/2949, Loss: 0.8693\n",
      "Epoch: 1, Step: 1280/2949, Loss: 0.8415\n",
      "Epoch: 1, Step: 1281/2949, Loss: 0.8800\n",
      "Epoch: 1, Step: 1282/2949, Loss: 0.8302\n",
      "Epoch: 1, Step: 1283/2949, Loss: 0.8380\n",
      "Epoch: 1, Step: 1284/2949, Loss: 0.8593\n",
      "Epoch: 1, Step: 1285/2949, Loss: 0.8657\n",
      "Epoch: 1, Step: 1286/2949, Loss: 0.8459\n",
      "Epoch: 1, Step: 1287/2949, Loss: 0.8764\n",
      "Epoch: 1, Step: 1288/2949, Loss: 0.8260\n",
      "Epoch: 1, Step: 1289/2949, Loss: 0.8627\n",
      "Epoch: 1, Step: 1290/2949, Loss: 0.8935\n",
      "Epoch: 1, Step: 1291/2949, Loss: 0.8429\n",
      "Epoch: 1, Step: 1292/2949, Loss: 0.8528\n",
      "Epoch: 1, Step: 1293/2949, Loss: 0.9208\n",
      "Epoch: 1, Step: 1294/2949, Loss: 0.8626\n",
      "Epoch: 1, Step: 1295/2949, Loss: 0.7889\n",
      "Epoch: 1, Step: 1296/2949, Loss: 0.8813\n",
      "Epoch: 1, Step: 1297/2949, Loss: 0.8426\n",
      "Epoch: 1, Step: 1298/2949, Loss: 0.8670\n",
      "Epoch: 1, Step: 1299/2949, Loss: 0.8350\n",
      "Epoch: 1, Step: 1300/2949, Loss: 0.8112\n",
      "Epoch: 1, Step: 1301/2949, Loss: 0.8799\n",
      "Epoch: 1, Step: 1302/2949, Loss: 0.8080\n",
      "Epoch: 1, Step: 1303/2949, Loss: 0.7931\n",
      "Epoch: 1, Step: 1304/2949, Loss: 0.7976\n",
      "Epoch: 1, Step: 1305/2949, Loss: 0.8663\n",
      "Epoch: 1, Step: 1306/2949, Loss: 0.8034\n",
      "Epoch: 1, Step: 1307/2949, Loss: 0.8272\n",
      "Epoch: 1, Step: 1308/2949, Loss: 0.8540\n",
      "Epoch: 1, Step: 1309/2949, Loss: 0.8499\n",
      "Epoch: 1, Step: 1310/2949, Loss: 0.8394\n",
      "Epoch: 1, Step: 1311/2949, Loss: 0.8747\n",
      "Epoch: 1, Step: 1312/2949, Loss: 0.8303\n",
      "Epoch: 1, Step: 1313/2949, Loss: 0.8911\n",
      "Epoch: 1, Step: 1314/2949, Loss: 0.8769\n",
      "Epoch: 1, Step: 1315/2949, Loss: 0.8453\n",
      "Epoch: 1, Step: 1316/2949, Loss: 0.8200\n",
      "Epoch: 1, Step: 1317/2949, Loss: 0.8058\n",
      "Epoch: 1, Step: 1318/2949, Loss: 0.8367\n",
      "Epoch: 1, Step: 1319/2949, Loss: 0.8947\n",
      "Epoch: 1, Step: 1320/2949, Loss: 0.8227\n",
      "Epoch: 1, Step: 1321/2949, Loss: 0.8725\n",
      "Epoch: 1, Step: 1322/2949, Loss: 0.8424\n",
      "Epoch: 1, Step: 1323/2949, Loss: 0.7896\n",
      "Epoch: 1, Step: 1324/2949, Loss: 0.8439\n",
      "Epoch: 1, Step: 1325/2949, Loss: 0.8338\n",
      "Epoch: 1, Step: 1326/2949, Loss: 0.8251\n",
      "Epoch: 1, Step: 1327/2949, Loss: 0.8185\n",
      "Epoch: 1, Step: 1328/2949, Loss: 0.8452\n",
      "Epoch: 1, Step: 1329/2949, Loss: 0.8686\n",
      "Epoch: 1, Step: 1330/2949, Loss: 0.8188\n",
      "Epoch: 1, Step: 1331/2949, Loss: 0.8395\n",
      "Epoch: 1, Step: 1332/2949, Loss: 0.8294\n",
      "Epoch: 1, Step: 1333/2949, Loss: 0.9088\n",
      "Epoch: 1, Step: 1334/2949, Loss: 0.8460\n",
      "Epoch: 1, Step: 1335/2949, Loss: 0.8670\n",
      "Epoch: 1, Step: 1336/2949, Loss: 0.8478\n",
      "Epoch: 1, Step: 1337/2949, Loss: 0.8746\n",
      "Epoch: 1, Step: 1338/2949, Loss: 0.8558\n",
      "Epoch: 1, Step: 1339/2949, Loss: 0.8734\n",
      "Epoch: 1, Step: 1340/2949, Loss: 0.8385\n",
      "Epoch: 1, Step: 1341/2949, Loss: 0.8305\n",
      "Epoch: 1, Step: 1342/2949, Loss: 0.8273\n",
      "Epoch: 1, Step: 1343/2949, Loss: 0.8754\n",
      "Epoch: 1, Step: 1344/2949, Loss: 0.9281\n",
      "Epoch: 1, Step: 1345/2949, Loss: 0.8525\n",
      "Epoch: 1, Step: 1346/2949, Loss: 0.8100\n",
      "Epoch: 1, Step: 1347/2949, Loss: 0.8314\n",
      "Epoch: 1, Step: 1348/2949, Loss: 0.8304\n",
      "Epoch: 1, Step: 1349/2949, Loss: 0.8556\n",
      "Epoch: 1, Step: 1350/2949, Loss: 0.8688\n",
      "Epoch: 1, Step: 1351/2949, Loss: 0.8403\n",
      "Epoch: 1, Step: 1352/2949, Loss: 0.8076\n",
      "Epoch: 1, Step: 1353/2949, Loss: 0.8733\n",
      "Epoch: 1, Step: 1354/2949, Loss: 0.8474\n",
      "Epoch: 1, Step: 1355/2949, Loss: 0.8790\n",
      "Epoch: 1, Step: 1356/2949, Loss: 0.8234\n",
      "Epoch: 1, Step: 1357/2949, Loss: 0.8413\n",
      "Epoch: 1, Step: 1358/2949, Loss: 0.8858\n",
      "Epoch: 1, Step: 1359/2949, Loss: 0.8621\n",
      "Epoch: 1, Step: 1360/2949, Loss: 0.8208\n",
      "Epoch: 1, Step: 1361/2949, Loss: 0.8515\n",
      "Epoch: 1, Step: 1362/2949, Loss: 0.8776\n",
      "Epoch: 1, Step: 1363/2949, Loss: 0.8948\n",
      "Epoch: 1, Step: 1364/2949, Loss: 0.8067\n",
      "Epoch: 1, Step: 1365/2949, Loss: 0.8987\n",
      "Epoch: 1, Step: 1366/2949, Loss: 0.8190\n",
      "Epoch: 1, Step: 1367/2949, Loss: 0.8325\n",
      "Epoch: 1, Step: 1368/2949, Loss: 0.8404\n",
      "Epoch: 1, Step: 1369/2949, Loss: 0.8520\n",
      "Epoch: 1, Step: 1370/2949, Loss: 0.8542\n",
      "Epoch: 1, Step: 1371/2949, Loss: 0.8341\n",
      "Epoch: 1, Step: 1372/2949, Loss: 0.8498\n",
      "Epoch: 1, Step: 1373/2949, Loss: 0.8862\n",
      "Epoch: 1, Step: 1374/2949, Loss: 0.8532\n",
      "Epoch: 1, Step: 1375/2949, Loss: 0.8672\n",
      "Epoch: 1, Step: 1376/2949, Loss: 0.8299\n",
      "Epoch: 1, Step: 1377/2949, Loss: 0.8216\n",
      "Epoch: 1, Step: 1378/2949, Loss: 0.8287\n",
      "Epoch: 1, Step: 1379/2949, Loss: 0.8796\n",
      "Epoch: 1, Step: 1380/2949, Loss: 0.8485\n",
      "Epoch: 1, Step: 1381/2949, Loss: 0.8242\n",
      "Epoch: 1, Step: 1382/2949, Loss: 0.8335\n",
      "Epoch: 1, Step: 1383/2949, Loss: 0.8043\n",
      "Epoch: 1, Step: 1384/2949, Loss: 0.8397\n",
      "Epoch: 1, Step: 1385/2949, Loss: 0.8493\n",
      "Epoch: 1, Step: 1386/2949, Loss: 0.8262\n",
      "Epoch: 1, Step: 1387/2949, Loss: 0.8584\n",
      "Epoch: 1, Step: 1388/2949, Loss: 0.8449\n",
      "Epoch: 1, Step: 1389/2949, Loss: 0.8619\n",
      "Epoch: 1, Step: 1390/2949, Loss: 0.8391\n",
      "Epoch: 1, Step: 1391/2949, Loss: 0.8235\n",
      "Epoch: 1, Step: 1392/2949, Loss: 0.8358\n",
      "Epoch: 1, Step: 1393/2949, Loss: 0.8821\n",
      "Epoch: 1, Step: 1394/2949, Loss: 0.9148\n",
      "Epoch: 1, Step: 1395/2949, Loss: 0.8530\n",
      "Epoch: 1, Step: 1396/2949, Loss: 0.8394\n",
      "Epoch: 1, Step: 1397/2949, Loss: 0.8735\n",
      "Epoch: 1, Step: 1398/2949, Loss: 0.8946\n",
      "Epoch: 1, Step: 1399/2949, Loss: 0.7836\n",
      "Epoch: 1, Step: 1400/2949, Loss: 0.8819\n",
      "Epoch: 1, Step: 1401/2949, Loss: 0.8994\n",
      "Epoch: 1, Step: 1402/2949, Loss: 0.8449\n",
      "Epoch: 1, Step: 1403/2949, Loss: 0.9100\n",
      "Epoch: 1, Step: 1404/2949, Loss: 0.8716\n",
      "Epoch: 1, Step: 1405/2949, Loss: 0.7952\n",
      "Epoch: 1, Step: 1406/2949, Loss: 0.8048\n",
      "Epoch: 1, Step: 1407/2949, Loss: 0.8496\n",
      "Epoch: 1, Step: 1408/2949, Loss: 0.8355\n",
      "Epoch: 1, Step: 1409/2949, Loss: 0.9392\n",
      "Epoch: 1, Step: 1410/2949, Loss: 0.9046\n",
      "Epoch: 1, Step: 1411/2949, Loss: 0.8653\n",
      "Epoch: 1, Step: 1412/2949, Loss: 0.8720\n",
      "Epoch: 1, Step: 1413/2949, Loss: 0.8597\n",
      "Epoch: 1, Step: 1414/2949, Loss: 0.8397\n",
      "Epoch: 1, Step: 1415/2949, Loss: 0.8701\n",
      "Epoch: 1, Step: 1416/2949, Loss: 0.8521\n",
      "Epoch: 1, Step: 1417/2949, Loss: 0.8796\n",
      "Epoch: 1, Step: 1418/2949, Loss: 0.8531\n",
      "Epoch: 1, Step: 1419/2949, Loss: 0.8553\n",
      "Epoch: 1, Step: 1420/2949, Loss: 0.8519\n",
      "Epoch: 1, Step: 1421/2949, Loss: 0.8501\n",
      "Epoch: 1, Step: 1422/2949, Loss: 0.8316\n",
      "Epoch: 1, Step: 1423/2949, Loss: 0.8266\n",
      "Epoch: 1, Step: 1424/2949, Loss: 0.8369\n",
      "Epoch: 1, Step: 1425/2949, Loss: 0.8108\n",
      "Epoch: 1, Step: 1426/2949, Loss: 0.8820\n",
      "Epoch: 1, Step: 1427/2949, Loss: 0.9037\n",
      "Epoch: 1, Step: 1428/2949, Loss: 0.9173\n",
      "Epoch: 1, Step: 1429/2949, Loss: 0.8794\n",
      "Epoch: 1, Step: 1430/2949, Loss: 0.8322\n",
      "Epoch: 1, Step: 1431/2949, Loss: 0.8196\n",
      "Epoch: 1, Step: 1432/2949, Loss: 0.8585\n",
      "Epoch: 1, Step: 1433/2949, Loss: 0.9004\n",
      "Epoch: 1, Step: 1434/2949, Loss: 0.8502\n",
      "Epoch: 1, Step: 1435/2949, Loss: 0.8556\n",
      "Epoch: 1, Step: 1436/2949, Loss: 0.8503\n",
      "Epoch: 1, Step: 1437/2949, Loss: 0.8395\n",
      "Epoch: 1, Step: 1438/2949, Loss: 0.8922\n",
      "Epoch: 1, Step: 1439/2949, Loss: 0.8799\n",
      "Epoch: 1, Step: 1440/2949, Loss: 0.8477\n",
      "Epoch: 1, Step: 1441/2949, Loss: 0.7972\n",
      "Epoch: 1, Step: 1442/2949, Loss: 0.8405\n",
      "Epoch: 1, Step: 1443/2949, Loss: 0.8454\n",
      "Epoch: 1, Step: 1444/2949, Loss: 0.8337\n",
      "Epoch: 1, Step: 1445/2949, Loss: 0.8413\n",
      "Epoch: 1, Step: 1446/2949, Loss: 0.8472\n",
      "Epoch: 1, Step: 1447/2949, Loss: 0.7890\n",
      "Epoch: 1, Step: 1448/2949, Loss: 0.8773\n",
      "Epoch: 1, Step: 1449/2949, Loss: 0.8056\n",
      "Epoch: 1, Step: 1450/2949, Loss: 0.8421\n",
      "Epoch: 1, Step: 1451/2949, Loss: 0.8383\n",
      "Epoch: 1, Step: 1452/2949, Loss: 0.8567\n",
      "Epoch: 1, Step: 1453/2949, Loss: 0.8062\n",
      "Epoch: 1, Step: 1454/2949, Loss: 0.8474\n",
      "Epoch: 1, Step: 1455/2949, Loss: 0.7929\n",
      "Epoch: 1, Step: 1456/2949, Loss: 0.8945\n",
      "Epoch: 1, Step: 1457/2949, Loss: 0.8420\n",
      "Epoch: 1, Step: 1458/2949, Loss: 0.7752\n",
      "Epoch: 1, Step: 1459/2949, Loss: 0.8722\n",
      "Epoch: 1, Step: 1460/2949, Loss: 0.8424\n",
      "Epoch: 1, Step: 1461/2949, Loss: 0.8695\n",
      "Epoch: 1, Step: 1462/2949, Loss: 0.8428\n",
      "Epoch: 1, Step: 1463/2949, Loss: 0.8664\n",
      "Epoch: 1, Step: 1464/2949, Loss: 0.7880\n",
      "Epoch: 1, Step: 1465/2949, Loss: 0.8680\n",
      "Epoch: 1, Step: 1466/2949, Loss: 0.8666\n",
      "Epoch: 1, Step: 1467/2949, Loss: 0.8743\n",
      "Epoch: 1, Step: 1468/2949, Loss: 0.8591\n",
      "Epoch: 1, Step: 1469/2949, Loss: 0.8072\n",
      "Epoch: 1, Step: 1470/2949, Loss: 0.8482\n",
      "Epoch: 1, Step: 1471/2949, Loss: 0.8478\n",
      "Epoch: 1, Step: 1472/2949, Loss: 0.8649\n",
      "Epoch: 1, Step: 1473/2949, Loss: 0.8269\n",
      "Epoch: 1, Step: 1474/2949, Loss: 0.9082\n",
      "Epoch: 1, Step: 1475/2949, Loss: 0.7987\n",
      "Epoch: 1, Step: 1476/2949, Loss: 0.8940\n",
      "Epoch: 1, Step: 1477/2949, Loss: 0.9087\n",
      "Epoch: 1, Step: 1478/2949, Loss: 0.8683\n",
      "Epoch: 1, Step: 1479/2949, Loss: 0.9060\n",
      "Epoch: 1, Step: 1480/2949, Loss: 0.8700\n",
      "Epoch: 1, Step: 1481/2949, Loss: 0.8343\n",
      "Epoch: 1, Step: 1482/2949, Loss: 0.8171\n",
      "Epoch: 1, Step: 1483/2949, Loss: 0.8678\n",
      "Epoch: 1, Step: 1484/2949, Loss: 0.8402\n",
      "Epoch: 1, Step: 1485/2949, Loss: 0.8646\n",
      "Epoch: 1, Step: 1486/2949, Loss: 0.8854\n",
      "Epoch: 1, Step: 1487/2949, Loss: 0.7956\n",
      "Epoch: 1, Step: 1488/2949, Loss: 0.8476\n",
      "Epoch: 1, Step: 1489/2949, Loss: 0.8820\n",
      "Epoch: 1, Step: 1490/2949, Loss: 0.8398\n",
      "Epoch: 1, Step: 1491/2949, Loss: 0.8543\n",
      "Epoch: 1, Step: 1492/2949, Loss: 0.9014\n",
      "Epoch: 1, Step: 1493/2949, Loss: 0.9344\n",
      "Epoch: 1, Step: 1494/2949, Loss: 0.8917\n",
      "Epoch: 1, Step: 1495/2949, Loss: 0.8508\n",
      "Epoch: 1, Step: 1496/2949, Loss: 0.8140\n",
      "Epoch: 1, Step: 1497/2949, Loss: 0.8587\n",
      "Epoch: 1, Step: 1498/2949, Loss: 0.8893\n",
      "Epoch: 1, Step: 1499/2949, Loss: 0.8367\n",
      "Epoch: 1, Step: 1500/2949, Loss: 0.8348\n",
      "Epoch: 1, Step: 1501/2949, Loss: 0.8736\n",
      "Epoch: 1, Step: 1502/2949, Loss: 0.8236\n",
      "Epoch: 1, Step: 1503/2949, Loss: 0.8477\n",
      "Epoch: 1, Step: 1504/2949, Loss: 0.8839\n",
      "Epoch: 1, Step: 1505/2949, Loss: 0.8750\n",
      "Epoch: 1, Step: 1506/2949, Loss: 0.9013\n",
      "Epoch: 1, Step: 1507/2949, Loss: 0.8070\n",
      "Epoch: 1, Step: 1508/2949, Loss: 0.8891\n",
      "Epoch: 1, Step: 1509/2949, Loss: 0.8126\n",
      "Epoch: 1, Step: 1510/2949, Loss: 0.9056\n",
      "Epoch: 1, Step: 1511/2949, Loss: 0.8673\n",
      "Epoch: 1, Step: 1512/2949, Loss: 0.8640\n",
      "Epoch: 1, Step: 1513/2949, Loss: 0.8965\n",
      "Epoch: 1, Step: 1514/2949, Loss: 0.8253\n",
      "Epoch: 1, Step: 1515/2949, Loss: 0.8090\n",
      "Epoch: 1, Step: 1516/2949, Loss: 0.8530\n",
      "Epoch: 1, Step: 1517/2949, Loss: 0.8657\n",
      "Epoch: 1, Step: 1518/2949, Loss: 0.8087\n",
      "Epoch: 1, Step: 1519/2949, Loss: 0.8386\n",
      "Epoch: 1, Step: 1520/2949, Loss: 0.9127\n",
      "Epoch: 1, Step: 1521/2949, Loss: 0.8695\n",
      "Epoch: 1, Step: 1522/2949, Loss: 0.8644\n",
      "Epoch: 1, Step: 1523/2949, Loss: 0.8250\n",
      "Epoch: 1, Step: 1524/2949, Loss: 0.8397\n",
      "Epoch: 1, Step: 1525/2949, Loss: 0.8636\n",
      "Epoch: 1, Step: 1526/2949, Loss: 0.7833\n",
      "Epoch: 1, Step: 1527/2949, Loss: 0.8241\n",
      "Epoch: 1, Step: 1528/2949, Loss: 0.9056\n",
      "Epoch: 1, Step: 1529/2949, Loss: 0.8155\n",
      "Epoch: 1, Step: 1530/2949, Loss: 0.8526\n",
      "Epoch: 1, Step: 1531/2949, Loss: 0.8089\n",
      "Epoch: 1, Step: 1532/2949, Loss: 0.8915\n",
      "Epoch: 1, Step: 1533/2949, Loss: 0.8111\n",
      "Epoch: 1, Step: 1534/2949, Loss: 0.8617\n",
      "Epoch: 1, Step: 1535/2949, Loss: 0.9017\n",
      "Epoch: 1, Step: 1536/2949, Loss: 0.9001\n",
      "Epoch: 1, Step: 1537/2949, Loss: 0.8419\n",
      "Epoch: 1, Step: 1538/2949, Loss: 0.8389\n",
      "Epoch: 1, Step: 1539/2949, Loss: 0.8696\n",
      "Epoch: 1, Step: 1540/2949, Loss: 0.8084\n",
      "Epoch: 1, Step: 1541/2949, Loss: 0.8104\n",
      "Epoch: 1, Step: 1542/2949, Loss: 0.8384\n",
      "Epoch: 1, Step: 1543/2949, Loss: 0.9136\n",
      "Epoch: 1, Step: 1544/2949, Loss: 0.8287\n",
      "Epoch: 1, Step: 1545/2949, Loss: 0.8030\n",
      "Epoch: 1, Step: 1546/2949, Loss: 0.8602\n",
      "Epoch: 1, Step: 1547/2949, Loss: 0.8849\n",
      "Epoch: 1, Step: 1548/2949, Loss: 0.9270\n",
      "Epoch: 1, Step: 1549/2949, Loss: 0.8579\n",
      "Epoch: 1, Step: 1550/2949, Loss: 0.8423\n",
      "Epoch: 1, Step: 1551/2949, Loss: 0.9030\n",
      "Epoch: 1, Step: 1552/2949, Loss: 0.8428\n",
      "Epoch: 1, Step: 1553/2949, Loss: 0.8858\n",
      "Epoch: 1, Step: 1554/2949, Loss: 0.8509\n",
      "Epoch: 1, Step: 1555/2949, Loss: 0.8104\n",
      "Epoch: 1, Step: 1556/2949, Loss: 0.8735\n",
      "Epoch: 1, Step: 1557/2949, Loss: 0.8724\n",
      "Epoch: 1, Step: 1558/2949, Loss: 0.8432\n",
      "Epoch: 1, Step: 1559/2949, Loss: 0.8638\n",
      "Epoch: 1, Step: 1560/2949, Loss: 0.8418\n",
      "Epoch: 1, Step: 1561/2949, Loss: 0.8747\n",
      "Epoch: 1, Step: 1562/2949, Loss: 0.7850\n",
      "Epoch: 1, Step: 1563/2949, Loss: 0.8642\n",
      "Epoch: 1, Step: 1564/2949, Loss: 0.8193\n",
      "Epoch: 1, Step: 1565/2949, Loss: 0.8520\n",
      "Epoch: 1, Step: 1566/2949, Loss: 0.8592\n",
      "Epoch: 1, Step: 1567/2949, Loss: 0.8521\n",
      "Epoch: 1, Step: 1568/2949, Loss: 0.8115\n",
      "Epoch: 1, Step: 1569/2949, Loss: 0.8427\n",
      "Epoch: 1, Step: 1570/2949, Loss: 0.8706\n",
      "Epoch: 1, Step: 1571/2949, Loss: 0.8259\n",
      "Epoch: 1, Step: 1572/2949, Loss: 0.8596\n",
      "Epoch: 1, Step: 1573/2949, Loss: 0.8860\n",
      "Epoch: 1, Step: 1574/2949, Loss: 0.8500\n",
      "Epoch: 1, Step: 1575/2949, Loss: 0.8438\n",
      "Epoch: 1, Step: 1576/2949, Loss: 0.8788\n",
      "Epoch: 1, Step: 1577/2949, Loss: 0.8371\n",
      "Epoch: 1, Step: 1578/2949, Loss: 0.8480\n",
      "Epoch: 1, Step: 1579/2949, Loss: 0.8218\n",
      "Epoch: 1, Step: 1580/2949, Loss: 0.8372\n",
      "Epoch: 1, Step: 1581/2949, Loss: 0.8437\n",
      "Epoch: 1, Step: 1582/2949, Loss: 0.9188\n",
      "Epoch: 1, Step: 1583/2949, Loss: 0.8743\n",
      "Epoch: 1, Step: 1584/2949, Loss: 0.8579\n",
      "Epoch: 1, Step: 1585/2949, Loss: 0.8511\n",
      "Epoch: 1, Step: 1586/2949, Loss: 0.8692\n",
      "Epoch: 1, Step: 1587/2949, Loss: 0.8344\n",
      "Epoch: 1, Step: 1588/2949, Loss: 0.8874\n",
      "Epoch: 1, Step: 1589/2949, Loss: 0.8392\n",
      "Epoch: 1, Step: 1590/2949, Loss: 0.8301\n",
      "Epoch: 1, Step: 1591/2949, Loss: 0.8943\n",
      "Epoch: 1, Step: 1592/2949, Loss: 0.8375\n",
      "Epoch: 1, Step: 1593/2949, Loss: 0.9060\n",
      "Epoch: 1, Step: 1594/2949, Loss: 0.8930\n",
      "Epoch: 1, Step: 1595/2949, Loss: 0.8833\n",
      "Epoch: 1, Step: 1596/2949, Loss: 0.8453\n",
      "Epoch: 1, Step: 1597/2949, Loss: 0.8356\n",
      "Epoch: 1, Step: 1598/2949, Loss: 0.8837\n",
      "Epoch: 1, Step: 1599/2949, Loss: 0.8813\n",
      "Epoch: 1, Step: 1600/2949, Loss: 0.8555\n",
      "Epoch: 1, Step: 1601/2949, Loss: 0.9084\n",
      "Epoch: 1, Step: 1602/2949, Loss: 0.7795\n",
      "Epoch: 1, Step: 1603/2949, Loss: 0.8990\n",
      "Epoch: 1, Step: 1604/2949, Loss: 0.8325\n",
      "Epoch: 1, Step: 1605/2949, Loss: 0.9139\n",
      "Epoch: 1, Step: 1606/2949, Loss: 0.8530\n",
      "Epoch: 1, Step: 1607/2949, Loss: 0.8745\n",
      "Epoch: 1, Step: 1608/2949, Loss: 0.8627\n",
      "Epoch: 1, Step: 1609/2949, Loss: 0.8386\n",
      "Epoch: 1, Step: 1610/2949, Loss: 0.8241\n",
      "Epoch: 1, Step: 1611/2949, Loss: 0.7695\n",
      "Epoch: 1, Step: 1612/2949, Loss: 0.8520\n",
      "Epoch: 1, Step: 1613/2949, Loss: 0.8513\n",
      "Epoch: 1, Step: 1614/2949, Loss: 0.8125\n",
      "Epoch: 1, Step: 1615/2949, Loss: 0.8316\n",
      "Epoch: 1, Step: 1616/2949, Loss: 0.8567\n",
      "Epoch: 1, Step: 1617/2949, Loss: 0.8321\n",
      "Epoch: 1, Step: 1618/2949, Loss: 0.8515\n",
      "Epoch: 1, Step: 1619/2949, Loss: 0.7931\n",
      "Epoch: 1, Step: 1620/2949, Loss: 0.8364\n",
      "Epoch: 1, Step: 1621/2949, Loss: 0.8305\n",
      "Epoch: 1, Step: 1622/2949, Loss: 0.8442\n",
      "Epoch: 1, Step: 1623/2949, Loss: 0.8494\n",
      "Epoch: 1, Step: 1624/2949, Loss: 0.9111\n",
      "Epoch: 1, Step: 1625/2949, Loss: 0.8513\n",
      "Epoch: 1, Step: 1626/2949, Loss: 0.8569\n",
      "Epoch: 1, Step: 1627/2949, Loss: 0.8826\n",
      "Epoch: 1, Step: 1628/2949, Loss: 0.8256\n",
      "Epoch: 1, Step: 1629/2949, Loss: 0.8411\n",
      "Epoch: 1, Step: 1630/2949, Loss: 0.8088\n",
      "Epoch: 1, Step: 1631/2949, Loss: 0.8067\n",
      "Epoch: 1, Step: 1632/2949, Loss: 0.8719\n",
      "Epoch: 1, Step: 1633/2949, Loss: 0.7995\n",
      "Epoch: 1, Step: 1634/2949, Loss: 0.8224\n",
      "Epoch: 1, Step: 1635/2949, Loss: 0.8684\n",
      "Epoch: 1, Step: 1636/2949, Loss: 0.8711\n",
      "Epoch: 1, Step: 1637/2949, Loss: 0.8912\n",
      "Epoch: 1, Step: 1638/2949, Loss: 0.8204\n",
      "Epoch: 1, Step: 1639/2949, Loss: 0.8563\n",
      "Epoch: 1, Step: 1640/2949, Loss: 0.8402\n",
      "Epoch: 1, Step: 1641/2949, Loss: 0.9033\n",
      "Epoch: 1, Step: 1642/2949, Loss: 0.8232\n",
      "Epoch: 1, Step: 1643/2949, Loss: 0.8613\n",
      "Epoch: 1, Step: 1644/2949, Loss: 0.8433\n",
      "Epoch: 1, Step: 1645/2949, Loss: 0.7866\n",
      "Epoch: 1, Step: 1646/2949, Loss: 0.8792\n",
      "Epoch: 1, Step: 1647/2949, Loss: 0.8103\n",
      "Epoch: 1, Step: 1648/2949, Loss: 0.8373\n",
      "Epoch: 1, Step: 1649/2949, Loss: 0.8776\n",
      "Epoch: 1, Step: 1650/2949, Loss: 0.8394\n",
      "Epoch: 1, Step: 1651/2949, Loss: 0.8279\n",
      "Epoch: 1, Step: 1652/2949, Loss: 0.8644\n",
      "Epoch: 1, Step: 1653/2949, Loss: 0.8420\n",
      "Epoch: 1, Step: 1654/2949, Loss: 0.8611\n",
      "Epoch: 1, Step: 1655/2949, Loss: 0.8087\n",
      "Epoch: 1, Step: 1656/2949, Loss: 0.8201\n",
      "Epoch: 1, Step: 1657/2949, Loss: 0.9053\n",
      "Epoch: 1, Step: 1658/2949, Loss: 0.8698\n",
      "Epoch: 1, Step: 1659/2949, Loss: 0.7881\n",
      "Epoch: 1, Step: 1660/2949, Loss: 0.8344\n",
      "Epoch: 1, Step: 1661/2949, Loss: 0.8759\n",
      "Epoch: 1, Step: 1662/2949, Loss: 0.8598\n",
      "Epoch: 1, Step: 1663/2949, Loss: 0.8609\n",
      "Epoch: 1, Step: 1664/2949, Loss: 0.8735\n",
      "Epoch: 1, Step: 1665/2949, Loss: 0.8753\n",
      "Epoch: 1, Step: 1666/2949, Loss: 0.8653\n",
      "Epoch: 1, Step: 1667/2949, Loss: 0.8407\n",
      "Epoch: 1, Step: 1668/2949, Loss: 0.8117\n",
      "Epoch: 1, Step: 1669/2949, Loss: 0.8147\n",
      "Epoch: 1, Step: 1670/2949, Loss: 0.9065\n",
      "Epoch: 1, Step: 1671/2949, Loss: 0.7848\n",
      "Epoch: 1, Step: 1672/2949, Loss: 0.8666\n",
      "Epoch: 1, Step: 1673/2949, Loss: 0.8629\n",
      "Epoch: 1, Step: 1674/2949, Loss: 0.8090\n",
      "Epoch: 1, Step: 1675/2949, Loss: 0.8666\n",
      "Epoch: 1, Step: 1676/2949, Loss: 0.8613\n",
      "Epoch: 1, Step: 1677/2949, Loss: 0.7982\n",
      "Epoch: 1, Step: 1678/2949, Loss: 0.7916\n",
      "Epoch: 1, Step: 1679/2949, Loss: 0.8513\n",
      "Epoch: 1, Step: 1680/2949, Loss: 0.8389\n",
      "Epoch: 1, Step: 1681/2949, Loss: 0.8688\n",
      "Epoch: 1, Step: 1682/2949, Loss: 0.8561\n",
      "Epoch: 1, Step: 1683/2949, Loss: 0.8309\n",
      "Epoch: 1, Step: 1684/2949, Loss: 0.7981\n",
      "Epoch: 1, Step: 1685/2949, Loss: 0.8540\n",
      "Epoch: 1, Step: 1686/2949, Loss: 0.8502\n",
      "Epoch: 1, Step: 1687/2949, Loss: 0.8648\n",
      "Epoch: 1, Step: 1688/2949, Loss: 0.8202\n",
      "Epoch: 1, Step: 1689/2949, Loss: 0.8174\n",
      "Epoch: 1, Step: 1690/2949, Loss: 0.8305\n",
      "Epoch: 1, Step: 1691/2949, Loss: 0.8144\n",
      "Epoch: 1, Step: 1692/2949, Loss: 0.9177\n",
      "Epoch: 1, Step: 1693/2949, Loss: 0.9044\n",
      "Epoch: 1, Step: 1694/2949, Loss: 0.8989\n",
      "Epoch: 1, Step: 1695/2949, Loss: 0.8588\n",
      "Epoch: 1, Step: 1696/2949, Loss: 0.8620\n",
      "Epoch: 1, Step: 1697/2949, Loss: 0.7939\n",
      "Epoch: 1, Step: 1698/2949, Loss: 0.8283\n",
      "Epoch: 1, Step: 1699/2949, Loss: 0.8607\n",
      "Epoch: 1, Step: 1700/2949, Loss: 0.8618\n",
      "Epoch: 1, Step: 1701/2949, Loss: 0.8178\n",
      "Epoch: 1, Step: 1702/2949, Loss: 0.8202\n",
      "Epoch: 1, Step: 1703/2949, Loss: 0.8375\n",
      "Epoch: 1, Step: 1704/2949, Loss: 0.8268\n",
      "Epoch: 1, Step: 1705/2949, Loss: 0.8562\n",
      "Epoch: 1, Step: 1706/2949, Loss: 0.8341\n",
      "Epoch: 1, Step: 1707/2949, Loss: 0.8392\n",
      "Epoch: 1, Step: 1708/2949, Loss: 0.8374\n",
      "Epoch: 1, Step: 1709/2949, Loss: 0.8242\n",
      "Epoch: 1, Step: 1710/2949, Loss: 0.8590\n",
      "Epoch: 1, Step: 1711/2949, Loss: 0.8289\n",
      "Epoch: 1, Step: 1712/2949, Loss: 0.7992\n",
      "Epoch: 1, Step: 1713/2949, Loss: 0.8648\n",
      "Epoch: 1, Step: 1714/2949, Loss: 0.9139\n",
      "Epoch: 1, Step: 1715/2949, Loss: 0.8836\n",
      "Epoch: 1, Step: 1716/2949, Loss: 0.8525\n",
      "Epoch: 1, Step: 1717/2949, Loss: 0.7930\n",
      "Epoch: 1, Step: 1718/2949, Loss: 0.8649\n",
      "Epoch: 1, Step: 1719/2949, Loss: 0.8402\n",
      "Epoch: 1, Step: 1720/2949, Loss: 0.8490\n",
      "Epoch: 1, Step: 1721/2949, Loss: 0.8292\n",
      "Epoch: 1, Step: 1722/2949, Loss: 0.8455\n",
      "Epoch: 1, Step: 1723/2949, Loss: 0.8577\n",
      "Epoch: 1, Step: 1724/2949, Loss: 0.8400\n",
      "Epoch: 1, Step: 1725/2949, Loss: 0.8639\n",
      "Epoch: 1, Step: 1726/2949, Loss: 0.8321\n",
      "Epoch: 1, Step: 1727/2949, Loss: 0.8266\n",
      "Epoch: 1, Step: 1728/2949, Loss: 0.8645\n",
      "Epoch: 1, Step: 1729/2949, Loss: 0.8975\n",
      "Epoch: 1, Step: 1730/2949, Loss: 0.8834\n",
      "Epoch: 1, Step: 1731/2949, Loss: 0.8403\n",
      "Epoch: 1, Step: 1732/2949, Loss: 0.8082\n",
      "Epoch: 1, Step: 1733/2949, Loss: 0.8552\n",
      "Epoch: 1, Step: 1734/2949, Loss: 0.8705\n",
      "Epoch: 1, Step: 1735/2949, Loss: 0.8498\n",
      "Epoch: 1, Step: 1736/2949, Loss: 0.8778\n",
      "Epoch: 1, Step: 1737/2949, Loss: 0.8469\n",
      "Epoch: 1, Step: 1738/2949, Loss: 0.8884\n",
      "Epoch: 1, Step: 1739/2949, Loss: 0.8172\n",
      "Epoch: 1, Step: 1740/2949, Loss: 0.8204\n",
      "Epoch: 1, Step: 1741/2949, Loss: 0.8629\n",
      "Epoch: 1, Step: 1742/2949, Loss: 0.8234\n",
      "Epoch: 1, Step: 1743/2949, Loss: 0.8430\n",
      "Epoch: 1, Step: 1744/2949, Loss: 0.8920\n",
      "Epoch: 1, Step: 1745/2949, Loss: 0.8548\n",
      "Epoch: 1, Step: 1746/2949, Loss: 0.8322\n",
      "Epoch: 1, Step: 1747/2949, Loss: 0.8603\n",
      "Epoch: 1, Step: 1748/2949, Loss: 0.8283\n",
      "Epoch: 1, Step: 1749/2949, Loss: 0.7902\n",
      "Epoch: 1, Step: 1750/2949, Loss: 0.9110\n",
      "Epoch: 1, Step: 1751/2949, Loss: 0.8549\n",
      "Epoch: 1, Step: 1752/2949, Loss: 0.8105\n",
      "Epoch: 1, Step: 1753/2949, Loss: 0.8212\n",
      "Epoch: 1, Step: 1754/2949, Loss: 0.8755\n",
      "Epoch: 1, Step: 1755/2949, Loss: 0.8871\n",
      "Epoch: 1, Step: 1756/2949, Loss: 0.8558\n",
      "Epoch: 1, Step: 1757/2949, Loss: 0.7997\n",
      "Epoch: 1, Step: 1758/2949, Loss: 0.8097\n",
      "Epoch: 1, Step: 1759/2949, Loss: 0.8332\n",
      "Epoch: 1, Step: 1760/2949, Loss: 0.8326\n",
      "Epoch: 1, Step: 1761/2949, Loss: 0.8642\n",
      "Epoch: 1, Step: 1762/2949, Loss: 0.8445\n",
      "Epoch: 1, Step: 1763/2949, Loss: 0.8155\n",
      "Epoch: 1, Step: 1764/2949, Loss: 0.8356\n",
      "Epoch: 1, Step: 1765/2949, Loss: 0.8373\n",
      "Epoch: 1, Step: 1766/2949, Loss: 0.8204\n",
      "Epoch: 1, Step: 1767/2949, Loss: 0.8265\n",
      "Epoch: 1, Step: 1768/2949, Loss: 0.8332\n",
      "Epoch: 1, Step: 1769/2949, Loss: 0.8520\n",
      "Epoch: 1, Step: 1770/2949, Loss: 0.8593\n",
      "Epoch: 1, Step: 1771/2949, Loss: 0.8656\n",
      "Epoch: 1, Step: 1772/2949, Loss: 0.8448\n",
      "Epoch: 1, Step: 1773/2949, Loss: 0.7945\n",
      "Epoch: 1, Step: 1774/2949, Loss: 0.8332\n",
      "Epoch: 1, Step: 1775/2949, Loss: 0.8813\n",
      "Epoch: 1, Step: 1776/2949, Loss: 0.8757\n",
      "Epoch: 1, Step: 1777/2949, Loss: 0.8701\n",
      "Epoch: 1, Step: 1778/2949, Loss: 0.7843\n",
      "Epoch: 1, Step: 1779/2949, Loss: 0.8880\n",
      "Epoch: 1, Step: 1780/2949, Loss: 0.8618\n",
      "Epoch: 1, Step: 1781/2949, Loss: 0.8158\n",
      "Epoch: 1, Step: 1782/2949, Loss: 0.8765\n",
      "Epoch: 1, Step: 1783/2949, Loss: 0.8341\n",
      "Epoch: 1, Step: 1784/2949, Loss: 0.8384\n",
      "Epoch: 1, Step: 1785/2949, Loss: 0.8719\n",
      "Epoch: 1, Step: 1786/2949, Loss: 0.8754\n",
      "Epoch: 1, Step: 1787/2949, Loss: 0.7699\n",
      "Epoch: 1, Step: 1788/2949, Loss: 0.8295\n",
      "Epoch: 1, Step: 1789/2949, Loss: 0.8125\n",
      "Epoch: 1, Step: 1790/2949, Loss: 0.8484\n",
      "Epoch: 1, Step: 1791/2949, Loss: 0.8688\n",
      "Epoch: 1, Step: 1792/2949, Loss: 0.8672\n",
      "Epoch: 1, Step: 1793/2949, Loss: 0.8451\n",
      "Epoch: 1, Step: 1794/2949, Loss: 0.8124\n",
      "Epoch: 1, Step: 1795/2949, Loss: 0.7915\n",
      "Epoch: 1, Step: 1796/2949, Loss: 0.8409\n",
      "Epoch: 1, Step: 1797/2949, Loss: 0.8807\n",
      "Epoch: 1, Step: 1798/2949, Loss: 0.8473\n",
      "Epoch: 1, Step: 1799/2949, Loss: 0.8604\n",
      "Epoch: 1, Step: 1800/2949, Loss: 0.8091\n",
      "Epoch: 1, Step: 1801/2949, Loss: 0.8821\n",
      "Epoch: 1, Step: 1802/2949, Loss: 0.8523\n",
      "Epoch: 1, Step: 1803/2949, Loss: 0.8259\n",
      "Epoch: 1, Step: 1804/2949, Loss: 0.8409\n",
      "Epoch: 1, Step: 1805/2949, Loss: 0.8499\n",
      "Epoch: 1, Step: 1806/2949, Loss: 0.8345\n",
      "Epoch: 1, Step: 1807/2949, Loss: 0.8479\n",
      "Epoch: 1, Step: 1808/2949, Loss: 0.8347\n",
      "Epoch: 1, Step: 1809/2949, Loss: 0.8524\n",
      "Epoch: 1, Step: 1810/2949, Loss: 0.8331\n",
      "Epoch: 1, Step: 1811/2949, Loss: 0.9119\n",
      "Epoch: 1, Step: 1812/2949, Loss: 0.8492\n",
      "Epoch: 1, Step: 1813/2949, Loss: 0.8671\n",
      "Epoch: 1, Step: 1814/2949, Loss: 0.8481\n",
      "Epoch: 1, Step: 1815/2949, Loss: 0.8704\n",
      "Epoch: 1, Step: 1816/2949, Loss: 0.8028\n",
      "Epoch: 1, Step: 1817/2949, Loss: 0.8435\n",
      "Epoch: 1, Step: 1818/2949, Loss: 0.8153\n",
      "Epoch: 1, Step: 1819/2949, Loss: 0.8462\n",
      "Epoch: 1, Step: 1820/2949, Loss: 0.7962\n",
      "Epoch: 1, Step: 1821/2949, Loss: 0.8654\n",
      "Epoch: 1, Step: 1822/2949, Loss: 0.8900\n",
      "Epoch: 1, Step: 1823/2949, Loss: 0.8583\n",
      "Epoch: 1, Step: 1824/2949, Loss: 0.8261\n",
      "Epoch: 1, Step: 1825/2949, Loss: 0.8818\n",
      "Epoch: 1, Step: 1826/2949, Loss: 0.8714\n",
      "Epoch: 1, Step: 1827/2949, Loss: 0.7635\n",
      "Epoch: 1, Step: 1828/2949, Loss: 0.8700\n",
      "Epoch: 1, Step: 1829/2949, Loss: 0.8189\n",
      "Epoch: 1, Step: 1830/2949, Loss: 0.8519\n",
      "Epoch: 1, Step: 1831/2949, Loss: 0.8589\n",
      "Epoch: 1, Step: 1832/2949, Loss: 0.8344\n",
      "Epoch: 1, Step: 1833/2949, Loss: 0.7879\n",
      "Epoch: 1, Step: 1834/2949, Loss: 0.8402\n",
      "Epoch: 1, Step: 1835/2949, Loss: 0.8587\n",
      "Epoch: 1, Step: 1836/2949, Loss: 0.8071\n",
      "Epoch: 1, Step: 1837/2949, Loss: 0.8127\n",
      "Epoch: 1, Step: 1838/2949, Loss: 0.8365\n",
      "Epoch: 1, Step: 1839/2949, Loss: 0.8622\n",
      "Epoch: 1, Step: 1840/2949, Loss: 0.8459\n",
      "Epoch: 1, Step: 1841/2949, Loss: 0.7928\n",
      "Epoch: 1, Step: 1842/2949, Loss: 0.8208\n",
      "Epoch: 1, Step: 1843/2949, Loss: 0.8402\n",
      "Epoch: 1, Step: 1844/2949, Loss: 0.8148\n",
      "Epoch: 1, Step: 1845/2949, Loss: 0.8247\n",
      "Epoch: 1, Step: 1846/2949, Loss: 0.8466\n",
      "Epoch: 1, Step: 1847/2949, Loss: 0.8667\n",
      "Epoch: 1, Step: 1848/2949, Loss: 0.8235\n",
      "Epoch: 1, Step: 1849/2949, Loss: 0.8560\n",
      "Epoch: 1, Step: 1850/2949, Loss: 0.8004\n",
      "Epoch: 1, Step: 1851/2949, Loss: 0.8570\n",
      "Epoch: 1, Step: 1852/2949, Loss: 0.8360\n",
      "Epoch: 1, Step: 1853/2949, Loss: 0.8318\n",
      "Epoch: 1, Step: 1854/2949, Loss: 0.8701\n",
      "Epoch: 1, Step: 1855/2949, Loss: 0.7941\n",
      "Epoch: 1, Step: 1856/2949, Loss: 0.8678\n",
      "Epoch: 1, Step: 1857/2949, Loss: 0.8050\n",
      "Epoch: 1, Step: 1858/2949, Loss: 0.8184\n",
      "Epoch: 1, Step: 1859/2949, Loss: 0.8624\n",
      "Epoch: 1, Step: 1860/2949, Loss: 0.8378\n",
      "Epoch: 1, Step: 1861/2949, Loss: 0.8470\n",
      "Epoch: 1, Step: 1862/2949, Loss: 0.8321\n",
      "Epoch: 1, Step: 1863/2949, Loss: 0.8312\n",
      "Epoch: 1, Step: 1864/2949, Loss: 0.8464\n",
      "Epoch: 1, Step: 1865/2949, Loss: 0.9114\n",
      "Epoch: 1, Step: 1866/2949, Loss: 0.8435\n",
      "Epoch: 1, Step: 1867/2949, Loss: 0.7987\n",
      "Epoch: 1, Step: 1868/2949, Loss: 0.8371\n",
      "Epoch: 1, Step: 1869/2949, Loss: 0.8507\n",
      "Epoch: 1, Step: 1870/2949, Loss: 0.8798\n",
      "Epoch: 1, Step: 1871/2949, Loss: 0.8327\n",
      "Epoch: 1, Step: 1872/2949, Loss: 0.8766\n",
      "Epoch: 1, Step: 1873/2949, Loss: 0.8279\n",
      "Epoch: 1, Step: 1874/2949, Loss: 0.8109\n",
      "Epoch: 1, Step: 1875/2949, Loss: 0.8329\n",
      "Epoch: 1, Step: 1876/2949, Loss: 0.8573\n",
      "Epoch: 1, Step: 1877/2949, Loss: 0.9242\n",
      "Epoch: 1, Step: 1878/2949, Loss: 0.8598\n",
      "Epoch: 1, Step: 1879/2949, Loss: 0.7866\n",
      "Epoch: 1, Step: 1880/2949, Loss: 0.8519\n",
      "Epoch: 1, Step: 1881/2949, Loss: 0.8457\n",
      "Epoch: 1, Step: 1882/2949, Loss: 0.8696\n",
      "Epoch: 1, Step: 1883/2949, Loss: 0.8725\n",
      "Epoch: 1, Step: 1884/2949, Loss: 0.8008\n",
      "Epoch: 1, Step: 1885/2949, Loss: 0.9097\n",
      "Epoch: 1, Step: 1886/2949, Loss: 0.8443\n",
      "Epoch: 1, Step: 1887/2949, Loss: 0.8335\n",
      "Epoch: 1, Step: 1888/2949, Loss: 0.8977\n",
      "Epoch: 1, Step: 1889/2949, Loss: 0.8345\n",
      "Epoch: 1, Step: 1890/2949, Loss: 0.8506\n",
      "Epoch: 1, Step: 1891/2949, Loss: 0.8602\n",
      "Epoch: 1, Step: 1892/2949, Loss: 0.8382\n",
      "Epoch: 1, Step: 1893/2949, Loss: 0.9165\n",
      "Epoch: 1, Step: 1894/2949, Loss: 0.8115\n",
      "Epoch: 1, Step: 1895/2949, Loss: 0.9200\n",
      "Epoch: 1, Step: 1896/2949, Loss: 0.8111\n",
      "Epoch: 1, Step: 1897/2949, Loss: 0.8445\n",
      "Epoch: 1, Step: 1898/2949, Loss: 0.8386\n",
      "Epoch: 1, Step: 1899/2949, Loss: 0.8819\n",
      "Epoch: 1, Step: 1900/2949, Loss: 0.8393\n",
      "Epoch: 1, Step: 1901/2949, Loss: 0.8711\n",
      "Epoch: 1, Step: 1902/2949, Loss: 0.8353\n",
      "Epoch: 1, Step: 1903/2949, Loss: 0.7976\n",
      "Epoch: 1, Step: 1904/2949, Loss: 0.8143\n",
      "Epoch: 1, Step: 1905/2949, Loss: 0.8164\n",
      "Epoch: 1, Step: 1906/2949, Loss: 0.8254\n",
      "Epoch: 1, Step: 1907/2949, Loss: 0.8346\n",
      "Epoch: 1, Step: 1908/2949, Loss: 0.9138\n",
      "Epoch: 1, Step: 1909/2949, Loss: 0.8091\n",
      "Epoch: 1, Step: 1910/2949, Loss: 0.8452\n",
      "Epoch: 1, Step: 1911/2949, Loss: 0.8833\n",
      "Epoch: 1, Step: 1912/2949, Loss: 0.8381\n",
      "Epoch: 1, Step: 1913/2949, Loss: 0.8627\n",
      "Epoch: 1, Step: 1914/2949, Loss: 0.8546\n",
      "Epoch: 1, Step: 1915/2949, Loss: 0.8644\n",
      "Epoch: 1, Step: 1916/2949, Loss: 0.8225\n",
      "Epoch: 1, Step: 1917/2949, Loss: 0.8422\n",
      "Epoch: 1, Step: 1918/2949, Loss: 0.7888\n",
      "Epoch: 1, Step: 1919/2949, Loss: 0.9075\n",
      "Epoch: 1, Step: 1920/2949, Loss: 0.8722\n",
      "Epoch: 1, Step: 1921/2949, Loss: 0.8393\n",
      "Epoch: 1, Step: 1922/2949, Loss: 0.8559\n",
      "Epoch: 1, Step: 1923/2949, Loss: 0.8488\n",
      "Epoch: 1, Step: 1924/2949, Loss: 0.8514\n",
      "Epoch: 1, Step: 1925/2949, Loss: 0.8489\n",
      "Epoch: 1, Step: 1926/2949, Loss: 0.8464\n",
      "Epoch: 1, Step: 1927/2949, Loss: 0.8201\n",
      "Epoch: 1, Step: 1928/2949, Loss: 0.8170\n",
      "Epoch: 1, Step: 1929/2949, Loss: 0.8451\n",
      "Epoch: 1, Step: 1930/2949, Loss: 0.8019\n",
      "Epoch: 1, Step: 1931/2949, Loss: 0.8266\n",
      "Epoch: 1, Step: 1932/2949, Loss: 0.8626\n",
      "Epoch: 1, Step: 1933/2949, Loss: 0.8212\n",
      "Epoch: 1, Step: 1934/2949, Loss: 0.8072\n",
      "Epoch: 1, Step: 1935/2949, Loss: 0.8520\n",
      "Epoch: 1, Step: 1936/2949, Loss: 0.7775\n",
      "Epoch: 1, Step: 1937/2949, Loss: 0.8598\n",
      "Epoch: 1, Step: 1938/2949, Loss: 0.8049\n",
      "Epoch: 1, Step: 1939/2949, Loss: 0.8079\n",
      "Epoch: 1, Step: 1940/2949, Loss: 0.8242\n",
      "Epoch: 1, Step: 1941/2949, Loss: 0.8557\n",
      "Epoch: 1, Step: 1942/2949, Loss: 0.8249\n",
      "Epoch: 1, Step: 1943/2949, Loss: 0.8450\n",
      "Epoch: 1, Step: 1944/2949, Loss: 0.8863\n",
      "Epoch: 1, Step: 1945/2949, Loss: 0.8566\n",
      "Epoch: 1, Step: 1946/2949, Loss: 0.8676\n",
      "Epoch: 1, Step: 1947/2949, Loss: 0.8520\n",
      "Epoch: 1, Step: 1948/2949, Loss: 0.8296\n",
      "Epoch: 1, Step: 1949/2949, Loss: 0.8397\n",
      "Epoch: 1, Step: 1950/2949, Loss: 0.8623\n",
      "Epoch: 1, Step: 1951/2949, Loss: 0.8851\n",
      "Epoch: 1, Step: 1952/2949, Loss: 0.8529\n",
      "Epoch: 1, Step: 1953/2949, Loss: 0.8352\n",
      "Epoch: 1, Step: 1954/2949, Loss: 0.7964\n",
      "Epoch: 1, Step: 1955/2949, Loss: 0.8403\n",
      "Epoch: 1, Step: 1956/2949, Loss: 0.8626\n",
      "Epoch: 1, Step: 1957/2949, Loss: 0.9118\n",
      "Epoch: 1, Step: 1958/2949, Loss: 0.9087\n",
      "Epoch: 1, Step: 1959/2949, Loss: 0.8432\n",
      "Epoch: 1, Step: 1960/2949, Loss: 0.8013\n",
      "Epoch: 1, Step: 1961/2949, Loss: 0.8847\n",
      "Epoch: 1, Step: 1962/2949, Loss: 0.8395\n",
      "Epoch: 1, Step: 1963/2949, Loss: 0.8620\n",
      "Epoch: 1, Step: 1964/2949, Loss: 0.7947\n",
      "Epoch: 1, Step: 1965/2949, Loss: 0.8289\n",
      "Epoch: 1, Step: 1966/2949, Loss: 0.8186\n",
      "Epoch: 1, Step: 1967/2949, Loss: 0.8401\n",
      "Epoch: 1, Step: 1968/2949, Loss: 0.8696\n",
      "Epoch: 1, Step: 1969/2949, Loss: 0.8073\n",
      "Epoch: 1, Step: 1970/2949, Loss: 0.8349\n",
      "Epoch: 1, Step: 1971/2949, Loss: 0.8604\n",
      "Epoch: 1, Step: 1972/2949, Loss: 0.8610\n",
      "Epoch: 1, Step: 1973/2949, Loss: 0.8684\n",
      "Epoch: 1, Step: 1974/2949, Loss: 0.7673\n",
      "Epoch: 1, Step: 1975/2949, Loss: 0.8054\n",
      "Epoch: 1, Step: 1976/2949, Loss: 0.8391\n",
      "Epoch: 1, Step: 1977/2949, Loss: 0.8455\n",
      "Epoch: 1, Step: 1978/2949, Loss: 0.8056\n",
      "Epoch: 1, Step: 1979/2949, Loss: 0.7960\n",
      "Epoch: 1, Step: 1980/2949, Loss: 0.9181\n",
      "Epoch: 1, Step: 1981/2949, Loss: 0.8706\n",
      "Epoch: 1, Step: 1982/2949, Loss: 0.8467\n",
      "Epoch: 1, Step: 1983/2949, Loss: 0.8746\n",
      "Epoch: 1, Step: 1984/2949, Loss: 0.8618\n",
      "Epoch: 1, Step: 1985/2949, Loss: 0.7969\n",
      "Epoch: 1, Step: 1986/2949, Loss: 0.8558\n",
      "Epoch: 1, Step: 1987/2949, Loss: 0.8459\n",
      "Epoch: 1, Step: 1988/2949, Loss: 0.8000\n",
      "Epoch: 1, Step: 1989/2949, Loss: 0.8446\n",
      "Epoch: 1, Step: 1990/2949, Loss: 0.8670\n",
      "Epoch: 1, Step: 1991/2949, Loss: 0.8458\n",
      "Epoch: 1, Step: 1992/2949, Loss: 0.8263\n",
      "Epoch: 1, Step: 1993/2949, Loss: 0.8083\n",
      "Epoch: 1, Step: 1994/2949, Loss: 0.7824\n",
      "Epoch: 1, Step: 1995/2949, Loss: 0.8670\n",
      "Epoch: 1, Step: 1996/2949, Loss: 0.8319\n",
      "Epoch: 1, Step: 1997/2949, Loss: 0.8355\n",
      "Epoch: 1, Step: 1998/2949, Loss: 0.8343\n",
      "Epoch: 1, Step: 1999/2949, Loss: 0.8103\n",
      "Epoch: 1, Step: 2000/2949, Loss: 0.7921\n",
      "Epoch: 1, Step: 2001/2949, Loss: 0.8024\n",
      "Epoch: 1, Step: 2002/2949, Loss: 0.8268\n",
      "Epoch: 1, Step: 2003/2949, Loss: 0.8362\n",
      "Epoch: 1, Step: 2004/2949, Loss: 0.8552\n",
      "Epoch: 1, Step: 2005/2949, Loss: 0.8748\n",
      "Epoch: 1, Step: 2006/2949, Loss: 0.8996\n",
      "Epoch: 1, Step: 2007/2949, Loss: 0.8017\n",
      "Epoch: 1, Step: 2008/2949, Loss: 0.8837\n",
      "Epoch: 1, Step: 2009/2949, Loss: 0.8749\n",
      "Epoch: 1, Step: 2010/2949, Loss: 0.8750\n",
      "Epoch: 1, Step: 2011/2949, Loss: 0.8536\n",
      "Epoch: 1, Step: 2012/2949, Loss: 0.8183\n",
      "Epoch: 1, Step: 2013/2949, Loss: 0.8744\n",
      "Epoch: 1, Step: 2014/2949, Loss: 0.8321\n",
      "Epoch: 1, Step: 2015/2949, Loss: 0.8115\n",
      "Epoch: 1, Step: 2016/2949, Loss: 0.8614\n",
      "Epoch: 1, Step: 2017/2949, Loss: 0.8359\n",
      "Epoch: 1, Step: 2018/2949, Loss: 0.8563\n",
      "Epoch: 1, Step: 2019/2949, Loss: 0.8315\n",
      "Epoch: 1, Step: 2020/2949, Loss: 0.8377\n",
      "Epoch: 1, Step: 2021/2949, Loss: 0.7918\n",
      "Epoch: 1, Step: 2022/2949, Loss: 0.8448\n",
      "Epoch: 1, Step: 2023/2949, Loss: 0.8728\n",
      "Epoch: 1, Step: 2024/2949, Loss: 0.8110\n",
      "Epoch: 1, Step: 2025/2949, Loss: 0.8484\n",
      "Epoch: 1, Step: 2026/2949, Loss: 0.8370\n",
      "Epoch: 1, Step: 2027/2949, Loss: 0.7820\n",
      "Epoch: 1, Step: 2028/2949, Loss: 0.8433\n",
      "Epoch: 1, Step: 2029/2949, Loss: 0.8233\n",
      "Epoch: 1, Step: 2030/2949, Loss: 0.8598\n",
      "Epoch: 1, Step: 2031/2949, Loss: 0.8771\n",
      "Epoch: 1, Step: 2032/2949, Loss: 0.8352\n",
      "Epoch: 1, Step: 2033/2949, Loss: 0.8060\n",
      "Epoch: 1, Step: 2034/2949, Loss: 0.8690\n",
      "Epoch: 1, Step: 2035/2949, Loss: 0.8660\n",
      "Epoch: 1, Step: 2036/2949, Loss: 0.8595\n",
      "Epoch: 1, Step: 2037/2949, Loss: 0.8485\n",
      "Epoch: 1, Step: 2038/2949, Loss: 0.7901\n",
      "Epoch: 1, Step: 2039/2949, Loss: 0.8511\n",
      "Epoch: 1, Step: 2040/2949, Loss: 0.8046\n",
      "Epoch: 1, Step: 2041/2949, Loss: 0.8243\n",
      "Epoch: 1, Step: 2042/2949, Loss: 0.8631\n",
      "Epoch: 1, Step: 2043/2949, Loss: 0.8974\n",
      "Epoch: 1, Step: 2044/2949, Loss: 0.8678\n",
      "Epoch: 1, Step: 2045/2949, Loss: 0.8853\n",
      "Epoch: 1, Step: 2046/2949, Loss: 0.8673\n",
      "Epoch: 1, Step: 2047/2949, Loss: 0.8432\n",
      "Epoch: 1, Step: 2048/2949, Loss: 0.8242\n",
      "Epoch: 1, Step: 2049/2949, Loss: 0.8576\n",
      "Epoch: 1, Step: 2050/2949, Loss: 0.8454\n",
      "Epoch: 1, Step: 2051/2949, Loss: 0.8433\n",
      "Epoch: 1, Step: 2052/2949, Loss: 0.8026\n",
      "Epoch: 1, Step: 2053/2949, Loss: 0.8098\n",
      "Epoch: 1, Step: 2054/2949, Loss: 0.8880\n",
      "Epoch: 1, Step: 2055/2949, Loss: 0.8275\n",
      "Epoch: 1, Step: 2056/2949, Loss: 0.8964\n",
      "Epoch: 1, Step: 2057/2949, Loss: 0.8621\n",
      "Epoch: 1, Step: 2058/2949, Loss: 0.8906\n",
      "Epoch: 1, Step: 2059/2949, Loss: 0.7769\n",
      "Epoch: 1, Step: 2060/2949, Loss: 0.8600\n",
      "Epoch: 1, Step: 2061/2949, Loss: 0.8256\n",
      "Epoch: 1, Step: 2062/2949, Loss: 0.7711\n",
      "Epoch: 1, Step: 2063/2949, Loss: 0.8720\n",
      "Epoch: 1, Step: 2064/2949, Loss: 0.8216\n",
      "Epoch: 1, Step: 2065/2949, Loss: 0.8190\n",
      "Epoch: 1, Step: 2066/2949, Loss: 0.8509\n",
      "Epoch: 1, Step: 2067/2949, Loss: 0.8224\n",
      "Epoch: 1, Step: 2068/2949, Loss: 0.8493\n",
      "Epoch: 1, Step: 2069/2949, Loss: 0.7988\n",
      "Epoch: 1, Step: 2070/2949, Loss: 0.8037\n",
      "Epoch: 1, Step: 2071/2949, Loss: 0.8371\n",
      "Epoch: 1, Step: 2072/2949, Loss: 0.9061\n",
      "Epoch: 1, Step: 2073/2949, Loss: 0.7987\n",
      "Epoch: 1, Step: 2074/2949, Loss: 0.8579\n",
      "Epoch: 1, Step: 2075/2949, Loss: 0.8591\n",
      "Epoch: 1, Step: 2076/2949, Loss: 0.8154\n",
      "Epoch: 1, Step: 2077/2949, Loss: 0.8118\n",
      "Epoch: 1, Step: 2078/2949, Loss: 0.8689\n",
      "Epoch: 1, Step: 2079/2949, Loss: 0.8210\n",
      "Epoch: 1, Step: 2080/2949, Loss: 0.8896\n",
      "Epoch: 1, Step: 2081/2949, Loss: 0.8374\n",
      "Epoch: 1, Step: 2082/2949, Loss: 0.8437\n",
      "Epoch: 1, Step: 2083/2949, Loss: 0.8206\n",
      "Epoch: 1, Step: 2084/2949, Loss: 0.8425\n",
      "Epoch: 1, Step: 2085/2949, Loss: 0.8362\n",
      "Epoch: 1, Step: 2086/2949, Loss: 0.8295\n",
      "Epoch: 1, Step: 2087/2949, Loss: 0.8304\n",
      "Epoch: 1, Step: 2088/2949, Loss: 0.8015\n",
      "Epoch: 1, Step: 2089/2949, Loss: 0.8361\n",
      "Epoch: 1, Step: 2090/2949, Loss: 0.8368\n",
      "Epoch: 1, Step: 2091/2949, Loss: 0.8377\n",
      "Epoch: 1, Step: 2092/2949, Loss: 0.8575\n",
      "Epoch: 1, Step: 2093/2949, Loss: 0.8595\n",
      "Epoch: 1, Step: 2094/2949, Loss: 0.8547\n",
      "Epoch: 1, Step: 2095/2949, Loss: 0.8117\n",
      "Epoch: 1, Step: 2096/2949, Loss: 0.8528\n",
      "Epoch: 1, Step: 2097/2949, Loss: 0.8555\n",
      "Epoch: 1, Step: 2098/2949, Loss: 0.8507\n",
      "Epoch: 1, Step: 2099/2949, Loss: 0.8258\n",
      "Epoch: 1, Step: 2100/2949, Loss: 0.8450\n",
      "Epoch: 1, Step: 2101/2949, Loss: 0.8379\n",
      "Epoch: 1, Step: 2102/2949, Loss: 0.8282\n",
      "Epoch: 1, Step: 2103/2949, Loss: 0.8460\n",
      "Epoch: 1, Step: 2104/2949, Loss: 0.8345\n",
      "Epoch: 1, Step: 2105/2949, Loss: 0.8449\n",
      "Epoch: 1, Step: 2106/2949, Loss: 0.8038\n",
      "Epoch: 1, Step: 2107/2949, Loss: 0.8707\n",
      "Epoch: 1, Step: 2108/2949, Loss: 0.8201\n",
      "Epoch: 1, Step: 2109/2949, Loss: 0.9164\n",
      "Epoch: 1, Step: 2110/2949, Loss: 0.8438\n",
      "Epoch: 1, Step: 2111/2949, Loss: 0.8676\n",
      "Epoch: 1, Step: 2112/2949, Loss: 0.8868\n",
      "Epoch: 1, Step: 2113/2949, Loss: 0.8623\n",
      "Epoch: 1, Step: 2114/2949, Loss: 0.8614\n",
      "Epoch: 1, Step: 2115/2949, Loss: 0.8576\n",
      "Epoch: 1, Step: 2116/2949, Loss: 0.8453\n",
      "Epoch: 1, Step: 2117/2949, Loss: 0.8580\n",
      "Epoch: 1, Step: 2118/2949, Loss: 0.7848\n",
      "Epoch: 1, Step: 2119/2949, Loss: 0.8152\n",
      "Epoch: 1, Step: 2120/2949, Loss: 0.8265\n",
      "Epoch: 1, Step: 2121/2949, Loss: 0.8908\n",
      "Epoch: 1, Step: 2122/2949, Loss: 0.8248\n",
      "Epoch: 1, Step: 2123/2949, Loss: 0.7975\n",
      "Epoch: 1, Step: 2124/2949, Loss: 0.8289\n",
      "Epoch: 1, Step: 2125/2949, Loss: 0.8570\n",
      "Epoch: 1, Step: 2126/2949, Loss: 0.8536\n",
      "Epoch: 1, Step: 2127/2949, Loss: 0.8256\n",
      "Epoch: 1, Step: 2128/2949, Loss: 0.8321\n",
      "Epoch: 1, Step: 2129/2949, Loss: 0.8634\n",
      "Epoch: 1, Step: 2130/2949, Loss: 0.8796\n",
      "Epoch: 1, Step: 2131/2949, Loss: 0.8426\n",
      "Epoch: 1, Step: 2132/2949, Loss: 0.8192\n",
      "Epoch: 1, Step: 2133/2949, Loss: 0.8869\n",
      "Epoch: 1, Step: 2134/2949, Loss: 0.8250\n",
      "Epoch: 1, Step: 2135/2949, Loss: 0.8629\n",
      "Epoch: 1, Step: 2136/2949, Loss: 0.8558\n",
      "Epoch: 1, Step: 2137/2949, Loss: 0.8256\n",
      "Epoch: 1, Step: 2138/2949, Loss: 0.7869\n",
      "Epoch: 1, Step: 2139/2949, Loss: 0.8595\n",
      "Epoch: 1, Step: 2140/2949, Loss: 0.8217\n",
      "Epoch: 1, Step: 2141/2949, Loss: 0.7935\n",
      "Epoch: 1, Step: 2142/2949, Loss: 0.8609\n",
      "Epoch: 1, Step: 2143/2949, Loss: 0.8338\n",
      "Epoch: 1, Step: 2144/2949, Loss: 0.8749\n",
      "Epoch: 1, Step: 2145/2949, Loss: 0.8732\n",
      "Epoch: 1, Step: 2146/2949, Loss: 0.8276\n",
      "Epoch: 1, Step: 2147/2949, Loss: 0.8888\n",
      "Epoch: 1, Step: 2148/2949, Loss: 0.8571\n",
      "Epoch: 1, Step: 2149/2949, Loss: 0.8353\n",
      "Epoch: 1, Step: 2150/2949, Loss: 0.8706\n",
      "Epoch: 1, Step: 2151/2949, Loss: 0.8170\n",
      "Epoch: 1, Step: 2152/2949, Loss: 0.8202\n",
      "Epoch: 1, Step: 2153/2949, Loss: 0.8599\n",
      "Epoch: 1, Step: 2154/2949, Loss: 0.8631\n",
      "Epoch: 1, Step: 2155/2949, Loss: 0.8654\n",
      "Epoch: 1, Step: 2156/2949, Loss: 0.8386\n",
      "Epoch: 1, Step: 2157/2949, Loss: 0.8361\n",
      "Epoch: 1, Step: 2158/2949, Loss: 0.8754\n",
      "Epoch: 1, Step: 2159/2949, Loss: 0.8280\n",
      "Epoch: 1, Step: 2160/2949, Loss: 0.8194\n",
      "Epoch: 1, Step: 2161/2949, Loss: 0.8026\n",
      "Epoch: 1, Step: 2162/2949, Loss: 0.8308\n",
      "Epoch: 1, Step: 2163/2949, Loss: 0.8044\n",
      "Epoch: 1, Step: 2164/2949, Loss: 0.9163\n",
      "Epoch: 1, Step: 2165/2949, Loss: 0.8720\n",
      "Epoch: 1, Step: 2166/2949, Loss: 0.8573\n",
      "Epoch: 1, Step: 2167/2949, Loss: 0.8020\n",
      "Epoch: 1, Step: 2168/2949, Loss: 0.8395\n",
      "Epoch: 1, Step: 2169/2949, Loss: 0.7898\n",
      "Epoch: 1, Step: 2170/2949, Loss: 0.8533\n",
      "Epoch: 1, Step: 2171/2949, Loss: 0.7905\n",
      "Epoch: 1, Step: 2172/2949, Loss: 0.8207\n",
      "Epoch: 1, Step: 2173/2949, Loss: 0.8534\n",
      "Epoch: 1, Step: 2174/2949, Loss: 0.9029\n",
      "Epoch: 1, Step: 2175/2949, Loss: 0.8577\n",
      "Epoch: 1, Step: 2176/2949, Loss: 0.8134\n",
      "Epoch: 1, Step: 2177/2949, Loss: 0.8293\n",
      "Epoch: 1, Step: 2178/2949, Loss: 0.8605\n",
      "Epoch: 1, Step: 2179/2949, Loss: 0.8451\n",
      "Epoch: 1, Step: 2180/2949, Loss: 0.8497\n",
      "Epoch: 1, Step: 2181/2949, Loss: 0.7841\n",
      "Epoch: 1, Step: 2182/2949, Loss: 0.8254\n",
      "Epoch: 1, Step: 2183/2949, Loss: 0.8914\n",
      "Epoch: 1, Step: 2184/2949, Loss: 0.8838\n",
      "Epoch: 1, Step: 2185/2949, Loss: 0.7985\n",
      "Epoch: 1, Step: 2186/2949, Loss: 0.8784\n",
      "Epoch: 1, Step: 2187/2949, Loss: 0.8847\n",
      "Epoch: 1, Step: 2188/2949, Loss: 0.8339\n",
      "Epoch: 1, Step: 2189/2949, Loss: 0.8677\n",
      "Epoch: 1, Step: 2190/2949, Loss: 0.8688\n",
      "Epoch: 1, Step: 2191/2949, Loss: 0.8009\n",
      "Epoch: 1, Step: 2192/2949, Loss: 0.8291\n",
      "Epoch: 1, Step: 2193/2949, Loss: 0.8737\n",
      "Epoch: 1, Step: 2194/2949, Loss: 0.8305\n",
      "Epoch: 1, Step: 2195/2949, Loss: 0.8538\n",
      "Epoch: 1, Step: 2196/2949, Loss: 0.8252\n",
      "Epoch: 1, Step: 2197/2949, Loss: 0.8648\n",
      "Epoch: 1, Step: 2198/2949, Loss: 0.8448\n",
      "Epoch: 1, Step: 2199/2949, Loss: 0.8371\n",
      "Epoch: 1, Step: 2200/2949, Loss: 0.9038\n",
      "Epoch: 1, Step: 2201/2949, Loss: 0.8204\n",
      "Epoch: 1, Step: 2202/2949, Loss: 0.8238\n",
      "Epoch: 1, Step: 2203/2949, Loss: 0.8492\n",
      "Epoch: 1, Step: 2204/2949, Loss: 0.7662\n",
      "Epoch: 1, Step: 2205/2949, Loss: 0.8046\n",
      "Epoch: 1, Step: 2206/2949, Loss: 0.9069\n",
      "Epoch: 1, Step: 2207/2949, Loss: 0.8701\n",
      "Epoch: 1, Step: 2208/2949, Loss: 0.8644\n",
      "Epoch: 1, Step: 2209/2949, Loss: 0.8531\n",
      "Epoch: 1, Step: 2210/2949, Loss: 0.8250\n",
      "Epoch: 1, Step: 2211/2949, Loss: 0.8603\n",
      "Epoch: 1, Step: 2212/2949, Loss: 0.8409\n",
      "Epoch: 1, Step: 2213/2949, Loss: 0.8308\n",
      "Epoch: 1, Step: 2214/2949, Loss: 0.8458\n",
      "Epoch: 1, Step: 2215/2949, Loss: 0.8750\n",
      "Epoch: 1, Step: 2216/2949, Loss: 0.8451\n",
      "Epoch: 1, Step: 2217/2949, Loss: 0.8018\n",
      "Epoch: 1, Step: 2218/2949, Loss: 0.8739\n",
      "Epoch: 1, Step: 2219/2949, Loss: 0.8009\n",
      "Epoch: 1, Step: 2220/2949, Loss: 0.8261\n",
      "Epoch: 1, Step: 2221/2949, Loss: 0.8182\n",
      "Epoch: 1, Step: 2222/2949, Loss: 0.8203\n",
      "Epoch: 1, Step: 2223/2949, Loss: 0.8069\n",
      "Epoch: 1, Step: 2224/2949, Loss: 0.7794\n",
      "Epoch: 1, Step: 2225/2949, Loss: 0.7893\n",
      "Epoch: 1, Step: 2226/2949, Loss: 0.8212\n",
      "Epoch: 1, Step: 2227/2949, Loss: 0.8587\n",
      "Epoch: 1, Step: 2228/2949, Loss: 0.8510\n",
      "Epoch: 1, Step: 2229/2949, Loss: 0.8642\n",
      "Epoch: 1, Step: 2230/2949, Loss: 0.7794\n",
      "Epoch: 1, Step: 2231/2949, Loss: 0.8736\n",
      "Epoch: 1, Step: 2232/2949, Loss: 0.8638\n",
      "Epoch: 1, Step: 2233/2949, Loss: 0.8441\n",
      "Epoch: 1, Step: 2234/2949, Loss: 0.8587\n",
      "Epoch: 1, Step: 2235/2949, Loss: 0.7927\n",
      "Epoch: 1, Step: 2236/2949, Loss: 0.8040\n",
      "Epoch: 1, Step: 2237/2949, Loss: 0.8291\n",
      "Epoch: 1, Step: 2238/2949, Loss: 0.8403\n",
      "Epoch: 1, Step: 2239/2949, Loss: 0.8161\n",
      "Epoch: 1, Step: 2240/2949, Loss: 0.8073\n",
      "Epoch: 1, Step: 2241/2949, Loss: 0.8267\n",
      "Epoch: 1, Step: 2242/2949, Loss: 0.8805\n",
      "Epoch: 1, Step: 2243/2949, Loss: 0.8594\n",
      "Epoch: 1, Step: 2244/2949, Loss: 0.8907\n",
      "Epoch: 1, Step: 2245/2949, Loss: 0.8558\n",
      "Epoch: 1, Step: 2246/2949, Loss: 0.8028\n",
      "Epoch: 1, Step: 2247/2949, Loss: 0.8039\n",
      "Epoch: 1, Step: 2248/2949, Loss: 0.8400\n",
      "Epoch: 1, Step: 2249/2949, Loss: 0.8746\n",
      "Epoch: 1, Step: 2250/2949, Loss: 0.8713\n",
      "Epoch: 1, Step: 2251/2949, Loss: 0.7934\n",
      "Epoch: 1, Step: 2252/2949, Loss: 0.8389\n",
      "Epoch: 1, Step: 2253/2949, Loss: 0.7859\n",
      "Epoch: 1, Step: 2254/2949, Loss: 0.8277\n",
      "Epoch: 1, Step: 2255/2949, Loss: 0.8891\n",
      "Epoch: 1, Step: 2256/2949, Loss: 0.8672\n",
      "Epoch: 1, Step: 2257/2949, Loss: 0.8476\n",
      "Epoch: 1, Step: 2258/2949, Loss: 0.8403\n",
      "Epoch: 1, Step: 2259/2949, Loss: 0.8035\n",
      "Epoch: 1, Step: 2260/2949, Loss: 0.7941\n",
      "Epoch: 1, Step: 2261/2949, Loss: 0.8402\n",
      "Epoch: 1, Step: 2262/2949, Loss: 0.8259\n",
      "Epoch: 1, Step: 2263/2949, Loss: 0.8413\n",
      "Epoch: 1, Step: 2264/2949, Loss: 0.8358\n",
      "Epoch: 1, Step: 2265/2949, Loss: 0.8222\n",
      "Epoch: 1, Step: 2266/2949, Loss: 0.8494\n",
      "Epoch: 1, Step: 2267/2949, Loss: 0.8352\n",
      "Epoch: 1, Step: 2268/2949, Loss: 0.8712\n",
      "Epoch: 1, Step: 2269/2949, Loss: 0.8308\n",
      "Epoch: 1, Step: 2270/2949, Loss: 0.8531\n",
      "Epoch: 1, Step: 2271/2949, Loss: 0.8324\n",
      "Epoch: 1, Step: 2272/2949, Loss: 0.8303\n",
      "Epoch: 1, Step: 2273/2949, Loss: 0.8471\n",
      "Epoch: 1, Step: 2274/2949, Loss: 0.8070\n",
      "Epoch: 1, Step: 2275/2949, Loss: 0.8441\n",
      "Epoch: 1, Step: 2276/2949, Loss: 0.7762\n",
      "Epoch: 1, Step: 2277/2949, Loss: 0.8369\n",
      "Epoch: 1, Step: 2278/2949, Loss: 0.8612\n",
      "Epoch: 1, Step: 2279/2949, Loss: 0.8580\n",
      "Epoch: 1, Step: 2280/2949, Loss: 0.8274\n",
      "Epoch: 1, Step: 2281/2949, Loss: 0.8075\n",
      "Epoch: 1, Step: 2282/2949, Loss: 0.7190\n",
      "Epoch: 1, Step: 2283/2949, Loss: 0.7959\n",
      "Epoch: 1, Step: 2284/2949, Loss: 0.7798\n",
      "Epoch: 1, Step: 2285/2949, Loss: 0.8648\n",
      "Epoch: 1, Step: 2286/2949, Loss: 0.7999\n",
      "Epoch: 1, Step: 2287/2949, Loss: 0.8553\n",
      "Epoch: 1, Step: 2288/2949, Loss: 0.8324\n",
      "Epoch: 1, Step: 2289/2949, Loss: 0.8280\n",
      "Epoch: 1, Step: 2290/2949, Loss: 0.8321\n",
      "Epoch: 1, Step: 2291/2949, Loss: 0.7756\n",
      "Epoch: 1, Step: 2292/2949, Loss: 0.7936\n",
      "Epoch: 1, Step: 2293/2949, Loss: 0.8370\n",
      "Epoch: 1, Step: 2294/2949, Loss: 0.8366\n",
      "Epoch: 1, Step: 2295/2949, Loss: 0.8530\n",
      "Epoch: 1, Step: 2296/2949, Loss: 0.8412\n",
      "Epoch: 1, Step: 2297/2949, Loss: 0.8622\n",
      "Epoch: 1, Step: 2298/2949, Loss: 0.8015\n",
      "Epoch: 1, Step: 2299/2949, Loss: 0.8533\n",
      "Epoch: 1, Step: 2300/2949, Loss: 0.8469\n",
      "Epoch: 1, Step: 2301/2949, Loss: 0.8885\n",
      "Epoch: 1, Step: 2302/2949, Loss: 0.8525\n",
      "Epoch: 1, Step: 2303/2949, Loss: 0.8046\n",
      "Epoch: 1, Step: 2304/2949, Loss: 0.8229\n",
      "Epoch: 1, Step: 2305/2949, Loss: 0.9011\n",
      "Epoch: 1, Step: 2306/2949, Loss: 0.8413\n",
      "Epoch: 1, Step: 2307/2949, Loss: 0.8236\n",
      "Epoch: 1, Step: 2308/2949, Loss: 0.8417\n",
      "Epoch: 1, Step: 2309/2949, Loss: 0.8389\n",
      "Epoch: 1, Step: 2310/2949, Loss: 0.8371\n",
      "Epoch: 1, Step: 2311/2949, Loss: 0.8376\n",
      "Epoch: 1, Step: 2312/2949, Loss: 0.8327\n",
      "Epoch: 1, Step: 2313/2949, Loss: 0.8152\n",
      "Epoch: 1, Step: 2314/2949, Loss: 0.8451\n",
      "Epoch: 1, Step: 2315/2949, Loss: 0.8280\n",
      "Epoch: 1, Step: 2316/2949, Loss: 0.8271\n",
      "Epoch: 1, Step: 2317/2949, Loss: 0.8963\n",
      "Epoch: 1, Step: 2318/2949, Loss: 0.8032\n",
      "Epoch: 1, Step: 2319/2949, Loss: 0.8195\n",
      "Epoch: 1, Step: 2320/2949, Loss: 0.8030\n",
      "Epoch: 1, Step: 2321/2949, Loss: 0.8766\n",
      "Epoch: 1, Step: 2322/2949, Loss: 0.8260\n",
      "Epoch: 1, Step: 2323/2949, Loss: 0.8446\n",
      "Epoch: 1, Step: 2324/2949, Loss: 0.8718\n",
      "Epoch: 1, Step: 2325/2949, Loss: 0.8248\n",
      "Epoch: 1, Step: 2326/2949, Loss: 0.8244\n",
      "Epoch: 1, Step: 2327/2949, Loss: 0.8250\n",
      "Epoch: 1, Step: 2328/2949, Loss: 0.8115\n",
      "Epoch: 1, Step: 2329/2949, Loss: 0.8075\n",
      "Epoch: 1, Step: 2330/2949, Loss: 0.7783\n",
      "Epoch: 1, Step: 2331/2949, Loss: 0.8537\n",
      "Epoch: 1, Step: 2332/2949, Loss: 0.8803\n",
      "Epoch: 1, Step: 2333/2949, Loss: 0.8259\n",
      "Epoch: 1, Step: 2334/2949, Loss: 0.8684\n",
      "Epoch: 1, Step: 2335/2949, Loss: 0.8244\n",
      "Epoch: 1, Step: 2336/2949, Loss: 0.8537\n",
      "Epoch: 1, Step: 2337/2949, Loss: 0.7931\n",
      "Epoch: 1, Step: 2338/2949, Loss: 0.8343\n",
      "Epoch: 1, Step: 2339/2949, Loss: 0.8078\n",
      "Epoch: 1, Step: 2340/2949, Loss: 0.8365\n",
      "Epoch: 1, Step: 2341/2949, Loss: 0.7911\n",
      "Epoch: 1, Step: 2342/2949, Loss: 0.8222\n",
      "Epoch: 1, Step: 2343/2949, Loss: 0.7869\n",
      "Epoch: 1, Step: 2344/2949, Loss: 0.8109\n",
      "Epoch: 1, Step: 2345/2949, Loss: 0.8298\n",
      "Epoch: 1, Step: 2346/2949, Loss: 0.8172\n",
      "Epoch: 1, Step: 2347/2949, Loss: 0.8045\n",
      "Epoch: 1, Step: 2348/2949, Loss: 0.8179\n",
      "Epoch: 1, Step: 2349/2949, Loss: 0.8186\n",
      "Epoch: 1, Step: 2350/2949, Loss: 0.8579\n",
      "Epoch: 1, Step: 2351/2949, Loss: 0.8010\n",
      "Epoch: 1, Step: 2352/2949, Loss: 0.8297\n",
      "Epoch: 1, Step: 2353/2949, Loss: 0.8017\n",
      "Epoch: 1, Step: 2354/2949, Loss: 0.8117\n",
      "Epoch: 1, Step: 2355/2949, Loss: 0.8583\n",
      "Epoch: 1, Step: 2356/2949, Loss: 0.8293\n",
      "Epoch: 1, Step: 2357/2949, Loss: 0.8140\n",
      "Epoch: 1, Step: 2358/2949, Loss: 0.8340\n",
      "Epoch: 1, Step: 2359/2949, Loss: 0.7906\n",
      "Epoch: 1, Step: 2360/2949, Loss: 0.8201\n",
      "Epoch: 1, Step: 2361/2949, Loss: 0.8363\n",
      "Epoch: 1, Step: 2362/2949, Loss: 0.8510\n",
      "Epoch: 1, Step: 2363/2949, Loss: 0.8649\n",
      "Epoch: 1, Step: 2364/2949, Loss: 0.8402\n",
      "Epoch: 1, Step: 2365/2949, Loss: 0.8287\n",
      "Epoch: 1, Step: 2366/2949, Loss: 0.8681\n",
      "Epoch: 1, Step: 2367/2949, Loss: 0.8407\n",
      "Epoch: 1, Step: 2368/2949, Loss: 0.8609\n",
      "Epoch: 1, Step: 2369/2949, Loss: 0.8183\n",
      "Epoch: 1, Step: 2370/2949, Loss: 0.8517\n",
      "Epoch: 1, Step: 2371/2949, Loss: 0.8485\n",
      "Epoch: 1, Step: 2372/2949, Loss: 0.8399\n",
      "Epoch: 1, Step: 2373/2949, Loss: 0.8745\n",
      "Epoch: 1, Step: 2374/2949, Loss: 0.8546\n",
      "Epoch: 1, Step: 2375/2949, Loss: 0.8408\n",
      "Epoch: 1, Step: 2376/2949, Loss: 0.8134\n",
      "Epoch: 1, Step: 2377/2949, Loss: 0.7861\n",
      "Epoch: 1, Step: 2378/2949, Loss: 0.8441\n",
      "Epoch: 1, Step: 2379/2949, Loss: 0.8513\n",
      "Epoch: 1, Step: 2380/2949, Loss: 0.8260\n",
      "Epoch: 1, Step: 2381/2949, Loss: 0.8175\n",
      "Epoch: 1, Step: 2382/2949, Loss: 0.8308\n",
      "Epoch: 1, Step: 2383/2949, Loss: 0.8538\n",
      "Epoch: 1, Step: 2384/2949, Loss: 0.8405\n",
      "Epoch: 1, Step: 2385/2949, Loss: 0.8538\n",
      "Epoch: 1, Step: 2386/2949, Loss: 0.8823\n",
      "Epoch: 1, Step: 2387/2949, Loss: 0.8717\n",
      "Epoch: 1, Step: 2388/2949, Loss: 0.8734\n",
      "Epoch: 1, Step: 2389/2949, Loss: 0.8544\n",
      "Epoch: 1, Step: 2390/2949, Loss: 0.8318\n",
      "Epoch: 1, Step: 2391/2949, Loss: 0.8513\n",
      "Epoch: 1, Step: 2392/2949, Loss: 0.7875\n",
      "Epoch: 1, Step: 2393/2949, Loss: 0.8200\n",
      "Epoch: 1, Step: 2394/2949, Loss: 0.8355\n",
      "Epoch: 1, Step: 2395/2949, Loss: 0.8338\n",
      "Epoch: 1, Step: 2396/2949, Loss: 0.7994\n",
      "Epoch: 1, Step: 2397/2949, Loss: 0.7963\n",
      "Epoch: 1, Step: 2398/2949, Loss: 0.8356\n",
      "Epoch: 1, Step: 2399/2949, Loss: 0.8242\n",
      "Epoch: 1, Step: 2400/2949, Loss: 0.8275\n",
      "Epoch: 1, Step: 2401/2949, Loss: 0.8331\n",
      "Epoch: 1, Step: 2402/2949, Loss: 0.8271\n",
      "Epoch: 1, Step: 2403/2949, Loss: 0.8806\n",
      "Epoch: 1, Step: 2404/2949, Loss: 0.8913\n",
      "Epoch: 1, Step: 2405/2949, Loss: 0.8566\n",
      "Epoch: 1, Step: 2406/2949, Loss: 0.8808\n",
      "Epoch: 1, Step: 2407/2949, Loss: 0.8162\n",
      "Epoch: 1, Step: 2408/2949, Loss: 0.8390\n",
      "Epoch: 1, Step: 2409/2949, Loss: 0.8328\n",
      "Epoch: 1, Step: 2410/2949, Loss: 0.7842\n",
      "Epoch: 1, Step: 2411/2949, Loss: 0.8552\n",
      "Epoch: 1, Step: 2412/2949, Loss: 0.8499\n",
      "Epoch: 1, Step: 2413/2949, Loss: 0.8007\n",
      "Epoch: 1, Step: 2414/2949, Loss: 0.8770\n",
      "Epoch: 1, Step: 2415/2949, Loss: 0.8567\n",
      "Epoch: 1, Step: 2416/2949, Loss: 0.8696\n",
      "Epoch: 1, Step: 2417/2949, Loss: 0.8091\n",
      "Epoch: 1, Step: 2418/2949, Loss: 0.8199\n",
      "Epoch: 1, Step: 2419/2949, Loss: 0.8717\n",
      "Epoch: 1, Step: 2420/2949, Loss: 0.8845\n",
      "Epoch: 1, Step: 2421/2949, Loss: 0.8348\n",
      "Epoch: 1, Step: 2422/2949, Loss: 0.8358\n",
      "Epoch: 1, Step: 2423/2949, Loss: 0.8380\n",
      "Epoch: 1, Step: 2424/2949, Loss: 0.8458\n",
      "Epoch: 1, Step: 2425/2949, Loss: 0.8552\n",
      "Epoch: 1, Step: 2426/2949, Loss: 0.8059\n",
      "Epoch: 1, Step: 2427/2949, Loss: 0.8778\n",
      "Epoch: 1, Step: 2428/2949, Loss: 0.8422\n",
      "Epoch: 1, Step: 2429/2949, Loss: 0.8216\n",
      "Epoch: 1, Step: 2430/2949, Loss: 0.8390\n",
      "Epoch: 1, Step: 2431/2949, Loss: 0.7830\n",
      "Epoch: 1, Step: 2432/2949, Loss: 0.8254\n",
      "Epoch: 1, Step: 2433/2949, Loss: 0.7594\n",
      "Epoch: 1, Step: 2434/2949, Loss: 0.8557\n",
      "Epoch: 1, Step: 2435/2949, Loss: 0.8637\n",
      "Epoch: 1, Step: 2436/2949, Loss: 0.8521\n",
      "Epoch: 1, Step: 2437/2949, Loss: 0.8139\n",
      "Epoch: 1, Step: 2438/2949, Loss: 0.8563\n",
      "Epoch: 1, Step: 2439/2949, Loss: 0.7634\n",
      "Epoch: 1, Step: 2440/2949, Loss: 0.8359\n",
      "Epoch: 1, Step: 2441/2949, Loss: 0.7747\n",
      "Epoch: 1, Step: 2442/2949, Loss: 0.7990\n",
      "Epoch: 1, Step: 2443/2949, Loss: 0.8356\n",
      "Epoch: 1, Step: 2444/2949, Loss: 0.8104\n",
      "Epoch: 1, Step: 2445/2949, Loss: 0.9036\n",
      "Epoch: 1, Step: 2446/2949, Loss: 0.8551\n",
      "Epoch: 1, Step: 2447/2949, Loss: 0.8559\n",
      "Epoch: 1, Step: 2448/2949, Loss: 0.8054\n",
      "Epoch: 1, Step: 2449/2949, Loss: 0.8529\n",
      "Epoch: 1, Step: 2450/2949, Loss: 0.8291\n",
      "Epoch: 1, Step: 2451/2949, Loss: 0.8324\n",
      "Epoch: 1, Step: 2452/2949, Loss: 0.8271\n",
      "Epoch: 1, Step: 2453/2949, Loss: 0.8079\n",
      "Epoch: 1, Step: 2454/2949, Loss: 0.8547\n",
      "Epoch: 1, Step: 2455/2949, Loss: 0.8566\n",
      "Epoch: 1, Step: 2456/2949, Loss: 0.8316\n",
      "Epoch: 1, Step: 2457/2949, Loss: 0.8367\n",
      "Epoch: 1, Step: 2458/2949, Loss: 0.8735\n",
      "Epoch: 1, Step: 2459/2949, Loss: 0.8374\n",
      "Epoch: 1, Step: 2460/2949, Loss: 0.8359\n",
      "Epoch: 1, Step: 2461/2949, Loss: 0.8236\n",
      "Epoch: 1, Step: 2462/2949, Loss: 0.8343\n",
      "Epoch: 1, Step: 2463/2949, Loss: 0.8668\n",
      "Epoch: 1, Step: 2464/2949, Loss: 0.8068\n",
      "Epoch: 1, Step: 2465/2949, Loss: 0.7971\n",
      "Epoch: 1, Step: 2466/2949, Loss: 0.8195\n",
      "Epoch: 1, Step: 2467/2949, Loss: 0.7754\n",
      "Epoch: 1, Step: 2468/2949, Loss: 0.8203\n",
      "Epoch: 1, Step: 2469/2949, Loss: 0.8113\n",
      "Epoch: 1, Step: 2470/2949, Loss: 0.8962\n",
      "Epoch: 1, Step: 2471/2949, Loss: 0.8227\n",
      "Epoch: 1, Step: 2472/2949, Loss: 0.8736\n",
      "Epoch: 1, Step: 2473/2949, Loss: 0.8372\n",
      "Epoch: 1, Step: 2474/2949, Loss: 0.8639\n",
      "Epoch: 1, Step: 2475/2949, Loss: 0.8489\n",
      "Epoch: 1, Step: 2476/2949, Loss: 0.8042\n",
      "Epoch: 1, Step: 2477/2949, Loss: 0.8539\n",
      "Epoch: 1, Step: 2478/2949, Loss: 0.8187\n",
      "Epoch: 1, Step: 2479/2949, Loss: 0.8015\n",
      "Epoch: 1, Step: 2480/2949, Loss: 0.8501\n",
      "Epoch: 1, Step: 2481/2949, Loss: 0.8729\n",
      "Epoch: 1, Step: 2482/2949, Loss: 0.8374\n",
      "Epoch: 1, Step: 2483/2949, Loss: 0.8560\n",
      "Epoch: 1, Step: 2484/2949, Loss: 0.8447\n",
      "Epoch: 1, Step: 2485/2949, Loss: 0.7857\n",
      "Epoch: 1, Step: 2486/2949, Loss: 0.8104\n",
      "Epoch: 1, Step: 2487/2949, Loss: 0.8189\n",
      "Epoch: 1, Step: 2488/2949, Loss: 0.8495\n",
      "Epoch: 1, Step: 2489/2949, Loss: 0.7926\n",
      "Epoch: 1, Step: 2490/2949, Loss: 0.8336\n",
      "Epoch: 1, Step: 2491/2949, Loss: 0.8210\n",
      "Epoch: 1, Step: 2492/2949, Loss: 0.8590\n",
      "Epoch: 1, Step: 2493/2949, Loss: 0.8362\n",
      "Epoch: 1, Step: 2494/2949, Loss: 0.8193\n",
      "Epoch: 1, Step: 2495/2949, Loss: 0.8193\n",
      "Epoch: 1, Step: 2496/2949, Loss: 0.8825\n",
      "Epoch: 1, Step: 2497/2949, Loss: 0.8102\n",
      "Epoch: 1, Step: 2498/2949, Loss: 0.8425\n",
      "Epoch: 1, Step: 2499/2949, Loss: 0.8413\n",
      "Epoch: 1, Step: 2500/2949, Loss: 0.8159\n",
      "Epoch: 1, Step: 2501/2949, Loss: 0.8151\n",
      "Epoch: 1, Step: 2502/2949, Loss: 0.8255\n",
      "Epoch: 1, Step: 2503/2949, Loss: 0.8362\n",
      "Epoch: 1, Step: 2504/2949, Loss: 0.8827\n",
      "Epoch: 1, Step: 2505/2949, Loss: 0.8217\n",
      "Epoch: 1, Step: 2506/2949, Loss: 0.8448\n",
      "Epoch: 1, Step: 2507/2949, Loss: 0.8698\n",
      "Epoch: 1, Step: 2508/2949, Loss: 0.8229\n",
      "Epoch: 1, Step: 2509/2949, Loss: 0.8627\n",
      "Epoch: 1, Step: 2510/2949, Loss: 0.8405\n",
      "Epoch: 1, Step: 2511/2949, Loss: 0.7762\n",
      "Epoch: 1, Step: 2512/2949, Loss: 0.8712\n",
      "Epoch: 1, Step: 2513/2949, Loss: 0.9011\n",
      "Epoch: 1, Step: 2514/2949, Loss: 0.8891\n",
      "Epoch: 1, Step: 2515/2949, Loss: 0.7889\n",
      "Epoch: 1, Step: 2516/2949, Loss: 0.8139\n",
      "Epoch: 1, Step: 2517/2949, Loss: 0.7486\n",
      "Epoch: 1, Step: 2518/2949, Loss: 0.8214\n",
      "Epoch: 1, Step: 2519/2949, Loss: 0.7833\n",
      "Epoch: 1, Step: 2520/2949, Loss: 0.8609\n",
      "Epoch: 1, Step: 2521/2949, Loss: 0.8386\n",
      "Epoch: 1, Step: 2522/2949, Loss: 0.8302\n",
      "Epoch: 1, Step: 2523/2949, Loss: 0.8177\n",
      "Epoch: 1, Step: 2524/2949, Loss: 0.8252\n",
      "Epoch: 1, Step: 2525/2949, Loss: 0.8737\n",
      "Epoch: 1, Step: 2526/2949, Loss: 0.8247\n",
      "Epoch: 1, Step: 2527/2949, Loss: 0.8156\n",
      "Epoch: 1, Step: 2528/2949, Loss: 0.8330\n",
      "Epoch: 1, Step: 2529/2949, Loss: 0.8458\n",
      "Epoch: 1, Step: 2530/2949, Loss: 0.8069\n",
      "Epoch: 1, Step: 2531/2949, Loss: 0.8031\n",
      "Epoch: 1, Step: 2532/2949, Loss: 0.7999\n",
      "Epoch: 1, Step: 2533/2949, Loss: 0.8476\n",
      "Epoch: 1, Step: 2534/2949, Loss: 0.8272\n",
      "Epoch: 1, Step: 2535/2949, Loss: 0.8428\n",
      "Epoch: 1, Step: 2536/2949, Loss: 0.8182\n",
      "Epoch: 1, Step: 2537/2949, Loss: 0.7927\n",
      "Epoch: 1, Step: 2538/2949, Loss: 0.8578\n",
      "Epoch: 1, Step: 2539/2949, Loss: 0.8089\n",
      "Epoch: 1, Step: 2540/2949, Loss: 0.8076\n",
      "Epoch: 1, Step: 2541/2949, Loss: 0.8581\n",
      "Epoch: 1, Step: 2542/2949, Loss: 0.8320\n",
      "Epoch: 1, Step: 2543/2949, Loss: 0.8174\n",
      "Epoch: 1, Step: 2544/2949, Loss: 0.7979\n",
      "Epoch: 1, Step: 2545/2949, Loss: 0.8403\n",
      "Epoch: 1, Step: 2546/2949, Loss: 0.8062\n",
      "Epoch: 1, Step: 2547/2949, Loss: 0.8778\n",
      "Epoch: 1, Step: 2548/2949, Loss: 0.7803\n",
      "Epoch: 1, Step: 2549/2949, Loss: 0.7799\n",
      "Epoch: 1, Step: 2550/2949, Loss: 0.8335\n",
      "Epoch: 1, Step: 2551/2949, Loss: 0.8611\n",
      "Epoch: 1, Step: 2552/2949, Loss: 0.7798\n",
      "Epoch: 1, Step: 2553/2949, Loss: 0.8219\n",
      "Epoch: 1, Step: 2554/2949, Loss: 0.8491\n",
      "Epoch: 1, Step: 2555/2949, Loss: 0.8232\n",
      "Epoch: 1, Step: 2556/2949, Loss: 0.8521\n",
      "Epoch: 1, Step: 2557/2949, Loss: 0.8046\n",
      "Epoch: 1, Step: 2558/2949, Loss: 0.8542\n",
      "Epoch: 1, Step: 2559/2949, Loss: 0.8369\n",
      "Epoch: 1, Step: 2560/2949, Loss: 0.8406\n",
      "Epoch: 1, Step: 2561/2949, Loss: 0.8280\n",
      "Epoch: 1, Step: 2562/2949, Loss: 0.8633\n",
      "Epoch: 1, Step: 2563/2949, Loss: 0.8080\n",
      "Epoch: 1, Step: 2564/2949, Loss: 0.8398\n",
      "Epoch: 1, Step: 2565/2949, Loss: 0.8262\n",
      "Epoch: 1, Step: 2566/2949, Loss: 0.8276\n",
      "Epoch: 1, Step: 2567/2949, Loss: 0.8425\n",
      "Epoch: 1, Step: 2568/2949, Loss: 0.7593\n",
      "Epoch: 1, Step: 2569/2949, Loss: 0.7811\n",
      "Epoch: 1, Step: 2570/2949, Loss: 0.8106\n",
      "Epoch: 1, Step: 2571/2949, Loss: 0.8266\n",
      "Epoch: 1, Step: 2572/2949, Loss: 0.8249\n",
      "Epoch: 1, Step: 2573/2949, Loss: 0.8220\n",
      "Epoch: 1, Step: 2574/2949, Loss: 0.7927\n",
      "Epoch: 1, Step: 2575/2949, Loss: 0.8228\n",
      "Epoch: 1, Step: 2576/2949, Loss: 0.8171\n",
      "Epoch: 1, Step: 2577/2949, Loss: 0.8380\n",
      "Epoch: 1, Step: 2578/2949, Loss: 0.8702\n",
      "Epoch: 1, Step: 2579/2949, Loss: 0.7989\n",
      "Epoch: 1, Step: 2580/2949, Loss: 0.8185\n",
      "Epoch: 1, Step: 2581/2949, Loss: 0.8243\n",
      "Epoch: 1, Step: 2582/2949, Loss: 0.8443\n",
      "Epoch: 1, Step: 2583/2949, Loss: 0.8671\n",
      "Epoch: 1, Step: 2584/2949, Loss: 0.8106\n",
      "Epoch: 1, Step: 2585/2949, Loss: 0.8415\n",
      "Epoch: 1, Step: 2586/2949, Loss: 0.8169\n",
      "Epoch: 1, Step: 2587/2949, Loss: 0.8413\n",
      "Epoch: 1, Step: 2588/2949, Loss: 0.7928\n",
      "Epoch: 1, Step: 2589/2949, Loss: 0.8265\n",
      "Epoch: 1, Step: 2590/2949, Loss: 0.8186\n",
      "Epoch: 1, Step: 2591/2949, Loss: 0.8455\n",
      "Epoch: 1, Step: 2592/2949, Loss: 0.8032\n",
      "Epoch: 1, Step: 2593/2949, Loss: 0.8651\n",
      "Epoch: 1, Step: 2594/2949, Loss: 0.8324\n",
      "Epoch: 1, Step: 2595/2949, Loss: 0.7848\n",
      "Epoch: 1, Step: 2596/2949, Loss: 0.8230\n",
      "Epoch: 1, Step: 2597/2949, Loss: 0.8507\n",
      "Epoch: 1, Step: 2598/2949, Loss: 0.8285\n",
      "Epoch: 1, Step: 2599/2949, Loss: 0.8737\n",
      "Epoch: 1, Step: 2600/2949, Loss: 0.8646\n",
      "Epoch: 1, Step: 2601/2949, Loss: 0.7874\n",
      "Epoch: 1, Step: 2602/2949, Loss: 0.8082\n",
      "Epoch: 1, Step: 2603/2949, Loss: 0.8902\n",
      "Epoch: 1, Step: 2604/2949, Loss: 0.8317\n",
      "Epoch: 1, Step: 2605/2949, Loss: 0.8587\n",
      "Epoch: 1, Step: 2606/2949, Loss: 0.8426\n",
      "Epoch: 1, Step: 2607/2949, Loss: 0.8466\n",
      "Epoch: 1, Step: 2608/2949, Loss: 0.8197\n",
      "Epoch: 1, Step: 2609/2949, Loss: 0.8649\n",
      "Epoch: 1, Step: 2610/2949, Loss: 0.8113\n",
      "Epoch: 1, Step: 2611/2949, Loss: 0.8811\n",
      "Epoch: 1, Step: 2612/2949, Loss: 0.8758\n",
      "Epoch: 1, Step: 2613/2949, Loss: 0.8072\n",
      "Epoch: 1, Step: 2614/2949, Loss: 0.8257\n",
      "Epoch: 1, Step: 2615/2949, Loss: 0.8519\n",
      "Epoch: 1, Step: 2616/2949, Loss: 0.8328\n",
      "Epoch: 1, Step: 2617/2949, Loss: 0.8530\n",
      "Epoch: 1, Step: 2618/2949, Loss: 0.8399\n",
      "Epoch: 1, Step: 2619/2949, Loss: 0.8234\n",
      "Epoch: 1, Step: 2620/2949, Loss: 0.8106\n",
      "Epoch: 1, Step: 2621/2949, Loss: 0.8681\n",
      "Epoch: 1, Step: 2622/2949, Loss: 0.7347\n",
      "Epoch: 1, Step: 2623/2949, Loss: 0.8318\n",
      "Epoch: 1, Step: 2624/2949, Loss: 0.8399\n",
      "Epoch: 1, Step: 2625/2949, Loss: 0.7960\n",
      "Epoch: 1, Step: 2626/2949, Loss: 0.8464\n",
      "Epoch: 1, Step: 2627/2949, Loss: 0.8097\n",
      "Epoch: 1, Step: 2628/2949, Loss: 0.7856\n",
      "Epoch: 1, Step: 2629/2949, Loss: 0.7921\n",
      "Epoch: 1, Step: 2630/2949, Loss: 0.7777\n",
      "Epoch: 1, Step: 2631/2949, Loss: 0.8048\n",
      "Epoch: 1, Step: 2632/2949, Loss: 0.8825\n",
      "Epoch: 1, Step: 2633/2949, Loss: 0.8333\n",
      "Epoch: 1, Step: 2634/2949, Loss: 0.8178\n",
      "Epoch: 1, Step: 2635/2949, Loss: 0.8338\n",
      "Epoch: 1, Step: 2636/2949, Loss: 0.8308\n",
      "Epoch: 1, Step: 2637/2949, Loss: 0.8232\n",
      "Epoch: 1, Step: 2638/2949, Loss: 0.8637\n",
      "Epoch: 1, Step: 2639/2949, Loss: 0.8401\n",
      "Epoch: 1, Step: 2640/2949, Loss: 0.8136\n",
      "Epoch: 1, Step: 2641/2949, Loss: 0.8035\n",
      "Epoch: 1, Step: 2642/2949, Loss: 0.8071\n",
      "Epoch: 1, Step: 2643/2949, Loss: 0.8212\n",
      "Epoch: 1, Step: 2644/2949, Loss: 0.8091\n",
      "Epoch: 1, Step: 2645/2949, Loss: 0.7549\n",
      "Epoch: 1, Step: 2646/2949, Loss: 0.8467\n",
      "Epoch: 1, Step: 2647/2949, Loss: 0.8282\n",
      "Epoch: 1, Step: 2648/2949, Loss: 0.8591\n",
      "Epoch: 1, Step: 2649/2949, Loss: 0.8253\n",
      "Epoch: 1, Step: 2650/2949, Loss: 0.8700\n",
      "Epoch: 1, Step: 2651/2949, Loss: 0.8039\n",
      "Epoch: 1, Step: 2652/2949, Loss: 0.8553\n",
      "Epoch: 1, Step: 2653/2949, Loss: 0.8157\n",
      "Epoch: 1, Step: 2654/2949, Loss: 0.8731\n",
      "Epoch: 1, Step: 2655/2949, Loss: 0.8022\n",
      "Epoch: 1, Step: 2656/2949, Loss: 0.8121\n",
      "Epoch: 1, Step: 2657/2949, Loss: 0.7997\n",
      "Epoch: 1, Step: 2658/2949, Loss: 0.8279\n",
      "Epoch: 1, Step: 2659/2949, Loss: 0.8561\n",
      "Epoch: 1, Step: 2660/2949, Loss: 0.7979\n",
      "Epoch: 1, Step: 2661/2949, Loss: 0.8405\n",
      "Epoch: 1, Step: 2662/2949, Loss: 0.7898\n",
      "Epoch: 1, Step: 2663/2949, Loss: 0.8416\n",
      "Epoch: 1, Step: 2664/2949, Loss: 0.8343\n",
      "Epoch: 1, Step: 2665/2949, Loss: 0.8521\n",
      "Epoch: 1, Step: 2666/2949, Loss: 0.7956\n",
      "Epoch: 1, Step: 2667/2949, Loss: 0.8171\n",
      "Epoch: 1, Step: 2668/2949, Loss: 0.8280\n",
      "Epoch: 1, Step: 2669/2949, Loss: 0.8677\n",
      "Epoch: 1, Step: 2670/2949, Loss: 0.8258\n",
      "Epoch: 1, Step: 2671/2949, Loss: 0.8797\n",
      "Epoch: 1, Step: 2672/2949, Loss: 0.8412\n",
      "Epoch: 1, Step: 2673/2949, Loss: 0.8300\n",
      "Epoch: 1, Step: 2674/2949, Loss: 0.8059\n",
      "Epoch: 1, Step: 2675/2949, Loss: 0.8251\n",
      "Epoch: 1, Step: 2676/2949, Loss: 0.8232\n",
      "Epoch: 1, Step: 2677/2949, Loss: 0.8206\n",
      "Epoch: 1, Step: 2678/2949, Loss: 0.7971\n",
      "Epoch: 1, Step: 2679/2949, Loss: 0.7650\n",
      "Epoch: 1, Step: 2680/2949, Loss: 0.8279\n",
      "Epoch: 1, Step: 2681/2949, Loss: 0.8485\n",
      "Epoch: 1, Step: 2682/2949, Loss: 0.7824\n",
      "Epoch: 1, Step: 2683/2949, Loss: 0.8365\n",
      "Epoch: 1, Step: 2684/2949, Loss: 0.7771\n",
      "Epoch: 1, Step: 2685/2949, Loss: 0.7952\n",
      "Epoch: 1, Step: 2686/2949, Loss: 0.7759\n",
      "Epoch: 1, Step: 2687/2949, Loss: 0.8320\n",
      "Epoch: 1, Step: 2688/2949, Loss: 0.8665\n",
      "Epoch: 1, Step: 2689/2949, Loss: 0.7871\n",
      "Epoch: 1, Step: 2690/2949, Loss: 0.8173\n",
      "Epoch: 1, Step: 2691/2949, Loss: 0.8397\n",
      "Epoch: 1, Step: 2692/2949, Loss: 0.8785\n",
      "Epoch: 1, Step: 2693/2949, Loss: 0.8126\n",
      "Epoch: 1, Step: 2694/2949, Loss: 0.8263\n",
      "Epoch: 1, Step: 2695/2949, Loss: 0.8511\n",
      "Epoch: 1, Step: 2696/2949, Loss: 0.8743\n",
      "Epoch: 1, Step: 2697/2949, Loss: 0.8128\n",
      "Epoch: 1, Step: 2698/2949, Loss: 0.7907\n",
      "Epoch: 1, Step: 2699/2949, Loss: 0.8108\n",
      "Epoch: 1, Step: 2700/2949, Loss: 0.8372\n",
      "Epoch: 1, Step: 2701/2949, Loss: 0.8576\n",
      "Epoch: 1, Step: 2702/2949, Loss: 0.8466\n",
      "Epoch: 1, Step: 2703/2949, Loss: 0.8383\n",
      "Epoch: 1, Step: 2704/2949, Loss: 0.8311\n",
      "Epoch: 1, Step: 2705/2949, Loss: 0.8363\n",
      "Epoch: 1, Step: 2706/2949, Loss: 0.8811\n",
      "Epoch: 1, Step: 2707/2949, Loss: 0.8030\n",
      "Epoch: 1, Step: 2708/2949, Loss: 0.8283\n",
      "Epoch: 1, Step: 2709/2949, Loss: 0.8297\n",
      "Epoch: 1, Step: 2710/2949, Loss: 0.7950\n",
      "Epoch: 1, Step: 2711/2949, Loss: 0.8091\n",
      "Epoch: 1, Step: 2712/2949, Loss: 0.8305\n",
      "Epoch: 1, Step: 2713/2949, Loss: 0.8305\n",
      "Epoch: 1, Step: 2714/2949, Loss: 0.7953\n",
      "Epoch: 1, Step: 2715/2949, Loss: 0.9037\n",
      "Epoch: 1, Step: 2716/2949, Loss: 0.8295\n",
      "Epoch: 1, Step: 2717/2949, Loss: 0.7903\n",
      "Epoch: 1, Step: 2718/2949, Loss: 0.7884\n",
      "Epoch: 1, Step: 2719/2949, Loss: 0.7973\n",
      "Epoch: 1, Step: 2720/2949, Loss: 0.8191\n",
      "Epoch: 1, Step: 2721/2949, Loss: 0.8489\n",
      "Epoch: 1, Step: 2722/2949, Loss: 0.8472\n",
      "Epoch: 1, Step: 2723/2949, Loss: 0.8077\n",
      "Epoch: 1, Step: 2724/2949, Loss: 0.8331\n",
      "Epoch: 1, Step: 2725/2949, Loss: 0.8235\n",
      "Epoch: 1, Step: 2726/2949, Loss: 0.7688\n",
      "Epoch: 1, Step: 2727/2949, Loss: 0.8466\n",
      "Epoch: 1, Step: 2728/2949, Loss: 0.8120\n",
      "Epoch: 1, Step: 2729/2949, Loss: 0.8747\n",
      "Epoch: 1, Step: 2730/2949, Loss: 0.8577\n",
      "Epoch: 1, Step: 2731/2949, Loss: 0.8207\n",
      "Epoch: 1, Step: 2732/2949, Loss: 0.8560\n",
      "Epoch: 1, Step: 2733/2949, Loss: 0.8356\n",
      "Epoch: 1, Step: 2734/2949, Loss: 0.8788\n",
      "Epoch: 1, Step: 2735/2949, Loss: 0.8012\n",
      "Epoch: 1, Step: 2736/2949, Loss: 0.8617\n",
      "Epoch: 1, Step: 2737/2949, Loss: 0.7868\n",
      "Epoch: 1, Step: 2738/2949, Loss: 0.8469\n",
      "Epoch: 1, Step: 2739/2949, Loss: 0.8702\n",
      "Epoch: 1, Step: 2740/2949, Loss: 0.8486\n",
      "Epoch: 1, Step: 2741/2949, Loss: 0.7965\n",
      "Epoch: 1, Step: 2742/2949, Loss: 0.8299\n",
      "Epoch: 1, Step: 2743/2949, Loss: 0.7884\n",
      "Epoch: 1, Step: 2744/2949, Loss: 0.7982\n",
      "Epoch: 1, Step: 2745/2949, Loss: 0.8432\n",
      "Epoch: 1, Step: 2746/2949, Loss: 0.8599\n",
      "Epoch: 1, Step: 2747/2949, Loss: 0.7901\n",
      "Epoch: 1, Step: 2748/2949, Loss: 0.8373\n",
      "Epoch: 1, Step: 2749/2949, Loss: 0.8413\n",
      "Epoch: 1, Step: 2750/2949, Loss: 0.8395\n",
      "Epoch: 1, Step: 2751/2949, Loss: 0.8108\n",
      "Epoch: 1, Step: 2752/2949, Loss: 0.8609\n",
      "Epoch: 1, Step: 2753/2949, Loss: 0.8546\n",
      "Epoch: 1, Step: 2754/2949, Loss: 0.8036\n",
      "Epoch: 1, Step: 2755/2949, Loss: 0.8367\n",
      "Epoch: 1, Step: 2756/2949, Loss: 0.8881\n",
      "Epoch: 1, Step: 2757/2949, Loss: 0.7959\n",
      "Epoch: 1, Step: 2758/2949, Loss: 0.8189\n",
      "Epoch: 1, Step: 2759/2949, Loss: 0.8268\n",
      "Epoch: 1, Step: 2760/2949, Loss: 0.8162\n",
      "Epoch: 1, Step: 2761/2949, Loss: 0.8300\n",
      "Epoch: 1, Step: 2762/2949, Loss: 0.7672\n",
      "Epoch: 1, Step: 2763/2949, Loss: 0.8346\n",
      "Epoch: 1, Step: 2764/2949, Loss: 0.8099\n",
      "Epoch: 1, Step: 2765/2949, Loss: 0.8569\n",
      "Epoch: 1, Step: 2766/2949, Loss: 0.8406\n",
      "Epoch: 1, Step: 2767/2949, Loss: 0.8138\n",
      "Epoch: 1, Step: 2768/2949, Loss: 0.8337\n",
      "Epoch: 1, Step: 2769/2949, Loss: 0.8726\n",
      "Epoch: 1, Step: 2770/2949, Loss: 0.8258\n",
      "Epoch: 1, Step: 2771/2949, Loss: 0.8143\n",
      "Epoch: 1, Step: 2772/2949, Loss: 0.8373\n",
      "Epoch: 1, Step: 2773/2949, Loss: 0.8161\n",
      "Epoch: 1, Step: 2774/2949, Loss: 0.8437\n",
      "Epoch: 1, Step: 2775/2949, Loss: 0.8356\n",
      "Epoch: 1, Step: 2776/2949, Loss: 0.8327\n",
      "Epoch: 1, Step: 2777/2949, Loss: 0.8539\n",
      "Epoch: 1, Step: 2778/2949, Loss: 0.8020\n",
      "Epoch: 1, Step: 2779/2949, Loss: 0.7924\n",
      "Epoch: 1, Step: 2780/2949, Loss: 0.7908\n",
      "Epoch: 1, Step: 2781/2949, Loss: 0.8264\n",
      "Epoch: 1, Step: 2782/2949, Loss: 0.8270\n",
      "Epoch: 1, Step: 2783/2949, Loss: 0.8637\n",
      "Epoch: 1, Step: 2784/2949, Loss: 0.8442\n",
      "Epoch: 1, Step: 2785/2949, Loss: 0.8339\n",
      "Epoch: 1, Step: 2786/2949, Loss: 0.7707\n",
      "Epoch: 1, Step: 2787/2949, Loss: 0.8704\n",
      "Epoch: 1, Step: 2788/2949, Loss: 0.8281\n",
      "Epoch: 1, Step: 2789/2949, Loss: 0.8238\n",
      "Epoch: 1, Step: 2790/2949, Loss: 0.8287\n",
      "Epoch: 1, Step: 2791/2949, Loss: 0.8331\n",
      "Epoch: 1, Step: 2792/2949, Loss: 0.8306\n",
      "Epoch: 1, Step: 2793/2949, Loss: 0.7910\n",
      "Epoch: 1, Step: 2794/2949, Loss: 0.8808\n",
      "Epoch: 1, Step: 2795/2949, Loss: 0.7995\n",
      "Epoch: 1, Step: 2796/2949, Loss: 0.8607\n",
      "Epoch: 1, Step: 2797/2949, Loss: 0.8561\n",
      "Epoch: 1, Step: 2798/2949, Loss: 0.8331\n",
      "Epoch: 1, Step: 2799/2949, Loss: 0.8488\n",
      "Epoch: 1, Step: 2800/2949, Loss: 0.8393\n",
      "Epoch: 1, Step: 2801/2949, Loss: 0.8736\n",
      "Epoch: 1, Step: 2802/2949, Loss: 0.8710\n",
      "Epoch: 1, Step: 2803/2949, Loss: 0.8173\n",
      "Epoch: 1, Step: 2804/2949, Loss: 0.7834\n",
      "Epoch: 1, Step: 2805/2949, Loss: 0.8361\n",
      "Epoch: 1, Step: 2806/2949, Loss: 0.8334\n",
      "Epoch: 1, Step: 2807/2949, Loss: 0.8593\n",
      "Epoch: 1, Step: 2808/2949, Loss: 0.7865\n",
      "Epoch: 1, Step: 2809/2949, Loss: 0.7886\n",
      "Epoch: 1, Step: 2810/2949, Loss: 0.7397\n",
      "Epoch: 1, Step: 2811/2949, Loss: 0.8402\n",
      "Epoch: 1, Step: 2812/2949, Loss: 0.8530\n",
      "Epoch: 1, Step: 2813/2949, Loss: 0.8192\n",
      "Epoch: 1, Step: 2814/2949, Loss: 0.8062\n",
      "Epoch: 1, Step: 2815/2949, Loss: 0.8820\n",
      "Epoch: 1, Step: 2816/2949, Loss: 0.8458\n",
      "Epoch: 1, Step: 2817/2949, Loss: 0.8822\n",
      "Epoch: 1, Step: 2818/2949, Loss: 0.8118\n",
      "Epoch: 1, Step: 2819/2949, Loss: 0.8248\n",
      "Epoch: 1, Step: 2820/2949, Loss: 0.8444\n",
      "Epoch: 1, Step: 2821/2949, Loss: 0.8571\n",
      "Epoch: 1, Step: 2822/2949, Loss: 0.8424\n",
      "Epoch: 1, Step: 2823/2949, Loss: 0.8647\n",
      "Epoch: 1, Step: 2824/2949, Loss: 0.8380\n",
      "Epoch: 1, Step: 2825/2949, Loss: 0.8276\n",
      "Epoch: 1, Step: 2826/2949, Loss: 0.8126\n",
      "Epoch: 1, Step: 2827/2949, Loss: 0.8194\n",
      "Epoch: 1, Step: 2828/2949, Loss: 0.8052\n",
      "Epoch: 1, Step: 2829/2949, Loss: 0.8458\n",
      "Epoch: 1, Step: 2830/2949, Loss: 0.8328\n",
      "Epoch: 1, Step: 2831/2949, Loss: 0.8161\n",
      "Epoch: 1, Step: 2832/2949, Loss: 0.8537\n",
      "Epoch: 1, Step: 2833/2949, Loss: 0.8191\n",
      "Epoch: 1, Step: 2834/2949, Loss: 0.8180\n",
      "Epoch: 1, Step: 2835/2949, Loss: 0.8669\n",
      "Epoch: 1, Step: 2836/2949, Loss: 0.8145\n",
      "Epoch: 1, Step: 2837/2949, Loss: 0.8261\n",
      "Epoch: 1, Step: 2838/2949, Loss: 0.8045\n",
      "Epoch: 1, Step: 2839/2949, Loss: 0.8415\n",
      "Epoch: 1, Step: 2840/2949, Loss: 0.8446\n",
      "Epoch: 1, Step: 2841/2949, Loss: 0.8228\n",
      "Epoch: 1, Step: 2842/2949, Loss: 0.8540\n",
      "Epoch: 1, Step: 2843/2949, Loss: 0.8028\n",
      "Epoch: 1, Step: 2844/2949, Loss: 0.8500\n",
      "Epoch: 1, Step: 2845/2949, Loss: 0.8364\n",
      "Epoch: 1, Step: 2846/2949, Loss: 0.7946\n",
      "Epoch: 1, Step: 2847/2949, Loss: 0.8156\n",
      "Epoch: 1, Step: 2848/2949, Loss: 0.8230\n",
      "Epoch: 1, Step: 2849/2949, Loss: 0.8305\n",
      "Epoch: 1, Step: 2850/2949, Loss: 0.8517\n",
      "Epoch: 1, Step: 2851/2949, Loss: 0.7920\n",
      "Epoch: 1, Step: 2852/2949, Loss: 0.8342\n",
      "Epoch: 1, Step: 2853/2949, Loss: 0.8488\n",
      "Epoch: 1, Step: 2854/2949, Loss: 0.7659\n",
      "Epoch: 1, Step: 2855/2949, Loss: 0.8191\n",
      "Epoch: 1, Step: 2856/2949, Loss: 0.8257\n",
      "Epoch: 1, Step: 2857/2949, Loss: 0.8635\n",
      "Epoch: 1, Step: 2858/2949, Loss: 0.7797\n",
      "Epoch: 1, Step: 2859/2949, Loss: 0.8325\n",
      "Epoch: 1, Step: 2860/2949, Loss: 0.8273\n",
      "Epoch: 1, Step: 2861/2949, Loss: 0.7945\n",
      "Epoch: 1, Step: 2862/2949, Loss: 0.8336\n",
      "Epoch: 1, Step: 2863/2949, Loss: 0.8595\n",
      "Epoch: 1, Step: 2864/2949, Loss: 0.8950\n",
      "Epoch: 1, Step: 2865/2949, Loss: 0.8453\n",
      "Epoch: 1, Step: 2866/2949, Loss: 0.8861\n",
      "Epoch: 1, Step: 2867/2949, Loss: 0.8022\n",
      "Epoch: 1, Step: 2868/2949, Loss: 0.8696\n",
      "Epoch: 1, Step: 2869/2949, Loss: 0.7829\n",
      "Epoch: 1, Step: 2870/2949, Loss: 0.7985\n",
      "Epoch: 1, Step: 2871/2949, Loss: 0.8536\n",
      "Epoch: 1, Step: 2872/2949, Loss: 0.8288\n",
      "Epoch: 1, Step: 2873/2949, Loss: 0.8440\n",
      "Epoch: 1, Step: 2874/2949, Loss: 0.7540\n",
      "Epoch: 1, Step: 2875/2949, Loss: 0.8289\n",
      "Epoch: 1, Step: 2876/2949, Loss: 0.8085\n",
      "Epoch: 1, Step: 2877/2949, Loss: 0.8644\n",
      "Epoch: 1, Step: 2878/2949, Loss: 0.8230\n",
      "Epoch: 1, Step: 2879/2949, Loss: 0.7985\n",
      "Epoch: 1, Step: 2880/2949, Loss: 0.7821\n",
      "Epoch: 1, Step: 2881/2949, Loss: 0.8397\n",
      "Epoch: 1, Step: 2882/2949, Loss: 0.8479\n",
      "Epoch: 1, Step: 2883/2949, Loss: 0.8354\n",
      "Epoch: 1, Step: 2884/2949, Loss: 0.8254\n",
      "Epoch: 1, Step: 2885/2949, Loss: 0.8029\n",
      "Epoch: 1, Step: 2886/2949, Loss: 0.8863\n",
      "Epoch: 1, Step: 2887/2949, Loss: 0.8496\n",
      "Epoch: 1, Step: 2888/2949, Loss: 0.7977\n",
      "Epoch: 1, Step: 2889/2949, Loss: 0.8715\n",
      "Epoch: 1, Step: 2890/2949, Loss: 0.8380\n",
      "Epoch: 1, Step: 2891/2949, Loss: 0.8300\n",
      "Epoch: 1, Step: 2892/2949, Loss: 0.8476\n",
      "Epoch: 1, Step: 2893/2949, Loss: 0.8186\n",
      "Epoch: 1, Step: 2894/2949, Loss: 0.8231\n",
      "Epoch: 1, Step: 2895/2949, Loss: 0.8729\n",
      "Epoch: 1, Step: 2896/2949, Loss: 0.8094\n",
      "Epoch: 1, Step: 2897/2949, Loss: 0.8089\n",
      "Epoch: 1, Step: 2898/2949, Loss: 0.8651\n",
      "Epoch: 1, Step: 2899/2949, Loss: 0.8392\n",
      "Epoch: 1, Step: 2900/2949, Loss: 0.8522\n",
      "Epoch: 1, Step: 2901/2949, Loss: 0.8156\n",
      "Epoch: 1, Step: 2902/2949, Loss: 0.8107\n",
      "Epoch: 1, Step: 2903/2949, Loss: 0.8059\n",
      "Epoch: 1, Step: 2904/2949, Loss: 0.8083\n",
      "Epoch: 1, Step: 2905/2949, Loss: 0.8529\n",
      "Epoch: 1, Step: 2906/2949, Loss: 0.7979\n",
      "Epoch: 1, Step: 2907/2949, Loss: 0.8050\n",
      "Epoch: 1, Step: 2908/2949, Loss: 0.8198\n",
      "Epoch: 1, Step: 2909/2949, Loss: 0.8463\n",
      "Epoch: 1, Step: 2910/2949, Loss: 0.8240\n",
      "Epoch: 1, Step: 2911/2949, Loss: 0.8416\n",
      "Epoch: 1, Step: 2912/2949, Loss: 0.8150\n",
      "Epoch: 1, Step: 2913/2949, Loss: 0.8442\n",
      "Epoch: 1, Step: 2914/2949, Loss: 0.8035\n",
      "Epoch: 1, Step: 2915/2949, Loss: 0.8583\n",
      "Epoch: 1, Step: 2916/2949, Loss: 0.8760\n",
      "Epoch: 1, Step: 2917/2949, Loss: 0.7613\n",
      "Epoch: 1, Step: 2918/2949, Loss: 0.8440\n",
      "Epoch: 1, Step: 2919/2949, Loss: 0.8866\n",
      "Epoch: 1, Step: 2920/2949, Loss: 0.8494\n",
      "Epoch: 1, Step: 2921/2949, Loss: 0.7905\n",
      "Epoch: 1, Step: 2922/2949, Loss: 0.7713\n",
      "Epoch: 1, Step: 2923/2949, Loss: 0.7935\n",
      "Epoch: 1, Step: 2924/2949, Loss: 0.8479\n",
      "Epoch: 1, Step: 2925/2949, Loss: 0.8210\n",
      "Epoch: 1, Step: 2926/2949, Loss: 0.7930\n",
      "Epoch: 1, Step: 2927/2949, Loss: 0.7961\n",
      "Epoch: 1, Step: 2928/2949, Loss: 0.8344\n",
      "Epoch: 1, Step: 2929/2949, Loss: 0.8648\n",
      "Epoch: 1, Step: 2930/2949, Loss: 0.7783\n",
      "Epoch: 1, Step: 2931/2949, Loss: 0.8214\n",
      "Epoch: 1, Step: 2932/2949, Loss: 0.8746\n",
      "Epoch: 1, Step: 2933/2949, Loss: 0.8200\n",
      "Epoch: 1, Step: 2934/2949, Loss: 0.8362\n",
      "Epoch: 1, Step: 2935/2949, Loss: 0.8457\n",
      "Epoch: 1, Step: 2936/2949, Loss: 0.8469\n",
      "Epoch: 1, Step: 2937/2949, Loss: 0.8029\n",
      "Epoch: 1, Step: 2938/2949, Loss: 0.8215\n",
      "Epoch: 1, Step: 2939/2949, Loss: 0.8158\n",
      "Epoch: 1, Step: 2940/2949, Loss: 0.7723\n",
      "Epoch: 1, Step: 2941/2949, Loss: 0.8380\n",
      "Epoch: 1, Step: 2942/2949, Loss: 0.8352\n",
      "Epoch: 1, Step: 2943/2949, Loss: 0.8111\n",
      "Epoch: 1, Step: 2944/2949, Loss: 0.8280\n",
      "Epoch: 1, Step: 2945/2949, Loss: 0.8075\n",
      "Epoch: 1, Step: 2946/2949, Loss: 0.8028\n",
      "Epoch: 1, Step: 2947/2949, Loss: 0.8784\n",
      "Epoch: 1, Step: 2948/2949, Loss: 0.7849\n",
      "Epoch: 1, Step: 2949/2949, Loss: 0.9652\n",
      "Test Accuracy (xgboost): 0.3708\n",
      "Epoch: 1, Accuracy: 0.3708\n",
      "Epoch: 2, Step: 001/2949, Loss: 0.8719\n",
      "Epoch: 2, Step: 002/2949, Loss: 0.8266\n",
      "Epoch: 2, Step: 003/2949, Loss: 0.8193\n",
      "Epoch: 2, Step: 004/2949, Loss: 0.8450\n",
      "Epoch: 2, Step: 005/2949, Loss: 0.8476\n",
      "Epoch: 2, Step: 006/2949, Loss: 0.7850\n",
      "Epoch: 2, Step: 007/2949, Loss: 0.8120\n",
      "Epoch: 2, Step: 008/2949, Loss: 0.8560\n",
      "Epoch: 2, Step: 009/2949, Loss: 0.8127\n",
      "Epoch: 2, Step: 010/2949, Loss: 0.8161\n",
      "Epoch: 2, Step: 011/2949, Loss: 0.7616\n",
      "Epoch: 2, Step: 012/2949, Loss: 0.7516\n",
      "Epoch: 2, Step: 013/2949, Loss: 0.9154\n",
      "Epoch: 2, Step: 014/2949, Loss: 0.7819\n",
      "Epoch: 2, Step: 015/2949, Loss: 0.8315\n",
      "Epoch: 2, Step: 016/2949, Loss: 0.7941\n",
      "Epoch: 2, Step: 017/2949, Loss: 0.8022\n",
      "Epoch: 2, Step: 018/2949, Loss: 0.8059\n",
      "Epoch: 2, Step: 019/2949, Loss: 0.8775\n",
      "Epoch: 2, Step: 020/2949, Loss: 0.7720\n",
      "Epoch: 2, Step: 021/2949, Loss: 0.8266\n",
      "Epoch: 2, Step: 022/2949, Loss: 0.8298\n",
      "Epoch: 2, Step: 023/2949, Loss: 0.8209\n",
      "Epoch: 2, Step: 024/2949, Loss: 0.7859\n",
      "Epoch: 2, Step: 025/2949, Loss: 0.8281\n",
      "Epoch: 2, Step: 026/2949, Loss: 0.8189\n",
      "Epoch: 2, Step: 027/2949, Loss: 0.8119\n",
      "Epoch: 2, Step: 028/2949, Loss: 0.8184\n",
      "Epoch: 2, Step: 029/2949, Loss: 0.7853\n",
      "Epoch: 2, Step: 030/2949, Loss: 0.8491\n",
      "Epoch: 2, Step: 031/2949, Loss: 0.8539\n",
      "Epoch: 2, Step: 032/2949, Loss: 0.8231\n",
      "Epoch: 2, Step: 033/2949, Loss: 0.8425\n",
      "Epoch: 2, Step: 034/2949, Loss: 0.8480\n",
      "Epoch: 2, Step: 035/2949, Loss: 0.7796\n",
      "Epoch: 2, Step: 036/2949, Loss: 0.8479\n",
      "Epoch: 2, Step: 037/2949, Loss: 0.8647\n",
      "Epoch: 2, Step: 038/2949, Loss: 0.8292\n",
      "Epoch: 2, Step: 039/2949, Loss: 0.7956\n",
      "Epoch: 2, Step: 040/2949, Loss: 0.8237\n",
      "Epoch: 2, Step: 041/2949, Loss: 0.8278\n",
      "Epoch: 2, Step: 042/2949, Loss: 0.8101\n",
      "Epoch: 2, Step: 043/2949, Loss: 0.8054\n",
      "Epoch: 2, Step: 044/2949, Loss: 0.8203\n",
      "Epoch: 2, Step: 045/2949, Loss: 0.8818\n",
      "Epoch: 2, Step: 046/2949, Loss: 0.8623\n",
      "Epoch: 2, Step: 047/2949, Loss: 0.7850\n",
      "Epoch: 2, Step: 048/2949, Loss: 0.7728\n",
      "Epoch: 2, Step: 049/2949, Loss: 0.8407\n",
      "Epoch: 2, Step: 050/2949, Loss: 0.7672\n",
      "Epoch: 2, Step: 051/2949, Loss: 0.8373\n",
      "Epoch: 2, Step: 052/2949, Loss: 0.8056\n",
      "Epoch: 2, Step: 053/2949, Loss: 0.8310\n",
      "Epoch: 2, Step: 054/2949, Loss: 0.8028\n",
      "Epoch: 2, Step: 055/2949, Loss: 0.8218\n",
      "Epoch: 2, Step: 056/2949, Loss: 0.8202\n",
      "Epoch: 2, Step: 057/2949, Loss: 0.7959\n",
      "Epoch: 2, Step: 058/2949, Loss: 0.7971\n",
      "Epoch: 2, Step: 059/2949, Loss: 0.8158\n",
      "Epoch: 2, Step: 060/2949, Loss: 0.8247\n",
      "Epoch: 2, Step: 061/2949, Loss: 0.8313\n",
      "Epoch: 2, Step: 062/2949, Loss: 0.8712\n",
      "Epoch: 2, Step: 063/2949, Loss: 0.8467\n",
      "Epoch: 2, Step: 064/2949, Loss: 0.8210\n",
      "Epoch: 2, Step: 065/2949, Loss: 0.7722\n",
      "Epoch: 2, Step: 066/2949, Loss: 0.8152\n",
      "Epoch: 2, Step: 067/2949, Loss: 0.8039\n",
      "Epoch: 2, Step: 068/2949, Loss: 0.8101\n",
      "Epoch: 2, Step: 069/2949, Loss: 0.7890\n",
      "Epoch: 2, Step: 070/2949, Loss: 0.8236\n",
      "Epoch: 2, Step: 071/2949, Loss: 0.8216\n",
      "Epoch: 2, Step: 072/2949, Loss: 0.7974\n",
      "Epoch: 2, Step: 073/2949, Loss: 0.8343\n",
      "Epoch: 2, Step: 074/2949, Loss: 0.7820\n",
      "Epoch: 2, Step: 075/2949, Loss: 0.8047\n",
      "Epoch: 2, Step: 076/2949, Loss: 0.8536\n",
      "Epoch: 2, Step: 077/2949, Loss: 0.8369\n",
      "Epoch: 2, Step: 078/2949, Loss: 0.8036\n",
      "Epoch: 2, Step: 079/2949, Loss: 0.8437\n",
      "Epoch: 2, Step: 080/2949, Loss: 0.8627\n",
      "Epoch: 2, Step: 081/2949, Loss: 0.8221\n",
      "Epoch: 2, Step: 082/2949, Loss: 0.8581\n",
      "Epoch: 2, Step: 083/2949, Loss: 0.8500\n",
      "Epoch: 2, Step: 084/2949, Loss: 0.8495\n",
      "Epoch: 2, Step: 085/2949, Loss: 0.8081\n",
      "Epoch: 2, Step: 086/2949, Loss: 0.8519\n",
      "Epoch: 2, Step: 087/2949, Loss: 0.7689\n",
      "Epoch: 2, Step: 088/2949, Loss: 0.8466\n",
      "Epoch: 2, Step: 089/2949, Loss: 0.8316\n",
      "Epoch: 2, Step: 090/2949, Loss: 0.8092\n",
      "Epoch: 2, Step: 091/2949, Loss: 0.8578\n",
      "Epoch: 2, Step: 092/2949, Loss: 0.7544\n",
      "Epoch: 2, Step: 093/2949, Loss: 0.7960\n",
      "Epoch: 2, Step: 094/2949, Loss: 0.8081\n",
      "Epoch: 2, Step: 095/2949, Loss: 0.8387\n",
      "Epoch: 2, Step: 096/2949, Loss: 0.8438\n",
      "Epoch: 2, Step: 097/2949, Loss: 0.7868\n",
      "Epoch: 2, Step: 098/2949, Loss: 0.7855\n",
      "Epoch: 2, Step: 099/2949, Loss: 0.7508\n",
      "Epoch: 2, Step: 100/2949, Loss: 0.7810\n",
      "Epoch: 2, Step: 101/2949, Loss: 0.8639\n",
      "Epoch: 2, Step: 102/2949, Loss: 0.8013\n",
      "Epoch: 2, Step: 103/2949, Loss: 0.8116\n",
      "Epoch: 2, Step: 104/2949, Loss: 0.7822\n",
      "Epoch: 2, Step: 105/2949, Loss: 0.7985\n",
      "Epoch: 2, Step: 106/2949, Loss: 0.8590\n",
      "Epoch: 2, Step: 107/2949, Loss: 0.8685\n",
      "Epoch: 2, Step: 108/2949, Loss: 0.8463\n",
      "Epoch: 2, Step: 109/2949, Loss: 0.8023\n",
      "Epoch: 2, Step: 110/2949, Loss: 0.8081\n",
      "Epoch: 2, Step: 111/2949, Loss: 0.8189\n",
      "Epoch: 2, Step: 112/2949, Loss: 0.8548\n",
      "Epoch: 2, Step: 113/2949, Loss: 0.8137\n",
      "Epoch: 2, Step: 114/2949, Loss: 0.8066\n",
      "Epoch: 2, Step: 115/2949, Loss: 0.8538\n",
      "Epoch: 2, Step: 116/2949, Loss: 0.8524\n",
      "Epoch: 2, Step: 117/2949, Loss: 0.7884\n",
      "Epoch: 2, Step: 118/2949, Loss: 0.8748\n",
      "Epoch: 2, Step: 119/2949, Loss: 0.8048\n",
      "Epoch: 2, Step: 120/2949, Loss: 0.8218\n",
      "Epoch: 2, Step: 121/2949, Loss: 0.8259\n",
      "Epoch: 2, Step: 122/2949, Loss: 0.7968\n",
      "Epoch: 2, Step: 123/2949, Loss: 0.8625\n",
      "Epoch: 2, Step: 124/2949, Loss: 0.8112\n",
      "Epoch: 2, Step: 125/2949, Loss: 0.7985\n",
      "Epoch: 2, Step: 126/2949, Loss: 0.8086\n",
      "Epoch: 2, Step: 127/2949, Loss: 0.9010\n",
      "Epoch: 2, Step: 128/2949, Loss: 0.8259\n",
      "Epoch: 2, Step: 129/2949, Loss: 0.8559\n",
      "Epoch: 2, Step: 130/2949, Loss: 0.7260\n",
      "Epoch: 2, Step: 131/2949, Loss: 0.8307\n",
      "Epoch: 2, Step: 132/2949, Loss: 0.8196\n",
      "Epoch: 2, Step: 133/2949, Loss: 0.8724\n",
      "Epoch: 2, Step: 134/2949, Loss: 0.8285\n",
      "Epoch: 2, Step: 135/2949, Loss: 0.8448\n",
      "Epoch: 2, Step: 136/2949, Loss: 0.8911\n",
      "Epoch: 2, Step: 137/2949, Loss: 0.7963\n",
      "Epoch: 2, Step: 138/2949, Loss: 0.8420\n",
      "Epoch: 2, Step: 139/2949, Loss: 0.7803\n",
      "Epoch: 2, Step: 140/2949, Loss: 0.8066\n",
      "Epoch: 2, Step: 141/2949, Loss: 0.7692\n",
      "Epoch: 2, Step: 142/2949, Loss: 0.7995\n",
      "Epoch: 2, Step: 143/2949, Loss: 0.8091\n",
      "Epoch: 2, Step: 144/2949, Loss: 0.8476\n",
      "Epoch: 2, Step: 145/2949, Loss: 0.7873\n",
      "Epoch: 2, Step: 146/2949, Loss: 0.7682\n",
      "Epoch: 2, Step: 147/2949, Loss: 0.8207\n",
      "Epoch: 2, Step: 148/2949, Loss: 0.8519\n",
      "Epoch: 2, Step: 149/2949, Loss: 0.8141\n",
      "Epoch: 2, Step: 150/2949, Loss: 0.8136\n",
      "Epoch: 2, Step: 151/2949, Loss: 0.8238\n",
      "Epoch: 2, Step: 152/2949, Loss: 0.8136\n",
      "Epoch: 2, Step: 153/2949, Loss: 0.8039\n",
      "Epoch: 2, Step: 154/2949, Loss: 0.8631\n",
      "Epoch: 2, Step: 155/2949, Loss: 0.8597\n",
      "Epoch: 2, Step: 156/2949, Loss: 0.8301\n",
      "Epoch: 2, Step: 157/2949, Loss: 0.7767\n",
      "Epoch: 2, Step: 158/2949, Loss: 0.8214\n",
      "Epoch: 2, Step: 159/2949, Loss: 0.7932\n",
      "Epoch: 2, Step: 160/2949, Loss: 0.8227\n",
      "Epoch: 2, Step: 161/2949, Loss: 0.7651\n",
      "Epoch: 2, Step: 162/2949, Loss: 0.8575\n",
      "Epoch: 2, Step: 163/2949, Loss: 0.8480\n",
      "Epoch: 2, Step: 164/2949, Loss: 0.8063\n",
      "Epoch: 2, Step: 165/2949, Loss: 0.8282\n",
      "Epoch: 2, Step: 166/2949, Loss: 0.8566\n",
      "Epoch: 2, Step: 167/2949, Loss: 0.7637\n",
      "Epoch: 2, Step: 168/2949, Loss: 0.8415\n",
      "Epoch: 2, Step: 169/2949, Loss: 0.8121\n",
      "Epoch: 2, Step: 170/2949, Loss: 0.7777\n",
      "Epoch: 2, Step: 171/2949, Loss: 0.8038\n",
      "Epoch: 2, Step: 172/2949, Loss: 0.8154\n",
      "Epoch: 2, Step: 173/2949, Loss: 0.7932\n",
      "Epoch: 2, Step: 174/2949, Loss: 0.8017\n",
      "Epoch: 2, Step: 175/2949, Loss: 0.7874\n",
      "Epoch: 2, Step: 176/2949, Loss: 0.8003\n",
      "Epoch: 2, Step: 177/2949, Loss: 0.7929\n",
      "Epoch: 2, Step: 178/2949, Loss: 0.8869\n",
      "Epoch: 2, Step: 179/2949, Loss: 0.8107\n",
      "Epoch: 2, Step: 180/2949, Loss: 0.7681\n",
      "Epoch: 2, Step: 181/2949, Loss: 0.8303\n",
      "Epoch: 2, Step: 182/2949, Loss: 0.8945\n",
      "Epoch: 2, Step: 183/2949, Loss: 0.8409\n",
      "Epoch: 2, Step: 184/2949, Loss: 0.8694\n",
      "Epoch: 2, Step: 185/2949, Loss: 0.8459\n",
      "Epoch: 2, Step: 186/2949, Loss: 0.8103\n",
      "Epoch: 2, Step: 187/2949, Loss: 0.8459\n",
      "Epoch: 2, Step: 188/2949, Loss: 0.7825\n",
      "Epoch: 2, Step: 189/2949, Loss: 0.8101\n",
      "Epoch: 2, Step: 190/2949, Loss: 0.8459\n",
      "Epoch: 2, Step: 191/2949, Loss: 0.8296\n",
      "Epoch: 2, Step: 192/2949, Loss: 0.7978\n",
      "Epoch: 2, Step: 193/2949, Loss: 0.8026\n",
      "Epoch: 2, Step: 194/2949, Loss: 0.8131\n",
      "Epoch: 2, Step: 195/2949, Loss: 0.7944\n",
      "Epoch: 2, Step: 196/2949, Loss: 0.8624\n",
      "Epoch: 2, Step: 197/2949, Loss: 0.7664\n",
      "Epoch: 2, Step: 198/2949, Loss: 0.8504\n",
      "Epoch: 2, Step: 199/2949, Loss: 0.8185\n",
      "Epoch: 2, Step: 200/2949, Loss: 0.8098\n",
      "Epoch: 2, Step: 201/2949, Loss: 0.8755\n",
      "Epoch: 2, Step: 202/2949, Loss: 0.8274\n",
      "Epoch: 2, Step: 203/2949, Loss: 0.8543\n",
      "Epoch: 2, Step: 204/2949, Loss: 0.8073\n",
      "Epoch: 2, Step: 205/2949, Loss: 0.8334\n",
      "Epoch: 2, Step: 206/2949, Loss: 0.7901\n",
      "Epoch: 2, Step: 207/2949, Loss: 0.7994\n",
      "Epoch: 2, Step: 208/2949, Loss: 0.8899\n",
      "Epoch: 2, Step: 209/2949, Loss: 0.8407\n",
      "Epoch: 2, Step: 210/2949, Loss: 0.7780\n",
      "Epoch: 2, Step: 211/2949, Loss: 0.8347\n",
      "Epoch: 2, Step: 212/2949, Loss: 0.8025\n",
      "Epoch: 2, Step: 213/2949, Loss: 0.8208\n",
      "Epoch: 2, Step: 214/2949, Loss: 0.8360\n",
      "Epoch: 2, Step: 215/2949, Loss: 0.7247\n",
      "Epoch: 2, Step: 216/2949, Loss: 0.8097\n",
      "Epoch: 2, Step: 217/2949, Loss: 0.8556\n",
      "Epoch: 2, Step: 218/2949, Loss: 0.8264\n",
      "Epoch: 2, Step: 219/2949, Loss: 0.8771\n",
      "Epoch: 2, Step: 220/2949, Loss: 0.8140\n",
      "Epoch: 2, Step: 221/2949, Loss: 0.8501\n",
      "Epoch: 2, Step: 222/2949, Loss: 0.7777\n",
      "Epoch: 2, Step: 223/2949, Loss: 0.7987\n",
      "Epoch: 2, Step: 224/2949, Loss: 0.8137\n",
      "Epoch: 2, Step: 225/2949, Loss: 0.8097\n",
      "Epoch: 2, Step: 226/2949, Loss: 0.8128\n",
      "Epoch: 2, Step: 227/2949, Loss: 0.7846\n",
      "Epoch: 2, Step: 228/2949, Loss: 0.8460\n",
      "Epoch: 2, Step: 229/2949, Loss: 0.8314\n",
      "Epoch: 2, Step: 230/2949, Loss: 0.8766\n",
      "Epoch: 2, Step: 231/2949, Loss: 0.8222\n",
      "Epoch: 2, Step: 232/2949, Loss: 0.8588\n",
      "Epoch: 2, Step: 233/2949, Loss: 0.8355\n",
      "Epoch: 2, Step: 234/2949, Loss: 0.7868\n",
      "Epoch: 2, Step: 235/2949, Loss: 0.7865\n",
      "Epoch: 2, Step: 236/2949, Loss: 0.8542\n",
      "Epoch: 2, Step: 237/2949, Loss: 0.8866\n",
      "Epoch: 2, Step: 238/2949, Loss: 0.7551\n",
      "Epoch: 2, Step: 239/2949, Loss: 0.8118\n",
      "Epoch: 2, Step: 240/2949, Loss: 0.8244\n",
      "Epoch: 2, Step: 241/2949, Loss: 0.8077\n",
      "Epoch: 2, Step: 242/2949, Loss: 0.8133\n",
      "Epoch: 2, Step: 243/2949, Loss: 0.8215\n",
      "Epoch: 2, Step: 244/2949, Loss: 0.8079\n",
      "Epoch: 2, Step: 245/2949, Loss: 0.8257\n",
      "Epoch: 2, Step: 246/2949, Loss: 0.8436\n",
      "Epoch: 2, Step: 247/2949, Loss: 0.8117\n",
      "Epoch: 2, Step: 248/2949, Loss: 0.8024\n",
      "Epoch: 2, Step: 249/2949, Loss: 0.8505\n",
      "Epoch: 2, Step: 250/2949, Loss: 0.8019\n",
      "Epoch: 2, Step: 251/2949, Loss: 0.8171\n",
      "Epoch: 2, Step: 252/2949, Loss: 0.8514\n",
      "Epoch: 2, Step: 253/2949, Loss: 0.7840\n",
      "Epoch: 2, Step: 254/2949, Loss: 0.8211\n",
      "Epoch: 2, Step: 255/2949, Loss: 0.8679\n",
      "Epoch: 2, Step: 256/2949, Loss: 0.8102\n",
      "Epoch: 2, Step: 257/2949, Loss: 0.8088\n",
      "Epoch: 2, Step: 258/2949, Loss: 0.8481\n",
      "Epoch: 2, Step: 259/2949, Loss: 0.7846\n",
      "Epoch: 2, Step: 260/2949, Loss: 0.8423\n",
      "Epoch: 2, Step: 261/2949, Loss: 0.8296\n",
      "Epoch: 2, Step: 262/2949, Loss: 0.8490\n",
      "Epoch: 2, Step: 263/2949, Loss: 0.8557\n",
      "Epoch: 2, Step: 264/2949, Loss: 0.8193\n",
      "Epoch: 2, Step: 265/2949, Loss: 0.8322\n",
      "Epoch: 2, Step: 266/2949, Loss: 0.7865\n",
      "Epoch: 2, Step: 267/2949, Loss: 0.7793\n",
      "Epoch: 2, Step: 268/2949, Loss: 0.8251\n",
      "Epoch: 2, Step: 269/2949, Loss: 0.7971\n",
      "Epoch: 2, Step: 270/2949, Loss: 0.7987\n",
      "Epoch: 2, Step: 271/2949, Loss: 0.7623\n",
      "Epoch: 2, Step: 272/2949, Loss: 0.8346\n",
      "Epoch: 2, Step: 273/2949, Loss: 0.8379\n",
      "Epoch: 2, Step: 274/2949, Loss: 0.8162\n",
      "Epoch: 2, Step: 275/2949, Loss: 0.7544\n",
      "Epoch: 2, Step: 276/2949, Loss: 0.7987\n",
      "Epoch: 2, Step: 277/2949, Loss: 0.8450\n",
      "Epoch: 2, Step: 278/2949, Loss: 0.8437\n",
      "Epoch: 2, Step: 279/2949, Loss: 0.8516\n",
      "Epoch: 2, Step: 280/2949, Loss: 0.8087\n",
      "Epoch: 2, Step: 281/2949, Loss: 0.7852\n",
      "Epoch: 2, Step: 282/2949, Loss: 0.7866\n",
      "Epoch: 2, Step: 283/2949, Loss: 0.7936\n",
      "Epoch: 2, Step: 284/2949, Loss: 0.8470\n",
      "Epoch: 2, Step: 285/2949, Loss: 0.8263\n",
      "Epoch: 2, Step: 286/2949, Loss: 0.8155\n",
      "Epoch: 2, Step: 287/2949, Loss: 0.8223\n",
      "Epoch: 2, Step: 288/2949, Loss: 0.7981\n",
      "Epoch: 2, Step: 289/2949, Loss: 0.8335\n",
      "Epoch: 2, Step: 290/2949, Loss: 0.8450\n",
      "Epoch: 2, Step: 291/2949, Loss: 0.8992\n",
      "Epoch: 2, Step: 292/2949, Loss: 0.8196\n",
      "Epoch: 2, Step: 293/2949, Loss: 0.8174\n",
      "Epoch: 2, Step: 294/2949, Loss: 0.7801\n",
      "Epoch: 2, Step: 295/2949, Loss: 0.7972\n",
      "Epoch: 2, Step: 296/2949, Loss: 0.8125\n",
      "Epoch: 2, Step: 297/2949, Loss: 0.8862\n",
      "Epoch: 2, Step: 298/2949, Loss: 0.7869\n",
      "Epoch: 2, Step: 299/2949, Loss: 0.7979\n",
      "Epoch: 2, Step: 300/2949, Loss: 0.8637\n",
      "Epoch: 2, Step: 301/2949, Loss: 0.8156\n",
      "Epoch: 2, Step: 302/2949, Loss: 0.8287\n",
      "Epoch: 2, Step: 303/2949, Loss: 0.8372\n",
      "Epoch: 2, Step: 304/2949, Loss: 0.7711\n",
      "Epoch: 2, Step: 305/2949, Loss: 0.7770\n",
      "Epoch: 2, Step: 306/2949, Loss: 0.8264\n",
      "Epoch: 2, Step: 307/2949, Loss: 0.7962\n",
      "Epoch: 2, Step: 308/2949, Loss: 0.8025\n",
      "Epoch: 2, Step: 309/2949, Loss: 0.8357\n",
      "Epoch: 2, Step: 310/2949, Loss: 0.7668\n",
      "Epoch: 2, Step: 311/2949, Loss: 0.7935\n",
      "Epoch: 2, Step: 312/2949, Loss: 0.8112\n",
      "Epoch: 2, Step: 313/2949, Loss: 0.8800\n",
      "Epoch: 2, Step: 314/2949, Loss: 0.8582\n",
      "Epoch: 2, Step: 315/2949, Loss: 0.8120\n",
      "Epoch: 2, Step: 316/2949, Loss: 0.8254\n",
      "Epoch: 2, Step: 317/2949, Loss: 0.8196\n",
      "Epoch: 2, Step: 318/2949, Loss: 0.8251\n",
      "Epoch: 2, Step: 319/2949, Loss: 0.8527\n",
      "Epoch: 2, Step: 320/2949, Loss: 0.8627\n",
      "Epoch: 2, Step: 321/2949, Loss: 0.8143\n",
      "Epoch: 2, Step: 322/2949, Loss: 0.8127\n",
      "Epoch: 2, Step: 323/2949, Loss: 0.8260\n",
      "Epoch: 2, Step: 324/2949, Loss: 0.7430\n",
      "Epoch: 2, Step: 325/2949, Loss: 0.8197\n",
      "Epoch: 2, Step: 326/2949, Loss: 0.8671\n",
      "Epoch: 2, Step: 327/2949, Loss: 0.8007\n",
      "Epoch: 2, Step: 328/2949, Loss: 0.8128\n",
      "Epoch: 2, Step: 329/2949, Loss: 0.8332\n",
      "Epoch: 2, Step: 330/2949, Loss: 0.8375\n",
      "Epoch: 2, Step: 331/2949, Loss: 0.7636\n",
      "Epoch: 2, Step: 332/2949, Loss: 0.8313\n",
      "Epoch: 2, Step: 333/2949, Loss: 0.8194\n",
      "Epoch: 2, Step: 334/2949, Loss: 0.8369\n",
      "Epoch: 2, Step: 335/2949, Loss: 0.7824\n",
      "Epoch: 2, Step: 336/2949, Loss: 0.8147\n",
      "Epoch: 2, Step: 337/2949, Loss: 0.7968\n",
      "Epoch: 2, Step: 338/2949, Loss: 0.8727\n",
      "Epoch: 2, Step: 339/2949, Loss: 0.8321\n",
      "Epoch: 2, Step: 340/2949, Loss: 0.8309\n",
      "Epoch: 2, Step: 341/2949, Loss: 0.8157\n",
      "Epoch: 2, Step: 342/2949, Loss: 0.7846\n",
      "Epoch: 2, Step: 343/2949, Loss: 0.8436\n",
      "Epoch: 2, Step: 344/2949, Loss: 0.8085\n",
      "Epoch: 2, Step: 345/2949, Loss: 0.7836\n",
      "Epoch: 2, Step: 346/2949, Loss: 0.7918\n",
      "Epoch: 2, Step: 347/2949, Loss: 0.8238\n",
      "Epoch: 2, Step: 348/2949, Loss: 0.7980\n",
      "Epoch: 2, Step: 349/2949, Loss: 0.7902\n",
      "Epoch: 2, Step: 350/2949, Loss: 0.8068\n",
      "Epoch: 2, Step: 351/2949, Loss: 0.7465\n",
      "Epoch: 2, Step: 352/2949, Loss: 0.7601\n",
      "Epoch: 2, Step: 353/2949, Loss: 0.8203\n",
      "Epoch: 2, Step: 354/2949, Loss: 0.8054\n",
      "Epoch: 2, Step: 355/2949, Loss: 0.7341\n",
      "Epoch: 2, Step: 356/2949, Loss: 0.8273\n",
      "Epoch: 2, Step: 357/2949, Loss: 0.7898\n",
      "Epoch: 2, Step: 358/2949, Loss: 0.8106\n",
      "Epoch: 2, Step: 359/2949, Loss: 0.8573\n",
      "Epoch: 2, Step: 360/2949, Loss: 0.7680\n",
      "Epoch: 2, Step: 361/2949, Loss: 0.7907\n",
      "Epoch: 2, Step: 362/2949, Loss: 0.7856\n",
      "Epoch: 2, Step: 363/2949, Loss: 0.8325\n",
      "Epoch: 2, Step: 364/2949, Loss: 0.8011\n",
      "Epoch: 2, Step: 365/2949, Loss: 0.7839\n",
      "Epoch: 2, Step: 366/2949, Loss: 0.7706\n",
      "Epoch: 2, Step: 367/2949, Loss: 0.7883\n",
      "Epoch: 2, Step: 368/2949, Loss: 0.8250\n",
      "Epoch: 2, Step: 369/2949, Loss: 0.8181\n",
      "Epoch: 2, Step: 370/2949, Loss: 0.8545\n",
      "Epoch: 2, Step: 371/2949, Loss: 0.7884\n",
      "Epoch: 2, Step: 372/2949, Loss: 0.8146\n",
      "Epoch: 2, Step: 373/2949, Loss: 0.7842\n",
      "Epoch: 2, Step: 374/2949, Loss: 0.7838\n",
      "Epoch: 2, Step: 375/2949, Loss: 0.8390\n",
      "Epoch: 2, Step: 376/2949, Loss: 0.7967\n",
      "Epoch: 2, Step: 377/2949, Loss: 0.7867\n",
      "Epoch: 2, Step: 378/2949, Loss: 0.8614\n",
      "Epoch: 2, Step: 379/2949, Loss: 0.8113\n",
      "Epoch: 2, Step: 380/2949, Loss: 0.7989\n",
      "Epoch: 2, Step: 381/2949, Loss: 0.7488\n",
      "Epoch: 2, Step: 382/2949, Loss: 0.7917\n",
      "Epoch: 2, Step: 383/2949, Loss: 0.7811\n",
      "Epoch: 2, Step: 384/2949, Loss: 0.8245\n",
      "Epoch: 2, Step: 385/2949, Loss: 0.8737\n",
      "Epoch: 2, Step: 386/2949, Loss: 0.7675\n",
      "Epoch: 2, Step: 387/2949, Loss: 0.7780\n",
      "Epoch: 2, Step: 388/2949, Loss: 0.8365\n",
      "Epoch: 2, Step: 389/2949, Loss: 0.8193\n",
      "Epoch: 2, Step: 390/2949, Loss: 0.8116\n",
      "Epoch: 2, Step: 391/2949, Loss: 0.8176\n",
      "Epoch: 2, Step: 392/2949, Loss: 0.8278\n",
      "Epoch: 2, Step: 393/2949, Loss: 0.8226\n",
      "Epoch: 2, Step: 394/2949, Loss: 0.7859\n",
      "Epoch: 2, Step: 395/2949, Loss: 0.8402\n",
      "Epoch: 2, Step: 396/2949, Loss: 0.8531\n",
      "Epoch: 2, Step: 397/2949, Loss: 0.8487\n",
      "Epoch: 2, Step: 398/2949, Loss: 0.7767\n",
      "Epoch: 2, Step: 399/2949, Loss: 0.8574\n",
      "Epoch: 2, Step: 400/2949, Loss: 0.7660\n",
      "Epoch: 2, Step: 401/2949, Loss: 0.7777\n",
      "Epoch: 2, Step: 402/2949, Loss: 0.7925\n",
      "Epoch: 2, Step: 403/2949, Loss: 0.8105\n",
      "Epoch: 2, Step: 404/2949, Loss: 0.8161\n",
      "Epoch: 2, Step: 405/2949, Loss: 0.7876\n",
      "Epoch: 2, Step: 406/2949, Loss: 0.8040\n",
      "Epoch: 2, Step: 407/2949, Loss: 0.8357\n",
      "Epoch: 2, Step: 408/2949, Loss: 0.8298\n",
      "Epoch: 2, Step: 409/2949, Loss: 0.8208\n",
      "Epoch: 2, Step: 410/2949, Loss: 0.8043\n",
      "Epoch: 2, Step: 411/2949, Loss: 0.7829\n",
      "Epoch: 2, Step: 412/2949, Loss: 0.8144\n",
      "Epoch: 2, Step: 413/2949, Loss: 0.8684\n",
      "Epoch: 2, Step: 414/2949, Loss: 0.7919\n",
      "Epoch: 2, Step: 415/2949, Loss: 0.7944\n",
      "Epoch: 2, Step: 416/2949, Loss: 0.8216\n",
      "Epoch: 2, Step: 417/2949, Loss: 0.8028\n",
      "Epoch: 2, Step: 418/2949, Loss: 0.8371\n",
      "Epoch: 2, Step: 419/2949, Loss: 0.8135\n",
      "Epoch: 2, Step: 420/2949, Loss: 0.7540\n",
      "Epoch: 2, Step: 421/2949, Loss: 0.8015\n",
      "Epoch: 2, Step: 422/2949, Loss: 0.8111\n",
      "Epoch: 2, Step: 423/2949, Loss: 0.8415\n",
      "Epoch: 2, Step: 424/2949, Loss: 0.7732\n",
      "Epoch: 2, Step: 425/2949, Loss: 0.8374\n",
      "Epoch: 2, Step: 426/2949, Loss: 0.8207\n",
      "Epoch: 2, Step: 427/2949, Loss: 0.7991\n",
      "Epoch: 2, Step: 428/2949, Loss: 0.8320\n",
      "Epoch: 2, Step: 429/2949, Loss: 0.7703\n",
      "Epoch: 2, Step: 430/2949, Loss: 0.8152\n",
      "Epoch: 2, Step: 431/2949, Loss: 0.7920\n",
      "Epoch: 2, Step: 432/2949, Loss: 0.8119\n",
      "Epoch: 2, Step: 433/2949, Loss: 0.7934\n",
      "Epoch: 2, Step: 434/2949, Loss: 0.7975\n",
      "Epoch: 2, Step: 435/2949, Loss: 0.8262\n",
      "Epoch: 2, Step: 436/2949, Loss: 0.8338\n",
      "Epoch: 2, Step: 437/2949, Loss: 0.8589\n",
      "Epoch: 2, Step: 438/2949, Loss: 0.8578\n",
      "Epoch: 2, Step: 439/2949, Loss: 0.7841\n",
      "Epoch: 2, Step: 440/2949, Loss: 0.8377\n",
      "Epoch: 2, Step: 441/2949, Loss: 0.8209\n",
      "Epoch: 2, Step: 442/2949, Loss: 0.8548\n",
      "Epoch: 2, Step: 443/2949, Loss: 0.8401\n",
      "Epoch: 2, Step: 444/2949, Loss: 0.8371\n",
      "Epoch: 2, Step: 445/2949, Loss: 0.8498\n",
      "Epoch: 2, Step: 446/2949, Loss: 0.7375\n",
      "Epoch: 2, Step: 447/2949, Loss: 0.8095\n",
      "Epoch: 2, Step: 448/2949, Loss: 0.7586\n",
      "Epoch: 2, Step: 449/2949, Loss: 0.8233\n",
      "Epoch: 2, Step: 450/2949, Loss: 0.8054\n",
      "Epoch: 2, Step: 451/2949, Loss: 0.7661\n",
      "Epoch: 2, Step: 452/2949, Loss: 0.7398\n",
      "Epoch: 2, Step: 453/2949, Loss: 0.8191\n",
      "Epoch: 2, Step: 454/2949, Loss: 0.8547\n",
      "Epoch: 2, Step: 455/2949, Loss: 0.8498\n",
      "Epoch: 2, Step: 456/2949, Loss: 0.7586\n",
      "Epoch: 2, Step: 457/2949, Loss: 0.8141\n",
      "Epoch: 2, Step: 458/2949, Loss: 0.8134\n",
      "Epoch: 2, Step: 459/2949, Loss: 0.7749\n",
      "Epoch: 2, Step: 460/2949, Loss: 0.8209\n",
      "Epoch: 2, Step: 461/2949, Loss: 0.7869\n",
      "Epoch: 2, Step: 462/2949, Loss: 0.7953\n",
      "Epoch: 2, Step: 463/2949, Loss: 0.8236\n",
      "Epoch: 2, Step: 464/2949, Loss: 0.8195\n",
      "Epoch: 2, Step: 465/2949, Loss: 0.8339\n",
      "Epoch: 2, Step: 466/2949, Loss: 0.8185\n",
      "Epoch: 2, Step: 467/2949, Loss: 0.7588\n",
      "Epoch: 2, Step: 468/2949, Loss: 0.7994\n",
      "Epoch: 2, Step: 469/2949, Loss: 0.8190\n",
      "Epoch: 2, Step: 470/2949, Loss: 0.8087\n",
      "Epoch: 2, Step: 471/2949, Loss: 0.7993\n",
      "Epoch: 2, Step: 472/2949, Loss: 0.8446\n",
      "Epoch: 2, Step: 473/2949, Loss: 0.8056\n",
      "Epoch: 2, Step: 474/2949, Loss: 0.8078\n",
      "Epoch: 2, Step: 475/2949, Loss: 0.7928\n",
      "Epoch: 2, Step: 476/2949, Loss: 0.8093\n",
      "Epoch: 2, Step: 477/2949, Loss: 0.7718\n",
      "Epoch: 2, Step: 478/2949, Loss: 0.8406\n",
      "Epoch: 2, Step: 479/2949, Loss: 0.8098\n",
      "Epoch: 2, Step: 480/2949, Loss: 0.8449\n",
      "Epoch: 2, Step: 481/2949, Loss: 0.8629\n",
      "Epoch: 2, Step: 482/2949, Loss: 0.7460\n",
      "Epoch: 2, Step: 483/2949, Loss: 0.8202\n",
      "Epoch: 2, Step: 484/2949, Loss: 0.7895\n",
      "Epoch: 2, Step: 485/2949, Loss: 0.8602\n",
      "Epoch: 2, Step: 486/2949, Loss: 0.8197\n",
      "Epoch: 2, Step: 487/2949, Loss: 0.8613\n",
      "Epoch: 2, Step: 488/2949, Loss: 0.7771\n",
      "Epoch: 2, Step: 489/2949, Loss: 0.7735\n",
      "Epoch: 2, Step: 490/2949, Loss: 0.8068\n",
      "Epoch: 2, Step: 491/2949, Loss: 0.7764\n",
      "Epoch: 2, Step: 492/2949, Loss: 0.7855\n",
      "Epoch: 2, Step: 493/2949, Loss: 0.7945\n",
      "Epoch: 2, Step: 494/2949, Loss: 0.7775\n",
      "Epoch: 2, Step: 495/2949, Loss: 0.7980\n",
      "Epoch: 2, Step: 496/2949, Loss: 0.8088\n",
      "Epoch: 2, Step: 497/2949, Loss: 0.8103\n",
      "Epoch: 2, Step: 498/2949, Loss: 0.7912\n",
      "Epoch: 2, Step: 499/2949, Loss: 0.8295\n",
      "Epoch: 2, Step: 500/2949, Loss: 0.8187\n",
      "Epoch: 2, Step: 501/2949, Loss: 0.8374\n",
      "Epoch: 2, Step: 502/2949, Loss: 0.7897\n",
      "Epoch: 2, Step: 503/2949, Loss: 0.8235\n",
      "Epoch: 2, Step: 504/2949, Loss: 0.8722\n",
      "Epoch: 2, Step: 505/2949, Loss: 0.8035\n",
      "Epoch: 2, Step: 506/2949, Loss: 0.7800\n",
      "Epoch: 2, Step: 507/2949, Loss: 0.8343\n",
      "Epoch: 2, Step: 508/2949, Loss: 0.8213\n",
      "Epoch: 2, Step: 509/2949, Loss: 0.7781\n",
      "Epoch: 2, Step: 510/2949, Loss: 0.8373\n",
      "Epoch: 2, Step: 511/2949, Loss: 0.8198\n",
      "Epoch: 2, Step: 512/2949, Loss: 0.8202\n",
      "Epoch: 2, Step: 513/2949, Loss: 0.7959\n",
      "Epoch: 2, Step: 514/2949, Loss: 0.8256\n",
      "Epoch: 2, Step: 515/2949, Loss: 0.8145\n",
      "Epoch: 2, Step: 516/2949, Loss: 0.8157\n",
      "Epoch: 2, Step: 517/2949, Loss: 0.8040\n",
      "Epoch: 2, Step: 518/2949, Loss: 0.8007\n",
      "Epoch: 2, Step: 519/2949, Loss: 0.8029\n",
      "Epoch: 2, Step: 520/2949, Loss: 0.8064\n",
      "Epoch: 2, Step: 521/2949, Loss: 0.8164\n",
      "Epoch: 2, Step: 522/2949, Loss: 0.8572\n",
      "Epoch: 2, Step: 523/2949, Loss: 0.8147\n",
      "Epoch: 2, Step: 524/2949, Loss: 0.8432\n",
      "Epoch: 2, Step: 525/2949, Loss: 0.8086\n",
      "Epoch: 2, Step: 526/2949, Loss: 0.8120\n",
      "Epoch: 2, Step: 527/2949, Loss: 0.8257\n",
      "Epoch: 2, Step: 528/2949, Loss: 0.8446\n",
      "Epoch: 2, Step: 529/2949, Loss: 0.7929\n",
      "Epoch: 2, Step: 530/2949, Loss: 0.8003\n",
      "Epoch: 2, Step: 531/2949, Loss: 0.8006\n",
      "Epoch: 2, Step: 532/2949, Loss: 0.8245\n",
      "Epoch: 2, Step: 533/2949, Loss: 0.8426\n",
      "Epoch: 2, Step: 534/2949, Loss: 0.7414\n",
      "Epoch: 2, Step: 535/2949, Loss: 0.8248\n",
      "Epoch: 2, Step: 536/2949, Loss: 0.8319\n",
      "Epoch: 2, Step: 537/2949, Loss: 0.7969\n",
      "Epoch: 2, Step: 538/2949, Loss: 0.8291\n",
      "Epoch: 2, Step: 539/2949, Loss: 0.8625\n",
      "Epoch: 2, Step: 540/2949, Loss: 0.8229\n",
      "Epoch: 2, Step: 541/2949, Loss: 0.8026\n",
      "Epoch: 2, Step: 542/2949, Loss: 0.8154\n",
      "Epoch: 2, Step: 543/2949, Loss: 0.8136\n",
      "Epoch: 2, Step: 544/2949, Loss: 0.7973\n",
      "Epoch: 2, Step: 545/2949, Loss: 0.8012\n",
      "Epoch: 2, Step: 546/2949, Loss: 0.7622\n",
      "Epoch: 2, Step: 547/2949, Loss: 0.8041\n",
      "Epoch: 2, Step: 548/2949, Loss: 0.8124\n",
      "Epoch: 2, Step: 549/2949, Loss: 0.8250\n",
      "Epoch: 2, Step: 550/2949, Loss: 0.8194\n",
      "Epoch: 2, Step: 551/2949, Loss: 0.8010\n",
      "Epoch: 2, Step: 552/2949, Loss: 0.8102\n",
      "Epoch: 2, Step: 553/2949, Loss: 0.7664\n",
      "Epoch: 2, Step: 554/2949, Loss: 0.8187\n",
      "Epoch: 2, Step: 555/2949, Loss: 0.7925\n",
      "Epoch: 2, Step: 556/2949, Loss: 0.7930\n",
      "Epoch: 2, Step: 557/2949, Loss: 0.7570\n",
      "Epoch: 2, Step: 558/2949, Loss: 0.8368\n",
      "Epoch: 2, Step: 559/2949, Loss: 0.7933\n",
      "Epoch: 2, Step: 560/2949, Loss: 0.7939\n",
      "Epoch: 2, Step: 561/2949, Loss: 0.8356\n",
      "Epoch: 2, Step: 562/2949, Loss: 0.8066\n",
      "Epoch: 2, Step: 563/2949, Loss: 0.7944\n",
      "Epoch: 2, Step: 564/2949, Loss: 0.8287\n",
      "Epoch: 2, Step: 565/2949, Loss: 0.8204\n",
      "Epoch: 2, Step: 566/2949, Loss: 0.7708\n",
      "Epoch: 2, Step: 567/2949, Loss: 0.7799\n",
      "Epoch: 2, Step: 568/2949, Loss: 0.8072\n",
      "Epoch: 2, Step: 569/2949, Loss: 0.8040\n",
      "Epoch: 2, Step: 570/2949, Loss: 0.8063\n",
      "Epoch: 2, Step: 571/2949, Loss: 0.8124\n",
      "Epoch: 2, Step: 572/2949, Loss: 0.8400\n",
      "Epoch: 2, Step: 573/2949, Loss: 0.8278\n",
      "Epoch: 2, Step: 574/2949, Loss: 0.7882\n",
      "Epoch: 2, Step: 575/2949, Loss: 0.8035\n",
      "Epoch: 2, Step: 576/2949, Loss: 0.8124\n",
      "Epoch: 2, Step: 577/2949, Loss: 0.8342\n",
      "Epoch: 2, Step: 578/2949, Loss: 0.8453\n",
      "Epoch: 2, Step: 579/2949, Loss: 0.8429\n",
      "Epoch: 2, Step: 580/2949, Loss: 0.7699\n",
      "Epoch: 2, Step: 581/2949, Loss: 0.8436\n",
      "Epoch: 2, Step: 582/2949, Loss: 0.8543\n",
      "Epoch: 2, Step: 583/2949, Loss: 0.8579\n",
      "Epoch: 2, Step: 584/2949, Loss: 0.8378\n",
      "Epoch: 2, Step: 585/2949, Loss: 0.8461\n",
      "Epoch: 2, Step: 586/2949, Loss: 0.7918\n",
      "Epoch: 2, Step: 587/2949, Loss: 0.7970\n",
      "Epoch: 2, Step: 588/2949, Loss: 0.7687\n",
      "Epoch: 2, Step: 589/2949, Loss: 0.7708\n",
      "Epoch: 2, Step: 590/2949, Loss: 0.7899\n",
      "Epoch: 2, Step: 591/2949, Loss: 0.7746\n",
      "Epoch: 2, Step: 592/2949, Loss: 0.7846\n",
      "Epoch: 2, Step: 593/2949, Loss: 0.8261\n",
      "Epoch: 2, Step: 594/2949, Loss: 0.8381\n",
      "Epoch: 2, Step: 595/2949, Loss: 0.7539\n",
      "Epoch: 2, Step: 596/2949, Loss: 0.8285\n",
      "Epoch: 2, Step: 597/2949, Loss: 0.8146\n",
      "Epoch: 2, Step: 598/2949, Loss: 0.8492\n",
      "Epoch: 2, Step: 599/2949, Loss: 0.8396\n",
      "Epoch: 2, Step: 600/2949, Loss: 0.8429\n",
      "Epoch: 2, Step: 601/2949, Loss: 0.7918\n",
      "Epoch: 2, Step: 602/2949, Loss: 0.7997\n",
      "Epoch: 2, Step: 603/2949, Loss: 0.7818\n",
      "Epoch: 2, Step: 604/2949, Loss: 0.7974\n",
      "Epoch: 2, Step: 605/2949, Loss: 0.7403\n",
      "Epoch: 2, Step: 606/2949, Loss: 0.7898\n",
      "Epoch: 2, Step: 607/2949, Loss: 0.8277\n",
      "Epoch: 2, Step: 608/2949, Loss: 0.8193\n",
      "Epoch: 2, Step: 609/2949, Loss: 0.7437\n",
      "Epoch: 2, Step: 610/2949, Loss: 0.8111\n",
      "Epoch: 2, Step: 611/2949, Loss: 0.8831\n",
      "Epoch: 2, Step: 612/2949, Loss: 0.8129\n",
      "Epoch: 2, Step: 613/2949, Loss: 0.7911\n",
      "Epoch: 2, Step: 614/2949, Loss: 0.7866\n",
      "Epoch: 2, Step: 615/2949, Loss: 0.8330\n",
      "Epoch: 2, Step: 616/2949, Loss: 0.8213\n",
      "Epoch: 2, Step: 617/2949, Loss: 0.8099\n",
      "Epoch: 2, Step: 618/2949, Loss: 0.8339\n",
      "Epoch: 2, Step: 619/2949, Loss: 0.8446\n",
      "Epoch: 2, Step: 620/2949, Loss: 0.7738\n",
      "Epoch: 2, Step: 621/2949, Loss: 0.8283\n",
      "Epoch: 2, Step: 622/2949, Loss: 0.7896\n",
      "Epoch: 2, Step: 623/2949, Loss: 0.8471\n",
      "Epoch: 2, Step: 624/2949, Loss: 0.8593\n",
      "Epoch: 2, Step: 625/2949, Loss: 0.8428\n",
      "Epoch: 2, Step: 626/2949, Loss: 0.8381\n",
      "Epoch: 2, Step: 627/2949, Loss: 0.7993\n",
      "Epoch: 2, Step: 628/2949, Loss: 0.8038\n",
      "Epoch: 2, Step: 629/2949, Loss: 0.8451\n",
      "Epoch: 2, Step: 630/2949, Loss: 0.7932\n",
      "Epoch: 2, Step: 631/2949, Loss: 0.7845\n",
      "Epoch: 2, Step: 632/2949, Loss: 0.8123\n",
      "Epoch: 2, Step: 633/2949, Loss: 0.8214\n",
      "Epoch: 2, Step: 634/2949, Loss: 0.8112\n",
      "Epoch: 2, Step: 635/2949, Loss: 0.7705\n",
      "Epoch: 2, Step: 636/2949, Loss: 0.8035\n",
      "Epoch: 2, Step: 637/2949, Loss: 0.8144\n",
      "Epoch: 2, Step: 638/2949, Loss: 0.7814\n",
      "Epoch: 2, Step: 639/2949, Loss: 0.8239\n",
      "Epoch: 2, Step: 640/2949, Loss: 0.8448\n",
      "Epoch: 2, Step: 641/2949, Loss: 0.8063\n",
      "Epoch: 2, Step: 642/2949, Loss: 0.7841\n",
      "Epoch: 2, Step: 643/2949, Loss: 0.8545\n",
      "Epoch: 2, Step: 644/2949, Loss: 0.7661\n",
      "Epoch: 2, Step: 645/2949, Loss: 0.8342\n",
      "Epoch: 2, Step: 646/2949, Loss: 0.8572\n",
      "Epoch: 2, Step: 647/2949, Loss: 0.7930\n",
      "Epoch: 2, Step: 648/2949, Loss: 0.8570\n",
      "Epoch: 2, Step: 649/2949, Loss: 0.8233\n",
      "Epoch: 2, Step: 650/2949, Loss: 0.8216\n",
      "Epoch: 2, Step: 651/2949, Loss: 0.7755\n",
      "Epoch: 2, Step: 652/2949, Loss: 0.8106\n",
      "Epoch: 2, Step: 653/2949, Loss: 0.8149\n",
      "Epoch: 2, Step: 654/2949, Loss: 0.7757\n",
      "Epoch: 2, Step: 655/2949, Loss: 0.7871\n",
      "Epoch: 2, Step: 656/2949, Loss: 0.8147\n",
      "Epoch: 2, Step: 657/2949, Loss: 0.7958\n",
      "Epoch: 2, Step: 658/2949, Loss: 0.8115\n",
      "Epoch: 2, Step: 659/2949, Loss: 0.7774\n",
      "Epoch: 2, Step: 660/2949, Loss: 0.7802\n",
      "Epoch: 2, Step: 661/2949, Loss: 0.8524\n",
      "Epoch: 2, Step: 662/2949, Loss: 0.8111\n",
      "Epoch: 2, Step: 663/2949, Loss: 0.8384\n",
      "Epoch: 2, Step: 664/2949, Loss: 0.7871\n",
      "Epoch: 2, Step: 665/2949, Loss: 0.8710\n",
      "Epoch: 2, Step: 666/2949, Loss: 0.7579\n",
      "Epoch: 2, Step: 667/2949, Loss: 0.7838\n",
      "Epoch: 2, Step: 668/2949, Loss: 0.8270\n",
      "Epoch: 2, Step: 669/2949, Loss: 0.8252\n",
      "Epoch: 2, Step: 670/2949, Loss: 0.7872\n",
      "Epoch: 2, Step: 671/2949, Loss: 0.8300\n",
      "Epoch: 2, Step: 672/2949, Loss: 0.8023\n",
      "Epoch: 2, Step: 673/2949, Loss: 0.8276\n",
      "Epoch: 2, Step: 674/2949, Loss: 0.8320\n",
      "Epoch: 2, Step: 675/2949, Loss: 0.8348\n",
      "Epoch: 2, Step: 676/2949, Loss: 0.8289\n",
      "Epoch: 2, Step: 677/2949, Loss: 0.7959\n",
      "Epoch: 2, Step: 678/2949, Loss: 0.7770\n",
      "Epoch: 2, Step: 679/2949, Loss: 0.8263\n",
      "Epoch: 2, Step: 680/2949, Loss: 0.8353\n",
      "Epoch: 2, Step: 681/2949, Loss: 0.8235\n",
      "Epoch: 2, Step: 682/2949, Loss: 0.7909\n",
      "Epoch: 2, Step: 683/2949, Loss: 0.7777\n",
      "Epoch: 2, Step: 684/2949, Loss: 0.7986\n",
      "Epoch: 2, Step: 685/2949, Loss: 0.8172\n",
      "Epoch: 2, Step: 686/2949, Loss: 0.7656\n",
      "Epoch: 2, Step: 687/2949, Loss: 0.8356\n",
      "Epoch: 2, Step: 688/2949, Loss: 0.8064\n",
      "Epoch: 2, Step: 689/2949, Loss: 0.8451\n",
      "Epoch: 2, Step: 690/2949, Loss: 0.7593\n",
      "Epoch: 2, Step: 691/2949, Loss: 0.8548\n",
      "Epoch: 2, Step: 692/2949, Loss: 0.8329\n",
      "Epoch: 2, Step: 693/2949, Loss: 0.7843\n",
      "Epoch: 2, Step: 694/2949, Loss: 0.8245\n",
      "Epoch: 2, Step: 695/2949, Loss: 0.7702\n",
      "Epoch: 2, Step: 696/2949, Loss: 0.7557\n",
      "Epoch: 2, Step: 697/2949, Loss: 0.7998\n",
      "Epoch: 2, Step: 698/2949, Loss: 0.8255\n",
      "Epoch: 2, Step: 699/2949, Loss: 0.8146\n",
      "Epoch: 2, Step: 700/2949, Loss: 0.7942\n",
      "Epoch: 2, Step: 701/2949, Loss: 0.8222\n",
      "Epoch: 2, Step: 702/2949, Loss: 0.8512\n",
      "Epoch: 2, Step: 703/2949, Loss: 0.7767\n",
      "Epoch: 2, Step: 704/2949, Loss: 0.7762\n",
      "Epoch: 2, Step: 705/2949, Loss: 0.8452\n",
      "Epoch: 2, Step: 706/2949, Loss: 0.8007\n",
      "Epoch: 2, Step: 707/2949, Loss: 0.8517\n",
      "Epoch: 2, Step: 708/2949, Loss: 0.8049\n",
      "Epoch: 2, Step: 709/2949, Loss: 0.8000\n",
      "Epoch: 2, Step: 710/2949, Loss: 0.7277\n",
      "Epoch: 2, Step: 711/2949, Loss: 0.8170\n",
      "Epoch: 2, Step: 712/2949, Loss: 0.8359\n",
      "Epoch: 2, Step: 713/2949, Loss: 0.8080\n",
      "Epoch: 2, Step: 714/2949, Loss: 0.8106\n",
      "Epoch: 2, Step: 715/2949, Loss: 0.8271\n",
      "Epoch: 2, Step: 716/2949, Loss: 0.7867\n",
      "Epoch: 2, Step: 717/2949, Loss: 0.8070\n",
      "Epoch: 2, Step: 718/2949, Loss: 0.8264\n",
      "Epoch: 2, Step: 719/2949, Loss: 0.8403\n",
      "Epoch: 2, Step: 720/2949, Loss: 0.8467\n",
      "Epoch: 2, Step: 721/2949, Loss: 0.8299\n",
      "Epoch: 2, Step: 722/2949, Loss: 0.7596\n",
      "Epoch: 2, Step: 723/2949, Loss: 0.8190\n",
      "Epoch: 2, Step: 724/2949, Loss: 0.8214\n",
      "Epoch: 2, Step: 725/2949, Loss: 0.7913\n",
      "Epoch: 2, Step: 726/2949, Loss: 0.8298\n",
      "Epoch: 2, Step: 727/2949, Loss: 0.8240\n",
      "Epoch: 2, Step: 728/2949, Loss: 0.7723\n",
      "Epoch: 2, Step: 729/2949, Loss: 0.8626\n",
      "Epoch: 2, Step: 730/2949, Loss: 0.8174\n",
      "Epoch: 2, Step: 731/2949, Loss: 0.7875\n",
      "Epoch: 2, Step: 732/2949, Loss: 0.8386\n",
      "Epoch: 2, Step: 733/2949, Loss: 0.7827\n",
      "Epoch: 2, Step: 734/2949, Loss: 0.7666\n",
      "Epoch: 2, Step: 735/2949, Loss: 0.8272\n",
      "Epoch: 2, Step: 736/2949, Loss: 0.8095\n",
      "Epoch: 2, Step: 737/2949, Loss: 0.8251\n",
      "Epoch: 2, Step: 738/2949, Loss: 0.7699\n",
      "Epoch: 2, Step: 739/2949, Loss: 0.7879\n",
      "Epoch: 2, Step: 740/2949, Loss: 0.8266\n",
      "Epoch: 2, Step: 741/2949, Loss: 0.8207\n",
      "Epoch: 2, Step: 742/2949, Loss: 0.8206\n",
      "Epoch: 2, Step: 743/2949, Loss: 0.7722\n",
      "Epoch: 2, Step: 744/2949, Loss: 0.8271\n",
      "Epoch: 2, Step: 745/2949, Loss: 0.8542\n",
      "Epoch: 2, Step: 746/2949, Loss: 0.8194\n",
      "Epoch: 2, Step: 747/2949, Loss: 0.7890\n",
      "Epoch: 2, Step: 748/2949, Loss: 0.8151\n",
      "Epoch: 2, Step: 749/2949, Loss: 0.7477\n",
      "Epoch: 2, Step: 750/2949, Loss: 0.8496\n",
      "Epoch: 2, Step: 751/2949, Loss: 0.8197\n",
      "Epoch: 2, Step: 752/2949, Loss: 0.7845\n",
      "Epoch: 2, Step: 753/2949, Loss: 0.8505\n",
      "Epoch: 2, Step: 754/2949, Loss: 0.8358\n",
      "Epoch: 2, Step: 755/2949, Loss: 0.8162\n",
      "Epoch: 2, Step: 756/2949, Loss: 0.8315\n",
      "Epoch: 2, Step: 757/2949, Loss: 0.8080\n",
      "Epoch: 2, Step: 758/2949, Loss: 0.8300\n",
      "Epoch: 2, Step: 759/2949, Loss: 0.7796\n",
      "Epoch: 2, Step: 760/2949, Loss: 0.8192\n",
      "Epoch: 2, Step: 761/2949, Loss: 0.8067\n",
      "Epoch: 2, Step: 762/2949, Loss: 0.8544\n",
      "Epoch: 2, Step: 763/2949, Loss: 0.8328\n",
      "Epoch: 2, Step: 764/2949, Loss: 0.7756\n",
      "Epoch: 2, Step: 765/2949, Loss: 0.7937\n",
      "Epoch: 2, Step: 766/2949, Loss: 0.8047\n",
      "Epoch: 2, Step: 767/2949, Loss: 0.8015\n",
      "Epoch: 2, Step: 768/2949, Loss: 0.8143\n",
      "Epoch: 2, Step: 769/2949, Loss: 0.8291\n",
      "Epoch: 2, Step: 770/2949, Loss: 0.8327\n",
      "Epoch: 2, Step: 771/2949, Loss: 0.7715\n",
      "Epoch: 2, Step: 772/2949, Loss: 0.8221\n",
      "Epoch: 2, Step: 773/2949, Loss: 0.8289\n",
      "Epoch: 2, Step: 774/2949, Loss: 0.8390\n",
      "Epoch: 2, Step: 775/2949, Loss: 0.7925\n",
      "Epoch: 2, Step: 776/2949, Loss: 0.7949\n",
      "Epoch: 2, Step: 777/2949, Loss: 0.7717\n",
      "Epoch: 2, Step: 778/2949, Loss: 0.7581\n",
      "Epoch: 2, Step: 779/2949, Loss: 0.8086\n",
      "Epoch: 2, Step: 780/2949, Loss: 0.8379\n",
      "Epoch: 2, Step: 781/2949, Loss: 0.8226\n",
      "Epoch: 2, Step: 782/2949, Loss: 0.7403\n",
      "Epoch: 2, Step: 783/2949, Loss: 0.8192\n",
      "Epoch: 2, Step: 784/2949, Loss: 0.7974\n",
      "Epoch: 2, Step: 785/2949, Loss: 0.8360\n",
      "Epoch: 2, Step: 786/2949, Loss: 0.7874\n",
      "Epoch: 2, Step: 787/2949, Loss: 0.8104\n",
      "Epoch: 2, Step: 788/2949, Loss: 0.8128\n",
      "Epoch: 2, Step: 789/2949, Loss: 0.8413\n",
      "Epoch: 2, Step: 790/2949, Loss: 0.8310\n",
      "Epoch: 2, Step: 791/2949, Loss: 0.7803\n",
      "Epoch: 2, Step: 792/2949, Loss: 0.8127\n",
      "Epoch: 2, Step: 793/2949, Loss: 0.8520\n",
      "Epoch: 2, Step: 794/2949, Loss: 0.8566\n",
      "Epoch: 2, Step: 795/2949, Loss: 0.8239\n",
      "Epoch: 2, Step: 796/2949, Loss: 0.8175\n",
      "Epoch: 2, Step: 797/2949, Loss: 0.8235\n",
      "Epoch: 2, Step: 798/2949, Loss: 0.8210\n",
      "Epoch: 2, Step: 799/2949, Loss: 0.8082\n",
      "Epoch: 2, Step: 800/2949, Loss: 0.7856\n",
      "Epoch: 2, Step: 801/2949, Loss: 0.8216\n",
      "Epoch: 2, Step: 802/2949, Loss: 0.7940\n",
      "Epoch: 2, Step: 803/2949, Loss: 0.7923\n",
      "Epoch: 2, Step: 804/2949, Loss: 0.7378\n",
      "Epoch: 2, Step: 805/2949, Loss: 0.7834\n",
      "Epoch: 2, Step: 806/2949, Loss: 0.7835\n",
      "Epoch: 2, Step: 807/2949, Loss: 0.8544\n",
      "Epoch: 2, Step: 808/2949, Loss: 0.7758\n",
      "Epoch: 2, Step: 809/2949, Loss: 0.8030\n",
      "Epoch: 2, Step: 810/2949, Loss: 0.8568\n",
      "Epoch: 2, Step: 811/2949, Loss: 0.8201\n",
      "Epoch: 2, Step: 812/2949, Loss: 0.8062\n",
      "Epoch: 2, Step: 813/2949, Loss: 0.7882\n",
      "Epoch: 2, Step: 814/2949, Loss: 0.7699\n",
      "Epoch: 2, Step: 815/2949, Loss: 0.8339\n",
      "Epoch: 2, Step: 816/2949, Loss: 0.8599\n",
      "Epoch: 2, Step: 817/2949, Loss: 0.8219\n",
      "Epoch: 2, Step: 818/2949, Loss: 0.8427\n",
      "Epoch: 2, Step: 819/2949, Loss: 0.7933\n",
      "Epoch: 2, Step: 820/2949, Loss: 0.8008\n",
      "Epoch: 2, Step: 821/2949, Loss: 0.8204\n",
      "Epoch: 2, Step: 822/2949, Loss: 0.7239\n",
      "Epoch: 2, Step: 823/2949, Loss: 0.8403\n",
      "Epoch: 2, Step: 824/2949, Loss: 0.7979\n",
      "Epoch: 2, Step: 825/2949, Loss: 0.8056\n",
      "Epoch: 2, Step: 826/2949, Loss: 0.8372\n",
      "Epoch: 2, Step: 827/2949, Loss: 0.8188\n",
      "Epoch: 2, Step: 828/2949, Loss: 0.8105\n",
      "Epoch: 2, Step: 829/2949, Loss: 0.7849\n",
      "Epoch: 2, Step: 830/2949, Loss: 0.8306\n",
      "Epoch: 2, Step: 831/2949, Loss: 0.7768\n",
      "Epoch: 2, Step: 832/2949, Loss: 0.7193\n",
      "Epoch: 2, Step: 833/2949, Loss: 0.8187\n",
      "Epoch: 2, Step: 834/2949, Loss: 0.8004\n",
      "Epoch: 2, Step: 835/2949, Loss: 0.8512\n",
      "Epoch: 2, Step: 836/2949, Loss: 0.8505\n",
      "Epoch: 2, Step: 837/2949, Loss: 0.8545\n",
      "Epoch: 2, Step: 838/2949, Loss: 0.8136\n",
      "Epoch: 2, Step: 839/2949, Loss: 0.8186\n",
      "Epoch: 2, Step: 840/2949, Loss: 0.8256\n",
      "Epoch: 2, Step: 841/2949, Loss: 0.8091\n",
      "Epoch: 2, Step: 842/2949, Loss: 0.8123\n",
      "Epoch: 2, Step: 843/2949, Loss: 0.8440\n",
      "Epoch: 2, Step: 844/2949, Loss: 0.7840\n",
      "Epoch: 2, Step: 845/2949, Loss: 0.7971\n",
      "Epoch: 2, Step: 846/2949, Loss: 0.8147\n",
      "Epoch: 2, Step: 847/2949, Loss: 0.8235\n",
      "Epoch: 2, Step: 848/2949, Loss: 0.8304\n",
      "Epoch: 2, Step: 849/2949, Loss: 0.8482\n",
      "Epoch: 2, Step: 850/2949, Loss: 0.7936\n",
      "Epoch: 2, Step: 851/2949, Loss: 0.8133\n",
      "Epoch: 2, Step: 852/2949, Loss: 0.8202\n",
      "Epoch: 2, Step: 853/2949, Loss: 0.7805\n",
      "Epoch: 2, Step: 854/2949, Loss: 0.8258\n",
      "Epoch: 2, Step: 855/2949, Loss: 0.8604\n",
      "Epoch: 2, Step: 856/2949, Loss: 0.8180\n",
      "Epoch: 2, Step: 857/2949, Loss: 0.7990\n",
      "Epoch: 2, Step: 858/2949, Loss: 0.8254\n",
      "Epoch: 2, Step: 859/2949, Loss: 0.8074\n",
      "Epoch: 2, Step: 860/2949, Loss: 0.8198\n",
      "Epoch: 2, Step: 861/2949, Loss: 0.8194\n",
      "Epoch: 2, Step: 862/2949, Loss: 0.8239\n",
      "Epoch: 2, Step: 863/2949, Loss: 0.7673\n",
      "Epoch: 2, Step: 864/2949, Loss: 0.8081\n",
      "Epoch: 2, Step: 865/2949, Loss: 0.8175\n",
      "Epoch: 2, Step: 866/2949, Loss: 0.7870\n",
      "Epoch: 2, Step: 867/2949, Loss: 0.8237\n",
      "Epoch: 2, Step: 868/2949, Loss: 0.7892\n",
      "Epoch: 2, Step: 869/2949, Loss: 0.8505\n",
      "Epoch: 2, Step: 870/2949, Loss: 0.7970\n",
      "Epoch: 2, Step: 871/2949, Loss: 0.8113\n",
      "Epoch: 2, Step: 872/2949, Loss: 0.8338\n",
      "Epoch: 2, Step: 873/2949, Loss: 0.7974\n",
      "Epoch: 2, Step: 874/2949, Loss: 0.7955\n",
      "Epoch: 2, Step: 875/2949, Loss: 0.8259\n",
      "Epoch: 2, Step: 876/2949, Loss: 0.8357\n",
      "Epoch: 2, Step: 877/2949, Loss: 0.7410\n",
      "Epoch: 2, Step: 878/2949, Loss: 0.8191\n",
      "Epoch: 2, Step: 879/2949, Loss: 0.8137\n",
      "Epoch: 2, Step: 880/2949, Loss: 0.7902\n",
      "Epoch: 2, Step: 881/2949, Loss: 0.8098\n",
      "Epoch: 2, Step: 882/2949, Loss: 0.8066\n",
      "Epoch: 2, Step: 883/2949, Loss: 0.8330\n",
      "Epoch: 2, Step: 884/2949, Loss: 0.8050\n",
      "Epoch: 2, Step: 885/2949, Loss: 0.8037\n",
      "Epoch: 2, Step: 886/2949, Loss: 0.7968\n",
      "Epoch: 2, Step: 887/2949, Loss: 0.8207\n",
      "Epoch: 2, Step: 888/2949, Loss: 0.7698\n",
      "Epoch: 2, Step: 889/2949, Loss: 0.8240\n",
      "Epoch: 2, Step: 890/2949, Loss: 0.8232\n",
      "Epoch: 2, Step: 891/2949, Loss: 0.7917\n",
      "Epoch: 2, Step: 892/2949, Loss: 0.8112\n",
      "Epoch: 2, Step: 893/2949, Loss: 0.8122\n",
      "Epoch: 2, Step: 894/2949, Loss: 0.8241\n",
      "Epoch: 2, Step: 895/2949, Loss: 0.7977\n",
      "Epoch: 2, Step: 896/2949, Loss: 0.7851\n",
      "Epoch: 2, Step: 897/2949, Loss: 0.8309\n",
      "Epoch: 2, Step: 898/2949, Loss: 0.8058\n",
      "Epoch: 2, Step: 899/2949, Loss: 0.7931\n",
      "Epoch: 2, Step: 900/2949, Loss: 0.8005\n",
      "Epoch: 2, Step: 901/2949, Loss: 0.7733\n",
      "Epoch: 2, Step: 902/2949, Loss: 0.7668\n",
      "Epoch: 2, Step: 903/2949, Loss: 0.7995\n",
      "Epoch: 2, Step: 904/2949, Loss: 0.7912\n",
      "Epoch: 2, Step: 905/2949, Loss: 0.8194\n",
      "Epoch: 2, Step: 906/2949, Loss: 0.7495\n",
      "Epoch: 2, Step: 907/2949, Loss: 0.7958\n",
      "Epoch: 2, Step: 908/2949, Loss: 0.8012\n",
      "Epoch: 2, Step: 909/2949, Loss: 0.7837\n",
      "Epoch: 2, Step: 910/2949, Loss: 0.7747\n",
      "Epoch: 2, Step: 911/2949, Loss: 0.8503\n",
      "Epoch: 2, Step: 912/2949, Loss: 0.7524\n",
      "Epoch: 2, Step: 913/2949, Loss: 0.8248\n",
      "Epoch: 2, Step: 914/2949, Loss: 0.8119\n",
      "Epoch: 2, Step: 915/2949, Loss: 0.8214\n",
      "Epoch: 2, Step: 916/2949, Loss: 0.8484\n",
      "Epoch: 2, Step: 917/2949, Loss: 0.8048\n",
      "Epoch: 2, Step: 918/2949, Loss: 0.8169\n",
      "Epoch: 2, Step: 919/2949, Loss: 0.8303\n",
      "Epoch: 2, Step: 920/2949, Loss: 0.7755\n",
      "Epoch: 2, Step: 921/2949, Loss: 0.8363\n",
      "Epoch: 2, Step: 922/2949, Loss: 0.7999\n",
      "Epoch: 2, Step: 923/2949, Loss: 0.8331\n",
      "Epoch: 2, Step: 924/2949, Loss: 0.8338\n",
      "Epoch: 2, Step: 925/2949, Loss: 0.8447\n",
      "Epoch: 2, Step: 926/2949, Loss: 0.8225\n",
      "Epoch: 2, Step: 927/2949, Loss: 0.7463\n",
      "Epoch: 2, Step: 928/2949, Loss: 0.8074\n",
      "Epoch: 2, Step: 929/2949, Loss: 0.7781\n",
      "Epoch: 2, Step: 930/2949, Loss: 0.7690\n",
      "Epoch: 2, Step: 931/2949, Loss: 0.7951\n",
      "Epoch: 2, Step: 932/2949, Loss: 0.8373\n",
      "Epoch: 2, Step: 933/2949, Loss: 0.7907\n",
      "Epoch: 2, Step: 934/2949, Loss: 0.8136\n",
      "Epoch: 2, Step: 935/2949, Loss: 0.7817\n",
      "Epoch: 2, Step: 936/2949, Loss: 0.8314\n",
      "Epoch: 2, Step: 937/2949, Loss: 0.8374\n",
      "Epoch: 2, Step: 938/2949, Loss: 0.8205\n",
      "Epoch: 2, Step: 939/2949, Loss: 0.8568\n",
      "Epoch: 2, Step: 940/2949, Loss: 0.8135\n",
      "Epoch: 2, Step: 941/2949, Loss: 0.8014\n",
      "Epoch: 2, Step: 942/2949, Loss: 0.8175\n",
      "Epoch: 2, Step: 943/2949, Loss: 0.7693\n",
      "Epoch: 2, Step: 944/2949, Loss: 0.7952\n",
      "Epoch: 2, Step: 945/2949, Loss: 0.8182\n",
      "Epoch: 2, Step: 946/2949, Loss: 0.8070\n",
      "Epoch: 2, Step: 947/2949, Loss: 0.8604\n",
      "Epoch: 2, Step: 948/2949, Loss: 0.7926\n",
      "Epoch: 2, Step: 949/2949, Loss: 0.7683\n",
      "Epoch: 2, Step: 950/2949, Loss: 0.7914\n",
      "Epoch: 2, Step: 951/2949, Loss: 0.7813\n",
      "Epoch: 2, Step: 952/2949, Loss: 0.8195\n",
      "Epoch: 2, Step: 953/2949, Loss: 0.8476\n",
      "Epoch: 2, Step: 954/2949, Loss: 0.7842\n",
      "Epoch: 2, Step: 955/2949, Loss: 0.8309\n",
      "Epoch: 2, Step: 956/2949, Loss: 0.7928\n",
      "Epoch: 2, Step: 957/2949, Loss: 0.8448\n",
      "Epoch: 2, Step: 958/2949, Loss: 0.8497\n",
      "Epoch: 2, Step: 959/2949, Loss: 0.7941\n",
      "Epoch: 2, Step: 960/2949, Loss: 0.7970\n",
      "Epoch: 2, Step: 961/2949, Loss: 0.7583\n",
      "Epoch: 2, Step: 962/2949, Loss: 0.8115\n",
      "Epoch: 2, Step: 963/2949, Loss: 0.8324\n",
      "Epoch: 2, Step: 964/2949, Loss: 0.8511\n",
      "Epoch: 2, Step: 965/2949, Loss: 0.8431\n",
      "Epoch: 2, Step: 966/2949, Loss: 0.7992\n",
      "Epoch: 2, Step: 967/2949, Loss: 0.7996\n",
      "Epoch: 2, Step: 968/2949, Loss: 0.8136\n",
      "Epoch: 2, Step: 969/2949, Loss: 0.7756\n",
      "Epoch: 2, Step: 970/2949, Loss: 0.8414\n",
      "Epoch: 2, Step: 971/2949, Loss: 0.7893\n",
      "Epoch: 2, Step: 972/2949, Loss: 0.7418\n",
      "Epoch: 2, Step: 973/2949, Loss: 0.7957\n",
      "Epoch: 2, Step: 974/2949, Loss: 0.8138\n",
      "Epoch: 2, Step: 975/2949, Loss: 0.8261\n",
      "Epoch: 2, Step: 976/2949, Loss: 0.8336\n",
      "Epoch: 2, Step: 977/2949, Loss: 0.7825\n",
      "Epoch: 2, Step: 978/2949, Loss: 0.8262\n",
      "Epoch: 2, Step: 979/2949, Loss: 0.8329\n",
      "Epoch: 2, Step: 980/2949, Loss: 0.8356\n",
      "Epoch: 2, Step: 981/2949, Loss: 0.7159\n",
      "Epoch: 2, Step: 982/2949, Loss: 0.7843\n",
      "Epoch: 2, Step: 983/2949, Loss: 0.8180\n",
      "Epoch: 2, Step: 984/2949, Loss: 0.8142\n",
      "Epoch: 2, Step: 985/2949, Loss: 0.8043\n",
      "Epoch: 2, Step: 986/2949, Loss: 0.7813\n",
      "Epoch: 2, Step: 987/2949, Loss: 0.7949\n",
      "Epoch: 2, Step: 988/2949, Loss: 0.8133\n",
      "Epoch: 2, Step: 989/2949, Loss: 0.8055\n",
      "Epoch: 2, Step: 990/2949, Loss: 0.7926\n",
      "Epoch: 2, Step: 991/2949, Loss: 0.8385\n",
      "Epoch: 2, Step: 992/2949, Loss: 0.7844\n",
      "Epoch: 2, Step: 993/2949, Loss: 0.8579\n",
      "Epoch: 2, Step: 994/2949, Loss: 0.7936\n",
      "Epoch: 2, Step: 995/2949, Loss: 0.8150\n",
      "Epoch: 2, Step: 996/2949, Loss: 0.7762\n",
      "Epoch: 2, Step: 997/2949, Loss: 0.7431\n",
      "Epoch: 2, Step: 998/2949, Loss: 0.7763\n",
      "Epoch: 2, Step: 999/2949, Loss: 0.7792\n",
      "Epoch: 2, Step: 1000/2949, Loss: 0.8506\n",
      "Epoch: 2, Step: 1001/2949, Loss: 0.7817\n",
      "Epoch: 2, Step: 1002/2949, Loss: 0.8476\n",
      "Epoch: 2, Step: 1003/2949, Loss: 0.8006\n",
      "Epoch: 2, Step: 1004/2949, Loss: 0.8362\n",
      "Epoch: 2, Step: 1005/2949, Loss: 0.8086\n",
      "Epoch: 2, Step: 1006/2949, Loss: 0.7884\n",
      "Epoch: 2, Step: 1007/2949, Loss: 0.7920\n",
      "Epoch: 2, Step: 1008/2949, Loss: 0.8301\n",
      "Epoch: 2, Step: 1009/2949, Loss: 0.8572\n",
      "Epoch: 2, Step: 1010/2949, Loss: 0.8132\n",
      "Epoch: 2, Step: 1011/2949, Loss: 0.8101\n",
      "Epoch: 2, Step: 1012/2949, Loss: 0.8519\n",
      "Epoch: 2, Step: 1013/2949, Loss: 0.7490\n",
      "Epoch: 2, Step: 1014/2949, Loss: 0.8323\n",
      "Epoch: 2, Step: 1015/2949, Loss: 0.8031\n",
      "Epoch: 2, Step: 1016/2949, Loss: 0.8464\n",
      "Epoch: 2, Step: 1017/2949, Loss: 0.7817\n",
      "Epoch: 2, Step: 1018/2949, Loss: 0.8243\n",
      "Epoch: 2, Step: 1019/2949, Loss: 0.8134\n",
      "Epoch: 2, Step: 1020/2949, Loss: 0.7908\n",
      "Epoch: 2, Step: 1021/2949, Loss: 0.8215\n",
      "Epoch: 2, Step: 1022/2949, Loss: 0.7818\n",
      "Epoch: 2, Step: 1023/2949, Loss: 0.8314\n",
      "Epoch: 2, Step: 1024/2949, Loss: 0.8154\n",
      "Epoch: 2, Step: 1025/2949, Loss: 0.7778\n",
      "Epoch: 2, Step: 1026/2949, Loss: 0.8621\n",
      "Epoch: 2, Step: 1027/2949, Loss: 0.7581\n",
      "Epoch: 2, Step: 1028/2949, Loss: 0.7870\n",
      "Epoch: 2, Step: 1029/2949, Loss: 0.7419\n",
      "Epoch: 2, Step: 1030/2949, Loss: 0.8330\n",
      "Epoch: 2, Step: 1031/2949, Loss: 0.8055\n",
      "Epoch: 2, Step: 1032/2949, Loss: 0.8589\n",
      "Epoch: 2, Step: 1033/2949, Loss: 0.8042\n",
      "Epoch: 2, Step: 1034/2949, Loss: 0.8175\n",
      "Epoch: 2, Step: 1035/2949, Loss: 0.8419\n",
      "Epoch: 2, Step: 1036/2949, Loss: 0.8536\n",
      "Epoch: 2, Step: 1037/2949, Loss: 0.8137\n",
      "Epoch: 2, Step: 1038/2949, Loss: 0.8377\n",
      "Epoch: 2, Step: 1039/2949, Loss: 0.7874\n",
      "Epoch: 2, Step: 1040/2949, Loss: 0.7799\n",
      "Epoch: 2, Step: 1041/2949, Loss: 0.8073\n",
      "Epoch: 2, Step: 1042/2949, Loss: 0.7474\n",
      "Epoch: 2, Step: 1043/2949, Loss: 0.7699\n",
      "Epoch: 2, Step: 1044/2949, Loss: 0.7631\n",
      "Epoch: 2, Step: 1045/2949, Loss: 0.8490\n",
      "Epoch: 2, Step: 1046/2949, Loss: 0.7746\n",
      "Epoch: 2, Step: 1047/2949, Loss: 0.8559\n",
      "Epoch: 2, Step: 1048/2949, Loss: 0.8437\n",
      "Epoch: 2, Step: 1049/2949, Loss: 0.7814\n",
      "Epoch: 2, Step: 1050/2949, Loss: 0.8226\n",
      "Epoch: 2, Step: 1051/2949, Loss: 0.7996\n",
      "Epoch: 2, Step: 1052/2949, Loss: 0.8413\n",
      "Epoch: 2, Step: 1053/2949, Loss: 0.8155\n",
      "Epoch: 2, Step: 1054/2949, Loss: 0.8146\n",
      "Epoch: 2, Step: 1055/2949, Loss: 0.8473\n",
      "Epoch: 2, Step: 1056/2949, Loss: 0.7924\n",
      "Epoch: 2, Step: 1057/2949, Loss: 0.8489\n",
      "Epoch: 2, Step: 1058/2949, Loss: 0.8232\n",
      "Epoch: 2, Step: 1059/2949, Loss: 0.8033\n",
      "Epoch: 2, Step: 1060/2949, Loss: 0.7664\n",
      "Epoch: 2, Step: 1061/2949, Loss: 0.8230\n",
      "Epoch: 2, Step: 1062/2949, Loss: 0.8357\n",
      "Epoch: 2, Step: 1063/2949, Loss: 0.8282\n",
      "Epoch: 2, Step: 1064/2949, Loss: 0.8615\n",
      "Epoch: 2, Step: 1065/2949, Loss: 0.8587\n",
      "Epoch: 2, Step: 1066/2949, Loss: 0.8313\n",
      "Epoch: 2, Step: 1067/2949, Loss: 0.7224\n",
      "Epoch: 2, Step: 1068/2949, Loss: 0.8167\n",
      "Epoch: 2, Step: 1069/2949, Loss: 0.8108\n",
      "Epoch: 2, Step: 1070/2949, Loss: 0.8050\n",
      "Epoch: 2, Step: 1071/2949, Loss: 0.8114\n",
      "Epoch: 2, Step: 1072/2949, Loss: 0.8308\n",
      "Epoch: 2, Step: 1073/2949, Loss: 0.8481\n",
      "Epoch: 2, Step: 1074/2949, Loss: 0.8245\n",
      "Epoch: 2, Step: 1075/2949, Loss: 0.7980\n",
      "Epoch: 2, Step: 1076/2949, Loss: 0.7976\n",
      "Epoch: 2, Step: 1077/2949, Loss: 0.7947\n",
      "Epoch: 2, Step: 1078/2949, Loss: 0.7980\n",
      "Epoch: 2, Step: 1079/2949, Loss: 0.8086\n",
      "Epoch: 2, Step: 1080/2949, Loss: 0.8401\n",
      "Epoch: 2, Step: 1081/2949, Loss: 0.8564\n",
      "Epoch: 2, Step: 1082/2949, Loss: 0.8774\n",
      "Epoch: 2, Step: 1083/2949, Loss: 0.7954\n",
      "Epoch: 2, Step: 1084/2949, Loss: 0.7920\n",
      "Epoch: 2, Step: 1085/2949, Loss: 0.8068\n",
      "Epoch: 2, Step: 1086/2949, Loss: 0.7903\n",
      "Epoch: 2, Step: 1087/2949, Loss: 0.7780\n",
      "Epoch: 2, Step: 1088/2949, Loss: 0.8465\n",
      "Epoch: 2, Step: 1089/2949, Loss: 0.8036\n",
      "Epoch: 2, Step: 1090/2949, Loss: 0.8093\n",
      "Epoch: 2, Step: 1091/2949, Loss: 0.7999\n",
      "Epoch: 2, Step: 1092/2949, Loss: 0.7895\n",
      "Epoch: 2, Step: 1093/2949, Loss: 0.7729\n",
      "Epoch: 2, Step: 1094/2949, Loss: 0.8145\n",
      "Epoch: 2, Step: 1095/2949, Loss: 0.7897\n",
      "Epoch: 2, Step: 1096/2949, Loss: 0.8268\n",
      "Epoch: 2, Step: 1097/2949, Loss: 0.7826\n",
      "Epoch: 2, Step: 1098/2949, Loss: 0.8182\n",
      "Epoch: 2, Step: 1099/2949, Loss: 0.7892\n",
      "Epoch: 2, Step: 1100/2949, Loss: 0.8581\n",
      "Epoch: 2, Step: 1101/2949, Loss: 0.8340\n",
      "Epoch: 2, Step: 1102/2949, Loss: 0.7919\n",
      "Epoch: 2, Step: 1103/2949, Loss: 0.7699\n",
      "Epoch: 2, Step: 1104/2949, Loss: 0.7503\n",
      "Epoch: 2, Step: 1105/2949, Loss: 0.8038\n",
      "Epoch: 2, Step: 1106/2949, Loss: 0.8525\n",
      "Epoch: 2, Step: 1107/2949, Loss: 0.8105\n",
      "Epoch: 2, Step: 1108/2949, Loss: 0.7908\n",
      "Epoch: 2, Step: 1109/2949, Loss: 0.7770\n",
      "Epoch: 2, Step: 1110/2949, Loss: 0.7802\n",
      "Epoch: 2, Step: 1111/2949, Loss: 0.7888\n",
      "Epoch: 2, Step: 1112/2949, Loss: 0.7753\n",
      "Epoch: 2, Step: 1113/2949, Loss: 0.7455\n",
      "Epoch: 2, Step: 1114/2949, Loss: 0.8395\n",
      "Epoch: 2, Step: 1115/2949, Loss: 0.8611\n",
      "Epoch: 2, Step: 1116/2949, Loss: 0.7806\n",
      "Epoch: 2, Step: 1117/2949, Loss: 0.7654\n",
      "Epoch: 2, Step: 1118/2949, Loss: 0.8210\n",
      "Epoch: 2, Step: 1119/2949, Loss: 0.8568\n",
      "Epoch: 2, Step: 1120/2949, Loss: 0.7918\n",
      "Epoch: 2, Step: 1121/2949, Loss: 0.7634\n",
      "Epoch: 2, Step: 1122/2949, Loss: 0.8320\n",
      "Epoch: 2, Step: 1123/2949, Loss: 0.8101\n",
      "Epoch: 2, Step: 1124/2949, Loss: 0.7973\n",
      "Epoch: 2, Step: 1125/2949, Loss: 0.7743\n",
      "Epoch: 2, Step: 1126/2949, Loss: 0.7863\n",
      "Epoch: 2, Step: 1127/2949, Loss: 0.7656\n",
      "Epoch: 2, Step: 1128/2949, Loss: 0.8399\n",
      "Epoch: 2, Step: 1129/2949, Loss: 0.8058\n",
      "Epoch: 2, Step: 1130/2949, Loss: 0.7877\n",
      "Epoch: 2, Step: 1131/2949, Loss: 0.8185\n",
      "Epoch: 2, Step: 1132/2949, Loss: 0.8378\n",
      "Epoch: 2, Step: 1133/2949, Loss: 0.7440\n",
      "Epoch: 2, Step: 1134/2949, Loss: 0.8090\n",
      "Epoch: 2, Step: 1135/2949, Loss: 0.7660\n",
      "Epoch: 2, Step: 1136/2949, Loss: 0.8051\n",
      "Epoch: 2, Step: 1137/2949, Loss: 0.7943\n",
      "Epoch: 2, Step: 1138/2949, Loss: 0.8468\n",
      "Epoch: 2, Step: 1139/2949, Loss: 0.8561\n",
      "Epoch: 2, Step: 1140/2949, Loss: 0.7572\n",
      "Epoch: 2, Step: 1141/2949, Loss: 0.7628\n",
      "Epoch: 2, Step: 1142/2949, Loss: 0.8581\n",
      "Epoch: 2, Step: 1143/2949, Loss: 0.8115\n",
      "Epoch: 2, Step: 1144/2949, Loss: 0.7879\n",
      "Epoch: 2, Step: 1145/2949, Loss: 0.8052\n",
      "Epoch: 2, Step: 1146/2949, Loss: 0.7854\n",
      "Epoch: 2, Step: 1147/2949, Loss: 0.7907\n",
      "Epoch: 2, Step: 1148/2949, Loss: 0.7550\n",
      "Epoch: 2, Step: 1149/2949, Loss: 0.8521\n",
      "Epoch: 2, Step: 1150/2949, Loss: 0.8251\n",
      "Epoch: 2, Step: 1151/2949, Loss: 0.8238\n",
      "Epoch: 2, Step: 1152/2949, Loss: 0.8329\n",
      "Epoch: 2, Step: 1153/2949, Loss: 0.8165\n",
      "Epoch: 2, Step: 1154/2949, Loss: 0.8228\n",
      "Epoch: 2, Step: 1155/2949, Loss: 0.8118\n",
      "Epoch: 2, Step: 1156/2949, Loss: 0.8146\n",
      "Epoch: 2, Step: 1157/2949, Loss: 0.8111\n",
      "Epoch: 2, Step: 1158/2949, Loss: 0.7858\n",
      "Epoch: 2, Step: 1159/2949, Loss: 0.8141\n",
      "Epoch: 2, Step: 1160/2949, Loss: 0.7976\n",
      "Epoch: 2, Step: 1161/2949, Loss: 0.8092\n",
      "Epoch: 2, Step: 1162/2949, Loss: 0.8141\n",
      "Epoch: 2, Step: 1163/2949, Loss: 0.8366\n",
      "Epoch: 2, Step: 1164/2949, Loss: 0.7969\n",
      "Epoch: 2, Step: 1165/2949, Loss: 0.8399\n",
      "Epoch: 2, Step: 1166/2949, Loss: 0.7910\n",
      "Epoch: 2, Step: 1167/2949, Loss: 0.8446\n",
      "Epoch: 2, Step: 1168/2949, Loss: 0.8203\n",
      "Epoch: 2, Step: 1169/2949, Loss: 0.8157\n",
      "Epoch: 2, Step: 1170/2949, Loss: 0.7745\n",
      "Epoch: 2, Step: 1171/2949, Loss: 0.7866\n",
      "Epoch: 2, Step: 1172/2949, Loss: 0.7745\n",
      "Epoch: 2, Step: 1173/2949, Loss: 0.8044\n",
      "Epoch: 2, Step: 1174/2949, Loss: 0.8442\n",
      "Epoch: 2, Step: 1175/2949, Loss: 0.8378\n",
      "Epoch: 2, Step: 1176/2949, Loss: 0.7735\n",
      "Epoch: 2, Step: 1177/2949, Loss: 0.8225\n",
      "Epoch: 2, Step: 1178/2949, Loss: 0.8247\n",
      "Epoch: 2, Step: 1179/2949, Loss: 0.8298\n",
      "Epoch: 2, Step: 1180/2949, Loss: 0.7855\n",
      "Epoch: 2, Step: 1181/2949, Loss: 0.7996\n",
      "Epoch: 2, Step: 1182/2949, Loss: 0.8075\n",
      "Epoch: 2, Step: 1183/2949, Loss: 0.8111\n",
      "Epoch: 2, Step: 1184/2949, Loss: 0.7673\n",
      "Epoch: 2, Step: 1185/2949, Loss: 0.7665\n",
      "Epoch: 2, Step: 1186/2949, Loss: 0.8225\n",
      "Epoch: 2, Step: 1187/2949, Loss: 0.8706\n",
      "Epoch: 2, Step: 1188/2949, Loss: 0.7936\n",
      "Epoch: 2, Step: 1189/2949, Loss: 0.8076\n",
      "Epoch: 2, Step: 1190/2949, Loss: 0.7553\n",
      "Epoch: 2, Step: 1191/2949, Loss: 0.7891\n",
      "Epoch: 2, Step: 1192/2949, Loss: 0.8162\n",
      "Epoch: 2, Step: 1193/2949, Loss: 0.7608\n",
      "Epoch: 2, Step: 1194/2949, Loss: 0.8356\n",
      "Epoch: 2, Step: 1195/2949, Loss: 0.8198\n",
      "Epoch: 2, Step: 1196/2949, Loss: 0.8054\n",
      "Epoch: 2, Step: 1197/2949, Loss: 0.7305\n",
      "Epoch: 2, Step: 1198/2949, Loss: 0.7521\n",
      "Epoch: 2, Step: 1199/2949, Loss: 0.8060\n",
      "Epoch: 2, Step: 1200/2949, Loss: 0.8310\n",
      "Epoch: 2, Step: 1201/2949, Loss: 0.7986\n",
      "Epoch: 2, Step: 1202/2949, Loss: 0.8284\n",
      "Epoch: 2, Step: 1203/2949, Loss: 0.7984\n",
      "Epoch: 2, Step: 1204/2949, Loss: 0.8112\n",
      "Epoch: 2, Step: 1205/2949, Loss: 0.7996\n",
      "Epoch: 2, Step: 1206/2949, Loss: 0.7941\n",
      "Epoch: 2, Step: 1207/2949, Loss: 0.8306\n",
      "Epoch: 2, Step: 1208/2949, Loss: 0.8004\n",
      "Epoch: 2, Step: 1209/2949, Loss: 0.8329\n",
      "Epoch: 2, Step: 1210/2949, Loss: 0.8401\n",
      "Epoch: 2, Step: 1211/2949, Loss: 0.7669\n",
      "Epoch: 2, Step: 1212/2949, Loss: 0.8268\n",
      "Epoch: 2, Step: 1213/2949, Loss: 0.7847\n",
      "Epoch: 2, Step: 1214/2949, Loss: 0.7878\n",
      "Epoch: 2, Step: 1215/2949, Loss: 0.8632\n",
      "Epoch: 2, Step: 1216/2949, Loss: 0.8048\n",
      "Epoch: 2, Step: 1217/2949, Loss: 0.7678\n",
      "Epoch: 2, Step: 1218/2949, Loss: 0.7940\n",
      "Epoch: 2, Step: 1219/2949, Loss: 0.8411\n",
      "Epoch: 2, Step: 1220/2949, Loss: 0.7873\n",
      "Epoch: 2, Step: 1221/2949, Loss: 0.8113\n",
      "Epoch: 2, Step: 1222/2949, Loss: 0.7487\n",
      "Epoch: 2, Step: 1223/2949, Loss: 0.7503\n",
      "Epoch: 2, Step: 1224/2949, Loss: 0.8022\n",
      "Epoch: 2, Step: 1225/2949, Loss: 0.8087\n",
      "Epoch: 2, Step: 1226/2949, Loss: 0.8426\n",
      "Epoch: 2, Step: 1227/2949, Loss: 0.8052\n",
      "Epoch: 2, Step: 1228/2949, Loss: 0.8420\n",
      "Epoch: 2, Step: 1229/2949, Loss: 0.8142\n",
      "Epoch: 2, Step: 1230/2949, Loss: 0.8177\n",
      "Epoch: 2, Step: 1231/2949, Loss: 0.8005\n",
      "Epoch: 2, Step: 1232/2949, Loss: 0.7495\n",
      "Epoch: 2, Step: 1233/2949, Loss: 0.8129\n",
      "Epoch: 2, Step: 1234/2949, Loss: 0.7889\n",
      "Epoch: 2, Step: 1235/2949, Loss: 0.7868\n",
      "Epoch: 2, Step: 1236/2949, Loss: 0.8034\n",
      "Epoch: 2, Step: 1237/2949, Loss: 0.8332\n",
      "Epoch: 2, Step: 1238/2949, Loss: 0.8209\n",
      "Epoch: 2, Step: 1239/2949, Loss: 0.7870\n",
      "Epoch: 2, Step: 1240/2949, Loss: 0.8285\n",
      "Epoch: 2, Step: 1241/2949, Loss: 0.7517\n",
      "Epoch: 2, Step: 1242/2949, Loss: 0.7906\n",
      "Epoch: 2, Step: 1243/2949, Loss: 0.7380\n",
      "Epoch: 2, Step: 1244/2949, Loss: 0.7552\n",
      "Epoch: 2, Step: 1245/2949, Loss: 0.8021\n",
      "Epoch: 2, Step: 1246/2949, Loss: 0.7926\n",
      "Epoch: 2, Step: 1247/2949, Loss: 0.8294\n",
      "Epoch: 2, Step: 1248/2949, Loss: 0.8423\n",
      "Epoch: 2, Step: 1249/2949, Loss: 0.7559\n",
      "Epoch: 2, Step: 1250/2949, Loss: 0.7512\n",
      "Epoch: 2, Step: 1251/2949, Loss: 0.7406\n",
      "Epoch: 2, Step: 1252/2949, Loss: 0.7847\n",
      "Epoch: 2, Step: 1253/2949, Loss: 0.7625\n",
      "Epoch: 2, Step: 1254/2949, Loss: 0.7905\n",
      "Epoch: 2, Step: 1255/2949, Loss: 0.8461\n",
      "Epoch: 2, Step: 1256/2949, Loss: 0.7451\n",
      "Epoch: 2, Step: 1257/2949, Loss: 0.8133\n",
      "Epoch: 2, Step: 1258/2949, Loss: 0.8321\n",
      "Epoch: 2, Step: 1259/2949, Loss: 0.7761\n",
      "Epoch: 2, Step: 1260/2949, Loss: 0.8161\n",
      "Epoch: 2, Step: 1261/2949, Loss: 0.8243\n",
      "Epoch: 2, Step: 1262/2949, Loss: 0.7900\n",
      "Epoch: 2, Step: 1263/2949, Loss: 0.8031\n",
      "Epoch: 2, Step: 1264/2949, Loss: 0.8301\n",
      "Epoch: 2, Step: 1265/2949, Loss: 0.7551\n",
      "Epoch: 2, Step: 1266/2949, Loss: 0.7819\n",
      "Epoch: 2, Step: 1267/2949, Loss: 0.7388\n",
      "Epoch: 2, Step: 1268/2949, Loss: 0.7849\n",
      "Epoch: 2, Step: 1269/2949, Loss: 0.8654\n",
      "Epoch: 2, Step: 1270/2949, Loss: 0.8467\n",
      "Epoch: 2, Step: 1271/2949, Loss: 0.7655\n",
      "Epoch: 2, Step: 1272/2949, Loss: 0.8480\n",
      "Epoch: 2, Step: 1273/2949, Loss: 0.8234\n",
      "Epoch: 2, Step: 1274/2949, Loss: 0.8022\n",
      "Epoch: 2, Step: 1275/2949, Loss: 0.8699\n",
      "Epoch: 2, Step: 1276/2949, Loss: 0.7972\n",
      "Epoch: 2, Step: 1277/2949, Loss: 0.7736\n",
      "Epoch: 2, Step: 1278/2949, Loss: 0.8058\n",
      "Epoch: 2, Step: 1279/2949, Loss: 0.7649\n",
      "Epoch: 2, Step: 1280/2949, Loss: 0.7898\n",
      "Epoch: 2, Step: 1281/2949, Loss: 0.8286\n",
      "Epoch: 2, Step: 1282/2949, Loss: 0.8148\n",
      "Epoch: 2, Step: 1283/2949, Loss: 0.7927\n",
      "Epoch: 2, Step: 1284/2949, Loss: 0.7780\n",
      "Epoch: 2, Step: 1285/2949, Loss: 0.7911\n",
      "Epoch: 2, Step: 1286/2949, Loss: 0.7656\n",
      "Epoch: 2, Step: 1287/2949, Loss: 0.8304\n",
      "Epoch: 2, Step: 1288/2949, Loss: 0.8605\n",
      "Epoch: 2, Step: 1289/2949, Loss: 0.8126\n",
      "Epoch: 2, Step: 1290/2949, Loss: 0.8452\n",
      "Epoch: 2, Step: 1291/2949, Loss: 0.7969\n",
      "Epoch: 2, Step: 1292/2949, Loss: 0.8048\n",
      "Epoch: 2, Step: 1293/2949, Loss: 0.8390\n",
      "Epoch: 2, Step: 1294/2949, Loss: 0.8080\n",
      "Epoch: 2, Step: 1295/2949, Loss: 0.8056\n",
      "Epoch: 2, Step: 1296/2949, Loss: 0.8181\n",
      "Epoch: 2, Step: 1297/2949, Loss: 0.8512\n",
      "Epoch: 2, Step: 1298/2949, Loss: 0.7868\n",
      "Epoch: 2, Step: 1299/2949, Loss: 0.7849\n",
      "Epoch: 2, Step: 1300/2949, Loss: 0.8159\n",
      "Epoch: 2, Step: 1301/2949, Loss: 0.8121\n",
      "Epoch: 2, Step: 1302/2949, Loss: 0.7823\n",
      "Epoch: 2, Step: 1303/2949, Loss: 0.8092\n",
      "Epoch: 2, Step: 1304/2949, Loss: 0.8087\n",
      "Epoch: 2, Step: 1305/2949, Loss: 0.8510\n",
      "Epoch: 2, Step: 1306/2949, Loss: 0.7759\n",
      "Epoch: 2, Step: 1307/2949, Loss: 0.8259\n",
      "Epoch: 2, Step: 1308/2949, Loss: 0.7703\n",
      "Epoch: 2, Step: 1309/2949, Loss: 0.7818\n",
      "Epoch: 2, Step: 1310/2949, Loss: 0.7770\n",
      "Epoch: 2, Step: 1311/2949, Loss: 0.8032\n",
      "Epoch: 2, Step: 1312/2949, Loss: 0.7824\n",
      "Epoch: 2, Step: 1313/2949, Loss: 0.7894\n",
      "Epoch: 2, Step: 1314/2949, Loss: 0.7944\n",
      "Epoch: 2, Step: 1315/2949, Loss: 0.7565\n",
      "Epoch: 2, Step: 1316/2949, Loss: 0.8244\n",
      "Epoch: 2, Step: 1317/2949, Loss: 0.8559\n",
      "Epoch: 2, Step: 1318/2949, Loss: 0.8010\n",
      "Epoch: 2, Step: 1319/2949, Loss: 0.7892\n",
      "Epoch: 2, Step: 1320/2949, Loss: 0.8186\n",
      "Epoch: 2, Step: 1321/2949, Loss: 0.8239\n",
      "Epoch: 2, Step: 1322/2949, Loss: 0.7724\n",
      "Epoch: 2, Step: 1323/2949, Loss: 0.7844\n",
      "Epoch: 2, Step: 1324/2949, Loss: 0.8238\n",
      "Epoch: 2, Step: 1325/2949, Loss: 0.8337\n",
      "Epoch: 2, Step: 1326/2949, Loss: 0.7921\n",
      "Epoch: 2, Step: 1327/2949, Loss: 0.8128\n",
      "Epoch: 2, Step: 1328/2949, Loss: 0.8105\n",
      "Epoch: 2, Step: 1329/2949, Loss: 0.7749\n",
      "Epoch: 2, Step: 1330/2949, Loss: 0.8133\n",
      "Epoch: 2, Step: 1331/2949, Loss: 0.7698\n",
      "Epoch: 2, Step: 1332/2949, Loss: 0.8010\n",
      "Epoch: 2, Step: 1333/2949, Loss: 0.8108\n",
      "Epoch: 2, Step: 1334/2949, Loss: 0.8040\n",
      "Epoch: 2, Step: 1335/2949, Loss: 0.8115\n",
      "Epoch: 2, Step: 1336/2949, Loss: 0.8214\n",
      "Epoch: 2, Step: 1337/2949, Loss: 0.7547\n",
      "Epoch: 2, Step: 1338/2949, Loss: 0.8126\n",
      "Epoch: 2, Step: 1339/2949, Loss: 0.7819\n",
      "Epoch: 2, Step: 1340/2949, Loss: 0.8003\n",
      "Epoch: 2, Step: 1341/2949, Loss: 0.8279\n",
      "Epoch: 2, Step: 1342/2949, Loss: 0.7669\n",
      "Epoch: 2, Step: 1343/2949, Loss: 0.8461\n",
      "Epoch: 2, Step: 1344/2949, Loss: 0.8047\n",
      "Epoch: 2, Step: 1345/2949, Loss: 0.8007\n",
      "Epoch: 2, Step: 1346/2949, Loss: 0.8234\n",
      "Epoch: 2, Step: 1347/2949, Loss: 0.8262\n",
      "Epoch: 2, Step: 1348/2949, Loss: 0.8452\n",
      "Epoch: 2, Step: 1349/2949, Loss: 0.8092\n",
      "Epoch: 2, Step: 1350/2949, Loss: 0.7857\n",
      "Epoch: 2, Step: 1351/2949, Loss: 0.8133\n",
      "Epoch: 2, Step: 1352/2949, Loss: 0.8227\n",
      "Epoch: 2, Step: 1353/2949, Loss: 0.8056\n",
      "Epoch: 2, Step: 1354/2949, Loss: 0.8162\n",
      "Epoch: 2, Step: 1355/2949, Loss: 0.8096\n",
      "Epoch: 2, Step: 1356/2949, Loss: 0.8214\n",
      "Epoch: 2, Step: 1357/2949, Loss: 0.8173\n",
      "Epoch: 2, Step: 1358/2949, Loss: 0.7759\n",
      "Epoch: 2, Step: 1359/2949, Loss: 0.7802\n",
      "Epoch: 2, Step: 1360/2949, Loss: 0.8090\n",
      "Epoch: 2, Step: 1361/2949, Loss: 0.7699\n",
      "Epoch: 2, Step: 1362/2949, Loss: 0.7682\n",
      "Epoch: 2, Step: 1363/2949, Loss: 0.8216\n",
      "Epoch: 2, Step: 1364/2949, Loss: 0.7710\n",
      "Epoch: 2, Step: 1365/2949, Loss: 0.8003\n",
      "Epoch: 2, Step: 1366/2949, Loss: 0.7825\n",
      "Epoch: 2, Step: 1367/2949, Loss: 0.7726\n",
      "Epoch: 2, Step: 1368/2949, Loss: 0.7892\n",
      "Epoch: 2, Step: 1369/2949, Loss: 0.8035\n",
      "Epoch: 2, Step: 1370/2949, Loss: 0.7986\n",
      "Epoch: 2, Step: 1371/2949, Loss: 0.7625\n",
      "Epoch: 2, Step: 1372/2949, Loss: 0.7618\n",
      "Epoch: 2, Step: 1373/2949, Loss: 0.8313\n",
      "Epoch: 2, Step: 1374/2949, Loss: 0.8033\n",
      "Epoch: 2, Step: 1375/2949, Loss: 0.7350\n",
      "Epoch: 2, Step: 1376/2949, Loss: 0.7944\n",
      "Epoch: 2, Step: 1377/2949, Loss: 0.7695\n",
      "Epoch: 2, Step: 1378/2949, Loss: 0.7974\n",
      "Epoch: 2, Step: 1379/2949, Loss: 0.7810\n",
      "Epoch: 2, Step: 1380/2949, Loss: 0.8310\n",
      "Epoch: 2, Step: 1381/2949, Loss: 0.8302\n",
      "Epoch: 2, Step: 1382/2949, Loss: 0.7593\n",
      "Epoch: 2, Step: 1383/2949, Loss: 0.8156\n",
      "Epoch: 2, Step: 1384/2949, Loss: 0.7953\n",
      "Epoch: 2, Step: 1385/2949, Loss: 0.8208\n",
      "Epoch: 2, Step: 1386/2949, Loss: 0.7788\n",
      "Epoch: 2, Step: 1387/2949, Loss: 0.8530\n",
      "Epoch: 2, Step: 1388/2949, Loss: 0.8123\n",
      "Epoch: 2, Step: 1389/2949, Loss: 0.7324\n",
      "Epoch: 2, Step: 1390/2949, Loss: 0.8495\n",
      "Epoch: 2, Step: 1391/2949, Loss: 0.7744\n",
      "Epoch: 2, Step: 1392/2949, Loss: 0.8112\n",
      "Epoch: 2, Step: 1393/2949, Loss: 0.7630\n",
      "Epoch: 2, Step: 1394/2949, Loss: 0.8262\n",
      "Epoch: 2, Step: 1395/2949, Loss: 0.7733\n",
      "Epoch: 2, Step: 1396/2949, Loss: 0.8485\n",
      "Epoch: 2, Step: 1397/2949, Loss: 0.8076\n",
      "Epoch: 2, Step: 1398/2949, Loss: 0.7970\n",
      "Epoch: 2, Step: 1399/2949, Loss: 0.8287\n",
      "Epoch: 2, Step: 1400/2949, Loss: 0.8095\n",
      "Epoch: 2, Step: 1401/2949, Loss: 0.8190\n",
      "Epoch: 2, Step: 1402/2949, Loss: 0.8566\n",
      "Epoch: 2, Step: 1403/2949, Loss: 0.7806\n",
      "Epoch: 2, Step: 1404/2949, Loss: 0.8051\n",
      "Epoch: 2, Step: 1405/2949, Loss: 0.8012\n",
      "Epoch: 2, Step: 1406/2949, Loss: 0.8353\n",
      "Epoch: 2, Step: 1407/2949, Loss: 0.8433\n",
      "Epoch: 2, Step: 1408/2949, Loss: 0.7990\n",
      "Epoch: 2, Step: 1409/2949, Loss: 0.8195\n",
      "Epoch: 2, Step: 1410/2949, Loss: 0.8555\n",
      "Epoch: 2, Step: 1411/2949, Loss: 0.8225\n",
      "Epoch: 2, Step: 1412/2949, Loss: 0.8370\n",
      "Epoch: 2, Step: 1413/2949, Loss: 0.7981\n",
      "Epoch: 2, Step: 1414/2949, Loss: 0.7574\n",
      "Epoch: 2, Step: 1415/2949, Loss: 0.8303\n",
      "Epoch: 2, Step: 1416/2949, Loss: 0.7949\n",
      "Epoch: 2, Step: 1417/2949, Loss: 0.7534\n",
      "Epoch: 2, Step: 1418/2949, Loss: 0.7827\n",
      "Epoch: 2, Step: 1419/2949, Loss: 0.7686\n",
      "Epoch: 2, Step: 1420/2949, Loss: 0.7606\n",
      "Epoch: 2, Step: 1421/2949, Loss: 0.7983\n",
      "Epoch: 2, Step: 1422/2949, Loss: 0.8043\n",
      "Epoch: 2, Step: 1423/2949, Loss: 0.8023\n",
      "Epoch: 2, Step: 1424/2949, Loss: 0.7689\n",
      "Epoch: 2, Step: 1425/2949, Loss: 0.7804\n",
      "Epoch: 2, Step: 1426/2949, Loss: 0.7836\n",
      "Epoch: 2, Step: 1427/2949, Loss: 0.8144\n",
      "Epoch: 2, Step: 1428/2949, Loss: 0.7480\n",
      "Epoch: 2, Step: 1429/2949, Loss: 0.8265\n",
      "Epoch: 2, Step: 1430/2949, Loss: 0.8315\n",
      "Epoch: 2, Step: 1431/2949, Loss: 0.7530\n",
      "Epoch: 2, Step: 1432/2949, Loss: 0.8525\n",
      "Epoch: 2, Step: 1433/2949, Loss: 0.8924\n",
      "Epoch: 2, Step: 1434/2949, Loss: 0.7593\n",
      "Epoch: 2, Step: 1435/2949, Loss: 0.7716\n",
      "Epoch: 2, Step: 1436/2949, Loss: 0.8303\n",
      "Epoch: 2, Step: 1437/2949, Loss: 0.7924\n",
      "Epoch: 2, Step: 1438/2949, Loss: 0.8152\n",
      "Epoch: 2, Step: 1439/2949, Loss: 0.7669\n",
      "Epoch: 2, Step: 1440/2949, Loss: 0.7923\n",
      "Epoch: 2, Step: 1441/2949, Loss: 0.8087\n",
      "Epoch: 2, Step: 1442/2949, Loss: 0.8177\n",
      "Epoch: 2, Step: 1443/2949, Loss: 0.7521\n",
      "Epoch: 2, Step: 1444/2949, Loss: 0.8195\n",
      "Epoch: 2, Step: 1445/2949, Loss: 0.7223\n",
      "Epoch: 2, Step: 1446/2949, Loss: 0.7984\n",
      "Epoch: 2, Step: 1447/2949, Loss: 0.8068\n",
      "Epoch: 2, Step: 1448/2949, Loss: 0.8377\n",
      "Epoch: 2, Step: 1449/2949, Loss: 0.8123\n",
      "Epoch: 2, Step: 1450/2949, Loss: 0.8357\n",
      "Epoch: 2, Step: 1451/2949, Loss: 0.8050\n",
      "Epoch: 2, Step: 1452/2949, Loss: 0.8079\n",
      "Epoch: 2, Step: 1453/2949, Loss: 0.8189\n",
      "Epoch: 2, Step: 1454/2949, Loss: 0.8091\n",
      "Epoch: 2, Step: 1455/2949, Loss: 0.8550\n",
      "Epoch: 2, Step: 1456/2949, Loss: 0.7683\n",
      "Epoch: 2, Step: 1457/2949, Loss: 0.8500\n",
      "Epoch: 2, Step: 1458/2949, Loss: 0.7774\n",
      "Epoch: 2, Step: 1459/2949, Loss: 0.7691\n",
      "Epoch: 2, Step: 1460/2949, Loss: 0.7852\n",
      "Epoch: 2, Step: 1461/2949, Loss: 0.8036\n",
      "Epoch: 2, Step: 1462/2949, Loss: 0.8263\n",
      "Epoch: 2, Step: 1463/2949, Loss: 0.7799\n",
      "Epoch: 2, Step: 1464/2949, Loss: 0.7993\n",
      "Epoch: 2, Step: 1465/2949, Loss: 0.8435\n",
      "Epoch: 2, Step: 1466/2949, Loss: 0.7422\n",
      "Epoch: 2, Step: 1467/2949, Loss: 0.7997\n",
      "Epoch: 2, Step: 1468/2949, Loss: 0.7880\n",
      "Epoch: 2, Step: 1469/2949, Loss: 0.7619\n",
      "Epoch: 2, Step: 1470/2949, Loss: 0.7963\n",
      "Epoch: 2, Step: 1471/2949, Loss: 0.7448\n",
      "Epoch: 2, Step: 1472/2949, Loss: 0.8477\n",
      "Epoch: 2, Step: 1473/2949, Loss: 0.8145\n",
      "Epoch: 2, Step: 1474/2949, Loss: 0.7684\n",
      "Epoch: 2, Step: 1475/2949, Loss: 0.7513\n",
      "Epoch: 2, Step: 1476/2949, Loss: 0.8039\n",
      "Epoch: 2, Step: 1477/2949, Loss: 0.7916\n",
      "Epoch: 2, Step: 1478/2949, Loss: 0.8099\n",
      "Epoch: 2, Step: 1479/2949, Loss: 0.8391\n",
      "Epoch: 2, Step: 1480/2949, Loss: 0.7931\n",
      "Epoch: 2, Step: 1481/2949, Loss: 0.8005\n",
      "Epoch: 2, Step: 1482/2949, Loss: 0.7744\n",
      "Epoch: 2, Step: 1483/2949, Loss: 0.7945\n",
      "Epoch: 2, Step: 1484/2949, Loss: 0.7494\n",
      "Epoch: 2, Step: 1485/2949, Loss: 0.8045\n",
      "Epoch: 2, Step: 1486/2949, Loss: 0.7994\n",
      "Epoch: 2, Step: 1487/2949, Loss: 0.7460\n",
      "Epoch: 2, Step: 1488/2949, Loss: 0.8120\n",
      "Epoch: 2, Step: 1489/2949, Loss: 0.7767\n",
      "Epoch: 2, Step: 1490/2949, Loss: 0.8220\n",
      "Epoch: 2, Step: 1491/2949, Loss: 0.8163\n",
      "Epoch: 2, Step: 1492/2949, Loss: 0.8393\n",
      "Epoch: 2, Step: 1493/2949, Loss: 0.8390\n",
      "Epoch: 2, Step: 1494/2949, Loss: 0.7993\n",
      "Epoch: 2, Step: 1495/2949, Loss: 0.8358\n",
      "Epoch: 2, Step: 1496/2949, Loss: 0.8396\n",
      "Epoch: 2, Step: 1497/2949, Loss: 0.7909\n",
      "Epoch: 2, Step: 1498/2949, Loss: 0.8131\n",
      "Epoch: 2, Step: 1499/2949, Loss: 0.7763\n",
      "Epoch: 2, Step: 1500/2949, Loss: 0.7903\n",
      "Epoch: 2, Step: 1501/2949, Loss: 0.7925\n",
      "Epoch: 2, Step: 1502/2949, Loss: 0.7374\n",
      "Epoch: 2, Step: 1503/2949, Loss: 0.8146\n",
      "Epoch: 2, Step: 1504/2949, Loss: 0.8299\n",
      "Epoch: 2, Step: 1505/2949, Loss: 0.7987\n",
      "Epoch: 2, Step: 1506/2949, Loss: 0.8513\n",
      "Epoch: 2, Step: 1507/2949, Loss: 0.7612\n",
      "Epoch: 2, Step: 1508/2949, Loss: 0.8034\n",
      "Epoch: 2, Step: 1509/2949, Loss: 0.7966\n",
      "Epoch: 2, Step: 1510/2949, Loss: 0.8088\n",
      "Epoch: 2, Step: 1511/2949, Loss: 0.8387\n",
      "Epoch: 2, Step: 1512/2949, Loss: 0.8268\n",
      "Epoch: 2, Step: 1513/2949, Loss: 0.8626\n",
      "Epoch: 2, Step: 1514/2949, Loss: 0.7846\n",
      "Epoch: 2, Step: 1515/2949, Loss: 0.7743\n",
      "Epoch: 2, Step: 1516/2949, Loss: 0.8380\n",
      "Epoch: 2, Step: 1517/2949, Loss: 0.8155\n",
      "Epoch: 2, Step: 1518/2949, Loss: 0.7932\n",
      "Epoch: 2, Step: 1519/2949, Loss: 0.8062\n",
      "Epoch: 2, Step: 1520/2949, Loss: 0.8522\n",
      "Epoch: 2, Step: 1521/2949, Loss: 0.8149\n",
      "Epoch: 2, Step: 1522/2949, Loss: 0.7495\n",
      "Epoch: 2, Step: 1523/2949, Loss: 0.8173\n",
      "Epoch: 2, Step: 1524/2949, Loss: 0.7771\n",
      "Epoch: 2, Step: 1525/2949, Loss: 0.8007\n",
      "Epoch: 2, Step: 1526/2949, Loss: 0.7949\n",
      "Epoch: 2, Step: 1527/2949, Loss: 0.7983\n",
      "Epoch: 2, Step: 1528/2949, Loss: 0.7994\n",
      "Epoch: 2, Step: 1529/2949, Loss: 0.8336\n",
      "Epoch: 2, Step: 1530/2949, Loss: 0.8004\n",
      "Epoch: 2, Step: 1531/2949, Loss: 0.7887\n",
      "Epoch: 2, Step: 1532/2949, Loss: 0.8312\n",
      "Epoch: 2, Step: 1533/2949, Loss: 0.8118\n",
      "Epoch: 2, Step: 1534/2949, Loss: 0.7882\n",
      "Epoch: 2, Step: 1535/2949, Loss: 0.8082\n",
      "Epoch: 2, Step: 1536/2949, Loss: 0.8020\n",
      "Epoch: 2, Step: 1537/2949, Loss: 0.7852\n",
      "Epoch: 2, Step: 1538/2949, Loss: 0.8002\n",
      "Epoch: 2, Step: 1539/2949, Loss: 0.7803\n",
      "Epoch: 2, Step: 1540/2949, Loss: 0.8414\n",
      "Epoch: 2, Step: 1541/2949, Loss: 0.7740\n",
      "Epoch: 2, Step: 1542/2949, Loss: 0.8083\n",
      "Epoch: 2, Step: 1543/2949, Loss: 0.7783\n",
      "Epoch: 2, Step: 1544/2949, Loss: 0.7976\n",
      "Epoch: 2, Step: 1545/2949, Loss: 0.7900\n",
      "Epoch: 2, Step: 1546/2949, Loss: 0.7994\n",
      "Epoch: 2, Step: 1547/2949, Loss: 0.7424\n",
      "Epoch: 2, Step: 1548/2949, Loss: 0.7678\n",
      "Epoch: 2, Step: 1549/2949, Loss: 0.7536\n",
      "Epoch: 2, Step: 1550/2949, Loss: 0.8489\n",
      "Epoch: 2, Step: 1551/2949, Loss: 0.8188\n",
      "Epoch: 2, Step: 1552/2949, Loss: 0.8317\n",
      "Epoch: 2, Step: 1553/2949, Loss: 0.8206\n",
      "Epoch: 2, Step: 1554/2949, Loss: 0.7304\n",
      "Epoch: 2, Step: 1555/2949, Loss: 0.7762\n",
      "Epoch: 2, Step: 1556/2949, Loss: 0.8142\n",
      "Epoch: 2, Step: 1557/2949, Loss: 0.8535\n",
      "Epoch: 2, Step: 1558/2949, Loss: 0.8058\n",
      "Epoch: 2, Step: 1559/2949, Loss: 0.7940\n",
      "Epoch: 2, Step: 1560/2949, Loss: 0.8160\n",
      "Epoch: 2, Step: 1561/2949, Loss: 0.8077\n",
      "Epoch: 2, Step: 1562/2949, Loss: 0.7718\n",
      "Epoch: 2, Step: 1563/2949, Loss: 0.7658\n",
      "Epoch: 2, Step: 1564/2949, Loss: 0.8055\n",
      "Epoch: 2, Step: 1565/2949, Loss: 0.7812\n",
      "Epoch: 2, Step: 1566/2949, Loss: 0.8397\n",
      "Epoch: 2, Step: 1567/2949, Loss: 0.7768\n",
      "Epoch: 2, Step: 1568/2949, Loss: 0.8442\n",
      "Epoch: 2, Step: 1569/2949, Loss: 0.7616\n",
      "Epoch: 2, Step: 1570/2949, Loss: 0.8096\n",
      "Epoch: 2, Step: 1571/2949, Loss: 0.7942\n",
      "Epoch: 2, Step: 1572/2949, Loss: 0.7866\n",
      "Epoch: 2, Step: 1573/2949, Loss: 0.8243\n",
      "Epoch: 2, Step: 1574/2949, Loss: 0.7710\n",
      "Epoch: 2, Step: 1575/2949, Loss: 0.8066\n",
      "Epoch: 2, Step: 1576/2949, Loss: 0.8415\n",
      "Epoch: 2, Step: 1577/2949, Loss: 0.8464\n",
      "Epoch: 2, Step: 1578/2949, Loss: 0.8217\n",
      "Epoch: 2, Step: 1579/2949, Loss: 0.7694\n",
      "Epoch: 2, Step: 1580/2949, Loss: 0.8005\n",
      "Epoch: 2, Step: 1581/2949, Loss: 0.7451\n",
      "Epoch: 2, Step: 1582/2949, Loss: 0.8029\n",
      "Epoch: 2, Step: 1583/2949, Loss: 0.8034\n",
      "Epoch: 2, Step: 1584/2949, Loss: 0.8074\n",
      "Epoch: 2, Step: 1585/2949, Loss: 0.7968\n",
      "Epoch: 2, Step: 1586/2949, Loss: 0.8409\n",
      "Epoch: 2, Step: 1587/2949, Loss: 0.7837\n",
      "Epoch: 2, Step: 1588/2949, Loss: 0.7967\n",
      "Epoch: 2, Step: 1589/2949, Loss: 0.8263\n",
      "Epoch: 2, Step: 1590/2949, Loss: 0.7438\n",
      "Epoch: 2, Step: 1591/2949, Loss: 0.7673\n",
      "Epoch: 2, Step: 1592/2949, Loss: 0.8017\n",
      "Epoch: 2, Step: 1593/2949, Loss: 0.8513\n",
      "Epoch: 2, Step: 1594/2949, Loss: 0.7997\n",
      "Epoch: 2, Step: 1595/2949, Loss: 0.8166\n",
      "Epoch: 2, Step: 1596/2949, Loss: 0.8066\n",
      "Epoch: 2, Step: 1597/2949, Loss: 0.8416\n",
      "Epoch: 2, Step: 1598/2949, Loss: 0.8167\n",
      "Epoch: 2, Step: 1599/2949, Loss: 0.7848\n",
      "Epoch: 2, Step: 1600/2949, Loss: 0.8167\n",
      "Epoch: 2, Step: 1601/2949, Loss: 0.7848\n",
      "Epoch: 2, Step: 1602/2949, Loss: 0.8050\n",
      "Epoch: 2, Step: 1603/2949, Loss: 0.8152\n",
      "Epoch: 2, Step: 1604/2949, Loss: 0.8460\n",
      "Epoch: 2, Step: 1605/2949, Loss: 0.8363\n",
      "Epoch: 2, Step: 1606/2949, Loss: 0.7547\n",
      "Epoch: 2, Step: 1607/2949, Loss: 0.7945\n",
      "Epoch: 2, Step: 1608/2949, Loss: 0.7798\n",
      "Epoch: 2, Step: 1609/2949, Loss: 0.8039\n",
      "Epoch: 2, Step: 1610/2949, Loss: 0.8114\n",
      "Epoch: 2, Step: 1611/2949, Loss: 0.7706\n",
      "Epoch: 2, Step: 1612/2949, Loss: 0.8357\n",
      "Epoch: 2, Step: 1613/2949, Loss: 0.8209\n",
      "Epoch: 2, Step: 1614/2949, Loss: 0.8197\n",
      "Epoch: 2, Step: 1615/2949, Loss: 0.7969\n",
      "Epoch: 2, Step: 1616/2949, Loss: 0.8143\n",
      "Epoch: 2, Step: 1617/2949, Loss: 0.7895\n",
      "Epoch: 2, Step: 1618/2949, Loss: 0.8004\n",
      "Epoch: 2, Step: 1619/2949, Loss: 0.8258\n",
      "Epoch: 2, Step: 1620/2949, Loss: 0.7324\n",
      "Epoch: 2, Step: 1621/2949, Loss: 0.8352\n",
      "Epoch: 2, Step: 1622/2949, Loss: 0.7998\n",
      "Epoch: 2, Step: 1623/2949, Loss: 0.8163\n",
      "Epoch: 2, Step: 1624/2949, Loss: 0.7684\n",
      "Epoch: 2, Step: 1625/2949, Loss: 0.8405\n",
      "Epoch: 2, Step: 1626/2949, Loss: 0.8029\n",
      "Epoch: 2, Step: 1627/2949, Loss: 0.7856\n",
      "Epoch: 2, Step: 1628/2949, Loss: 0.8253\n",
      "Epoch: 2, Step: 1629/2949, Loss: 0.7461\n",
      "Epoch: 2, Step: 1630/2949, Loss: 0.8275\n",
      "Epoch: 2, Step: 1631/2949, Loss: 0.8170\n",
      "Epoch: 2, Step: 1632/2949, Loss: 0.8443\n",
      "Epoch: 2, Step: 1633/2949, Loss: 0.8143\n",
      "Epoch: 2, Step: 1634/2949, Loss: 0.7740\n",
      "Epoch: 2, Step: 1635/2949, Loss: 0.8367\n",
      "Epoch: 2, Step: 1636/2949, Loss: 0.8266\n",
      "Epoch: 2, Step: 1637/2949, Loss: 0.8072\n",
      "Epoch: 2, Step: 1638/2949, Loss: 0.7903\n",
      "Epoch: 2, Step: 1639/2949, Loss: 0.8056\n",
      "Epoch: 2, Step: 1640/2949, Loss: 0.7958\n",
      "Epoch: 2, Step: 1641/2949, Loss: 0.8308\n",
      "Epoch: 2, Step: 1642/2949, Loss: 0.8326\n",
      "Epoch: 2, Step: 1643/2949, Loss: 0.8194\n",
      "Epoch: 2, Step: 1644/2949, Loss: 0.7636\n",
      "Epoch: 2, Step: 1645/2949, Loss: 0.8197\n",
      "Epoch: 2, Step: 1646/2949, Loss: 0.7515\n",
      "Epoch: 2, Step: 1647/2949, Loss: 0.8197\n",
      "Epoch: 2, Step: 1648/2949, Loss: 0.7652\n",
      "Epoch: 2, Step: 1649/2949, Loss: 0.7778\n",
      "Epoch: 2, Step: 1650/2949, Loss: 0.8024\n",
      "Epoch: 2, Step: 1651/2949, Loss: 0.8158\n",
      "Epoch: 2, Step: 1652/2949, Loss: 0.7755\n",
      "Epoch: 2, Step: 1653/2949, Loss: 0.7755\n",
      "Epoch: 2, Step: 1654/2949, Loss: 0.8233\n",
      "Epoch: 2, Step: 1655/2949, Loss: 0.7971\n",
      "Epoch: 2, Step: 1656/2949, Loss: 0.7922\n",
      "Epoch: 2, Step: 1657/2949, Loss: 0.8207\n",
      "Epoch: 2, Step: 1658/2949, Loss: 0.7709\n",
      "Epoch: 2, Step: 1659/2949, Loss: 0.7884\n",
      "Epoch: 2, Step: 1660/2949, Loss: 0.7667\n",
      "Epoch: 2, Step: 1661/2949, Loss: 0.8596\n",
      "Epoch: 2, Step: 1662/2949, Loss: 0.8300\n",
      "Epoch: 2, Step: 1663/2949, Loss: 0.8098\n",
      "Epoch: 2, Step: 1664/2949, Loss: 0.8501\n",
      "Epoch: 2, Step: 1665/2949, Loss: 0.7837\n",
      "Epoch: 2, Step: 1666/2949, Loss: 0.8236\n",
      "Epoch: 2, Step: 1667/2949, Loss: 0.7874\n",
      "Epoch: 2, Step: 1668/2949, Loss: 0.7986\n",
      "Epoch: 2, Step: 1669/2949, Loss: 0.7867\n",
      "Epoch: 2, Step: 1670/2949, Loss: 0.7938\n",
      "Epoch: 2, Step: 1671/2949, Loss: 0.8217\n",
      "Epoch: 2, Step: 1672/2949, Loss: 0.8078\n",
      "Epoch: 2, Step: 1673/2949, Loss: 0.7724\n",
      "Epoch: 2, Step: 1674/2949, Loss: 0.8378\n",
      "Epoch: 2, Step: 1675/2949, Loss: 0.7898\n",
      "Epoch: 2, Step: 1676/2949, Loss: 0.8327\n",
      "Epoch: 2, Step: 1677/2949, Loss: 0.7631\n",
      "Epoch: 2, Step: 1678/2949, Loss: 0.7863\n",
      "Epoch: 2, Step: 1679/2949, Loss: 0.7889\n",
      "Epoch: 2, Step: 1680/2949, Loss: 0.7857\n",
      "Epoch: 2, Step: 1681/2949, Loss: 0.8094\n",
      "Epoch: 2, Step: 1682/2949, Loss: 0.7396\n",
      "Epoch: 2, Step: 1683/2949, Loss: 0.7564\n",
      "Epoch: 2, Step: 1684/2949, Loss: 0.8702\n",
      "Epoch: 2, Step: 1685/2949, Loss: 0.7613\n",
      "Epoch: 2, Step: 1686/2949, Loss: 0.7502\n",
      "Epoch: 2, Step: 1687/2949, Loss: 0.7878\n",
      "Epoch: 2, Step: 1688/2949, Loss: 0.7817\n",
      "Epoch: 2, Step: 1689/2949, Loss: 0.7943\n",
      "Epoch: 2, Step: 1690/2949, Loss: 0.8288\n",
      "Epoch: 2, Step: 1691/2949, Loss: 0.8155\n",
      "Epoch: 2, Step: 1692/2949, Loss: 0.7931\n",
      "Epoch: 2, Step: 1693/2949, Loss: 0.8223\n",
      "Epoch: 2, Step: 1694/2949, Loss: 0.8491\n",
      "Epoch: 2, Step: 1695/2949, Loss: 0.7789\n",
      "Epoch: 2, Step: 1696/2949, Loss: 0.8134\n",
      "Epoch: 2, Step: 1697/2949, Loss: 0.7777\n",
      "Epoch: 2, Step: 1698/2949, Loss: 0.8078\n",
      "Epoch: 2, Step: 1699/2949, Loss: 0.8042\n",
      "Epoch: 2, Step: 1700/2949, Loss: 0.8534\n",
      "Epoch: 2, Step: 1701/2949, Loss: 0.8250\n",
      "Epoch: 2, Step: 1702/2949, Loss: 0.8089\n",
      "Epoch: 2, Step: 1703/2949, Loss: 0.7464\n",
      "Epoch: 2, Step: 1704/2949, Loss: 0.8023\n",
      "Epoch: 2, Step: 1705/2949, Loss: 0.8809\n",
      "Epoch: 2, Step: 1706/2949, Loss: 0.7615\n",
      "Epoch: 2, Step: 1707/2949, Loss: 0.7594\n",
      "Epoch: 2, Step: 1708/2949, Loss: 0.8045\n",
      "Epoch: 2, Step: 1709/2949, Loss: 0.7248\n",
      "Epoch: 2, Step: 1710/2949, Loss: 0.7886\n",
      "Epoch: 2, Step: 1711/2949, Loss: 0.7882\n",
      "Epoch: 2, Step: 1712/2949, Loss: 0.8257\n",
      "Epoch: 2, Step: 1713/2949, Loss: 0.7917\n",
      "Epoch: 2, Step: 1714/2949, Loss: 0.8280\n",
      "Epoch: 2, Step: 1715/2949, Loss: 0.8470\n",
      "Epoch: 2, Step: 1716/2949, Loss: 0.7882\n",
      "Epoch: 2, Step: 1717/2949, Loss: 0.8347\n",
      "Epoch: 2, Step: 1718/2949, Loss: 0.7998\n",
      "Epoch: 2, Step: 1719/2949, Loss: 0.8204\n",
      "Epoch: 2, Step: 1720/2949, Loss: 0.7554\n",
      "Epoch: 2, Step: 1721/2949, Loss: 0.7480\n",
      "Epoch: 2, Step: 1722/2949, Loss: 0.7707\n",
      "Epoch: 2, Step: 1723/2949, Loss: 0.8360\n",
      "Epoch: 2, Step: 1724/2949, Loss: 0.8001\n",
      "Epoch: 2, Step: 1725/2949, Loss: 0.7893\n",
      "Epoch: 2, Step: 1726/2949, Loss: 0.8184\n",
      "Epoch: 2, Step: 1727/2949, Loss: 0.8145\n",
      "Epoch: 2, Step: 1728/2949, Loss: 0.8116\n",
      "Epoch: 2, Step: 1729/2949, Loss: 0.7217\n",
      "Epoch: 2, Step: 1730/2949, Loss: 0.7601\n",
      "Epoch: 2, Step: 1731/2949, Loss: 0.8142\n",
      "Epoch: 2, Step: 1732/2949, Loss: 0.7533\n",
      "Epoch: 2, Step: 1733/2949, Loss: 0.8019\n",
      "Epoch: 2, Step: 1734/2949, Loss: 0.8206\n",
      "Epoch: 2, Step: 1735/2949, Loss: 0.8338\n",
      "Epoch: 2, Step: 1736/2949, Loss: 0.7534\n",
      "Epoch: 2, Step: 1737/2949, Loss: 0.8536\n",
      "Epoch: 2, Step: 1738/2949, Loss: 0.8034\n",
      "Epoch: 2, Step: 1739/2949, Loss: 0.7810\n",
      "Epoch: 2, Step: 1740/2949, Loss: 0.8119\n",
      "Epoch: 2, Step: 1741/2949, Loss: 0.7900\n",
      "Epoch: 2, Step: 1742/2949, Loss: 0.7957\n",
      "Epoch: 2, Step: 1743/2949, Loss: 0.7128\n",
      "Epoch: 2, Step: 1744/2949, Loss: 0.8074\n",
      "Epoch: 2, Step: 1745/2949, Loss: 0.7654\n",
      "Epoch: 2, Step: 1746/2949, Loss: 0.7723\n",
      "Epoch: 2, Step: 1747/2949, Loss: 0.7660\n",
      "Epoch: 2, Step: 1748/2949, Loss: 0.8100\n",
      "Epoch: 2, Step: 1749/2949, Loss: 0.7921\n",
      "Epoch: 2, Step: 1750/2949, Loss: 0.7651\n",
      "Epoch: 2, Step: 1751/2949, Loss: 0.7850\n",
      "Epoch: 2, Step: 1752/2949, Loss: 0.7618\n",
      "Epoch: 2, Step: 1753/2949, Loss: 0.7877\n",
      "Epoch: 2, Step: 1754/2949, Loss: 0.8256\n",
      "Epoch: 2, Step: 1755/2949, Loss: 0.7307\n",
      "Epoch: 2, Step: 1756/2949, Loss: 0.9210\n",
      "Epoch: 2, Step: 1757/2949, Loss: 0.8043\n",
      "Epoch: 2, Step: 1758/2949, Loss: 0.8045\n",
      "Epoch: 2, Step: 1759/2949, Loss: 0.8172\n",
      "Epoch: 2, Step: 1760/2949, Loss: 0.8004\n",
      "Epoch: 2, Step: 1761/2949, Loss: 0.8176\n",
      "Epoch: 2, Step: 1762/2949, Loss: 0.8450\n",
      "Epoch: 2, Step: 1763/2949, Loss: 0.7956\n",
      "Epoch: 2, Step: 1764/2949, Loss: 0.8013\n",
      "Epoch: 2, Step: 1765/2949, Loss: 0.8503\n",
      "Epoch: 2, Step: 1766/2949, Loss: 0.8204\n",
      "Epoch: 2, Step: 1767/2949, Loss: 0.7932\n",
      "Epoch: 2, Step: 1768/2949, Loss: 0.7937\n",
      "Epoch: 2, Step: 1769/2949, Loss: 0.7826\n",
      "Epoch: 2, Step: 1770/2949, Loss: 0.7865\n",
      "Epoch: 2, Step: 1771/2949, Loss: 0.8132\n",
      "Epoch: 2, Step: 1772/2949, Loss: 0.8228\n",
      "Epoch: 2, Step: 1773/2949, Loss: 0.8427\n",
      "Epoch: 2, Step: 1774/2949, Loss: 0.7512\n",
      "Epoch: 2, Step: 1775/2949, Loss: 0.7915\n",
      "Epoch: 2, Step: 1776/2949, Loss: 0.8281\n",
      "Epoch: 2, Step: 1777/2949, Loss: 0.8070\n",
      "Epoch: 2, Step: 1778/2949, Loss: 0.7930\n",
      "Epoch: 2, Step: 1779/2949, Loss: 0.8526\n",
      "Epoch: 2, Step: 1780/2949, Loss: 0.7668\n",
      "Epoch: 2, Step: 1781/2949, Loss: 0.7874\n",
      "Epoch: 2, Step: 1782/2949, Loss: 0.7967\n",
      "Epoch: 2, Step: 1783/2949, Loss: 0.8095\n",
      "Epoch: 2, Step: 1784/2949, Loss: 0.8147\n",
      "Epoch: 2, Step: 1785/2949, Loss: 0.7920\n",
      "Epoch: 2, Step: 1786/2949, Loss: 0.8072\n",
      "Epoch: 2, Step: 1787/2949, Loss: 0.8174\n",
      "Epoch: 2, Step: 1788/2949, Loss: 0.8452\n",
      "Epoch: 2, Step: 1789/2949, Loss: 0.8598\n",
      "Epoch: 2, Step: 1790/2949, Loss: 0.7941\n",
      "Epoch: 2, Step: 1791/2949, Loss: 0.8019\n",
      "Epoch: 2, Step: 1792/2949, Loss: 0.8485\n",
      "Epoch: 2, Step: 1793/2949, Loss: 0.7931\n",
      "Epoch: 2, Step: 1794/2949, Loss: 0.7873\n",
      "Epoch: 2, Step: 1795/2949, Loss: 0.7969\n",
      "Epoch: 2, Step: 1796/2949, Loss: 0.8451\n",
      "Epoch: 2, Step: 1797/2949, Loss: 0.8178\n",
      "Epoch: 2, Step: 1798/2949, Loss: 0.7622\n",
      "Epoch: 2, Step: 1799/2949, Loss: 0.8109\n",
      "Epoch: 2, Step: 1800/2949, Loss: 0.7916\n",
      "Epoch: 2, Step: 1801/2949, Loss: 0.7403\n",
      "Epoch: 2, Step: 1802/2949, Loss: 0.7973\n",
      "Epoch: 2, Step: 1803/2949, Loss: 0.8431\n",
      "Epoch: 2, Step: 1804/2949, Loss: 0.8386\n",
      "Epoch: 2, Step: 1805/2949, Loss: 0.7770\n",
      "Epoch: 2, Step: 1806/2949, Loss: 0.8347\n",
      "Epoch: 2, Step: 1807/2949, Loss: 0.8116\n",
      "Epoch: 2, Step: 1808/2949, Loss: 0.8491\n",
      "Epoch: 2, Step: 1809/2949, Loss: 0.7856\n",
      "Epoch: 2, Step: 1810/2949, Loss: 0.8070\n",
      "Epoch: 2, Step: 1811/2949, Loss: 0.7907\n",
      "Epoch: 2, Step: 1812/2949, Loss: 0.7951\n",
      "Epoch: 2, Step: 1813/2949, Loss: 0.8159\n",
      "Epoch: 2, Step: 1814/2949, Loss: 0.8031\n",
      "Epoch: 2, Step: 1815/2949, Loss: 0.7807\n",
      "Epoch: 2, Step: 1816/2949, Loss: 0.8174\n",
      "Epoch: 2, Step: 1817/2949, Loss: 0.7993\n",
      "Epoch: 2, Step: 1818/2949, Loss: 0.7928\n",
      "Epoch: 2, Step: 1819/2949, Loss: 0.8041\n",
      "Epoch: 2, Step: 1820/2949, Loss: 0.8394\n",
      "Epoch: 2, Step: 1821/2949, Loss: 0.7955\n",
      "Epoch: 2, Step: 1822/2949, Loss: 0.8141\n",
      "Epoch: 2, Step: 1823/2949, Loss: 0.7871\n",
      "Epoch: 2, Step: 1824/2949, Loss: 0.7767\n",
      "Epoch: 2, Step: 1825/2949, Loss: 0.8385\n",
      "Epoch: 2, Step: 1826/2949, Loss: 0.8423\n",
      "Epoch: 2, Step: 1827/2949, Loss: 0.8459\n",
      "Epoch: 2, Step: 1828/2949, Loss: 0.7222\n",
      "Epoch: 2, Step: 1829/2949, Loss: 0.7924\n",
      "Epoch: 2, Step: 1830/2949, Loss: 0.8181\n",
      "Epoch: 2, Step: 1831/2949, Loss: 0.7971\n",
      "Epoch: 2, Step: 1832/2949, Loss: 0.8182\n",
      "Epoch: 2, Step: 1833/2949, Loss: 0.7923\n",
      "Epoch: 2, Step: 1834/2949, Loss: 0.8452\n",
      "Epoch: 2, Step: 1835/2949, Loss: 0.7627\n",
      "Epoch: 2, Step: 1836/2949, Loss: 0.8145\n",
      "Epoch: 2, Step: 1837/2949, Loss: 0.7559\n",
      "Epoch: 2, Step: 1838/2949, Loss: 0.7658\n",
      "Epoch: 2, Step: 1839/2949, Loss: 0.8224\n",
      "Epoch: 2, Step: 1840/2949, Loss: 0.8198\n",
      "Epoch: 2, Step: 1841/2949, Loss: 0.8128\n",
      "Epoch: 2, Step: 1842/2949, Loss: 0.8470\n",
      "Epoch: 2, Step: 1843/2949, Loss: 0.8546\n",
      "Epoch: 2, Step: 1844/2949, Loss: 0.7624\n",
      "Epoch: 2, Step: 1845/2949, Loss: 0.7971\n",
      "Epoch: 2, Step: 1846/2949, Loss: 0.8634\n",
      "Epoch: 2, Step: 1847/2949, Loss: 0.8057\n",
      "Epoch: 2, Step: 1848/2949, Loss: 0.8416\n",
      "Epoch: 2, Step: 1849/2949, Loss: 0.8457\n",
      "Epoch: 2, Step: 1850/2949, Loss: 0.7467\n",
      "Epoch: 2, Step: 1851/2949, Loss: 0.8322\n",
      "Epoch: 2, Step: 1852/2949, Loss: 0.7715\n",
      "Epoch: 2, Step: 1853/2949, Loss: 0.8446\n",
      "Epoch: 2, Step: 1854/2949, Loss: 0.7465\n",
      "Epoch: 2, Step: 1855/2949, Loss: 0.8355\n",
      "Epoch: 2, Step: 1856/2949, Loss: 0.8203\n",
      "Epoch: 2, Step: 1857/2949, Loss: 0.7836\n",
      "Epoch: 2, Step: 1858/2949, Loss: 0.8199\n",
      "Epoch: 2, Step: 1859/2949, Loss: 0.8023\n",
      "Epoch: 2, Step: 1860/2949, Loss: 0.7642\n",
      "Epoch: 2, Step: 1861/2949, Loss: 0.7562\n",
      "Epoch: 2, Step: 1862/2949, Loss: 0.8185\n",
      "Epoch: 2, Step: 1863/2949, Loss: 0.7529\n",
      "Epoch: 2, Step: 1864/2949, Loss: 0.7500\n",
      "Epoch: 2, Step: 1865/2949, Loss: 0.7556\n",
      "Epoch: 2, Step: 1866/2949, Loss: 0.8053\n",
      "Epoch: 2, Step: 1867/2949, Loss: 0.8001\n",
      "Epoch: 2, Step: 1868/2949, Loss: 0.8013\n",
      "Epoch: 2, Step: 1869/2949, Loss: 0.7258\n",
      "Epoch: 2, Step: 1870/2949, Loss: 0.7965\n",
      "Epoch: 2, Step: 1871/2949, Loss: 0.8180\n",
      "Epoch: 2, Step: 1872/2949, Loss: 0.8421\n",
      "Epoch: 2, Step: 1873/2949, Loss: 0.8307\n",
      "Epoch: 2, Step: 1874/2949, Loss: 0.8073\n",
      "Epoch: 2, Step: 1875/2949, Loss: 0.7855\n",
      "Epoch: 2, Step: 1876/2949, Loss: 0.7730\n",
      "Epoch: 2, Step: 1877/2949, Loss: 0.7299\n",
      "Epoch: 2, Step: 1878/2949, Loss: 0.7635\n",
      "Epoch: 2, Step: 1879/2949, Loss: 0.8348\n",
      "Epoch: 2, Step: 1880/2949, Loss: 0.8155\n",
      "Epoch: 2, Step: 1881/2949, Loss: 0.7948\n",
      "Epoch: 2, Step: 1882/2949, Loss: 0.8140\n",
      "Epoch: 2, Step: 1883/2949, Loss: 0.7846\n",
      "Epoch: 2, Step: 1884/2949, Loss: 0.8452\n",
      "Epoch: 2, Step: 1885/2949, Loss: 0.8356\n",
      "Epoch: 2, Step: 1886/2949, Loss: 0.8198\n",
      "Epoch: 2, Step: 1887/2949, Loss: 0.7966\n",
      "Epoch: 2, Step: 1888/2949, Loss: 0.7973\n",
      "Epoch: 2, Step: 1889/2949, Loss: 0.8068\n",
      "Epoch: 2, Step: 1890/2949, Loss: 0.8287\n",
      "Epoch: 2, Step: 1891/2949, Loss: 0.7712\n",
      "Epoch: 2, Step: 1892/2949, Loss: 0.8084\n",
      "Epoch: 2, Step: 1893/2949, Loss: 0.8735\n",
      "Epoch: 2, Step: 1894/2949, Loss: 0.8230\n",
      "Epoch: 2, Step: 1895/2949, Loss: 0.8196\n",
      "Epoch: 2, Step: 1896/2949, Loss: 0.7725\n",
      "Epoch: 2, Step: 1897/2949, Loss: 0.8104\n",
      "Epoch: 2, Step: 1898/2949, Loss: 0.7709\n",
      "Epoch: 2, Step: 1899/2949, Loss: 0.7701\n",
      "Epoch: 2, Step: 1900/2949, Loss: 0.8102\n",
      "Epoch: 2, Step: 1901/2949, Loss: 0.8397\n",
      "Epoch: 2, Step: 1902/2949, Loss: 0.7805\n",
      "Epoch: 2, Step: 1903/2949, Loss: 0.7862\n",
      "Epoch: 2, Step: 1904/2949, Loss: 0.8073\n",
      "Epoch: 2, Step: 1905/2949, Loss: 0.7717\n",
      "Epoch: 2, Step: 1906/2949, Loss: 0.7972\n",
      "Epoch: 2, Step: 1907/2949, Loss: 0.8032\n",
      "Epoch: 2, Step: 1908/2949, Loss: 0.8033\n",
      "Epoch: 2, Step: 1909/2949, Loss: 0.8055\n",
      "Epoch: 2, Step: 1910/2949, Loss: 0.7959\n",
      "Epoch: 2, Step: 1911/2949, Loss: 0.8404\n",
      "Epoch: 2, Step: 1912/2949, Loss: 0.8342\n",
      "Epoch: 2, Step: 1913/2949, Loss: 0.7812\n",
      "Epoch: 2, Step: 1914/2949, Loss: 0.8060\n",
      "Epoch: 2, Step: 1915/2949, Loss: 0.7641\n",
      "Epoch: 2, Step: 1916/2949, Loss: 0.7796\n",
      "Epoch: 2, Step: 1917/2949, Loss: 0.7610\n",
      "Epoch: 2, Step: 1918/2949, Loss: 0.8363\n",
      "Epoch: 2, Step: 1919/2949, Loss: 0.8070\n",
      "Epoch: 2, Step: 1920/2949, Loss: 0.8468\n",
      "Epoch: 2, Step: 1921/2949, Loss: 0.8110\n",
      "Epoch: 2, Step: 1922/2949, Loss: 0.7927\n",
      "Epoch: 2, Step: 1923/2949, Loss: 0.8031\n",
      "Epoch: 2, Step: 1924/2949, Loss: 0.7958\n",
      "Epoch: 2, Step: 1925/2949, Loss: 0.7882\n",
      "Epoch: 2, Step: 1926/2949, Loss: 0.8169\n",
      "Epoch: 2, Step: 1927/2949, Loss: 0.8117\n",
      "Epoch: 2, Step: 1928/2949, Loss: 0.7927\n",
      "Epoch: 2, Step: 1929/2949, Loss: 0.7754\n",
      "Epoch: 2, Step: 1930/2949, Loss: 0.7969\n",
      "Epoch: 2, Step: 1931/2949, Loss: 0.8480\n",
      "Epoch: 2, Step: 1932/2949, Loss: 0.7619\n",
      "Epoch: 2, Step: 1933/2949, Loss: 0.7884\n",
      "Epoch: 2, Step: 1934/2949, Loss: 0.8020\n",
      "Epoch: 2, Step: 1935/2949, Loss: 0.8150\n",
      "Epoch: 2, Step: 1936/2949, Loss: 0.7645\n",
      "Epoch: 2, Step: 1937/2949, Loss: 0.7710\n",
      "Epoch: 2, Step: 1938/2949, Loss: 0.8379\n",
      "Epoch: 2, Step: 1939/2949, Loss: 0.8312\n",
      "Epoch: 2, Step: 1940/2949, Loss: 0.8035\n",
      "Epoch: 2, Step: 1941/2949, Loss: 0.7761\n",
      "Epoch: 2, Step: 1942/2949, Loss: 0.7861\n",
      "Epoch: 2, Step: 1943/2949, Loss: 0.8089\n",
      "Epoch: 2, Step: 1944/2949, Loss: 0.7848\n",
      "Epoch: 2, Step: 1945/2949, Loss: 0.8034\n",
      "Epoch: 2, Step: 1946/2949, Loss: 0.7967\n",
      "Epoch: 2, Step: 1947/2949, Loss: 0.7842\n",
      "Epoch: 2, Step: 1948/2949, Loss: 0.7987\n",
      "Epoch: 2, Step: 1949/2949, Loss: 0.7651\n",
      "Epoch: 2, Step: 1950/2949, Loss: 0.8122\n",
      "Epoch: 2, Step: 1951/2949, Loss: 0.8145\n",
      "Epoch: 2, Step: 1952/2949, Loss: 0.8045\n",
      "Epoch: 2, Step: 1953/2949, Loss: 0.7857\n",
      "Epoch: 2, Step: 1954/2949, Loss: 0.7796\n",
      "Epoch: 2, Step: 1955/2949, Loss: 0.8145\n",
      "Epoch: 2, Step: 1956/2949, Loss: 0.7600\n",
      "Epoch: 2, Step: 1957/2949, Loss: 0.7929\n",
      "Epoch: 2, Step: 1958/2949, Loss: 0.8388\n",
      "Epoch: 2, Step: 1959/2949, Loss: 0.8209\n",
      "Epoch: 2, Step: 1960/2949, Loss: 0.8096\n",
      "Epoch: 2, Step: 1961/2949, Loss: 0.8080\n",
      "Epoch: 2, Step: 1962/2949, Loss: 0.7945\n",
      "Epoch: 2, Step: 1963/2949, Loss: 0.7838\n",
      "Epoch: 2, Step: 1964/2949, Loss: 0.7571\n",
      "Epoch: 2, Step: 1965/2949, Loss: 0.8007\n",
      "Epoch: 2, Step: 1966/2949, Loss: 0.7826\n",
      "Epoch: 2, Step: 1967/2949, Loss: 0.8096\n",
      "Epoch: 2, Step: 1968/2949, Loss: 0.7697\n",
      "Epoch: 2, Step: 1969/2949, Loss: 0.8685\n",
      "Epoch: 2, Step: 1970/2949, Loss: 0.8383\n",
      "Epoch: 2, Step: 1971/2949, Loss: 0.8034\n",
      "Epoch: 2, Step: 1972/2949, Loss: 0.8083\n",
      "Epoch: 2, Step: 1973/2949, Loss: 0.8113\n",
      "Epoch: 2, Step: 1974/2949, Loss: 0.8196\n",
      "Epoch: 2, Step: 1975/2949, Loss: 0.8171\n",
      "Epoch: 2, Step: 1976/2949, Loss: 0.7551\n",
      "Epoch: 2, Step: 1977/2949, Loss: 0.7674\n",
      "Epoch: 2, Step: 1978/2949, Loss: 0.8223\n",
      "Epoch: 2, Step: 1979/2949, Loss: 0.8060\n",
      "Epoch: 2, Step: 1980/2949, Loss: 0.7640\n",
      "Epoch: 2, Step: 1981/2949, Loss: 0.8353\n",
      "Epoch: 2, Step: 1982/2949, Loss: 0.8172\n",
      "Epoch: 2, Step: 1983/2949, Loss: 0.7508\n",
      "Epoch: 2, Step: 1984/2949, Loss: 0.8369\n",
      "Epoch: 2, Step: 1985/2949, Loss: 0.7981\n",
      "Epoch: 2, Step: 1986/2949, Loss: 0.8062\n",
      "Epoch: 2, Step: 1987/2949, Loss: 0.8567\n",
      "Epoch: 2, Step: 1988/2949, Loss: 0.7168\n",
      "Epoch: 2, Step: 1989/2949, Loss: 0.8242\n",
      "Epoch: 2, Step: 1990/2949, Loss: 0.8655\n",
      "Epoch: 2, Step: 1991/2949, Loss: 0.7845\n",
      "Epoch: 2, Step: 1992/2949, Loss: 0.8107\n",
      "Epoch: 2, Step: 1993/2949, Loss: 0.8154\n",
      "Epoch: 2, Step: 1994/2949, Loss: 0.7713\n",
      "Epoch: 2, Step: 1995/2949, Loss: 0.7645\n",
      "Epoch: 2, Step: 1996/2949, Loss: 0.8347\n",
      "Epoch: 2, Step: 1997/2949, Loss: 0.7821\n",
      "Epoch: 2, Step: 1998/2949, Loss: 0.7696\n",
      "Epoch: 2, Step: 1999/2949, Loss: 0.7566\n",
      "Epoch: 2, Step: 2000/2949, Loss: 0.8031\n",
      "Epoch: 2, Step: 2001/2949, Loss: 0.7670\n",
      "Epoch: 2, Step: 2002/2949, Loss: 0.7908\n",
      "Epoch: 2, Step: 2003/2949, Loss: 0.7891\n",
      "Epoch: 2, Step: 2004/2949, Loss: 0.8150\n",
      "Epoch: 2, Step: 2005/2949, Loss: 0.8073\n",
      "Epoch: 2, Step: 2006/2949, Loss: 0.8454\n",
      "Epoch: 2, Step: 2007/2949, Loss: 0.8213\n",
      "Epoch: 2, Step: 2008/2949, Loss: 0.7875\n",
      "Epoch: 2, Step: 2009/2949, Loss: 0.8208\n",
      "Epoch: 2, Step: 2010/2949, Loss: 0.7422\n",
      "Epoch: 2, Step: 2011/2949, Loss: 0.7529\n",
      "Epoch: 2, Step: 2012/2949, Loss: 0.7645\n",
      "Epoch: 2, Step: 2013/2949, Loss: 0.8315\n",
      "Epoch: 2, Step: 2014/2949, Loss: 0.7765\n",
      "Epoch: 2, Step: 2015/2949, Loss: 0.7670\n",
      "Epoch: 2, Step: 2016/2949, Loss: 0.8016\n",
      "Epoch: 2, Step: 2017/2949, Loss: 0.7915\n",
      "Epoch: 2, Step: 2018/2949, Loss: 0.8554\n",
      "Epoch: 2, Step: 2019/2949, Loss: 0.8245\n",
      "Epoch: 2, Step: 2020/2949, Loss: 0.8075\n",
      "Epoch: 2, Step: 2021/2949, Loss: 0.7882\n",
      "Epoch: 2, Step: 2022/2949, Loss: 0.7919\n",
      "Epoch: 2, Step: 2023/2949, Loss: 0.7495\n",
      "Epoch: 2, Step: 2024/2949, Loss: 0.8405\n",
      "Epoch: 2, Step: 2025/2949, Loss: 0.7907\n",
      "Epoch: 2, Step: 2026/2949, Loss: 0.7431\n",
      "Epoch: 2, Step: 2027/2949, Loss: 0.8034\n",
      "Epoch: 2, Step: 2028/2949, Loss: 0.8396\n",
      "Epoch: 2, Step: 2029/2949, Loss: 0.8707\n",
      "Epoch: 2, Step: 2030/2949, Loss: 0.8176\n",
      "Epoch: 2, Step: 2031/2949, Loss: 0.7841\n",
      "Epoch: 2, Step: 2032/2949, Loss: 0.8128\n",
      "Epoch: 2, Step: 2033/2949, Loss: 0.8126\n",
      "Epoch: 2, Step: 2034/2949, Loss: 0.8391\n",
      "Epoch: 2, Step: 2035/2949, Loss: 0.8061\n",
      "Epoch: 2, Step: 2036/2949, Loss: 0.8352\n",
      "Epoch: 2, Step: 2037/2949, Loss: 0.7136\n",
      "Epoch: 2, Step: 2038/2949, Loss: 0.8205\n",
      "Epoch: 2, Step: 2039/2949, Loss: 0.8304\n",
      "Epoch: 2, Step: 2040/2949, Loss: 0.8442\n",
      "Epoch: 2, Step: 2041/2949, Loss: 0.7577\n",
      "Epoch: 2, Step: 2042/2949, Loss: 0.8597\n",
      "Epoch: 2, Step: 2043/2949, Loss: 0.8277\n",
      "Epoch: 2, Step: 2044/2949, Loss: 0.7929\n",
      "Epoch: 2, Step: 2045/2949, Loss: 0.7998\n",
      "Epoch: 2, Step: 2046/2949, Loss: 0.8001\n",
      "Epoch: 2, Step: 2047/2949, Loss: 0.7951\n",
      "Epoch: 2, Step: 2048/2949, Loss: 0.7876\n",
      "Epoch: 2, Step: 2049/2949, Loss: 0.8183\n",
      "Epoch: 2, Step: 2050/2949, Loss: 0.7164\n",
      "Epoch: 2, Step: 2051/2949, Loss: 0.7943\n",
      "Epoch: 2, Step: 2052/2949, Loss: 0.8443\n",
      "Epoch: 2, Step: 2053/2949, Loss: 0.7616\n",
      "Epoch: 2, Step: 2054/2949, Loss: 0.8111\n",
      "Epoch: 2, Step: 2055/2949, Loss: 0.8094\n",
      "Epoch: 2, Step: 2056/2949, Loss: 0.8207\n",
      "Epoch: 2, Step: 2057/2949, Loss: 0.8375\n",
      "Epoch: 2, Step: 2058/2949, Loss: 0.7919\n",
      "Epoch: 2, Step: 2059/2949, Loss: 0.7913\n",
      "Epoch: 2, Step: 2060/2949, Loss: 0.8011\n",
      "Epoch: 2, Step: 2061/2949, Loss: 0.7914\n",
      "Epoch: 2, Step: 2062/2949, Loss: 0.7874\n",
      "Epoch: 2, Step: 2063/2949, Loss: 0.8335\n",
      "Epoch: 2, Step: 2064/2949, Loss: 0.7759\n",
      "Epoch: 2, Step: 2065/2949, Loss: 0.8415\n",
      "Epoch: 2, Step: 2066/2949, Loss: 0.7916\n",
      "Epoch: 2, Step: 2067/2949, Loss: 0.8041\n",
      "Epoch: 2, Step: 2068/2949, Loss: 0.8627\n",
      "Epoch: 2, Step: 2069/2949, Loss: 0.8087\n",
      "Epoch: 2, Step: 2070/2949, Loss: 0.7912\n",
      "Epoch: 2, Step: 2071/2949, Loss: 0.7706\n",
      "Epoch: 2, Step: 2072/2949, Loss: 0.8470\n",
      "Epoch: 2, Step: 2073/2949, Loss: 0.7866\n",
      "Epoch: 2, Step: 2074/2949, Loss: 0.8436\n",
      "Epoch: 2, Step: 2075/2949, Loss: 0.7761\n",
      "Epoch: 2, Step: 2076/2949, Loss: 0.7905\n",
      "Epoch: 2, Step: 2077/2949, Loss: 0.7912\n",
      "Epoch: 2, Step: 2078/2949, Loss: 0.7993\n",
      "Epoch: 2, Step: 2079/2949, Loss: 0.7757\n",
      "Epoch: 2, Step: 2080/2949, Loss: 0.8357\n",
      "Epoch: 2, Step: 2081/2949, Loss: 0.8377\n",
      "Epoch: 2, Step: 2082/2949, Loss: 0.7494\n",
      "Epoch: 2, Step: 2083/2949, Loss: 0.7802\n",
      "Epoch: 2, Step: 2084/2949, Loss: 0.8115\n",
      "Epoch: 2, Step: 2085/2949, Loss: 0.7776\n",
      "Epoch: 2, Step: 2086/2949, Loss: 0.8270\n",
      "Epoch: 2, Step: 2087/2949, Loss: 0.7745\n",
      "Epoch: 2, Step: 2088/2949, Loss: 0.7776\n",
      "Epoch: 2, Step: 2089/2949, Loss: 0.8238\n",
      "Epoch: 2, Step: 2090/2949, Loss: 0.8019\n",
      "Epoch: 2, Step: 2091/2949, Loss: 0.7660\n",
      "Epoch: 2, Step: 2092/2949, Loss: 0.8405\n",
      "Epoch: 2, Step: 2093/2949, Loss: 0.7656\n",
      "Epoch: 2, Step: 2094/2949, Loss: 0.8033\n",
      "Epoch: 2, Step: 2095/2949, Loss: 0.7946\n",
      "Epoch: 2, Step: 2096/2949, Loss: 0.7745\n",
      "Epoch: 2, Step: 2097/2949, Loss: 0.7964\n",
      "Epoch: 2, Step: 2098/2949, Loss: 0.7879\n",
      "Epoch: 2, Step: 2099/2949, Loss: 0.7871\n",
      "Epoch: 2, Step: 2100/2949, Loss: 0.8098\n",
      "Epoch: 2, Step: 2101/2949, Loss: 0.8025\n",
      "Epoch: 2, Step: 2102/2949, Loss: 0.7775\n",
      "Epoch: 2, Step: 2103/2949, Loss: 0.8329\n",
      "Epoch: 2, Step: 2104/2949, Loss: 0.8173\n",
      "Epoch: 2, Step: 2105/2949, Loss: 0.7993\n",
      "Epoch: 2, Step: 2106/2949, Loss: 0.8285\n",
      "Epoch: 2, Step: 2107/2949, Loss: 0.7778\n",
      "Epoch: 2, Step: 2108/2949, Loss: 0.8321\n",
      "Epoch: 2, Step: 2109/2949, Loss: 0.7846\n",
      "Epoch: 2, Step: 2110/2949, Loss: 0.7674\n",
      "Epoch: 2, Step: 2111/2949, Loss: 0.7630\n",
      "Epoch: 2, Step: 2112/2949, Loss: 0.8034\n",
      "Epoch: 2, Step: 2113/2949, Loss: 0.7873\n",
      "Epoch: 2, Step: 2114/2949, Loss: 0.8367\n",
      "Epoch: 2, Step: 2115/2949, Loss: 0.8295\n",
      "Epoch: 2, Step: 2116/2949, Loss: 0.8191\n",
      "Epoch: 2, Step: 2117/2949, Loss: 0.7948\n",
      "Epoch: 2, Step: 2118/2949, Loss: 0.8010\n",
      "Epoch: 2, Step: 2119/2949, Loss: 0.7516\n",
      "Epoch: 2, Step: 2120/2949, Loss: 0.7804\n",
      "Epoch: 2, Step: 2121/2949, Loss: 0.7917\n",
      "Epoch: 2, Step: 2122/2949, Loss: 0.8007\n",
      "Epoch: 2, Step: 2123/2949, Loss: 0.7865\n",
      "Epoch: 2, Step: 2124/2949, Loss: 0.7734\n",
      "Epoch: 2, Step: 2125/2949, Loss: 0.7341\n",
      "Epoch: 2, Step: 2126/2949, Loss: 0.8167\n",
      "Epoch: 2, Step: 2127/2949, Loss: 0.8074\n",
      "Epoch: 2, Step: 2128/2949, Loss: 0.8329\n",
      "Epoch: 2, Step: 2129/2949, Loss: 0.7692\n",
      "Epoch: 2, Step: 2130/2949, Loss: 0.7833\n",
      "Epoch: 2, Step: 2131/2949, Loss: 0.7764\n",
      "Epoch: 2, Step: 2132/2949, Loss: 0.8098\n",
      "Epoch: 2, Step: 2133/2949, Loss: 0.8523\n",
      "Epoch: 2, Step: 2134/2949, Loss: 0.8068\n",
      "Epoch: 2, Step: 2135/2949, Loss: 0.8316\n",
      "Epoch: 2, Step: 2136/2949, Loss: 0.7995\n",
      "Epoch: 2, Step: 2137/2949, Loss: 0.8221\n",
      "Epoch: 2, Step: 2138/2949, Loss: 0.8332\n",
      "Epoch: 2, Step: 2139/2949, Loss: 0.8401\n",
      "Epoch: 2, Step: 2140/2949, Loss: 0.7961\n",
      "Epoch: 2, Step: 2141/2949, Loss: 0.7577\n",
      "Epoch: 2, Step: 2142/2949, Loss: 0.8030\n",
      "Epoch: 2, Step: 2143/2949, Loss: 0.7479\n",
      "Epoch: 2, Step: 2144/2949, Loss: 0.8060\n",
      "Epoch: 2, Step: 2145/2949, Loss: 0.7748\n",
      "Epoch: 2, Step: 2146/2949, Loss: 0.7927\n",
      "Epoch: 2, Step: 2147/2949, Loss: 0.7720\n",
      "Epoch: 2, Step: 2148/2949, Loss: 0.8227\n",
      "Epoch: 2, Step: 2149/2949, Loss: 0.7974\n",
      "Epoch: 2, Step: 2150/2949, Loss: 0.8285\n",
      "Epoch: 2, Step: 2151/2949, Loss: 0.8258\n",
      "Epoch: 2, Step: 2152/2949, Loss: 0.7991\n",
      "Epoch: 2, Step: 2153/2949, Loss: 0.7855\n",
      "Epoch: 2, Step: 2154/2949, Loss: 0.7814\n",
      "Epoch: 2, Step: 2155/2949, Loss: 0.8163\n",
      "Epoch: 2, Step: 2156/2949, Loss: 0.7897\n",
      "Epoch: 2, Step: 2157/2949, Loss: 0.8252\n",
      "Epoch: 2, Step: 2158/2949, Loss: 0.8130\n",
      "Epoch: 2, Step: 2159/2949, Loss: 0.8381\n",
      "Epoch: 2, Step: 2160/2949, Loss: 0.8029\n",
      "Epoch: 2, Step: 2161/2949, Loss: 0.8353\n",
      "Epoch: 2, Step: 2162/2949, Loss: 0.7730\n",
      "Epoch: 2, Step: 2163/2949, Loss: 0.7876\n",
      "Epoch: 2, Step: 2164/2949, Loss: 0.7825\n",
      "Epoch: 2, Step: 2165/2949, Loss: 0.7945\n",
      "Epoch: 2, Step: 2166/2949, Loss: 0.8250\n",
      "Epoch: 2, Step: 2167/2949, Loss: 0.7870\n",
      "Epoch: 2, Step: 2168/2949, Loss: 0.7514\n",
      "Epoch: 2, Step: 2169/2949, Loss: 0.7596\n",
      "Epoch: 2, Step: 2170/2949, Loss: 0.8266\n",
      "Epoch: 2, Step: 2171/2949, Loss: 0.7387\n",
      "Epoch: 2, Step: 2172/2949, Loss: 0.7744\n",
      "Epoch: 2, Step: 2173/2949, Loss: 0.7746\n",
      "Epoch: 2, Step: 2174/2949, Loss: 0.8002\n",
      "Epoch: 2, Step: 2175/2949, Loss: 0.8270\n",
      "Epoch: 2, Step: 2176/2949, Loss: 0.8133\n",
      "Epoch: 2, Step: 2177/2949, Loss: 0.8209\n",
      "Epoch: 2, Step: 2178/2949, Loss: 0.8268\n",
      "Epoch: 2, Step: 2179/2949, Loss: 0.7809\n",
      "Epoch: 2, Step: 2180/2949, Loss: 0.7550\n",
      "Epoch: 2, Step: 2181/2949, Loss: 0.7626\n",
      "Epoch: 2, Step: 2182/2949, Loss: 0.7566\n",
      "Epoch: 2, Step: 2183/2949, Loss: 0.7778\n",
      "Epoch: 2, Step: 2184/2949, Loss: 0.7885\n",
      "Epoch: 2, Step: 2185/2949, Loss: 0.8089\n",
      "Epoch: 2, Step: 2186/2949, Loss: 0.8014\n",
      "Epoch: 2, Step: 2187/2949, Loss: 0.7854\n",
      "Epoch: 2, Step: 2188/2949, Loss: 0.7831\n",
      "Epoch: 2, Step: 2189/2949, Loss: 0.8318\n",
      "Epoch: 2, Step: 2190/2949, Loss: 0.7938\n",
      "Epoch: 2, Step: 2191/2949, Loss: 0.7756\n",
      "Epoch: 2, Step: 2192/2949, Loss: 0.8133\n",
      "Epoch: 2, Step: 2193/2949, Loss: 0.8086\n",
      "Epoch: 2, Step: 2194/2949, Loss: 0.7687\n",
      "Epoch: 2, Step: 2195/2949, Loss: 0.8167\n",
      "Epoch: 2, Step: 2196/2949, Loss: 0.7516\n",
      "Epoch: 2, Step: 2197/2949, Loss: 0.8391\n",
      "Epoch: 2, Step: 2198/2949, Loss: 0.7946\n",
      "Epoch: 2, Step: 2199/2949, Loss: 0.8066\n",
      "Epoch: 2, Step: 2200/2949, Loss: 0.8372\n",
      "Epoch: 2, Step: 2201/2949, Loss: 0.7937\n",
      "Epoch: 2, Step: 2202/2949, Loss: 0.7466\n",
      "Epoch: 2, Step: 2203/2949, Loss: 0.7932\n",
      "Epoch: 2, Step: 2204/2949, Loss: 0.7860\n",
      "Epoch: 2, Step: 2205/2949, Loss: 0.7433\n",
      "Epoch: 2, Step: 2206/2949, Loss: 0.7420\n",
      "Epoch: 2, Step: 2207/2949, Loss: 0.8096\n",
      "Epoch: 2, Step: 2208/2949, Loss: 0.8077\n",
      "Epoch: 2, Step: 2209/2949, Loss: 0.7960\n",
      "Epoch: 2, Step: 2210/2949, Loss: 0.7567\n",
      "Epoch: 2, Step: 2211/2949, Loss: 0.7609\n",
      "Epoch: 2, Step: 2212/2949, Loss: 0.7784\n",
      "Epoch: 2, Step: 2213/2949, Loss: 0.7503\n",
      "Epoch: 2, Step: 2214/2949, Loss: 0.8224\n",
      "Epoch: 2, Step: 2215/2949, Loss: 0.7996\n",
      "Epoch: 2, Step: 2216/2949, Loss: 0.7918\n",
      "Epoch: 2, Step: 2217/2949, Loss: 0.7903\n",
      "Epoch: 2, Step: 2218/2949, Loss: 0.8335\n",
      "Epoch: 2, Step: 2219/2949, Loss: 0.7539\n",
      "Epoch: 2, Step: 2220/2949, Loss: 0.7709\n",
      "Epoch: 2, Step: 2221/2949, Loss: 0.7558\n",
      "Epoch: 2, Step: 2222/2949, Loss: 0.8255\n",
      "Epoch: 2, Step: 2223/2949, Loss: 0.8485\n",
      "Epoch: 2, Step: 2224/2949, Loss: 0.8577\n",
      "Epoch: 2, Step: 2225/2949, Loss: 0.8371\n",
      "Epoch: 2, Step: 2226/2949, Loss: 0.8257\n",
      "Epoch: 2, Step: 2227/2949, Loss: 0.7813\n",
      "Epoch: 2, Step: 2228/2949, Loss: 0.8258\n",
      "Epoch: 2, Step: 2229/2949, Loss: 0.7999\n",
      "Epoch: 2, Step: 2230/2949, Loss: 0.8083\n",
      "Epoch: 2, Step: 2231/2949, Loss: 0.7834\n",
      "Epoch: 2, Step: 2232/2949, Loss: 0.7341\n",
      "Epoch: 2, Step: 2233/2949, Loss: 0.8078\n",
      "Epoch: 2, Step: 2234/2949, Loss: 0.8054\n",
      "Epoch: 2, Step: 2235/2949, Loss: 0.8401\n",
      "Epoch: 2, Step: 2236/2949, Loss: 0.7402\n",
      "Epoch: 2, Step: 2237/2949, Loss: 0.7964\n",
      "Epoch: 2, Step: 2238/2949, Loss: 0.7683\n",
      "Epoch: 2, Step: 2239/2949, Loss: 0.7808\n",
      "Epoch: 2, Step: 2240/2949, Loss: 0.7625\n",
      "Epoch: 2, Step: 2241/2949, Loss: 0.7875\n",
      "Epoch: 2, Step: 2242/2949, Loss: 0.8526\n",
      "Epoch: 2, Step: 2243/2949, Loss: 0.7935\n",
      "Epoch: 2, Step: 2244/2949, Loss: 0.7650\n",
      "Epoch: 2, Step: 2245/2949, Loss: 0.7698\n",
      "Epoch: 2, Step: 2246/2949, Loss: 0.8007\n",
      "Epoch: 2, Step: 2247/2949, Loss: 0.8158\n",
      "Epoch: 2, Step: 2248/2949, Loss: 0.8105\n",
      "Epoch: 2, Step: 2249/2949, Loss: 0.8095\n",
      "Epoch: 2, Step: 2250/2949, Loss: 0.7574\n",
      "Epoch: 2, Step: 2251/2949, Loss: 0.7758\n",
      "Epoch: 2, Step: 2252/2949, Loss: 0.7665\n",
      "Epoch: 2, Step: 2253/2949, Loss: 0.7426\n",
      "Epoch: 2, Step: 2254/2949, Loss: 0.7948\n",
      "Epoch: 2, Step: 2255/2949, Loss: 0.8260\n",
      "Epoch: 2, Step: 2256/2949, Loss: 0.8212\n",
      "Epoch: 2, Step: 2257/2949, Loss: 0.8035\n",
      "Epoch: 2, Step: 2258/2949, Loss: 0.7767\n",
      "Epoch: 2, Step: 2259/2949, Loss: 0.8076\n",
      "Epoch: 2, Step: 2260/2949, Loss: 0.8072\n",
      "Epoch: 2, Step: 2261/2949, Loss: 0.7423\n",
      "Epoch: 2, Step: 2262/2949, Loss: 0.8073\n",
      "Epoch: 2, Step: 2263/2949, Loss: 0.7981\n",
      "Epoch: 2, Step: 2264/2949, Loss: 0.7667\n",
      "Epoch: 2, Step: 2265/2949, Loss: 0.7836\n",
      "Epoch: 2, Step: 2266/2949, Loss: 0.7558\n",
      "Epoch: 2, Step: 2267/2949, Loss: 0.7783\n",
      "Epoch: 2, Step: 2268/2949, Loss: 0.7857\n",
      "Epoch: 2, Step: 2269/2949, Loss: 0.8377\n",
      "Epoch: 2, Step: 2270/2949, Loss: 0.8454\n",
      "Epoch: 2, Step: 2271/2949, Loss: 0.8274\n",
      "Epoch: 2, Step: 2272/2949, Loss: 0.8128\n",
      "Epoch: 2, Step: 2273/2949, Loss: 0.7934\n",
      "Epoch: 2, Step: 2274/2949, Loss: 0.8019\n",
      "Epoch: 2, Step: 2275/2949, Loss: 0.8389\n",
      "Epoch: 2, Step: 2276/2949, Loss: 0.8147\n",
      "Epoch: 2, Step: 2277/2949, Loss: 0.7725\n",
      "Epoch: 2, Step: 2278/2949, Loss: 0.8025\n",
      "Epoch: 2, Step: 2279/2949, Loss: 0.7392\n",
      "Epoch: 2, Step: 2280/2949, Loss: 0.8316\n",
      "Epoch: 2, Step: 2281/2949, Loss: 0.8050\n",
      "Epoch: 2, Step: 2282/2949, Loss: 0.7533\n",
      "Epoch: 2, Step: 2283/2949, Loss: 0.7944\n",
      "Epoch: 2, Step: 2284/2949, Loss: 0.7846\n",
      "Epoch: 2, Step: 2285/2949, Loss: 0.8011\n",
      "Epoch: 2, Step: 2286/2949, Loss: 0.7949\n",
      "Epoch: 2, Step: 2287/2949, Loss: 0.8254\n",
      "Epoch: 2, Step: 2288/2949, Loss: 0.7992\n",
      "Epoch: 2, Step: 2289/2949, Loss: 0.8517\n",
      "Epoch: 2, Step: 2290/2949, Loss: 0.7806\n",
      "Epoch: 2, Step: 2291/2949, Loss: 0.7848\n",
      "Epoch: 2, Step: 2292/2949, Loss: 0.7943\n",
      "Epoch: 2, Step: 2293/2949, Loss: 0.7154\n",
      "Epoch: 2, Step: 2294/2949, Loss: 0.7910\n",
      "Epoch: 2, Step: 2295/2949, Loss: 0.7921\n",
      "Epoch: 2, Step: 2296/2949, Loss: 0.8414\n",
      "Epoch: 2, Step: 2297/2949, Loss: 0.7433\n",
      "Epoch: 2, Step: 2298/2949, Loss: 0.8367\n",
      "Epoch: 2, Step: 2299/2949, Loss: 0.8050\n",
      "Epoch: 2, Step: 2300/2949, Loss: 0.8023\n",
      "Epoch: 2, Step: 2301/2949, Loss: 0.7747\n",
      "Epoch: 2, Step: 2302/2949, Loss: 0.8050\n",
      "Epoch: 2, Step: 2303/2949, Loss: 0.8025\n",
      "Epoch: 2, Step: 2304/2949, Loss: 0.7932\n",
      "Epoch: 2, Step: 2305/2949, Loss: 0.7709\n",
      "Epoch: 2, Step: 2306/2949, Loss: 0.7966\n",
      "Epoch: 2, Step: 2307/2949, Loss: 0.8169\n",
      "Epoch: 2, Step: 2308/2949, Loss: 0.7571\n",
      "Epoch: 2, Step: 2309/2949, Loss: 0.8164\n",
      "Epoch: 2, Step: 2310/2949, Loss: 0.7517\n",
      "Epoch: 2, Step: 2311/2949, Loss: 0.7404\n",
      "Epoch: 2, Step: 2312/2949, Loss: 0.8146\n",
      "Epoch: 2, Step: 2313/2949, Loss: 0.8216\n",
      "Epoch: 2, Step: 2314/2949, Loss: 0.8132\n",
      "Epoch: 2, Step: 2315/2949, Loss: 0.8121\n",
      "Epoch: 2, Step: 2316/2949, Loss: 0.8315\n",
      "Epoch: 2, Step: 2317/2949, Loss: 0.7681\n",
      "Epoch: 2, Step: 2318/2949, Loss: 0.7670\n",
      "Epoch: 2, Step: 2319/2949, Loss: 0.7647\n",
      "Epoch: 2, Step: 2320/2949, Loss: 0.8068\n",
      "Epoch: 2, Step: 2321/2949, Loss: 0.8051\n",
      "Epoch: 2, Step: 2322/2949, Loss: 0.8244\n",
      "Epoch: 2, Step: 2323/2949, Loss: 0.7350\n",
      "Epoch: 2, Step: 2324/2949, Loss: 0.7892\n",
      "Epoch: 2, Step: 2325/2949, Loss: 0.8348\n",
      "Epoch: 2, Step: 2326/2949, Loss: 0.7804\n",
      "Epoch: 2, Step: 2327/2949, Loss: 0.7558\n",
      "Epoch: 2, Step: 2328/2949, Loss: 0.7864\n",
      "Epoch: 2, Step: 2329/2949, Loss: 0.8021\n",
      "Epoch: 2, Step: 2330/2949, Loss: 0.7698\n",
      "Epoch: 2, Step: 2331/2949, Loss: 0.7962\n",
      "Epoch: 2, Step: 2332/2949, Loss: 0.8356\n",
      "Epoch: 2, Step: 2333/2949, Loss: 0.7761\n",
      "Epoch: 2, Step: 2334/2949, Loss: 0.7408\n",
      "Epoch: 2, Step: 2335/2949, Loss: 0.8034\n",
      "Epoch: 2, Step: 2336/2949, Loss: 0.8081\n",
      "Epoch: 2, Step: 2337/2949, Loss: 0.8043\n",
      "Epoch: 2, Step: 2338/2949, Loss: 0.7828\n",
      "Epoch: 2, Step: 2339/2949, Loss: 0.8212\n",
      "Epoch: 2, Step: 2340/2949, Loss: 0.8081\n",
      "Epoch: 2, Step: 2341/2949, Loss: 0.7923\n",
      "Epoch: 2, Step: 2342/2949, Loss: 0.7709\n",
      "Epoch: 2, Step: 2343/2949, Loss: 0.8162\n",
      "Epoch: 2, Step: 2344/2949, Loss: 0.8431\n",
      "Epoch: 2, Step: 2345/2949, Loss: 0.8607\n",
      "Epoch: 2, Step: 2346/2949, Loss: 0.7984\n",
      "Epoch: 2, Step: 2347/2949, Loss: 0.8099\n",
      "Epoch: 2, Step: 2348/2949, Loss: 0.7631\n",
      "Epoch: 2, Step: 2349/2949, Loss: 0.8045\n",
      "Epoch: 2, Step: 2350/2949, Loss: 0.7721\n",
      "Epoch: 2, Step: 2351/2949, Loss: 0.7845\n",
      "Epoch: 2, Step: 2352/2949, Loss: 0.8099\n",
      "Epoch: 2, Step: 2353/2949, Loss: 0.7952\n",
      "Epoch: 2, Step: 2354/2949, Loss: 0.8038\n",
      "Epoch: 2, Step: 2355/2949, Loss: 0.8211\n",
      "Epoch: 2, Step: 2356/2949, Loss: 0.8023\n",
      "Epoch: 2, Step: 2357/2949, Loss: 0.8030\n",
      "Epoch: 2, Step: 2358/2949, Loss: 0.8687\n",
      "Epoch: 2, Step: 2359/2949, Loss: 0.8263\n",
      "Epoch: 2, Step: 2360/2949, Loss: 0.7968\n",
      "Epoch: 2, Step: 2361/2949, Loss: 0.8013\n",
      "Epoch: 2, Step: 2362/2949, Loss: 0.7965\n",
      "Epoch: 2, Step: 2363/2949, Loss: 0.7646\n",
      "Epoch: 2, Step: 2364/2949, Loss: 0.7912\n",
      "Epoch: 2, Step: 2365/2949, Loss: 0.7921\n",
      "Epoch: 2, Step: 2366/2949, Loss: 0.8111\n",
      "Epoch: 2, Step: 2367/2949, Loss: 0.7942\n",
      "Epoch: 2, Step: 2368/2949, Loss: 0.7078\n",
      "Epoch: 2, Step: 2369/2949, Loss: 0.7625\n",
      "Epoch: 2, Step: 2370/2949, Loss: 0.8422\n",
      "Epoch: 2, Step: 2371/2949, Loss: 0.8419\n",
      "Epoch: 2, Step: 2372/2949, Loss: 0.7690\n",
      "Epoch: 2, Step: 2373/2949, Loss: 0.8025\n",
      "Epoch: 2, Step: 2374/2949, Loss: 0.8048\n",
      "Epoch: 2, Step: 2375/2949, Loss: 0.7662\n",
      "Epoch: 2, Step: 2376/2949, Loss: 0.7489\n",
      "Epoch: 2, Step: 2377/2949, Loss: 0.7903\n",
      "Epoch: 2, Step: 2378/2949, Loss: 0.7630\n",
      "Epoch: 2, Step: 2379/2949, Loss: 0.7996\n",
      "Epoch: 2, Step: 2380/2949, Loss: 0.7970\n",
      "Epoch: 2, Step: 2381/2949, Loss: 0.8003\n",
      "Epoch: 2, Step: 2382/2949, Loss: 0.7991\n",
      "Epoch: 2, Step: 2383/2949, Loss: 0.8159\n",
      "Epoch: 2, Step: 2384/2949, Loss: 0.7866\n",
      "Epoch: 2, Step: 2385/2949, Loss: 0.7833\n",
      "Epoch: 2, Step: 2386/2949, Loss: 0.7908\n",
      "Epoch: 2, Step: 2387/2949, Loss: 0.8039\n",
      "Epoch: 2, Step: 2388/2949, Loss: 0.7927\n",
      "Epoch: 2, Step: 2389/2949, Loss: 0.7263\n",
      "Epoch: 2, Step: 2390/2949, Loss: 0.8507\n",
      "Epoch: 2, Step: 2391/2949, Loss: 0.7871\n",
      "Epoch: 2, Step: 2392/2949, Loss: 0.7988\n",
      "Epoch: 2, Step: 2393/2949, Loss: 0.7412\n",
      "Epoch: 2, Step: 2394/2949, Loss: 0.8203\n",
      "Epoch: 2, Step: 2395/2949, Loss: 0.8574\n",
      "Epoch: 2, Step: 2396/2949, Loss: 0.8238\n",
      "Epoch: 2, Step: 2397/2949, Loss: 0.7687\n",
      "Epoch: 2, Step: 2398/2949, Loss: 0.7775\n",
      "Epoch: 2, Step: 2399/2949, Loss: 0.7722\n",
      "Epoch: 2, Step: 2400/2949, Loss: 0.7743\n",
      "Epoch: 2, Step: 2401/2949, Loss: 0.8179\n",
      "Epoch: 2, Step: 2402/2949, Loss: 0.7940\n",
      "Epoch: 2, Step: 2403/2949, Loss: 0.7196\n",
      "Epoch: 2, Step: 2404/2949, Loss: 0.7710\n",
      "Epoch: 2, Step: 2405/2949, Loss: 0.7178\n",
      "Epoch: 2, Step: 2406/2949, Loss: 0.8218\n",
      "Epoch: 2, Step: 2407/2949, Loss: 0.7983\n",
      "Epoch: 2, Step: 2408/2949, Loss: 0.8080\n",
      "Epoch: 2, Step: 2409/2949, Loss: 0.8021\n",
      "Epoch: 2, Step: 2410/2949, Loss: 0.7571\n",
      "Epoch: 2, Step: 2411/2949, Loss: 0.7505\n",
      "Epoch: 2, Step: 2412/2949, Loss: 0.8175\n",
      "Epoch: 2, Step: 2413/2949, Loss: 0.8295\n",
      "Epoch: 2, Step: 2414/2949, Loss: 0.7911\n",
      "Epoch: 2, Step: 2415/2949, Loss: 0.7778\n",
      "Epoch: 2, Step: 2416/2949, Loss: 0.7928\n",
      "Epoch: 2, Step: 2417/2949, Loss: 0.8220\n",
      "Epoch: 2, Step: 2418/2949, Loss: 0.8011\n",
      "Epoch: 2, Step: 2419/2949, Loss: 0.7785\n",
      "Epoch: 2, Step: 2420/2949, Loss: 0.7446\n",
      "Epoch: 2, Step: 2421/2949, Loss: 0.8184\n",
      "Epoch: 2, Step: 2422/2949, Loss: 0.7771\n",
      "Epoch: 2, Step: 2423/2949, Loss: 0.8147\n",
      "Epoch: 2, Step: 2424/2949, Loss: 0.7599\n",
      "Epoch: 2, Step: 2425/2949, Loss: 0.7972\n",
      "Epoch: 2, Step: 2426/2949, Loss: 0.7569\n",
      "Epoch: 2, Step: 2427/2949, Loss: 0.7918\n",
      "Epoch: 2, Step: 2428/2949, Loss: 0.8219\n",
      "Epoch: 2, Step: 2429/2949, Loss: 0.7997\n",
      "Epoch: 2, Step: 2430/2949, Loss: 0.7511\n",
      "Epoch: 2, Step: 2431/2949, Loss: 0.7607\n",
      "Epoch: 2, Step: 2432/2949, Loss: 0.7875\n",
      "Epoch: 2, Step: 2433/2949, Loss: 0.7809\n",
      "Epoch: 2, Step: 2434/2949, Loss: 0.8010\n",
      "Epoch: 2, Step: 2435/2949, Loss: 0.8005\n",
      "Epoch: 2, Step: 2436/2949, Loss: 0.8019\n",
      "Epoch: 2, Step: 2437/2949, Loss: 0.7821\n",
      "Epoch: 2, Step: 2438/2949, Loss: 0.7972\n",
      "Epoch: 2, Step: 2439/2949, Loss: 0.8034\n",
      "Epoch: 2, Step: 2440/2949, Loss: 0.8243\n",
      "Epoch: 2, Step: 2441/2949, Loss: 0.7591\n",
      "Epoch: 2, Step: 2442/2949, Loss: 0.7564\n",
      "Epoch: 2, Step: 2443/2949, Loss: 0.7923\n",
      "Epoch: 2, Step: 2444/2949, Loss: 0.7657\n",
      "Epoch: 2, Step: 2445/2949, Loss: 0.7763\n",
      "Epoch: 2, Step: 2446/2949, Loss: 0.7463\n",
      "Epoch: 2, Step: 2447/2949, Loss: 0.8011\n",
      "Epoch: 2, Step: 2448/2949, Loss: 0.8309\n",
      "Epoch: 2, Step: 2449/2949, Loss: 0.7505\n",
      "Epoch: 2, Step: 2450/2949, Loss: 0.8416\n",
      "Epoch: 2, Step: 2451/2949, Loss: 0.7413\n",
      "Epoch: 2, Step: 2452/2949, Loss: 0.7759\n",
      "Epoch: 2, Step: 2453/2949, Loss: 0.7772\n",
      "Epoch: 2, Step: 2454/2949, Loss: 0.7446\n",
      "Epoch: 2, Step: 2455/2949, Loss: 0.7678\n",
      "Epoch: 2, Step: 2456/2949, Loss: 0.7634\n",
      "Epoch: 2, Step: 2457/2949, Loss: 0.8203\n",
      "Epoch: 2, Step: 2458/2949, Loss: 0.7657\n",
      "Epoch: 2, Step: 2459/2949, Loss: 0.7763\n",
      "Epoch: 2, Step: 2460/2949, Loss: 0.8248\n",
      "Epoch: 2, Step: 2461/2949, Loss: 0.8305\n",
      "Epoch: 2, Step: 2462/2949, Loss: 0.8196\n",
      "Epoch: 2, Step: 2463/2949, Loss: 0.8219\n",
      "Epoch: 2, Step: 2464/2949, Loss: 0.7665\n",
      "Epoch: 2, Step: 2465/2949, Loss: 0.7814\n",
      "Epoch: 2, Step: 2466/2949, Loss: 0.7744\n",
      "Epoch: 2, Step: 2467/2949, Loss: 0.7340\n",
      "Epoch: 2, Step: 2468/2949, Loss: 0.8265\n",
      "Epoch: 2, Step: 2469/2949, Loss: 0.8175\n",
      "Epoch: 2, Step: 2470/2949, Loss: 0.7927\n",
      "Epoch: 2, Step: 2471/2949, Loss: 0.8374\n",
      "Epoch: 2, Step: 2472/2949, Loss: 0.8089\n",
      "Epoch: 2, Step: 2473/2949, Loss: 0.8029\n",
      "Epoch: 2, Step: 2474/2949, Loss: 0.8153\n",
      "Epoch: 2, Step: 2475/2949, Loss: 0.7550\n",
      "Epoch: 2, Step: 2476/2949, Loss: 0.7907\n",
      "Epoch: 2, Step: 2477/2949, Loss: 0.8184\n",
      "Epoch: 2, Step: 2478/2949, Loss: 0.8035\n",
      "Epoch: 2, Step: 2479/2949, Loss: 0.7742\n",
      "Epoch: 2, Step: 2480/2949, Loss: 0.8053\n",
      "Epoch: 2, Step: 2481/2949, Loss: 0.7808\n",
      "Epoch: 2, Step: 2482/2949, Loss: 0.7754\n",
      "Epoch: 2, Step: 2483/2949, Loss: 0.7443\n",
      "Epoch: 2, Step: 2484/2949, Loss: 0.8169\n",
      "Epoch: 2, Step: 2485/2949, Loss: 0.7742\n",
      "Epoch: 2, Step: 2486/2949, Loss: 0.8655\n",
      "Epoch: 2, Step: 2487/2949, Loss: 0.7735\n",
      "Epoch: 2, Step: 2488/2949, Loss: 0.7490\n",
      "Epoch: 2, Step: 2489/2949, Loss: 0.8074\n",
      "Epoch: 2, Step: 2490/2949, Loss: 0.8073\n",
      "Epoch: 2, Step: 2491/2949, Loss: 0.7421\n",
      "Epoch: 2, Step: 2492/2949, Loss: 0.7888\n",
      "Epoch: 2, Step: 2493/2949, Loss: 0.7984\n",
      "Epoch: 2, Step: 2494/2949, Loss: 0.7708\n",
      "Epoch: 2, Step: 2495/2949, Loss: 0.7765\n",
      "Epoch: 2, Step: 2496/2949, Loss: 0.8276\n",
      "Epoch: 2, Step: 2497/2949, Loss: 0.7732\n",
      "Epoch: 2, Step: 2498/2949, Loss: 0.8158\n",
      "Epoch: 2, Step: 2499/2949, Loss: 0.7836\n",
      "Epoch: 2, Step: 2500/2949, Loss: 0.8440\n",
      "Epoch: 2, Step: 2501/2949, Loss: 0.7662\n",
      "Epoch: 2, Step: 2502/2949, Loss: 0.7876\n",
      "Epoch: 2, Step: 2503/2949, Loss: 0.7998\n",
      "Epoch: 2, Step: 2504/2949, Loss: 0.7780\n",
      "Epoch: 2, Step: 2505/2949, Loss: 0.7952\n",
      "Epoch: 2, Step: 2506/2949, Loss: 0.7298\n",
      "Epoch: 2, Step: 2507/2949, Loss: 0.8384\n",
      "Epoch: 2, Step: 2508/2949, Loss: 0.8210\n",
      "Epoch: 2, Step: 2509/2949, Loss: 0.8381\n",
      "Epoch: 2, Step: 2510/2949, Loss: 0.8133\n",
      "Epoch: 2, Step: 2511/2949, Loss: 0.7503\n",
      "Epoch: 2, Step: 2512/2949, Loss: 0.7517\n",
      "Epoch: 2, Step: 2513/2949, Loss: 0.7773\n",
      "Epoch: 2, Step: 2514/2949, Loss: 0.8193\n",
      "Epoch: 2, Step: 2515/2949, Loss: 0.7644\n",
      "Epoch: 2, Step: 2516/2949, Loss: 0.8317\n",
      "Epoch: 2, Step: 2517/2949, Loss: 0.8228\n",
      "Epoch: 2, Step: 2518/2949, Loss: 0.7678\n",
      "Epoch: 2, Step: 2519/2949, Loss: 0.8138\n",
      "Epoch: 2, Step: 2520/2949, Loss: 0.7499\n",
      "Epoch: 2, Step: 2521/2949, Loss: 0.7878\n",
      "Epoch: 2, Step: 2522/2949, Loss: 0.7894\n",
      "Epoch: 2, Step: 2523/2949, Loss: 0.8317\n",
      "Epoch: 2, Step: 2524/2949, Loss: 0.8049\n",
      "Epoch: 2, Step: 2525/2949, Loss: 0.7868\n",
      "Epoch: 2, Step: 2526/2949, Loss: 0.7962\n",
      "Epoch: 2, Step: 2527/2949, Loss: 0.7831\n",
      "Epoch: 2, Step: 2528/2949, Loss: 0.7662\n",
      "Epoch: 2, Step: 2529/2949, Loss: 0.8039\n",
      "Epoch: 2, Step: 2530/2949, Loss: 0.7821\n",
      "Epoch: 2, Step: 2531/2949, Loss: 0.7769\n",
      "Epoch: 2, Step: 2532/2949, Loss: 0.8044\n",
      "Epoch: 2, Step: 2533/2949, Loss: 0.7649\n",
      "Epoch: 2, Step: 2534/2949, Loss: 0.8332\n",
      "Epoch: 2, Step: 2535/2949, Loss: 0.7717\n",
      "Epoch: 2, Step: 2536/2949, Loss: 0.7848\n",
      "Epoch: 2, Step: 2537/2949, Loss: 0.7946\n",
      "Epoch: 2, Step: 2538/2949, Loss: 0.8222\n",
      "Epoch: 2, Step: 2539/2949, Loss: 0.8544\n",
      "Epoch: 2, Step: 2540/2949, Loss: 0.8160\n",
      "Epoch: 2, Step: 2541/2949, Loss: 0.7845\n",
      "Epoch: 2, Step: 2542/2949, Loss: 0.7675\n",
      "Epoch: 2, Step: 2543/2949, Loss: 0.7871\n",
      "Epoch: 2, Step: 2544/2949, Loss: 0.8153\n",
      "Epoch: 2, Step: 2545/2949, Loss: 0.8407\n",
      "Epoch: 2, Step: 2546/2949, Loss: 0.7716\n",
      "Epoch: 2, Step: 2547/2949, Loss: 0.7961\n",
      "Epoch: 2, Step: 2548/2949, Loss: 0.7875\n",
      "Epoch: 2, Step: 2549/2949, Loss: 0.8482\n",
      "Epoch: 2, Step: 2550/2949, Loss: 0.8128\n",
      "Epoch: 2, Step: 2551/2949, Loss: 0.7218\n",
      "Epoch: 2, Step: 2552/2949, Loss: 0.7735\n",
      "Epoch: 2, Step: 2553/2949, Loss: 0.7810\n",
      "Epoch: 2, Step: 2554/2949, Loss: 0.7520\n",
      "Epoch: 2, Step: 2555/2949, Loss: 0.8212\n",
      "Epoch: 2, Step: 2556/2949, Loss: 0.8013\n",
      "Epoch: 2, Step: 2557/2949, Loss: 0.7788\n",
      "Epoch: 2, Step: 2558/2949, Loss: 0.7996\n",
      "Epoch: 2, Step: 2559/2949, Loss: 0.7675\n",
      "Epoch: 2, Step: 2560/2949, Loss: 0.8014\n",
      "Epoch: 2, Step: 2561/2949, Loss: 0.7830\n",
      "Epoch: 2, Step: 2562/2949, Loss: 0.7519\n",
      "Epoch: 2, Step: 2563/2949, Loss: 0.7770\n",
      "Epoch: 2, Step: 2564/2949, Loss: 0.7680\n",
      "Epoch: 2, Step: 2565/2949, Loss: 0.7561\n",
      "Epoch: 2, Step: 2566/2949, Loss: 0.8193\n",
      "Epoch: 2, Step: 2567/2949, Loss: 0.8138\n",
      "Epoch: 2, Step: 2568/2949, Loss: 0.7418\n",
      "Epoch: 2, Step: 2569/2949, Loss: 0.7670\n",
      "Epoch: 2, Step: 2570/2949, Loss: 0.8309\n",
      "Epoch: 2, Step: 2571/2949, Loss: 0.8278\n",
      "Epoch: 2, Step: 2572/2949, Loss: 0.8160\n",
      "Epoch: 2, Step: 2573/2949, Loss: 0.7649\n",
      "Epoch: 2, Step: 2574/2949, Loss: 0.7873\n",
      "Epoch: 2, Step: 2575/2949, Loss: 0.7577\n",
      "Epoch: 2, Step: 2576/2949, Loss: 0.7839\n",
      "Epoch: 2, Step: 2577/2949, Loss: 0.7257\n",
      "Epoch: 2, Step: 2578/2949, Loss: 0.7768\n",
      "Epoch: 2, Step: 2579/2949, Loss: 0.7809\n",
      "Epoch: 2, Step: 2580/2949, Loss: 0.7734\n",
      "Epoch: 2, Step: 2581/2949, Loss: 0.7918\n",
      "Epoch: 2, Step: 2582/2949, Loss: 0.8384\n",
      "Epoch: 2, Step: 2583/2949, Loss: 0.7721\n",
      "Epoch: 2, Step: 2584/2949, Loss: 0.7515\n",
      "Epoch: 2, Step: 2585/2949, Loss: 0.7765\n",
      "Epoch: 2, Step: 2586/2949, Loss: 0.7776\n",
      "Epoch: 2, Step: 2587/2949, Loss: 0.8026\n",
      "Epoch: 2, Step: 2588/2949, Loss: 0.8026\n",
      "Epoch: 2, Step: 2589/2949, Loss: 0.7507\n",
      "Epoch: 2, Step: 2590/2949, Loss: 0.7899\n",
      "Epoch: 2, Step: 2591/2949, Loss: 0.8192\n",
      "Epoch: 2, Step: 2592/2949, Loss: 0.7898\n",
      "Epoch: 2, Step: 2593/2949, Loss: 0.7576\n",
      "Epoch: 2, Step: 2594/2949, Loss: 0.7778\n",
      "Epoch: 2, Step: 2595/2949, Loss: 0.7959\n",
      "Epoch: 2, Step: 2596/2949, Loss: 0.8416\n",
      "Epoch: 2, Step: 2597/2949, Loss: 0.7658\n",
      "Epoch: 2, Step: 2598/2949, Loss: 0.8548\n",
      "Epoch: 2, Step: 2599/2949, Loss: 0.7793\n",
      "Epoch: 2, Step: 2600/2949, Loss: 0.7738\n",
      "Epoch: 2, Step: 2601/2949, Loss: 0.8462\n",
      "Epoch: 2, Step: 2602/2949, Loss: 0.8570\n",
      "Epoch: 2, Step: 2603/2949, Loss: 0.7469\n",
      "Epoch: 2, Step: 2604/2949, Loss: 0.7859\n",
      "Epoch: 2, Step: 2605/2949, Loss: 0.7351\n",
      "Epoch: 2, Step: 2606/2949, Loss: 0.8461\n",
      "Epoch: 2, Step: 2607/2949, Loss: 0.7672\n",
      "Epoch: 2, Step: 2608/2949, Loss: 0.8286\n",
      "Epoch: 2, Step: 2609/2949, Loss: 0.8019\n",
      "Epoch: 2, Step: 2610/2949, Loss: 0.7918\n",
      "Epoch: 2, Step: 2611/2949, Loss: 0.7664\n",
      "Epoch: 2, Step: 2612/2949, Loss: 0.7812\n",
      "Epoch: 2, Step: 2613/2949, Loss: 0.7681\n",
      "Epoch: 2, Step: 2614/2949, Loss: 0.7522\n",
      "Epoch: 2, Step: 2615/2949, Loss: 0.7553\n",
      "Epoch: 2, Step: 2616/2949, Loss: 0.7657\n",
      "Epoch: 2, Step: 2617/2949, Loss: 0.8647\n",
      "Epoch: 2, Step: 2618/2949, Loss: 0.8284\n",
      "Epoch: 2, Step: 2619/2949, Loss: 0.8393\n",
      "Epoch: 2, Step: 2620/2949, Loss: 0.7871\n",
      "Epoch: 2, Step: 2621/2949, Loss: 0.8579\n",
      "Epoch: 2, Step: 2622/2949, Loss: 0.7882\n",
      "Epoch: 2, Step: 2623/2949, Loss: 0.8244\n",
      "Epoch: 2, Step: 2624/2949, Loss: 0.7769\n",
      "Epoch: 2, Step: 2625/2949, Loss: 0.8060\n",
      "Epoch: 2, Step: 2626/2949, Loss: 0.7693\n",
      "Epoch: 2, Step: 2627/2949, Loss: 0.8451\n",
      "Epoch: 2, Step: 2628/2949, Loss: 0.8404\n",
      "Epoch: 2, Step: 2629/2949, Loss: 0.7971\n",
      "Epoch: 2, Step: 2630/2949, Loss: 0.7436\n",
      "Epoch: 2, Step: 2631/2949, Loss: 0.8403\n",
      "Epoch: 2, Step: 2632/2949, Loss: 0.8069\n",
      "Epoch: 2, Step: 2633/2949, Loss: 0.7776\n",
      "Epoch: 2, Step: 2634/2949, Loss: 0.8307\n",
      "Epoch: 2, Step: 2635/2949, Loss: 0.7579\n",
      "Epoch: 2, Step: 2636/2949, Loss: 0.8069\n",
      "Epoch: 2, Step: 2637/2949, Loss: 0.7906\n",
      "Epoch: 2, Step: 2638/2949, Loss: 0.7850\n",
      "Epoch: 2, Step: 2639/2949, Loss: 0.7910\n",
      "Epoch: 2, Step: 2640/2949, Loss: 0.7801\n",
      "Epoch: 2, Step: 2641/2949, Loss: 0.7847\n",
      "Epoch: 2, Step: 2642/2949, Loss: 0.8136\n",
      "Epoch: 2, Step: 2643/2949, Loss: 0.8079\n",
      "Epoch: 2, Step: 2644/2949, Loss: 0.8074\n",
      "Epoch: 2, Step: 2645/2949, Loss: 0.8241\n",
      "Epoch: 2, Step: 2646/2949, Loss: 0.8900\n",
      "Epoch: 2, Step: 2647/2949, Loss: 0.7933\n",
      "Epoch: 2, Step: 2648/2949, Loss: 0.7834\n",
      "Epoch: 2, Step: 2649/2949, Loss: 0.7378\n",
      "Epoch: 2, Step: 2650/2949, Loss: 0.8041\n",
      "Epoch: 2, Step: 2651/2949, Loss: 0.8257\n",
      "Epoch: 2, Step: 2652/2949, Loss: 0.8203\n",
      "Epoch: 2, Step: 2653/2949, Loss: 0.7903\n",
      "Epoch: 2, Step: 2654/2949, Loss: 0.8012\n",
      "Epoch: 2, Step: 2655/2949, Loss: 0.7935\n",
      "Epoch: 2, Step: 2656/2949, Loss: 0.7958\n",
      "Epoch: 2, Step: 2657/2949, Loss: 0.8182\n",
      "Epoch: 2, Step: 2658/2949, Loss: 0.8116\n",
      "Epoch: 2, Step: 2659/2949, Loss: 0.7810\n",
      "Epoch: 2, Step: 2660/2949, Loss: 0.8117\n",
      "Epoch: 2, Step: 2661/2949, Loss: 0.7585\n",
      "Epoch: 2, Step: 2662/2949, Loss: 0.7944\n",
      "Epoch: 2, Step: 2663/2949, Loss: 0.7899\n",
      "Epoch: 2, Step: 2664/2949, Loss: 0.8131\n",
      "Epoch: 2, Step: 2665/2949, Loss: 0.7951\n",
      "Epoch: 2, Step: 2666/2949, Loss: 0.8070\n",
      "Epoch: 2, Step: 2667/2949, Loss: 0.8037\n",
      "Epoch: 2, Step: 2668/2949, Loss: 0.7994\n",
      "Epoch: 2, Step: 2669/2949, Loss: 0.7851\n",
      "Epoch: 2, Step: 2670/2949, Loss: 0.8158\n",
      "Epoch: 2, Step: 2671/2949, Loss: 0.7809\n",
      "Epoch: 2, Step: 2672/2949, Loss: 0.8187\n",
      "Epoch: 2, Step: 2673/2949, Loss: 0.7676\n",
      "Epoch: 2, Step: 2674/2949, Loss: 0.7872\n",
      "Epoch: 2, Step: 2675/2949, Loss: 0.7601\n",
      "Epoch: 2, Step: 2676/2949, Loss: 0.8203\n",
      "Epoch: 2, Step: 2677/2949, Loss: 0.7736\n",
      "Epoch: 2, Step: 2678/2949, Loss: 0.8017\n",
      "Epoch: 2, Step: 2679/2949, Loss: 0.7748\n",
      "Epoch: 2, Step: 2680/2949, Loss: 0.7684\n",
      "Epoch: 2, Step: 2681/2949, Loss: 0.7763\n",
      "Epoch: 2, Step: 2682/2949, Loss: 0.7893\n",
      "Epoch: 2, Step: 2683/2949, Loss: 0.7723\n",
      "Epoch: 2, Step: 2684/2949, Loss: 0.7712\n",
      "Epoch: 2, Step: 2685/2949, Loss: 0.7703\n",
      "Epoch: 2, Step: 2686/2949, Loss: 0.8143\n",
      "Epoch: 2, Step: 2687/2949, Loss: 0.8000\n",
      "Epoch: 2, Step: 2688/2949, Loss: 0.8000\n",
      "Epoch: 2, Step: 2689/2949, Loss: 0.8076\n",
      "Epoch: 2, Step: 2690/2949, Loss: 0.7443\n",
      "Epoch: 2, Step: 2691/2949, Loss: 0.7830\n",
      "Epoch: 2, Step: 2692/2949, Loss: 0.8224\n",
      "Epoch: 2, Step: 2693/2949, Loss: 0.7988\n",
      "Epoch: 2, Step: 2694/2949, Loss: 0.7694\n",
      "Epoch: 2, Step: 2695/2949, Loss: 0.8356\n",
      "Epoch: 2, Step: 2696/2949, Loss: 0.7812\n",
      "Epoch: 2, Step: 2697/2949, Loss: 0.7609\n",
      "Epoch: 2, Step: 2698/2949, Loss: 0.7680\n",
      "Epoch: 2, Step: 2699/2949, Loss: 0.7309\n",
      "Epoch: 2, Step: 2700/2949, Loss: 0.7718\n",
      "Epoch: 2, Step: 2701/2949, Loss: 0.7716\n",
      "Epoch: 2, Step: 2702/2949, Loss: 0.7501\n",
      "Epoch: 2, Step: 2703/2949, Loss: 0.7805\n",
      "Epoch: 2, Step: 2704/2949, Loss: 0.7689\n",
      "Epoch: 2, Step: 2705/2949, Loss: 0.8310\n",
      "Epoch: 2, Step: 2706/2949, Loss: 0.7416\n",
      "Epoch: 2, Step: 2707/2949, Loss: 0.8261\n",
      "Epoch: 2, Step: 2708/2949, Loss: 0.7076\n",
      "Epoch: 2, Step: 2709/2949, Loss: 0.8200\n",
      "Epoch: 2, Step: 2710/2949, Loss: 0.8174\n",
      "Epoch: 2, Step: 2711/2949, Loss: 0.7794\n",
      "Epoch: 2, Step: 2712/2949, Loss: 0.7863\n",
      "Epoch: 2, Step: 2713/2949, Loss: 0.7930\n",
      "Epoch: 2, Step: 2714/2949, Loss: 0.7773\n",
      "Epoch: 2, Step: 2715/2949, Loss: 0.7600\n",
      "Epoch: 2, Step: 2716/2949, Loss: 0.7486\n",
      "Epoch: 2, Step: 2717/2949, Loss: 0.7880\n",
      "Epoch: 2, Step: 2718/2949, Loss: 0.7909\n",
      "Epoch: 2, Step: 2719/2949, Loss: 0.7973\n",
      "Epoch: 2, Step: 2720/2949, Loss: 0.7615\n",
      "Epoch: 2, Step: 2721/2949, Loss: 0.7392\n",
      "Epoch: 2, Step: 2722/2949, Loss: 0.8807\n",
      "Epoch: 2, Step: 2723/2949, Loss: 0.8024\n",
      "Epoch: 2, Step: 2724/2949, Loss: 0.7933\n",
      "Epoch: 2, Step: 2725/2949, Loss: 0.7510\n",
      "Epoch: 2, Step: 2726/2949, Loss: 0.8151\n",
      "Epoch: 2, Step: 2727/2949, Loss: 0.8288\n",
      "Epoch: 2, Step: 2728/2949, Loss: 0.7708\n",
      "Epoch: 2, Step: 2729/2949, Loss: 0.8113\n",
      "Epoch: 2, Step: 2730/2949, Loss: 0.8121\n",
      "Epoch: 2, Step: 2731/2949, Loss: 0.7443\n",
      "Epoch: 2, Step: 2732/2949, Loss: 0.7712\n",
      "Epoch: 2, Step: 2733/2949, Loss: 0.7737\n",
      "Epoch: 2, Step: 2734/2949, Loss: 0.8014\n",
      "Epoch: 2, Step: 2735/2949, Loss: 0.8194\n",
      "Epoch: 2, Step: 2736/2949, Loss: 0.7806\n",
      "Epoch: 2, Step: 2737/2949, Loss: 0.7736\n",
      "Epoch: 2, Step: 2738/2949, Loss: 0.8108\n",
      "Epoch: 2, Step: 2739/2949, Loss: 0.8416\n",
      "Epoch: 2, Step: 2740/2949, Loss: 0.7532\n",
      "Epoch: 2, Step: 2741/2949, Loss: 0.7476\n",
      "Epoch: 2, Step: 2742/2949, Loss: 0.8067\n",
      "Epoch: 2, Step: 2743/2949, Loss: 0.8086\n",
      "Epoch: 2, Step: 2744/2949, Loss: 0.7901\n",
      "Epoch: 2, Step: 2745/2949, Loss: 0.8203\n",
      "Epoch: 2, Step: 2746/2949, Loss: 0.7763\n",
      "Epoch: 2, Step: 2747/2949, Loss: 0.7320\n",
      "Epoch: 2, Step: 2748/2949, Loss: 0.7745\n",
      "Epoch: 2, Step: 2749/2949, Loss: 0.7538\n",
      "Epoch: 2, Step: 2750/2949, Loss: 0.7871\n",
      "Epoch: 2, Step: 2751/2949, Loss: 0.7751\n",
      "Epoch: 2, Step: 2752/2949, Loss: 0.8172\n",
      "Epoch: 2, Step: 2753/2949, Loss: 0.7891\n",
      "Epoch: 2, Step: 2754/2949, Loss: 0.8164\n",
      "Epoch: 2, Step: 2755/2949, Loss: 0.7414\n",
      "Epoch: 2, Step: 2756/2949, Loss: 0.7736\n",
      "Epoch: 2, Step: 2757/2949, Loss: 0.7851\n",
      "Epoch: 2, Step: 2758/2949, Loss: 0.8122\n",
      "Epoch: 2, Step: 2759/2949, Loss: 0.7612\n",
      "Epoch: 2, Step: 2760/2949, Loss: 0.7708\n",
      "Epoch: 2, Step: 2761/2949, Loss: 0.7736\n",
      "Epoch: 2, Step: 2762/2949, Loss: 0.7938\n",
      "Epoch: 2, Step: 2763/2949, Loss: 0.7969\n",
      "Epoch: 2, Step: 2764/2949, Loss: 0.7850\n",
      "Epoch: 2, Step: 2765/2949, Loss: 0.7806\n",
      "Epoch: 2, Step: 2766/2949, Loss: 0.7730\n",
      "Epoch: 2, Step: 2767/2949, Loss: 0.7809\n",
      "Epoch: 2, Step: 2768/2949, Loss: 0.7325\n",
      "Epoch: 2, Step: 2769/2949, Loss: 0.7980\n",
      "Epoch: 2, Step: 2770/2949, Loss: 0.7754\n",
      "Epoch: 2, Step: 2771/2949, Loss: 0.7702\n",
      "Epoch: 2, Step: 2772/2949, Loss: 0.8073\n",
      "Epoch: 2, Step: 2773/2949, Loss: 0.8387\n",
      "Epoch: 2, Step: 2774/2949, Loss: 0.8489\n",
      "Epoch: 2, Step: 2775/2949, Loss: 0.7863\n",
      "Epoch: 2, Step: 2776/2949, Loss: 0.7812\n",
      "Epoch: 2, Step: 2777/2949, Loss: 0.7710\n",
      "Epoch: 2, Step: 2778/2949, Loss: 0.7931\n",
      "Epoch: 2, Step: 2779/2949, Loss: 0.7655\n",
      "Epoch: 2, Step: 2780/2949, Loss: 0.8198\n",
      "Epoch: 2, Step: 2781/2949, Loss: 0.8080\n",
      "Epoch: 2, Step: 2782/2949, Loss: 0.8242\n",
      "Epoch: 2, Step: 2783/2949, Loss: 0.8229\n",
      "Epoch: 2, Step: 2784/2949, Loss: 0.7907\n",
      "Epoch: 2, Step: 2785/2949, Loss: 0.7620\n",
      "Epoch: 2, Step: 2786/2949, Loss: 0.7641\n",
      "Epoch: 2, Step: 2787/2949, Loss: 0.7834\n",
      "Epoch: 2, Step: 2788/2949, Loss: 0.8041\n",
      "Epoch: 2, Step: 2789/2949, Loss: 0.8000\n",
      "Epoch: 2, Step: 2790/2949, Loss: 0.7749\n",
      "Epoch: 2, Step: 2791/2949, Loss: 0.7975\n",
      "Epoch: 2, Step: 2792/2949, Loss: 0.8202\n",
      "Epoch: 2, Step: 2793/2949, Loss: 0.7890\n",
      "Epoch: 2, Step: 2794/2949, Loss: 0.7981\n",
      "Epoch: 2, Step: 2795/2949, Loss: 0.7888\n",
      "Epoch: 2, Step: 2796/2949, Loss: 0.7900\n",
      "Epoch: 2, Step: 2797/2949, Loss: 0.7932\n",
      "Epoch: 2, Step: 2798/2949, Loss: 0.7813\n",
      "Epoch: 2, Step: 2799/2949, Loss: 0.7704\n",
      "Epoch: 2, Step: 2800/2949, Loss: 0.7963\n",
      "Epoch: 2, Step: 2801/2949, Loss: 0.7983\n",
      "Epoch: 2, Step: 2802/2949, Loss: 0.7597\n",
      "Epoch: 2, Step: 2803/2949, Loss: 0.7611\n",
      "Epoch: 2, Step: 2804/2949, Loss: 0.7924\n",
      "Epoch: 2, Step: 2805/2949, Loss: 0.7946\n",
      "Epoch: 2, Step: 2806/2949, Loss: 0.8299\n",
      "Epoch: 2, Step: 2807/2949, Loss: 0.7814\n",
      "Epoch: 2, Step: 2808/2949, Loss: 0.7520\n",
      "Epoch: 2, Step: 2809/2949, Loss: 0.7737\n",
      "Epoch: 2, Step: 2810/2949, Loss: 0.8055\n",
      "Epoch: 2, Step: 2811/2949, Loss: 0.7775\n",
      "Epoch: 2, Step: 2812/2949, Loss: 0.8063\n",
      "Epoch: 2, Step: 2813/2949, Loss: 0.7898\n",
      "Epoch: 2, Step: 2814/2949, Loss: 0.8057\n",
      "Epoch: 2, Step: 2815/2949, Loss: 0.8155\n",
      "Epoch: 2, Step: 2816/2949, Loss: 0.8141\n",
      "Epoch: 2, Step: 2817/2949, Loss: 0.7822\n",
      "Epoch: 2, Step: 2818/2949, Loss: 0.7920\n",
      "Epoch: 2, Step: 2819/2949, Loss: 0.7743\n",
      "Epoch: 2, Step: 2820/2949, Loss: 0.8244\n",
      "Epoch: 2, Step: 2821/2949, Loss: 0.7951\n",
      "Epoch: 2, Step: 2822/2949, Loss: 0.7758\n",
      "Epoch: 2, Step: 2823/2949, Loss: 0.7188\n",
      "Epoch: 2, Step: 2824/2949, Loss: 0.7817\n",
      "Epoch: 2, Step: 2825/2949, Loss: 0.7604\n",
      "Epoch: 2, Step: 2826/2949, Loss: 0.7737\n",
      "Epoch: 2, Step: 2827/2949, Loss: 0.7738\n",
      "Epoch: 2, Step: 2828/2949, Loss: 0.8233\n",
      "Epoch: 2, Step: 2829/2949, Loss: 0.7842\n",
      "Epoch: 2, Step: 2830/2949, Loss: 0.7771\n",
      "Epoch: 2, Step: 2831/2949, Loss: 0.8434\n",
      "Epoch: 2, Step: 2832/2949, Loss: 0.7578\n",
      "Epoch: 2, Step: 2833/2949, Loss: 0.7727\n",
      "Epoch: 2, Step: 2834/2949, Loss: 0.8175\n",
      "Epoch: 2, Step: 2835/2949, Loss: 0.7454\n",
      "Epoch: 2, Step: 2836/2949, Loss: 0.8138\n",
      "Epoch: 2, Step: 2837/2949, Loss: 0.7872\n",
      "Epoch: 2, Step: 2838/2949, Loss: 0.8139\n",
      "Epoch: 2, Step: 2839/2949, Loss: 0.7876\n",
      "Epoch: 2, Step: 2840/2949, Loss: 0.7840\n",
      "Epoch: 2, Step: 2841/2949, Loss: 0.7806\n",
      "Epoch: 2, Step: 2842/2949, Loss: 0.7895\n",
      "Epoch: 2, Step: 2843/2949, Loss: 0.8025\n",
      "Epoch: 2, Step: 2844/2949, Loss: 0.8391\n",
      "Epoch: 2, Step: 2845/2949, Loss: 0.7637\n",
      "Epoch: 2, Step: 2846/2949, Loss: 0.8212\n",
      "Epoch: 2, Step: 2847/2949, Loss: 0.8010\n",
      "Epoch: 2, Step: 2848/2949, Loss: 0.7914\n",
      "Epoch: 2, Step: 2849/2949, Loss: 0.7583\n",
      "Epoch: 2, Step: 2850/2949, Loss: 0.7953\n",
      "Epoch: 2, Step: 2851/2949, Loss: 0.8033\n",
      "Epoch: 2, Step: 2852/2949, Loss: 0.8080\n",
      "Epoch: 2, Step: 2853/2949, Loss: 0.7969\n",
      "Epoch: 2, Step: 2854/2949, Loss: 0.8349\n",
      "Epoch: 2, Step: 2855/2949, Loss: 0.7718\n",
      "Epoch: 2, Step: 2856/2949, Loss: 0.8005\n",
      "Epoch: 2, Step: 2857/2949, Loss: 0.7688\n",
      "Epoch: 2, Step: 2858/2949, Loss: 0.7925\n",
      "Epoch: 2, Step: 2859/2949, Loss: 0.7760\n",
      "Epoch: 2, Step: 2860/2949, Loss: 0.7582\n",
      "Epoch: 2, Step: 2861/2949, Loss: 0.8177\n",
      "Epoch: 2, Step: 2862/2949, Loss: 0.8170\n",
      "Epoch: 2, Step: 2863/2949, Loss: 0.7455\n",
      "Epoch: 2, Step: 2864/2949, Loss: 0.8001\n",
      "Epoch: 2, Step: 2865/2949, Loss: 0.7765\n",
      "Epoch: 2, Step: 2866/2949, Loss: 0.7612\n",
      "Epoch: 2, Step: 2867/2949, Loss: 0.7577\n",
      "Epoch: 2, Step: 2868/2949, Loss: 0.8395\n",
      "Epoch: 2, Step: 2869/2949, Loss: 0.8375\n",
      "Epoch: 2, Step: 2870/2949, Loss: 0.7825\n",
      "Epoch: 2, Step: 2871/2949, Loss: 0.7322\n",
      "Epoch: 2, Step: 2872/2949, Loss: 0.7629\n",
      "Epoch: 2, Step: 2873/2949, Loss: 0.8052\n",
      "Epoch: 2, Step: 2874/2949, Loss: 0.8138\n",
      "Epoch: 2, Step: 2875/2949, Loss: 0.7620\n",
      "Epoch: 2, Step: 2876/2949, Loss: 0.7534\n",
      "Epoch: 2, Step: 2877/2949, Loss: 0.7901\n",
      "Epoch: 2, Step: 2878/2949, Loss: 0.8085\n",
      "Epoch: 2, Step: 2879/2949, Loss: 0.7663\n",
      "Epoch: 2, Step: 2880/2949, Loss: 0.7391\n",
      "Epoch: 2, Step: 2881/2949, Loss: 0.8145\n",
      "Epoch: 2, Step: 2882/2949, Loss: 0.7559\n",
      "Epoch: 2, Step: 2883/2949, Loss: 0.7795\n",
      "Epoch: 2, Step: 2884/2949, Loss: 0.8085\n",
      "Epoch: 2, Step: 2885/2949, Loss: 0.8141\n",
      "Epoch: 2, Step: 2886/2949, Loss: 0.7616\n",
      "Epoch: 2, Step: 2887/2949, Loss: 0.7464\n",
      "Epoch: 2, Step: 2888/2949, Loss: 0.8468\n",
      "Epoch: 2, Step: 2889/2949, Loss: 0.7395\n",
      "Epoch: 2, Step: 2890/2949, Loss: 0.7814\n",
      "Epoch: 2, Step: 2891/2949, Loss: 0.7389\n",
      "Epoch: 2, Step: 2892/2949, Loss: 0.8042\n",
      "Epoch: 2, Step: 2893/2949, Loss: 0.7893\n",
      "Epoch: 2, Step: 2894/2949, Loss: 0.7726\n",
      "Epoch: 2, Step: 2895/2949, Loss: 0.7227\n",
      "Epoch: 2, Step: 2896/2949, Loss: 0.7925\n",
      "Epoch: 2, Step: 2897/2949, Loss: 0.7916\n",
      "Epoch: 2, Step: 2898/2949, Loss: 0.8115\n",
      "Epoch: 2, Step: 2899/2949, Loss: 0.7386\n",
      "Epoch: 2, Step: 2900/2949, Loss: 0.8175\n",
      "Epoch: 2, Step: 2901/2949, Loss: 0.7546\n",
      "Epoch: 2, Step: 2902/2949, Loss: 0.7236\n",
      "Epoch: 2, Step: 2903/2949, Loss: 0.8062\n",
      "Epoch: 2, Step: 2904/2949, Loss: 0.7984\n",
      "Epoch: 2, Step: 2905/2949, Loss: 0.7862\n",
      "Epoch: 2, Step: 2906/2949, Loss: 0.7924\n",
      "Epoch: 2, Step: 2907/2949, Loss: 0.7852\n",
      "Epoch: 2, Step: 2908/2949, Loss: 0.7810\n",
      "Epoch: 2, Step: 2909/2949, Loss: 0.8098\n",
      "Epoch: 2, Step: 2910/2949, Loss: 0.7821\n",
      "Epoch: 2, Step: 2911/2949, Loss: 0.7832\n",
      "Epoch: 2, Step: 2912/2949, Loss: 0.7768\n",
      "Epoch: 2, Step: 2913/2949, Loss: 0.8280\n",
      "Epoch: 2, Step: 2914/2949, Loss: 0.7551\n",
      "Epoch: 2, Step: 2915/2949, Loss: 0.7498\n",
      "Epoch: 2, Step: 2916/2949, Loss: 0.7863\n",
      "Epoch: 2, Step: 2917/2949, Loss: 0.7258\n",
      "Epoch: 2, Step: 2918/2949, Loss: 0.8006\n",
      "Epoch: 2, Step: 2919/2949, Loss: 0.7763\n",
      "Epoch: 2, Step: 2920/2949, Loss: 0.7614\n",
      "Epoch: 2, Step: 2921/2949, Loss: 0.7406\n",
      "Epoch: 2, Step: 2922/2949, Loss: 0.7781\n",
      "Epoch: 2, Step: 2923/2949, Loss: 0.7799\n",
      "Epoch: 2, Step: 2924/2949, Loss: 0.7874\n",
      "Epoch: 2, Step: 2925/2949, Loss: 0.7929\n",
      "Epoch: 2, Step: 2926/2949, Loss: 0.7905\n",
      "Epoch: 2, Step: 2927/2949, Loss: 0.7947\n",
      "Epoch: 2, Step: 2928/2949, Loss: 0.7596\n",
      "Epoch: 2, Step: 2929/2949, Loss: 0.8260\n",
      "Epoch: 2, Step: 2930/2949, Loss: 0.7952\n",
      "Epoch: 2, Step: 2931/2949, Loss: 0.8242\n",
      "Epoch: 2, Step: 2932/2949, Loss: 0.7739\n",
      "Epoch: 2, Step: 2933/2949, Loss: 0.8015\n",
      "Epoch: 2, Step: 2934/2949, Loss: 0.8301\n",
      "Epoch: 2, Step: 2935/2949, Loss: 0.7626\n",
      "Epoch: 2, Step: 2936/2949, Loss: 0.7560\n",
      "Epoch: 2, Step: 2937/2949, Loss: 0.8333\n",
      "Epoch: 2, Step: 2938/2949, Loss: 0.7976\n",
      "Epoch: 2, Step: 2939/2949, Loss: 0.7762\n",
      "Epoch: 2, Step: 2940/2949, Loss: 0.7806\n",
      "Epoch: 2, Step: 2941/2949, Loss: 0.7986\n",
      "Epoch: 2, Step: 2942/2949, Loss: 0.8090\n",
      "Epoch: 2, Step: 2943/2949, Loss: 0.8309\n",
      "Epoch: 2, Step: 2944/2949, Loss: 0.7195\n",
      "Epoch: 2, Step: 2945/2949, Loss: 0.8540\n",
      "Epoch: 2, Step: 2946/2949, Loss: 0.7996\n",
      "Epoch: 2, Step: 2947/2949, Loss: 0.8599\n",
      "Epoch: 2, Step: 2948/2949, Loss: 0.7739\n",
      "Epoch: 2, Step: 2949/2949, Loss: 0.8419\n",
      "Test Accuracy (xgboost): 0.3691\n",
      "Epoch: 2, Accuracy: 0.3691\n",
      "Epoch: 3, Step: 001/2949, Loss: 0.7762\n",
      "Epoch: 3, Step: 002/2949, Loss: 0.7527\n",
      "Epoch: 3, Step: 003/2949, Loss: 0.7736\n",
      "Epoch: 3, Step: 004/2949, Loss: 0.7709\n",
      "Epoch: 3, Step: 005/2949, Loss: 0.8001\n",
      "Epoch: 3, Step: 006/2949, Loss: 0.7857\n",
      "Epoch: 3, Step: 007/2949, Loss: 0.7893\n",
      "Epoch: 3, Step: 008/2949, Loss: 0.7457\n",
      "Epoch: 3, Step: 009/2949, Loss: 0.8444\n",
      "Epoch: 3, Step: 010/2949, Loss: 0.7984\n",
      "Epoch: 3, Step: 011/2949, Loss: 0.7757\n",
      "Epoch: 3, Step: 012/2949, Loss: 0.7466\n",
      "Epoch: 3, Step: 013/2949, Loss: 0.7770\n",
      "Epoch: 3, Step: 014/2949, Loss: 0.7995\n",
      "Epoch: 3, Step: 015/2949, Loss: 0.7800\n",
      "Epoch: 3, Step: 016/2949, Loss: 0.7641\n",
      "Epoch: 3, Step: 017/2949, Loss: 0.7520\n",
      "Epoch: 3, Step: 018/2949, Loss: 0.7789\n",
      "Epoch: 3, Step: 019/2949, Loss: 0.7565\n",
      "Epoch: 3, Step: 020/2949, Loss: 0.8069\n",
      "Epoch: 3, Step: 021/2949, Loss: 0.7848\n",
      "Epoch: 3, Step: 022/2949, Loss: 0.8072\n",
      "Epoch: 3, Step: 023/2949, Loss: 0.7695\n",
      "Epoch: 3, Step: 024/2949, Loss: 0.7638\n",
      "Epoch: 3, Step: 025/2949, Loss: 0.8015\n",
      "Epoch: 3, Step: 026/2949, Loss: 0.7803\n",
      "Epoch: 3, Step: 027/2949, Loss: 0.7922\n",
      "Epoch: 3, Step: 028/2949, Loss: 0.7827\n",
      "Epoch: 3, Step: 029/2949, Loss: 0.8185\n",
      "Epoch: 3, Step: 030/2949, Loss: 0.7240\n",
      "Epoch: 3, Step: 031/2949, Loss: 0.7586\n",
      "Epoch: 3, Step: 032/2949, Loss: 0.7637\n",
      "Epoch: 3, Step: 033/2949, Loss: 0.7530\n",
      "Epoch: 3, Step: 034/2949, Loss: 0.7717\n",
      "Epoch: 3, Step: 035/2949, Loss: 0.7846\n",
      "Epoch: 3, Step: 036/2949, Loss: 0.7943\n",
      "Epoch: 3, Step: 037/2949, Loss: 0.8586\n",
      "Epoch: 3, Step: 038/2949, Loss: 0.7620\n",
      "Epoch: 3, Step: 039/2949, Loss: 0.7572\n",
      "Epoch: 3, Step: 040/2949, Loss: 0.8047\n",
      "Epoch: 3, Step: 041/2949, Loss: 0.7882\n",
      "Epoch: 3, Step: 042/2949, Loss: 0.7231\n",
      "Epoch: 3, Step: 043/2949, Loss: 0.8013\n",
      "Epoch: 3, Step: 044/2949, Loss: 0.7720\n",
      "Epoch: 3, Step: 045/2949, Loss: 0.8337\n",
      "Epoch: 3, Step: 046/2949, Loss: 0.7490\n",
      "Epoch: 3, Step: 047/2949, Loss: 0.7760\n",
      "Epoch: 3, Step: 048/2949, Loss: 0.8207\n",
      "Epoch: 3, Step: 049/2949, Loss: 0.8175\n",
      "Epoch: 3, Step: 050/2949, Loss: 0.7689\n",
      "Epoch: 3, Step: 051/2949, Loss: 0.7911\n",
      "Epoch: 3, Step: 052/2949, Loss: 0.8035\n",
      "Epoch: 3, Step: 053/2949, Loss: 0.7682\n",
      "Epoch: 3, Step: 054/2949, Loss: 0.7861\n",
      "Epoch: 3, Step: 055/2949, Loss: 0.8064\n",
      "Epoch: 3, Step: 056/2949, Loss: 0.7644\n",
      "Epoch: 3, Step: 057/2949, Loss: 0.8082\n",
      "Epoch: 3, Step: 058/2949, Loss: 0.7196\n",
      "Epoch: 3, Step: 059/2949, Loss: 0.7574\n",
      "Epoch: 3, Step: 060/2949, Loss: 0.7974\n",
      "Epoch: 3, Step: 061/2949, Loss: 0.6992\n",
      "Epoch: 3, Step: 062/2949, Loss: 0.7037\n",
      "Epoch: 3, Step: 063/2949, Loss: 0.8014\n",
      "Epoch: 3, Step: 064/2949, Loss: 0.7817\n",
      "Epoch: 3, Step: 065/2949, Loss: 0.7947\n",
      "Epoch: 3, Step: 066/2949, Loss: 0.7743\n",
      "Epoch: 3, Step: 067/2949, Loss: 0.8020\n",
      "Epoch: 3, Step: 068/2949, Loss: 0.7917\n",
      "Epoch: 3, Step: 069/2949, Loss: 0.7823\n",
      "Epoch: 3, Step: 070/2949, Loss: 0.7677\n",
      "Epoch: 3, Step: 071/2949, Loss: 0.7969\n",
      "Epoch: 3, Step: 072/2949, Loss: 0.7883\n",
      "Epoch: 3, Step: 073/2949, Loss: 0.8019\n",
      "Epoch: 3, Step: 074/2949, Loss: 0.7665\n",
      "Epoch: 3, Step: 075/2949, Loss: 0.7528\n",
      "Epoch: 3, Step: 076/2949, Loss: 0.7719\n",
      "Epoch: 3, Step: 077/2949, Loss: 0.8334\n",
      "Epoch: 3, Step: 078/2949, Loss: 0.7874\n",
      "Epoch: 3, Step: 079/2949, Loss: 0.7885\n",
      "Epoch: 3, Step: 080/2949, Loss: 0.8181\n",
      "Epoch: 3, Step: 081/2949, Loss: 0.7783\n",
      "Epoch: 3, Step: 082/2949, Loss: 0.7653\n",
      "Epoch: 3, Step: 083/2949, Loss: 0.7772\n",
      "Epoch: 3, Step: 084/2949, Loss: 0.7943\n",
      "Epoch: 3, Step: 085/2949, Loss: 0.7739\n",
      "Epoch: 3, Step: 086/2949, Loss: 0.7519\n",
      "Epoch: 3, Step: 087/2949, Loss: 0.8196\n",
      "Epoch: 3, Step: 088/2949, Loss: 0.7975\n",
      "Epoch: 3, Step: 089/2949, Loss: 0.7426\n",
      "Epoch: 3, Step: 090/2949, Loss: 0.8036\n",
      "Epoch: 3, Step: 091/2949, Loss: 0.7537\n",
      "Epoch: 3, Step: 092/2949, Loss: 0.8191\n",
      "Epoch: 3, Step: 093/2949, Loss: 0.7968\n",
      "Epoch: 3, Step: 094/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 095/2949, Loss: 0.7709\n",
      "Epoch: 3, Step: 096/2949, Loss: 0.7687\n",
      "Epoch: 3, Step: 097/2949, Loss: 0.8059\n",
      "Epoch: 3, Step: 098/2949, Loss: 0.8380\n",
      "Epoch: 3, Step: 099/2949, Loss: 0.7789\n",
      "Epoch: 3, Step: 100/2949, Loss: 0.7990\n",
      "Epoch: 3, Step: 101/2949, Loss: 0.7264\n",
      "Epoch: 3, Step: 102/2949, Loss: 0.8068\n",
      "Epoch: 3, Step: 103/2949, Loss: 0.8107\n",
      "Epoch: 3, Step: 104/2949, Loss: 0.7603\n",
      "Epoch: 3, Step: 105/2949, Loss: 0.7716\n",
      "Epoch: 3, Step: 106/2949, Loss: 0.7460\n",
      "Epoch: 3, Step: 107/2949, Loss: 0.7860\n",
      "Epoch: 3, Step: 108/2949, Loss: 0.7792\n",
      "Epoch: 3, Step: 109/2949, Loss: 0.7888\n",
      "Epoch: 3, Step: 110/2949, Loss: 0.7537\n",
      "Epoch: 3, Step: 111/2949, Loss: 0.7800\n",
      "Epoch: 3, Step: 112/2949, Loss: 0.7719\n",
      "Epoch: 3, Step: 113/2949, Loss: 0.8432\n",
      "Epoch: 3, Step: 114/2949, Loss: 0.7641\n",
      "Epoch: 3, Step: 115/2949, Loss: 0.8274\n",
      "Epoch: 3, Step: 116/2949, Loss: 0.7831\n",
      "Epoch: 3, Step: 117/2949, Loss: 0.7499\n",
      "Epoch: 3, Step: 118/2949, Loss: 0.7559\n",
      "Epoch: 3, Step: 119/2949, Loss: 0.8056\n",
      "Epoch: 3, Step: 120/2949, Loss: 0.7903\n",
      "Epoch: 3, Step: 121/2949, Loss: 0.8494\n",
      "Epoch: 3, Step: 122/2949, Loss: 0.7428\n",
      "Epoch: 3, Step: 123/2949, Loss: 0.8395\n",
      "Epoch: 3, Step: 124/2949, Loss: 0.7765\n",
      "Epoch: 3, Step: 125/2949, Loss: 0.7857\n",
      "Epoch: 3, Step: 126/2949, Loss: 0.7426\n",
      "Epoch: 3, Step: 127/2949, Loss: 0.7536\n",
      "Epoch: 3, Step: 128/2949, Loss: 0.7360\n",
      "Epoch: 3, Step: 129/2949, Loss: 0.7790\n",
      "Epoch: 3, Step: 130/2949, Loss: 0.7559\n",
      "Epoch: 3, Step: 131/2949, Loss: 0.8600\n",
      "Epoch: 3, Step: 132/2949, Loss: 0.7634\n",
      "Epoch: 3, Step: 133/2949, Loss: 0.7330\n",
      "Epoch: 3, Step: 134/2949, Loss: 0.8578\n",
      "Epoch: 3, Step: 135/2949, Loss: 0.7971\n",
      "Epoch: 3, Step: 136/2949, Loss: 0.7698\n",
      "Epoch: 3, Step: 137/2949, Loss: 0.7632\n",
      "Epoch: 3, Step: 138/2949, Loss: 0.8389\n",
      "Epoch: 3, Step: 139/2949, Loss: 0.7878\n",
      "Epoch: 3, Step: 140/2949, Loss: 0.8102\n",
      "Epoch: 3, Step: 141/2949, Loss: 0.7552\n",
      "Epoch: 3, Step: 142/2949, Loss: 0.8022\n",
      "Epoch: 3, Step: 143/2949, Loss: 0.6845\n",
      "Epoch: 3, Step: 144/2949, Loss: 0.7765\n",
      "Epoch: 3, Step: 145/2949, Loss: 0.7564\n",
      "Epoch: 3, Step: 146/2949, Loss: 0.7786\n",
      "Epoch: 3, Step: 147/2949, Loss: 0.8806\n",
      "Epoch: 3, Step: 148/2949, Loss: 0.7363\n",
      "Epoch: 3, Step: 149/2949, Loss: 0.8169\n",
      "Epoch: 3, Step: 150/2949, Loss: 0.8016\n",
      "Epoch: 3, Step: 151/2949, Loss: 0.7405\n",
      "Epoch: 3, Step: 152/2949, Loss: 0.7647\n",
      "Epoch: 3, Step: 153/2949, Loss: 0.7811\n",
      "Epoch: 3, Step: 154/2949, Loss: 0.7939\n",
      "Epoch: 3, Step: 155/2949, Loss: 0.7951\n",
      "Epoch: 3, Step: 156/2949, Loss: 0.7816\n",
      "Epoch: 3, Step: 157/2949, Loss: 0.7463\n",
      "Epoch: 3, Step: 158/2949, Loss: 0.7728\n",
      "Epoch: 3, Step: 159/2949, Loss: 0.7846\n",
      "Epoch: 3, Step: 160/2949, Loss: 0.7809\n",
      "Epoch: 3, Step: 161/2949, Loss: 0.7328\n",
      "Epoch: 3, Step: 162/2949, Loss: 0.7464\n",
      "Epoch: 3, Step: 163/2949, Loss: 0.7872\n",
      "Epoch: 3, Step: 164/2949, Loss: 0.8032\n",
      "Epoch: 3, Step: 165/2949, Loss: 0.7900\n",
      "Epoch: 3, Step: 166/2949, Loss: 0.7929\n",
      "Epoch: 3, Step: 167/2949, Loss: 0.7542\n",
      "Epoch: 3, Step: 168/2949, Loss: 0.8086\n",
      "Epoch: 3, Step: 169/2949, Loss: 0.7767\n",
      "Epoch: 3, Step: 170/2949, Loss: 0.7993\n",
      "Epoch: 3, Step: 171/2949, Loss: 0.8060\n",
      "Epoch: 3, Step: 172/2949, Loss: 0.8080\n",
      "Epoch: 3, Step: 173/2949, Loss: 0.7928\n",
      "Epoch: 3, Step: 174/2949, Loss: 0.8301\n",
      "Epoch: 3, Step: 175/2949, Loss: 0.8030\n",
      "Epoch: 3, Step: 176/2949, Loss: 0.8040\n",
      "Epoch: 3, Step: 177/2949, Loss: 0.7676\n",
      "Epoch: 3, Step: 178/2949, Loss: 0.8521\n",
      "Epoch: 3, Step: 179/2949, Loss: 0.7465\n",
      "Epoch: 3, Step: 180/2949, Loss: 0.8020\n",
      "Epoch: 3, Step: 181/2949, Loss: 0.8327\n",
      "Epoch: 3, Step: 182/2949, Loss: 0.8008\n",
      "Epoch: 3, Step: 183/2949, Loss: 0.7688\n",
      "Epoch: 3, Step: 184/2949, Loss: 0.7474\n",
      "Epoch: 3, Step: 185/2949, Loss: 0.7809\n",
      "Epoch: 3, Step: 186/2949, Loss: 0.7968\n",
      "Epoch: 3, Step: 187/2949, Loss: 0.7841\n",
      "Epoch: 3, Step: 188/2949, Loss: 0.7721\n",
      "Epoch: 3, Step: 189/2949, Loss: 0.8152\n",
      "Epoch: 3, Step: 190/2949, Loss: 0.7364\n",
      "Epoch: 3, Step: 191/2949, Loss: 0.7965\n",
      "Epoch: 3, Step: 192/2949, Loss: 0.7668\n",
      "Epoch: 3, Step: 193/2949, Loss: 0.7859\n",
      "Epoch: 3, Step: 194/2949, Loss: 0.7437\n",
      "Epoch: 3, Step: 195/2949, Loss: 0.7528\n",
      "Epoch: 3, Step: 196/2949, Loss: 0.8220\n",
      "Epoch: 3, Step: 197/2949, Loss: 0.7928\n",
      "Epoch: 3, Step: 198/2949, Loss: 0.7634\n",
      "Epoch: 3, Step: 199/2949, Loss: 0.7325\n",
      "Epoch: 3, Step: 200/2949, Loss: 0.7997\n",
      "Epoch: 3, Step: 201/2949, Loss: 0.7776\n",
      "Epoch: 3, Step: 202/2949, Loss: 0.7953\n",
      "Epoch: 3, Step: 203/2949, Loss: 0.7747\n",
      "Epoch: 3, Step: 204/2949, Loss: 0.7121\n",
      "Epoch: 3, Step: 205/2949, Loss: 0.8003\n",
      "Epoch: 3, Step: 206/2949, Loss: 0.7964\n",
      "Epoch: 3, Step: 207/2949, Loss: 0.7698\n",
      "Epoch: 3, Step: 208/2949, Loss: 0.8241\n",
      "Epoch: 3, Step: 209/2949, Loss: 0.8011\n",
      "Epoch: 3, Step: 210/2949, Loss: 0.7882\n",
      "Epoch: 3, Step: 211/2949, Loss: 0.8173\n",
      "Epoch: 3, Step: 212/2949, Loss: 0.7564\n",
      "Epoch: 3, Step: 213/2949, Loss: 0.7636\n",
      "Epoch: 3, Step: 214/2949, Loss: 0.7941\n",
      "Epoch: 3, Step: 215/2949, Loss: 0.8118\n",
      "Epoch: 3, Step: 216/2949, Loss: 0.7361\n",
      "Epoch: 3, Step: 217/2949, Loss: 0.7421\n",
      "Epoch: 3, Step: 218/2949, Loss: 0.7544\n",
      "Epoch: 3, Step: 219/2949, Loss: 0.7886\n",
      "Epoch: 3, Step: 220/2949, Loss: 0.8118\n",
      "Epoch: 3, Step: 221/2949, Loss: 0.7956\n",
      "Epoch: 3, Step: 222/2949, Loss: 0.7547\n",
      "Epoch: 3, Step: 223/2949, Loss: 0.7458\n",
      "Epoch: 3, Step: 224/2949, Loss: 0.7164\n",
      "Epoch: 3, Step: 225/2949, Loss: 0.8126\n",
      "Epoch: 3, Step: 226/2949, Loss: 0.7815\n",
      "Epoch: 3, Step: 227/2949, Loss: 0.7523\n",
      "Epoch: 3, Step: 228/2949, Loss: 0.7779\n",
      "Epoch: 3, Step: 229/2949, Loss: 0.7758\n",
      "Epoch: 3, Step: 230/2949, Loss: 0.7807\n",
      "Epoch: 3, Step: 231/2949, Loss: 0.7603\n",
      "Epoch: 3, Step: 232/2949, Loss: 0.7817\n",
      "Epoch: 3, Step: 233/2949, Loss: 0.7982\n",
      "Epoch: 3, Step: 234/2949, Loss: 0.7820\n",
      "Epoch: 3, Step: 235/2949, Loss: 0.8023\n",
      "Epoch: 3, Step: 236/2949, Loss: 0.7492\n",
      "Epoch: 3, Step: 237/2949, Loss: 0.7878\n",
      "Epoch: 3, Step: 238/2949, Loss: 0.7868\n",
      "Epoch: 3, Step: 239/2949, Loss: 0.8302\n",
      "Epoch: 3, Step: 240/2949, Loss: 0.8251\n",
      "Epoch: 3, Step: 241/2949, Loss: 0.7583\n",
      "Epoch: 3, Step: 242/2949, Loss: 0.7685\n",
      "Epoch: 3, Step: 243/2949, Loss: 0.7698\n",
      "Epoch: 3, Step: 244/2949, Loss: 0.7695\n",
      "Epoch: 3, Step: 245/2949, Loss: 0.8074\n",
      "Epoch: 3, Step: 246/2949, Loss: 0.7426\n",
      "Epoch: 3, Step: 247/2949, Loss: 0.8672\n",
      "Epoch: 3, Step: 248/2949, Loss: 0.7740\n",
      "Epoch: 3, Step: 249/2949, Loss: 0.8118\n",
      "Epoch: 3, Step: 250/2949, Loss: 0.7923\n",
      "Epoch: 3, Step: 251/2949, Loss: 0.7621\n",
      "Epoch: 3, Step: 252/2949, Loss: 0.7571\n",
      "Epoch: 3, Step: 253/2949, Loss: 0.7703\n",
      "Epoch: 3, Step: 254/2949, Loss: 0.8110\n",
      "Epoch: 3, Step: 255/2949, Loss: 0.7311\n",
      "Epoch: 3, Step: 256/2949, Loss: 0.7471\n",
      "Epoch: 3, Step: 257/2949, Loss: 0.7572\n",
      "Epoch: 3, Step: 258/2949, Loss: 0.7331\n",
      "Epoch: 3, Step: 259/2949, Loss: 0.7846\n",
      "Epoch: 3, Step: 260/2949, Loss: 0.7817\n",
      "Epoch: 3, Step: 261/2949, Loss: 0.7818\n",
      "Epoch: 3, Step: 262/2949, Loss: 0.7489\n",
      "Epoch: 3, Step: 263/2949, Loss: 0.8157\n",
      "Epoch: 3, Step: 264/2949, Loss: 0.8100\n",
      "Epoch: 3, Step: 265/2949, Loss: 0.7721\n",
      "Epoch: 3, Step: 266/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 267/2949, Loss: 0.8325\n",
      "Epoch: 3, Step: 268/2949, Loss: 0.7654\n",
      "Epoch: 3, Step: 269/2949, Loss: 0.7409\n",
      "Epoch: 3, Step: 270/2949, Loss: 0.7836\n",
      "Epoch: 3, Step: 271/2949, Loss: 0.7636\n",
      "Epoch: 3, Step: 272/2949, Loss: 0.8252\n",
      "Epoch: 3, Step: 273/2949, Loss: 0.7863\n",
      "Epoch: 3, Step: 274/2949, Loss: 0.7597\n",
      "Epoch: 3, Step: 275/2949, Loss: 0.7802\n",
      "Epoch: 3, Step: 276/2949, Loss: 0.7601\n",
      "Epoch: 3, Step: 277/2949, Loss: 0.7885\n",
      "Epoch: 3, Step: 278/2949, Loss: 0.7553\n",
      "Epoch: 3, Step: 279/2949, Loss: 0.7584\n",
      "Epoch: 3, Step: 280/2949, Loss: 0.7105\n",
      "Epoch: 3, Step: 281/2949, Loss: 0.7283\n",
      "Epoch: 3, Step: 282/2949, Loss: 0.7925\n",
      "Epoch: 3, Step: 283/2949, Loss: 0.8009\n",
      "Epoch: 3, Step: 284/2949, Loss: 0.7687\n",
      "Epoch: 3, Step: 285/2949, Loss: 0.7827\n",
      "Epoch: 3, Step: 286/2949, Loss: 0.7472\n",
      "Epoch: 3, Step: 287/2949, Loss: 0.7488\n",
      "Epoch: 3, Step: 288/2949, Loss: 0.7909\n",
      "Epoch: 3, Step: 289/2949, Loss: 0.7782\n",
      "Epoch: 3, Step: 290/2949, Loss: 0.7880\n",
      "Epoch: 3, Step: 291/2949, Loss: 0.7696\n",
      "Epoch: 3, Step: 292/2949, Loss: 0.7432\n",
      "Epoch: 3, Step: 293/2949, Loss: 0.7695\n",
      "Epoch: 3, Step: 294/2949, Loss: 0.7436\n",
      "Epoch: 3, Step: 295/2949, Loss: 0.8184\n",
      "Epoch: 3, Step: 296/2949, Loss: 0.7879\n",
      "Epoch: 3, Step: 297/2949, Loss: 0.7641\n",
      "Epoch: 3, Step: 298/2949, Loss: 0.8039\n",
      "Epoch: 3, Step: 299/2949, Loss: 0.7375\n",
      "Epoch: 3, Step: 300/2949, Loss: 0.7562\n",
      "Epoch: 3, Step: 301/2949, Loss: 0.7732\n",
      "Epoch: 3, Step: 302/2949, Loss: 0.8020\n",
      "Epoch: 3, Step: 303/2949, Loss: 0.7883\n",
      "Epoch: 3, Step: 304/2949, Loss: 0.7834\n",
      "Epoch: 3, Step: 305/2949, Loss: 0.7767\n",
      "Epoch: 3, Step: 306/2949, Loss: 0.7719\n",
      "Epoch: 3, Step: 307/2949, Loss: 0.7711\n",
      "Epoch: 3, Step: 308/2949, Loss: 0.7763\n",
      "Epoch: 3, Step: 309/2949, Loss: 0.7746\n",
      "Epoch: 3, Step: 310/2949, Loss: 0.7995\n",
      "Epoch: 3, Step: 311/2949, Loss: 0.8241\n",
      "Epoch: 3, Step: 312/2949, Loss: 0.7639\n",
      "Epoch: 3, Step: 313/2949, Loss: 0.7588\n",
      "Epoch: 3, Step: 314/2949, Loss: 0.7723\n",
      "Epoch: 3, Step: 315/2949, Loss: 0.7902\n",
      "Epoch: 3, Step: 316/2949, Loss: 0.7628\n",
      "Epoch: 3, Step: 317/2949, Loss: 0.7962\n",
      "Epoch: 3, Step: 318/2949, Loss: 0.7985\n",
      "Epoch: 3, Step: 319/2949, Loss: 0.8010\n",
      "Epoch: 3, Step: 320/2949, Loss: 0.7759\n",
      "Epoch: 3, Step: 321/2949, Loss: 0.7944\n",
      "Epoch: 3, Step: 322/2949, Loss: 0.7833\n",
      "Epoch: 3, Step: 323/2949, Loss: 0.7802\n",
      "Epoch: 3, Step: 324/2949, Loss: 0.7819\n",
      "Epoch: 3, Step: 325/2949, Loss: 0.8001\n",
      "Epoch: 3, Step: 326/2949, Loss: 0.7650\n",
      "Epoch: 3, Step: 327/2949, Loss: 0.7365\n",
      "Epoch: 3, Step: 328/2949, Loss: 0.7228\n",
      "Epoch: 3, Step: 329/2949, Loss: 0.7284\n",
      "Epoch: 3, Step: 330/2949, Loss: 0.8031\n",
      "Epoch: 3, Step: 331/2949, Loss: 0.7895\n",
      "Epoch: 3, Step: 332/2949, Loss: 0.7765\n",
      "Epoch: 3, Step: 333/2949, Loss: 0.7962\n",
      "Epoch: 3, Step: 334/2949, Loss: 0.7713\n",
      "Epoch: 3, Step: 335/2949, Loss: 0.7784\n",
      "Epoch: 3, Step: 336/2949, Loss: 0.7796\n",
      "Epoch: 3, Step: 337/2949, Loss: 0.7234\n",
      "Epoch: 3, Step: 338/2949, Loss: 0.8071\n",
      "Epoch: 3, Step: 339/2949, Loss: 0.8017\n",
      "Epoch: 3, Step: 340/2949, Loss: 0.8075\n",
      "Epoch: 3, Step: 341/2949, Loss: 0.8179\n",
      "Epoch: 3, Step: 342/2949, Loss: 0.7434\n",
      "Epoch: 3, Step: 343/2949, Loss: 0.7541\n",
      "Epoch: 3, Step: 344/2949, Loss: 0.7496\n",
      "Epoch: 3, Step: 345/2949, Loss: 0.7371\n",
      "Epoch: 3, Step: 346/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 347/2949, Loss: 0.7634\n",
      "Epoch: 3, Step: 348/2949, Loss: 0.8157\n",
      "Epoch: 3, Step: 349/2949, Loss: 0.7917\n",
      "Epoch: 3, Step: 350/2949, Loss: 0.7683\n",
      "Epoch: 3, Step: 351/2949, Loss: 0.7591\n",
      "Epoch: 3, Step: 352/2949, Loss: 0.7973\n",
      "Epoch: 3, Step: 353/2949, Loss: 0.8002\n",
      "Epoch: 3, Step: 354/2949, Loss: 0.7651\n",
      "Epoch: 3, Step: 355/2949, Loss: 0.8072\n",
      "Epoch: 3, Step: 356/2949, Loss: 0.7808\n",
      "Epoch: 3, Step: 357/2949, Loss: 0.7705\n",
      "Epoch: 3, Step: 358/2949, Loss: 0.7384\n",
      "Epoch: 3, Step: 359/2949, Loss: 0.7536\n",
      "Epoch: 3, Step: 360/2949, Loss: 0.7709\n",
      "Epoch: 3, Step: 361/2949, Loss: 0.8224\n",
      "Epoch: 3, Step: 362/2949, Loss: 0.8171\n",
      "Epoch: 3, Step: 363/2949, Loss: 0.7529\n",
      "Epoch: 3, Step: 364/2949, Loss: 0.8053\n",
      "Epoch: 3, Step: 365/2949, Loss: 0.7820\n",
      "Epoch: 3, Step: 366/2949, Loss: 0.7761\n",
      "Epoch: 3, Step: 367/2949, Loss: 0.7994\n",
      "Epoch: 3, Step: 368/2949, Loss: 0.7904\n",
      "Epoch: 3, Step: 369/2949, Loss: 0.8062\n",
      "Epoch: 3, Step: 370/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 371/2949, Loss: 0.7752\n",
      "Epoch: 3, Step: 372/2949, Loss: 0.8004\n",
      "Epoch: 3, Step: 373/2949, Loss: 0.8766\n",
      "Epoch: 3, Step: 374/2949, Loss: 0.7668\n",
      "Epoch: 3, Step: 375/2949, Loss: 0.7614\n",
      "Epoch: 3, Step: 376/2949, Loss: 0.8002\n",
      "Epoch: 3, Step: 377/2949, Loss: 0.7734\n",
      "Epoch: 3, Step: 378/2949, Loss: 0.8666\n",
      "Epoch: 3, Step: 379/2949, Loss: 0.7879\n",
      "Epoch: 3, Step: 380/2949, Loss: 0.7773\n",
      "Epoch: 3, Step: 381/2949, Loss: 0.7983\n",
      "Epoch: 3, Step: 382/2949, Loss: 0.8064\n",
      "Epoch: 3, Step: 383/2949, Loss: 0.8143\n",
      "Epoch: 3, Step: 384/2949, Loss: 0.8184\n",
      "Epoch: 3, Step: 385/2949, Loss: 0.8089\n",
      "Epoch: 3, Step: 386/2949, Loss: 0.8035\n",
      "Epoch: 3, Step: 387/2949, Loss: 0.7514\n",
      "Epoch: 3, Step: 388/2949, Loss: 0.8124\n",
      "Epoch: 3, Step: 389/2949, Loss: 0.7991\n",
      "Epoch: 3, Step: 390/2949, Loss: 0.7938\n",
      "Epoch: 3, Step: 391/2949, Loss: 0.7612\n",
      "Epoch: 3, Step: 392/2949, Loss: 0.7841\n",
      "Epoch: 3, Step: 393/2949, Loss: 0.8341\n",
      "Epoch: 3, Step: 394/2949, Loss: 0.7724\n",
      "Epoch: 3, Step: 395/2949, Loss: 0.8304\n",
      "Epoch: 3, Step: 396/2949, Loss: 0.8403\n",
      "Epoch: 3, Step: 397/2949, Loss: 0.7791\n",
      "Epoch: 3, Step: 398/2949, Loss: 0.8068\n",
      "Epoch: 3, Step: 399/2949, Loss: 0.8024\n",
      "Epoch: 3, Step: 400/2949, Loss: 0.7642\n",
      "Epoch: 3, Step: 401/2949, Loss: 0.8008\n",
      "Epoch: 3, Step: 402/2949, Loss: 0.7748\n",
      "Epoch: 3, Step: 403/2949, Loss: 0.7953\n",
      "Epoch: 3, Step: 404/2949, Loss: 0.7934\n",
      "Epoch: 3, Step: 405/2949, Loss: 0.7916\n",
      "Epoch: 3, Step: 406/2949, Loss: 0.7570\n",
      "Epoch: 3, Step: 407/2949, Loss: 0.7580\n",
      "Epoch: 3, Step: 408/2949, Loss: 0.8316\n",
      "Epoch: 3, Step: 409/2949, Loss: 0.7951\n",
      "Epoch: 3, Step: 410/2949, Loss: 0.8418\n",
      "Epoch: 3, Step: 411/2949, Loss: 0.8052\n",
      "Epoch: 3, Step: 412/2949, Loss: 0.7877\n",
      "Epoch: 3, Step: 413/2949, Loss: 0.7760\n",
      "Epoch: 3, Step: 414/2949, Loss: 0.8046\n",
      "Epoch: 3, Step: 415/2949, Loss: 0.7932\n",
      "Epoch: 3, Step: 416/2949, Loss: 0.8102\n",
      "Epoch: 3, Step: 417/2949, Loss: 0.7790\n",
      "Epoch: 3, Step: 418/2949, Loss: 0.7581\n",
      "Epoch: 3, Step: 419/2949, Loss: 0.7642\n",
      "Epoch: 3, Step: 420/2949, Loss: 0.7688\n",
      "Epoch: 3, Step: 421/2949, Loss: 0.7739\n",
      "Epoch: 3, Step: 422/2949, Loss: 0.7667\n",
      "Epoch: 3, Step: 423/2949, Loss: 0.7870\n",
      "Epoch: 3, Step: 424/2949, Loss: 0.7501\n",
      "Epoch: 3, Step: 425/2949, Loss: 0.7811\n",
      "Epoch: 3, Step: 426/2949, Loss: 0.7773\n",
      "Epoch: 3, Step: 427/2949, Loss: 0.7452\n",
      "Epoch: 3, Step: 428/2949, Loss: 0.7956\n",
      "Epoch: 3, Step: 429/2949, Loss: 0.7792\n",
      "Epoch: 3, Step: 430/2949, Loss: 0.7498\n",
      "Epoch: 3, Step: 431/2949, Loss: 0.8001\n",
      "Epoch: 3, Step: 432/2949, Loss: 0.8094\n",
      "Epoch: 3, Step: 433/2949, Loss: 0.7964\n",
      "Epoch: 3, Step: 434/2949, Loss: 0.7177\n",
      "Epoch: 3, Step: 435/2949, Loss: 0.7408\n",
      "Epoch: 3, Step: 436/2949, Loss: 0.7838\n",
      "Epoch: 3, Step: 437/2949, Loss: 0.8101\n",
      "Epoch: 3, Step: 438/2949, Loss: 0.8138\n",
      "Epoch: 3, Step: 439/2949, Loss: 0.8181\n",
      "Epoch: 3, Step: 440/2949, Loss: 0.8115\n",
      "Epoch: 3, Step: 441/2949, Loss: 0.8110\n",
      "Epoch: 3, Step: 442/2949, Loss: 0.7647\n",
      "Epoch: 3, Step: 443/2949, Loss: 0.7234\n",
      "Epoch: 3, Step: 444/2949, Loss: 0.7428\n",
      "Epoch: 3, Step: 445/2949, Loss: 0.7875\n",
      "Epoch: 3, Step: 446/2949, Loss: 0.7539\n",
      "Epoch: 3, Step: 447/2949, Loss: 0.7761\n",
      "Epoch: 3, Step: 448/2949, Loss: 0.8114\n",
      "Epoch: 3, Step: 449/2949, Loss: 0.7825\n",
      "Epoch: 3, Step: 450/2949, Loss: 0.8116\n",
      "Epoch: 3, Step: 451/2949, Loss: 0.7541\n",
      "Epoch: 3, Step: 452/2949, Loss: 0.7853\n",
      "Epoch: 3, Step: 453/2949, Loss: 0.7058\n",
      "Epoch: 3, Step: 454/2949, Loss: 0.7951\n",
      "Epoch: 3, Step: 455/2949, Loss: 0.7925\n",
      "Epoch: 3, Step: 456/2949, Loss: 0.8241\n",
      "Epoch: 3, Step: 457/2949, Loss: 0.7276\n",
      "Epoch: 3, Step: 458/2949, Loss: 0.7749\n",
      "Epoch: 3, Step: 459/2949, Loss: 0.7414\n",
      "Epoch: 3, Step: 460/2949, Loss: 0.7618\n",
      "Epoch: 3, Step: 461/2949, Loss: 0.7893\n",
      "Epoch: 3, Step: 462/2949, Loss: 0.7865\n",
      "Epoch: 3, Step: 463/2949, Loss: 0.7718\n",
      "Epoch: 3, Step: 464/2949, Loss: 0.7754\n",
      "Epoch: 3, Step: 465/2949, Loss: 0.7597\n",
      "Epoch: 3, Step: 466/2949, Loss: 0.8032\n",
      "Epoch: 3, Step: 467/2949, Loss: 0.7917\n",
      "Epoch: 3, Step: 468/2949, Loss: 0.7973\n",
      "Epoch: 3, Step: 469/2949, Loss: 0.8533\n",
      "Epoch: 3, Step: 470/2949, Loss: 0.7581\n",
      "Epoch: 3, Step: 471/2949, Loss: 0.7790\n",
      "Epoch: 3, Step: 472/2949, Loss: 0.7696\n",
      "Epoch: 3, Step: 473/2949, Loss: 0.7568\n",
      "Epoch: 3, Step: 474/2949, Loss: 0.7987\n",
      "Epoch: 3, Step: 475/2949, Loss: 0.7757\n",
      "Epoch: 3, Step: 476/2949, Loss: 0.7717\n",
      "Epoch: 3, Step: 477/2949, Loss: 0.7753\n",
      "Epoch: 3, Step: 478/2949, Loss: 0.7749\n",
      "Epoch: 3, Step: 479/2949, Loss: 0.7671\n",
      "Epoch: 3, Step: 480/2949, Loss: 0.7824\n",
      "Epoch: 3, Step: 481/2949, Loss: 0.6927\n",
      "Epoch: 3, Step: 482/2949, Loss: 0.8452\n",
      "Epoch: 3, Step: 483/2949, Loss: 0.7686\n",
      "Epoch: 3, Step: 484/2949, Loss: 0.7276\n",
      "Epoch: 3, Step: 485/2949, Loss: 0.7945\n",
      "Epoch: 3, Step: 486/2949, Loss: 0.8381\n",
      "Epoch: 3, Step: 487/2949, Loss: 0.8110\n",
      "Epoch: 3, Step: 488/2949, Loss: 0.7559\n",
      "Epoch: 3, Step: 489/2949, Loss: 0.7965\n",
      "Epoch: 3, Step: 490/2949, Loss: 0.7928\n",
      "Epoch: 3, Step: 491/2949, Loss: 0.7728\n",
      "Epoch: 3, Step: 492/2949, Loss: 0.7691\n",
      "Epoch: 3, Step: 493/2949, Loss: 0.7364\n",
      "Epoch: 3, Step: 494/2949, Loss: 0.8176\n",
      "Epoch: 3, Step: 495/2949, Loss: 0.8110\n",
      "Epoch: 3, Step: 496/2949, Loss: 0.7662\n",
      "Epoch: 3, Step: 497/2949, Loss: 0.7843\n",
      "Epoch: 3, Step: 498/2949, Loss: 0.7414\n",
      "Epoch: 3, Step: 499/2949, Loss: 0.7704\n",
      "Epoch: 3, Step: 500/2949, Loss: 0.7958\n",
      "Epoch: 3, Step: 501/2949, Loss: 0.7620\n",
      "Epoch: 3, Step: 502/2949, Loss: 0.7519\n",
      "Epoch: 3, Step: 503/2949, Loss: 0.7420\n",
      "Epoch: 3, Step: 504/2949, Loss: 0.7748\n",
      "Epoch: 3, Step: 505/2949, Loss: 0.8013\n",
      "Epoch: 3, Step: 506/2949, Loss: 0.7496\n",
      "Epoch: 3, Step: 507/2949, Loss: 0.7656\n",
      "Epoch: 3, Step: 508/2949, Loss: 0.7369\n",
      "Epoch: 3, Step: 509/2949, Loss: 0.7611\n",
      "Epoch: 3, Step: 510/2949, Loss: 0.7974\n",
      "Epoch: 3, Step: 511/2949, Loss: 0.7125\n",
      "Epoch: 3, Step: 512/2949, Loss: 0.7624\n",
      "Epoch: 3, Step: 513/2949, Loss: 0.7756\n",
      "Epoch: 3, Step: 514/2949, Loss: 0.7588\n",
      "Epoch: 3, Step: 515/2949, Loss: 0.7806\n",
      "Epoch: 3, Step: 516/2949, Loss: 0.7664\n",
      "Epoch: 3, Step: 517/2949, Loss: 0.7529\n",
      "Epoch: 3, Step: 518/2949, Loss: 0.7652\n",
      "Epoch: 3, Step: 519/2949, Loss: 0.7612\n",
      "Epoch: 3, Step: 520/2949, Loss: 0.7745\n",
      "Epoch: 3, Step: 521/2949, Loss: 0.7597\n",
      "Epoch: 3, Step: 522/2949, Loss: 0.7791\n",
      "Epoch: 3, Step: 523/2949, Loss: 0.7701\n",
      "Epoch: 3, Step: 524/2949, Loss: 0.7757\n",
      "Epoch: 3, Step: 525/2949, Loss: 0.7909\n",
      "Epoch: 3, Step: 526/2949, Loss: 0.7613\n",
      "Epoch: 3, Step: 527/2949, Loss: 0.7643\n",
      "Epoch: 3, Step: 528/2949, Loss: 0.7756\n",
      "Epoch: 3, Step: 529/2949, Loss: 0.7570\n",
      "Epoch: 3, Step: 530/2949, Loss: 0.7318\n",
      "Epoch: 3, Step: 531/2949, Loss: 0.7814\n",
      "Epoch: 3, Step: 532/2949, Loss: 0.7590\n",
      "Epoch: 3, Step: 533/2949, Loss: 0.7645\n",
      "Epoch: 3, Step: 534/2949, Loss: 0.7868\n",
      "Epoch: 3, Step: 535/2949, Loss: 0.7686\n",
      "Epoch: 3, Step: 536/2949, Loss: 0.7748\n",
      "Epoch: 3, Step: 537/2949, Loss: 0.7966\n",
      "Epoch: 3, Step: 538/2949, Loss: 0.7841\n",
      "Epoch: 3, Step: 539/2949, Loss: 0.7609\n",
      "Epoch: 3, Step: 540/2949, Loss: 0.7336\n",
      "Epoch: 3, Step: 541/2949, Loss: 0.7955\n",
      "Epoch: 3, Step: 542/2949, Loss: 0.7421\n",
      "Epoch: 3, Step: 543/2949, Loss: 0.7148\n",
      "Epoch: 3, Step: 544/2949, Loss: 0.8191\n",
      "Epoch: 3, Step: 545/2949, Loss: 0.7449\n",
      "Epoch: 3, Step: 546/2949, Loss: 0.7685\n",
      "Epoch: 3, Step: 547/2949, Loss: 0.7908\n",
      "Epoch: 3, Step: 548/2949, Loss: 0.8175\n",
      "Epoch: 3, Step: 549/2949, Loss: 0.7451\n",
      "Epoch: 3, Step: 550/2949, Loss: 0.8262\n",
      "Epoch: 3, Step: 551/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 552/2949, Loss: 0.7617\n",
      "Epoch: 3, Step: 553/2949, Loss: 0.8248\n",
      "Epoch: 3, Step: 554/2949, Loss: 0.7885\n",
      "Epoch: 3, Step: 555/2949, Loss: 0.8101\n",
      "Epoch: 3, Step: 556/2949, Loss: 0.8102\n",
      "Epoch: 3, Step: 557/2949, Loss: 0.7338\n",
      "Epoch: 3, Step: 558/2949, Loss: 0.7941\n",
      "Epoch: 3, Step: 559/2949, Loss: 0.7798\n",
      "Epoch: 3, Step: 560/2949, Loss: 0.8305\n",
      "Epoch: 3, Step: 561/2949, Loss: 0.8204\n",
      "Epoch: 3, Step: 562/2949, Loss: 0.7464\n",
      "Epoch: 3, Step: 563/2949, Loss: 0.7775\n",
      "Epoch: 3, Step: 564/2949, Loss: 0.7502\n",
      "Epoch: 3, Step: 565/2949, Loss: 0.7991\n",
      "Epoch: 3, Step: 566/2949, Loss: 0.7904\n",
      "Epoch: 3, Step: 567/2949, Loss: 0.8023\n",
      "Epoch: 3, Step: 568/2949, Loss: 0.7483\n",
      "Epoch: 3, Step: 569/2949, Loss: 0.7733\n",
      "Epoch: 3, Step: 570/2949, Loss: 0.7908\n",
      "Epoch: 3, Step: 571/2949, Loss: 0.7926\n",
      "Epoch: 3, Step: 572/2949, Loss: 0.7532\n",
      "Epoch: 3, Step: 573/2949, Loss: 0.7672\n",
      "Epoch: 3, Step: 574/2949, Loss: 0.7771\n",
      "Epoch: 3, Step: 575/2949, Loss: 0.7693\n",
      "Epoch: 3, Step: 576/2949, Loss: 0.7791\n",
      "Epoch: 3, Step: 577/2949, Loss: 0.7633\n",
      "Epoch: 3, Step: 578/2949, Loss: 0.8059\n",
      "Epoch: 3, Step: 579/2949, Loss: 0.7941\n",
      "Epoch: 3, Step: 580/2949, Loss: 0.8473\n",
      "Epoch: 3, Step: 581/2949, Loss: 0.7127\n",
      "Epoch: 3, Step: 582/2949, Loss: 0.8100\n",
      "Epoch: 3, Step: 583/2949, Loss: 0.8113\n",
      "Epoch: 3, Step: 584/2949, Loss: 0.7723\n",
      "Epoch: 3, Step: 585/2949, Loss: 0.7731\n",
      "Epoch: 3, Step: 586/2949, Loss: 0.7696\n",
      "Epoch: 3, Step: 587/2949, Loss: 0.7827\n",
      "Epoch: 3, Step: 588/2949, Loss: 0.7762\n",
      "Epoch: 3, Step: 589/2949, Loss: 0.7657\n",
      "Epoch: 3, Step: 590/2949, Loss: 0.7956\n",
      "Epoch: 3, Step: 591/2949, Loss: 0.7456\n",
      "Epoch: 3, Step: 592/2949, Loss: 0.7758\n",
      "Epoch: 3, Step: 593/2949, Loss: 0.7719\n",
      "Epoch: 3, Step: 594/2949, Loss: 0.7828\n",
      "Epoch: 3, Step: 595/2949, Loss: 0.8153\n",
      "Epoch: 3, Step: 596/2949, Loss: 0.7883\n",
      "Epoch: 3, Step: 597/2949, Loss: 0.8018\n",
      "Epoch: 3, Step: 598/2949, Loss: 0.8322\n",
      "Epoch: 3, Step: 599/2949, Loss: 0.7818\n",
      "Epoch: 3, Step: 600/2949, Loss: 0.7463\n",
      "Epoch: 3, Step: 601/2949, Loss: 0.7839\n",
      "Epoch: 3, Step: 602/2949, Loss: 0.7661\n",
      "Epoch: 3, Step: 603/2949, Loss: 0.7361\n",
      "Epoch: 3, Step: 604/2949, Loss: 0.7774\n",
      "Epoch: 3, Step: 605/2949, Loss: 0.8014\n",
      "Epoch: 3, Step: 606/2949, Loss: 0.8209\n",
      "Epoch: 3, Step: 607/2949, Loss: 0.7772\n",
      "Epoch: 3, Step: 608/2949, Loss: 0.7546\n",
      "Epoch: 3, Step: 609/2949, Loss: 0.7991\n",
      "Epoch: 3, Step: 610/2949, Loss: 0.7799\n",
      "Epoch: 3, Step: 611/2949, Loss: 0.7682\n",
      "Epoch: 3, Step: 612/2949, Loss: 0.7986\n",
      "Epoch: 3, Step: 613/2949, Loss: 0.7759\n",
      "Epoch: 3, Step: 614/2949, Loss: 0.8291\n",
      "Epoch: 3, Step: 615/2949, Loss: 0.7761\n",
      "Epoch: 3, Step: 616/2949, Loss: 0.7328\n",
      "Epoch: 3, Step: 617/2949, Loss: 0.7777\n",
      "Epoch: 3, Step: 618/2949, Loss: 0.7772\n",
      "Epoch: 3, Step: 619/2949, Loss: 0.8264\n",
      "Epoch: 3, Step: 620/2949, Loss: 0.7837\n",
      "Epoch: 3, Step: 621/2949, Loss: 0.7458\n",
      "Epoch: 3, Step: 622/2949, Loss: 0.7229\n",
      "Epoch: 3, Step: 623/2949, Loss: 0.7847\n",
      "Epoch: 3, Step: 624/2949, Loss: 0.7743\n",
      "Epoch: 3, Step: 625/2949, Loss: 0.7702\n",
      "Epoch: 3, Step: 626/2949, Loss: 0.7243\n",
      "Epoch: 3, Step: 627/2949, Loss: 0.8060\n",
      "Epoch: 3, Step: 628/2949, Loss: 0.7768\n",
      "Epoch: 3, Step: 629/2949, Loss: 0.7798\n",
      "Epoch: 3, Step: 630/2949, Loss: 0.7092\n",
      "Epoch: 3, Step: 631/2949, Loss: 0.7556\n",
      "Epoch: 3, Step: 632/2949, Loss: 0.7882\n",
      "Epoch: 3, Step: 633/2949, Loss: 0.8431\n",
      "Epoch: 3, Step: 634/2949, Loss: 0.8049\n",
      "Epoch: 3, Step: 635/2949, Loss: 0.7528\n",
      "Epoch: 3, Step: 636/2949, Loss: 0.7536\n",
      "Epoch: 3, Step: 637/2949, Loss: 0.8244\n",
      "Epoch: 3, Step: 638/2949, Loss: 0.7459\n",
      "Epoch: 3, Step: 639/2949, Loss: 0.8133\n",
      "Epoch: 3, Step: 640/2949, Loss: 0.7982\n",
      "Epoch: 3, Step: 641/2949, Loss: 0.8005\n",
      "Epoch: 3, Step: 642/2949, Loss: 0.7717\n",
      "Epoch: 3, Step: 643/2949, Loss: 0.7807\n",
      "Epoch: 3, Step: 644/2949, Loss: 0.7752\n",
      "Epoch: 3, Step: 645/2949, Loss: 0.8099\n",
      "Epoch: 3, Step: 646/2949, Loss: 0.7558\n",
      "Epoch: 3, Step: 647/2949, Loss: 0.7284\n",
      "Epoch: 3, Step: 648/2949, Loss: 0.7777\n",
      "Epoch: 3, Step: 649/2949, Loss: 0.8235\n",
      "Epoch: 3, Step: 650/2949, Loss: 0.7214\n",
      "Epoch: 3, Step: 651/2949, Loss: 0.7906\n",
      "Epoch: 3, Step: 652/2949, Loss: 0.6903\n",
      "Epoch: 3, Step: 653/2949, Loss: 0.8064\n",
      "Epoch: 3, Step: 654/2949, Loss: 0.7805\n",
      "Epoch: 3, Step: 655/2949, Loss: 0.7546\n",
      "Epoch: 3, Step: 656/2949, Loss: 0.7814\n",
      "Epoch: 3, Step: 657/2949, Loss: 0.7901\n",
      "Epoch: 3, Step: 658/2949, Loss: 0.8264\n",
      "Epoch: 3, Step: 659/2949, Loss: 0.7946\n",
      "Epoch: 3, Step: 660/2949, Loss: 0.7425\n",
      "Epoch: 3, Step: 661/2949, Loss: 0.7847\n",
      "Epoch: 3, Step: 662/2949, Loss: 0.7873\n",
      "Epoch: 3, Step: 663/2949, Loss: 0.7306\n",
      "Epoch: 3, Step: 664/2949, Loss: 0.7279\n",
      "Epoch: 3, Step: 665/2949, Loss: 0.7714\n",
      "Epoch: 3, Step: 666/2949, Loss: 0.8103\n",
      "Epoch: 3, Step: 667/2949, Loss: 0.7766\n",
      "Epoch: 3, Step: 668/2949, Loss: 0.7657\n",
      "Epoch: 3, Step: 669/2949, Loss: 0.7976\n",
      "Epoch: 3, Step: 670/2949, Loss: 0.7839\n",
      "Epoch: 3, Step: 671/2949, Loss: 0.7699\n",
      "Epoch: 3, Step: 672/2949, Loss: 0.8008\n",
      "Epoch: 3, Step: 673/2949, Loss: 0.7925\n",
      "Epoch: 3, Step: 674/2949, Loss: 0.7452\n",
      "Epoch: 3, Step: 675/2949, Loss: 0.7930\n",
      "Epoch: 3, Step: 676/2949, Loss: 0.7457\n",
      "Epoch: 3, Step: 677/2949, Loss: 0.8026\n",
      "Epoch: 3, Step: 678/2949, Loss: 0.7994\n",
      "Epoch: 3, Step: 679/2949, Loss: 0.7800\n",
      "Epoch: 3, Step: 680/2949, Loss: 0.7436\n",
      "Epoch: 3, Step: 681/2949, Loss: 0.7959\n",
      "Epoch: 3, Step: 682/2949, Loss: 0.8209\n",
      "Epoch: 3, Step: 683/2949, Loss: 0.7593\n",
      "Epoch: 3, Step: 684/2949, Loss: 0.7352\n",
      "Epoch: 3, Step: 685/2949, Loss: 0.7443\n",
      "Epoch: 3, Step: 686/2949, Loss: 0.7498\n",
      "Epoch: 3, Step: 687/2949, Loss: 0.7679\n",
      "Epoch: 3, Step: 688/2949, Loss: 0.7897\n",
      "Epoch: 3, Step: 689/2949, Loss: 0.7486\n",
      "Epoch: 3, Step: 690/2949, Loss: 0.7908\n",
      "Epoch: 3, Step: 691/2949, Loss: 0.7425\n",
      "Epoch: 3, Step: 692/2949, Loss: 0.7420\n",
      "Epoch: 3, Step: 693/2949, Loss: 0.7698\n",
      "Epoch: 3, Step: 694/2949, Loss: 0.7645\n",
      "Epoch: 3, Step: 695/2949, Loss: 0.7685\n",
      "Epoch: 3, Step: 696/2949, Loss: 0.7911\n",
      "Epoch: 3, Step: 697/2949, Loss: 0.7350\n",
      "Epoch: 3, Step: 698/2949, Loss: 0.7791\n",
      "Epoch: 3, Step: 699/2949, Loss: 0.7542\n",
      "Epoch: 3, Step: 700/2949, Loss: 0.7344\n",
      "Epoch: 3, Step: 701/2949, Loss: 0.7102\n",
      "Epoch: 3, Step: 702/2949, Loss: 0.7708\n",
      "Epoch: 3, Step: 703/2949, Loss: 0.7577\n",
      "Epoch: 3, Step: 704/2949, Loss: 0.7907\n",
      "Epoch: 3, Step: 705/2949, Loss: 0.7838\n",
      "Epoch: 3, Step: 706/2949, Loss: 0.7859\n",
      "Epoch: 3, Step: 707/2949, Loss: 0.8282\n",
      "Epoch: 3, Step: 708/2949, Loss: 0.8136\n",
      "Epoch: 3, Step: 709/2949, Loss: 0.8049\n",
      "Epoch: 3, Step: 710/2949, Loss: 0.7830\n",
      "Epoch: 3, Step: 711/2949, Loss: 0.7890\n",
      "Epoch: 3, Step: 712/2949, Loss: 0.8062\n",
      "Epoch: 3, Step: 713/2949, Loss: 0.7679\n",
      "Epoch: 3, Step: 714/2949, Loss: 0.8064\n",
      "Epoch: 3, Step: 715/2949, Loss: 0.7981\n",
      "Epoch: 3, Step: 716/2949, Loss: 0.7986\n",
      "Epoch: 3, Step: 717/2949, Loss: 0.8072\n",
      "Epoch: 3, Step: 718/2949, Loss: 0.7940\n",
      "Epoch: 3, Step: 719/2949, Loss: 0.8198\n",
      "Epoch: 3, Step: 720/2949, Loss: 0.7701\n",
      "Epoch: 3, Step: 721/2949, Loss: 0.7982\n",
      "Epoch: 3, Step: 722/2949, Loss: 0.7785\n",
      "Epoch: 3, Step: 723/2949, Loss: 0.7802\n",
      "Epoch: 3, Step: 724/2949, Loss: 0.7731\n",
      "Epoch: 3, Step: 725/2949, Loss: 0.7764\n",
      "Epoch: 3, Step: 726/2949, Loss: 0.7998\n",
      "Epoch: 3, Step: 727/2949, Loss: 0.7260\n",
      "Epoch: 3, Step: 728/2949, Loss: 0.7661\n",
      "Epoch: 3, Step: 729/2949, Loss: 0.7985\n",
      "Epoch: 3, Step: 730/2949, Loss: 0.7667\n",
      "Epoch: 3, Step: 731/2949, Loss: 0.7699\n",
      "Epoch: 3, Step: 732/2949, Loss: 0.8079\n",
      "Epoch: 3, Step: 733/2949, Loss: 0.7739\n",
      "Epoch: 3, Step: 734/2949, Loss: 0.7792\n",
      "Epoch: 3, Step: 735/2949, Loss: 0.8183\n",
      "Epoch: 3, Step: 736/2949, Loss: 0.7794\n",
      "Epoch: 3, Step: 737/2949, Loss: 0.7922\n",
      "Epoch: 3, Step: 738/2949, Loss: 0.7726\n",
      "Epoch: 3, Step: 739/2949, Loss: 0.8013\n",
      "Epoch: 3, Step: 740/2949, Loss: 0.7325\n",
      "Epoch: 3, Step: 741/2949, Loss: 0.7603\n",
      "Epoch: 3, Step: 742/2949, Loss: 0.7701\n",
      "Epoch: 3, Step: 743/2949, Loss: 0.7724\n",
      "Epoch: 3, Step: 744/2949, Loss: 0.7607\n",
      "Epoch: 3, Step: 745/2949, Loss: 0.7327\n",
      "Epoch: 3, Step: 746/2949, Loss: 0.7707\n",
      "Epoch: 3, Step: 747/2949, Loss: 0.7603\n",
      "Epoch: 3, Step: 748/2949, Loss: 0.7764\n",
      "Epoch: 3, Step: 749/2949, Loss: 0.7783\n",
      "Epoch: 3, Step: 750/2949, Loss: 0.7365\n",
      "Epoch: 3, Step: 751/2949, Loss: 0.8150\n",
      "Epoch: 3, Step: 752/2949, Loss: 0.7470\n",
      "Epoch: 3, Step: 753/2949, Loss: 0.7951\n",
      "Epoch: 3, Step: 754/2949, Loss: 0.7438\n",
      "Epoch: 3, Step: 755/2949, Loss: 0.7987\n",
      "Epoch: 3, Step: 756/2949, Loss: 0.7039\n",
      "Epoch: 3, Step: 757/2949, Loss: 0.7688\n",
      "Epoch: 3, Step: 758/2949, Loss: 0.7836\n",
      "Epoch: 3, Step: 759/2949, Loss: 0.8261\n",
      "Epoch: 3, Step: 760/2949, Loss: 0.7640\n",
      "Epoch: 3, Step: 761/2949, Loss: 0.7707\n",
      "Epoch: 3, Step: 762/2949, Loss: 0.7646\n",
      "Epoch: 3, Step: 763/2949, Loss: 0.8161\n",
      "Epoch: 3, Step: 764/2949, Loss: 0.7881\n",
      "Epoch: 3, Step: 765/2949, Loss: 0.7747\n",
      "Epoch: 3, Step: 766/2949, Loss: 0.7787\n",
      "Epoch: 3, Step: 767/2949, Loss: 0.8126\n",
      "Epoch: 3, Step: 768/2949, Loss: 0.7660\n",
      "Epoch: 3, Step: 769/2949, Loss: 0.7671\n",
      "Epoch: 3, Step: 770/2949, Loss: 0.7941\n",
      "Epoch: 3, Step: 771/2949, Loss: 0.8084\n",
      "Epoch: 3, Step: 772/2949, Loss: 0.7675\n",
      "Epoch: 3, Step: 773/2949, Loss: 0.7693\n",
      "Epoch: 3, Step: 774/2949, Loss: 0.7719\n",
      "Epoch: 3, Step: 775/2949, Loss: 0.7609\n",
      "Epoch: 3, Step: 776/2949, Loss: 0.7551\n",
      "Epoch: 3, Step: 777/2949, Loss: 0.7501\n",
      "Epoch: 3, Step: 778/2949, Loss: 0.7974\n",
      "Epoch: 3, Step: 779/2949, Loss: 0.7974\n",
      "Epoch: 3, Step: 780/2949, Loss: 0.8353\n",
      "Epoch: 3, Step: 781/2949, Loss: 0.8150\n",
      "Epoch: 3, Step: 782/2949, Loss: 0.8338\n",
      "Epoch: 3, Step: 783/2949, Loss: 0.8199\n",
      "Epoch: 3, Step: 784/2949, Loss: 0.7364\n",
      "Epoch: 3, Step: 785/2949, Loss: 0.7901\n",
      "Epoch: 3, Step: 786/2949, Loss: 0.8236\n",
      "Epoch: 3, Step: 787/2949, Loss: 0.7518\n",
      "Epoch: 3, Step: 788/2949, Loss: 0.7660\n",
      "Epoch: 3, Step: 789/2949, Loss: 0.8241\n",
      "Epoch: 3, Step: 790/2949, Loss: 0.7605\n",
      "Epoch: 3, Step: 791/2949, Loss: 0.8088\n",
      "Epoch: 3, Step: 792/2949, Loss: 0.7471\n",
      "Epoch: 3, Step: 793/2949, Loss: 0.7205\n",
      "Epoch: 3, Step: 794/2949, Loss: 0.8116\n",
      "Epoch: 3, Step: 795/2949, Loss: 0.7709\n",
      "Epoch: 3, Step: 796/2949, Loss: 0.8080\n",
      "Epoch: 3, Step: 797/2949, Loss: 0.7439\n",
      "Epoch: 3, Step: 798/2949, Loss: 0.7586\n",
      "Epoch: 3, Step: 799/2949, Loss: 0.7946\n",
      "Epoch: 3, Step: 800/2949, Loss: 0.7602\n",
      "Epoch: 3, Step: 801/2949, Loss: 0.7803\n",
      "Epoch: 3, Step: 802/2949, Loss: 0.7957\n",
      "Epoch: 3, Step: 803/2949, Loss: 0.7605\n",
      "Epoch: 3, Step: 804/2949, Loss: 0.7632\n",
      "Epoch: 3, Step: 805/2949, Loss: 0.7786\n",
      "Epoch: 3, Step: 806/2949, Loss: 0.7875\n",
      "Epoch: 3, Step: 807/2949, Loss: 0.8318\n",
      "Epoch: 3, Step: 808/2949, Loss: 0.8073\n",
      "Epoch: 3, Step: 809/2949, Loss: 0.8000\n",
      "Epoch: 3, Step: 810/2949, Loss: 0.7797\n",
      "Epoch: 3, Step: 811/2949, Loss: 0.7777\n",
      "Epoch: 3, Step: 812/2949, Loss: 0.7973\n",
      "Epoch: 3, Step: 813/2949, Loss: 0.8103\n",
      "Epoch: 3, Step: 814/2949, Loss: 0.7596\n",
      "Epoch: 3, Step: 815/2949, Loss: 0.7806\n",
      "Epoch: 3, Step: 816/2949, Loss: 0.7964\n",
      "Epoch: 3, Step: 817/2949, Loss: 0.7523\n",
      "Epoch: 3, Step: 818/2949, Loss: 0.7136\n",
      "Epoch: 3, Step: 819/2949, Loss: 0.8243\n",
      "Epoch: 3, Step: 820/2949, Loss: 0.7972\n",
      "Epoch: 3, Step: 821/2949, Loss: 0.7956\n",
      "Epoch: 3, Step: 822/2949, Loss: 0.8042\n",
      "Epoch: 3, Step: 823/2949, Loss: 0.8005\n",
      "Epoch: 3, Step: 824/2949, Loss: 0.7869\n",
      "Epoch: 3, Step: 825/2949, Loss: 0.7848\n",
      "Epoch: 3, Step: 826/2949, Loss: 0.8309\n",
      "Epoch: 3, Step: 827/2949, Loss: 0.7884\n",
      "Epoch: 3, Step: 828/2949, Loss: 0.8060\n",
      "Epoch: 3, Step: 829/2949, Loss: 0.7664\n",
      "Epoch: 3, Step: 830/2949, Loss: 0.7646\n",
      "Epoch: 3, Step: 831/2949, Loss: 0.7821\n",
      "Epoch: 3, Step: 832/2949, Loss: 0.7502\n",
      "Epoch: 3, Step: 833/2949, Loss: 0.7680\n",
      "Epoch: 3, Step: 834/2949, Loss: 0.7568\n",
      "Epoch: 3, Step: 835/2949, Loss: 0.7630\n",
      "Epoch: 3, Step: 836/2949, Loss: 0.7332\n",
      "Epoch: 3, Step: 837/2949, Loss: 0.8085\n",
      "Epoch: 3, Step: 838/2949, Loss: 0.7969\n",
      "Epoch: 3, Step: 839/2949, Loss: 0.7483\n",
      "Epoch: 3, Step: 840/2949, Loss: 0.7870\n",
      "Epoch: 3, Step: 841/2949, Loss: 0.7942\n",
      "Epoch: 3, Step: 842/2949, Loss: 0.7539\n",
      "Epoch: 3, Step: 843/2949, Loss: 0.7991\n",
      "Epoch: 3, Step: 844/2949, Loss: 0.7762\n",
      "Epoch: 3, Step: 845/2949, Loss: 0.8263\n",
      "Epoch: 3, Step: 846/2949, Loss: 0.7984\n",
      "Epoch: 3, Step: 847/2949, Loss: 0.7658\n",
      "Epoch: 3, Step: 848/2949, Loss: 0.8026\n",
      "Epoch: 3, Step: 849/2949, Loss: 0.7358\n",
      "Epoch: 3, Step: 850/2949, Loss: 0.8207\n",
      "Epoch: 3, Step: 851/2949, Loss: 0.7859\n",
      "Epoch: 3, Step: 852/2949, Loss: 0.8078\n",
      "Epoch: 3, Step: 853/2949, Loss: 0.8210\n",
      "Epoch: 3, Step: 854/2949, Loss: 0.7691\n",
      "Epoch: 3, Step: 855/2949, Loss: 0.7510\n",
      "Epoch: 3, Step: 856/2949, Loss: 0.7964\n",
      "Epoch: 3, Step: 857/2949, Loss: 0.7884\n",
      "Epoch: 3, Step: 858/2949, Loss: 0.7658\n",
      "Epoch: 3, Step: 859/2949, Loss: 0.7639\n",
      "Epoch: 3, Step: 860/2949, Loss: 0.7922\n",
      "Epoch: 3, Step: 861/2949, Loss: 0.8421\n",
      "Epoch: 3, Step: 862/2949, Loss: 0.7690\n",
      "Epoch: 3, Step: 863/2949, Loss: 0.8060\n",
      "Epoch: 3, Step: 864/2949, Loss: 0.8157\n",
      "Epoch: 3, Step: 865/2949, Loss: 0.7738\n",
      "Epoch: 3, Step: 866/2949, Loss: 0.7934\n",
      "Epoch: 3, Step: 867/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 868/2949, Loss: 0.7783\n",
      "Epoch: 3, Step: 869/2949, Loss: 0.8034\n",
      "Epoch: 3, Step: 870/2949, Loss: 0.7750\n",
      "Epoch: 3, Step: 871/2949, Loss: 0.8076\n",
      "Epoch: 3, Step: 872/2949, Loss: 0.7629\n",
      "Epoch: 3, Step: 873/2949, Loss: 0.7930\n",
      "Epoch: 3, Step: 874/2949, Loss: 0.7680\n",
      "Epoch: 3, Step: 875/2949, Loss: 0.7458\n",
      "Epoch: 3, Step: 876/2949, Loss: 0.7887\n",
      "Epoch: 3, Step: 877/2949, Loss: 0.7590\n",
      "Epoch: 3, Step: 878/2949, Loss: 0.7725\n",
      "Epoch: 3, Step: 879/2949, Loss: 0.7723\n",
      "Epoch: 3, Step: 880/2949, Loss: 0.7720\n",
      "Epoch: 3, Step: 881/2949, Loss: 0.7447\n",
      "Epoch: 3, Step: 882/2949, Loss: 0.7715\n",
      "Epoch: 3, Step: 883/2949, Loss: 0.7720\n",
      "Epoch: 3, Step: 884/2949, Loss: 0.7741\n",
      "Epoch: 3, Step: 885/2949, Loss: 0.7807\n",
      "Epoch: 3, Step: 886/2949, Loss: 0.7841\n",
      "Epoch: 3, Step: 887/2949, Loss: 0.7969\n",
      "Epoch: 3, Step: 888/2949, Loss: 0.7751\n",
      "Epoch: 3, Step: 889/2949, Loss: 0.7754\n",
      "Epoch: 3, Step: 890/2949, Loss: 0.7597\n",
      "Epoch: 3, Step: 891/2949, Loss: 0.7384\n",
      "Epoch: 3, Step: 892/2949, Loss: 0.7927\n",
      "Epoch: 3, Step: 893/2949, Loss: 0.8163\n",
      "Epoch: 3, Step: 894/2949, Loss: 0.7605\n",
      "Epoch: 3, Step: 895/2949, Loss: 0.7371\n",
      "Epoch: 3, Step: 896/2949, Loss: 0.7761\n",
      "Epoch: 3, Step: 897/2949, Loss: 0.7645\n",
      "Epoch: 3, Step: 898/2949, Loss: 0.8142\n",
      "Epoch: 3, Step: 899/2949, Loss: 0.7733\n",
      "Epoch: 3, Step: 900/2949, Loss: 0.8221\n",
      "Epoch: 3, Step: 901/2949, Loss: 0.7733\n",
      "Epoch: 3, Step: 902/2949, Loss: 0.7418\n",
      "Epoch: 3, Step: 903/2949, Loss: 0.7469\n",
      "Epoch: 3, Step: 904/2949, Loss: 0.7519\n",
      "Epoch: 3, Step: 905/2949, Loss: 0.7525\n",
      "Epoch: 3, Step: 906/2949, Loss: 0.6875\n",
      "Epoch: 3, Step: 907/2949, Loss: 0.7364\n",
      "Epoch: 3, Step: 908/2949, Loss: 0.8113\n",
      "Epoch: 3, Step: 909/2949, Loss: 0.7724\n",
      "Epoch: 3, Step: 910/2949, Loss: 0.7554\n",
      "Epoch: 3, Step: 911/2949, Loss: 0.8075\n",
      "Epoch: 3, Step: 912/2949, Loss: 0.7723\n",
      "Epoch: 3, Step: 913/2949, Loss: 0.8131\n",
      "Epoch: 3, Step: 914/2949, Loss: 0.7886\n",
      "Epoch: 3, Step: 915/2949, Loss: 0.7675\n",
      "Epoch: 3, Step: 916/2949, Loss: 0.7641\n",
      "Epoch: 3, Step: 917/2949, Loss: 0.6932\n",
      "Epoch: 3, Step: 918/2949, Loss: 0.7610\n",
      "Epoch: 3, Step: 919/2949, Loss: 0.7688\n",
      "Epoch: 3, Step: 920/2949, Loss: 0.7518\n",
      "Epoch: 3, Step: 921/2949, Loss: 0.7581\n",
      "Epoch: 3, Step: 922/2949, Loss: 0.7479\n",
      "Epoch: 3, Step: 923/2949, Loss: 0.7591\n",
      "Epoch: 3, Step: 924/2949, Loss: 0.7719\n",
      "Epoch: 3, Step: 925/2949, Loss: 0.7121\n",
      "Epoch: 3, Step: 926/2949, Loss: 0.7887\n",
      "Epoch: 3, Step: 927/2949, Loss: 0.8057\n",
      "Epoch: 3, Step: 928/2949, Loss: 0.8095\n",
      "Epoch: 3, Step: 929/2949, Loss: 0.7817\n",
      "Epoch: 3, Step: 930/2949, Loss: 0.7846\n",
      "Epoch: 3, Step: 931/2949, Loss: 0.7951\n",
      "Epoch: 3, Step: 932/2949, Loss: 0.7699\n",
      "Epoch: 3, Step: 933/2949, Loss: 0.7517\n",
      "Epoch: 3, Step: 934/2949, Loss: 0.7542\n",
      "Epoch: 3, Step: 935/2949, Loss: 0.7686\n",
      "Epoch: 3, Step: 936/2949, Loss: 0.7831\n",
      "Epoch: 3, Step: 937/2949, Loss: 0.7657\n",
      "Epoch: 3, Step: 938/2949, Loss: 0.7423\n",
      "Epoch: 3, Step: 939/2949, Loss: 0.7658\n",
      "Epoch: 3, Step: 940/2949, Loss: 0.7723\n",
      "Epoch: 3, Step: 941/2949, Loss: 0.8147\n",
      "Epoch: 3, Step: 942/2949, Loss: 0.8431\n",
      "Epoch: 3, Step: 943/2949, Loss: 0.7966\n",
      "Epoch: 3, Step: 944/2949, Loss: 0.7586\n",
      "Epoch: 3, Step: 945/2949, Loss: 0.8219\n",
      "Epoch: 3, Step: 946/2949, Loss: 0.7138\n",
      "Epoch: 3, Step: 947/2949, Loss: 0.7716\n",
      "Epoch: 3, Step: 948/2949, Loss: 0.7688\n",
      "Epoch: 3, Step: 949/2949, Loss: 0.8071\n",
      "Epoch: 3, Step: 950/2949, Loss: 0.7659\n",
      "Epoch: 3, Step: 951/2949, Loss: 0.7538\n",
      "Epoch: 3, Step: 952/2949, Loss: 0.8143\n",
      "Epoch: 3, Step: 953/2949, Loss: 0.7633\n",
      "Epoch: 3, Step: 954/2949, Loss: 0.7642\n",
      "Epoch: 3, Step: 955/2949, Loss: 0.7303\n",
      "Epoch: 3, Step: 956/2949, Loss: 0.8310\n",
      "Epoch: 3, Step: 957/2949, Loss: 0.7354\n",
      "Epoch: 3, Step: 958/2949, Loss: 0.8004\n",
      "Epoch: 3, Step: 959/2949, Loss: 0.7847\n",
      "Epoch: 3, Step: 960/2949, Loss: 0.8289\n",
      "Epoch: 3, Step: 961/2949, Loss: 0.7680\n",
      "Epoch: 3, Step: 962/2949, Loss: 0.7164\n",
      "Epoch: 3, Step: 963/2949, Loss: 0.7886\n",
      "Epoch: 3, Step: 964/2949, Loss: 0.7919\n",
      "Epoch: 3, Step: 965/2949, Loss: 0.8096\n",
      "Epoch: 3, Step: 966/2949, Loss: 0.7959\n",
      "Epoch: 3, Step: 967/2949, Loss: 0.7862\n",
      "Epoch: 3, Step: 968/2949, Loss: 0.7780\n",
      "Epoch: 3, Step: 969/2949, Loss: 0.7615\n",
      "Epoch: 3, Step: 970/2949, Loss: 0.7695\n",
      "Epoch: 3, Step: 971/2949, Loss: 0.7687\n",
      "Epoch: 3, Step: 972/2949, Loss: 0.8400\n",
      "Epoch: 3, Step: 973/2949, Loss: 0.7199\n",
      "Epoch: 3, Step: 974/2949, Loss: 0.7562\n",
      "Epoch: 3, Step: 975/2949, Loss: 0.7423\n",
      "Epoch: 3, Step: 976/2949, Loss: 0.8156\n",
      "Epoch: 3, Step: 977/2949, Loss: 0.7712\n",
      "Epoch: 3, Step: 978/2949, Loss: 0.7857\n",
      "Epoch: 3, Step: 979/2949, Loss: 0.7911\n",
      "Epoch: 3, Step: 980/2949, Loss: 0.7748\n",
      "Epoch: 3, Step: 981/2949, Loss: 0.7303\n",
      "Epoch: 3, Step: 982/2949, Loss: 0.7834\n",
      "Epoch: 3, Step: 983/2949, Loss: 0.7796\n",
      "Epoch: 3, Step: 984/2949, Loss: 0.8362\n",
      "Epoch: 3, Step: 985/2949, Loss: 0.7590\n",
      "Epoch: 3, Step: 986/2949, Loss: 0.7767\n",
      "Epoch: 3, Step: 987/2949, Loss: 0.7512\n",
      "Epoch: 3, Step: 988/2949, Loss: 0.7728\n",
      "Epoch: 3, Step: 989/2949, Loss: 0.7628\n",
      "Epoch: 3, Step: 990/2949, Loss: 0.7496\n",
      "Epoch: 3, Step: 991/2949, Loss: 0.8399\n",
      "Epoch: 3, Step: 992/2949, Loss: 0.7365\n",
      "Epoch: 3, Step: 993/2949, Loss: 0.7703\n",
      "Epoch: 3, Step: 994/2949, Loss: 0.7876\n",
      "Epoch: 3, Step: 995/2949, Loss: 0.7471\n",
      "Epoch: 3, Step: 996/2949, Loss: 0.7388\n",
      "Epoch: 3, Step: 997/2949, Loss: 0.7842\n",
      "Epoch: 3, Step: 998/2949, Loss: 0.7495\n",
      "Epoch: 3, Step: 999/2949, Loss: 0.7842\n",
      "Epoch: 3, Step: 1000/2949, Loss: 0.7683\n",
      "Epoch: 3, Step: 1001/2949, Loss: 0.7578\n",
      "Epoch: 3, Step: 1002/2949, Loss: 0.7968\n",
      "Epoch: 3, Step: 1003/2949, Loss: 0.7669\n",
      "Epoch: 3, Step: 1004/2949, Loss: 0.7816\n",
      "Epoch: 3, Step: 1005/2949, Loss: 0.7962\n",
      "Epoch: 3, Step: 1006/2949, Loss: 0.7575\n",
      "Epoch: 3, Step: 1007/2949, Loss: 0.8053\n",
      "Epoch: 3, Step: 1008/2949, Loss: 0.8090\n",
      "Epoch: 3, Step: 1009/2949, Loss: 0.7849\n",
      "Epoch: 3, Step: 1010/2949, Loss: 0.8233\n",
      "Epoch: 3, Step: 1011/2949, Loss: 0.7150\n",
      "Epoch: 3, Step: 1012/2949, Loss: 0.7525\n",
      "Epoch: 3, Step: 1013/2949, Loss: 0.7575\n",
      "Epoch: 3, Step: 1014/2949, Loss: 0.7670\n",
      "Epoch: 3, Step: 1015/2949, Loss: 0.7724\n",
      "Epoch: 3, Step: 1016/2949, Loss: 0.7657\n",
      "Epoch: 3, Step: 1017/2949, Loss: 0.7844\n",
      "Epoch: 3, Step: 1018/2949, Loss: 0.7181\n",
      "Epoch: 3, Step: 1019/2949, Loss: 0.7643\n",
      "Epoch: 3, Step: 1020/2949, Loss: 0.7298\n",
      "Epoch: 3, Step: 1021/2949, Loss: 0.7825\n",
      "Epoch: 3, Step: 1022/2949, Loss: 0.7751\n",
      "Epoch: 3, Step: 1023/2949, Loss: 0.7667\n",
      "Epoch: 3, Step: 1024/2949, Loss: 0.7527\n",
      "Epoch: 3, Step: 1025/2949, Loss: 0.7908\n",
      "Epoch: 3, Step: 1026/2949, Loss: 0.7693\n",
      "Epoch: 3, Step: 1027/2949, Loss: 0.7576\n",
      "Epoch: 3, Step: 1028/2949, Loss: 0.7687\n",
      "Epoch: 3, Step: 1029/2949, Loss: 0.8165\n",
      "Epoch: 3, Step: 1030/2949, Loss: 0.7201\n",
      "Epoch: 3, Step: 1031/2949, Loss: 0.8181\n",
      "Epoch: 3, Step: 1032/2949, Loss: 0.7447\n",
      "Epoch: 3, Step: 1033/2949, Loss: 0.8302\n",
      "Epoch: 3, Step: 1034/2949, Loss: 0.7454\n",
      "Epoch: 3, Step: 1035/2949, Loss: 0.7508\n",
      "Epoch: 3, Step: 1036/2949, Loss: 0.8052\n",
      "Epoch: 3, Step: 1037/2949, Loss: 0.7967\n",
      "Epoch: 3, Step: 1038/2949, Loss: 0.7702\n",
      "Epoch: 3, Step: 1039/2949, Loss: 0.7780\n",
      "Epoch: 3, Step: 1040/2949, Loss: 0.8116\n",
      "Epoch: 3, Step: 1041/2949, Loss: 0.7937\n",
      "Epoch: 3, Step: 1042/2949, Loss: 0.8085\n",
      "Epoch: 3, Step: 1043/2949, Loss: 0.8114\n",
      "Epoch: 3, Step: 1044/2949, Loss: 0.7832\n",
      "Epoch: 3, Step: 1045/2949, Loss: 0.7909\n",
      "Epoch: 3, Step: 1046/2949, Loss: 0.7504\n",
      "Epoch: 3, Step: 1047/2949, Loss: 0.7447\n",
      "Epoch: 3, Step: 1048/2949, Loss: 0.7510\n",
      "Epoch: 3, Step: 1049/2949, Loss: 0.7622\n",
      "Epoch: 3, Step: 1050/2949, Loss: 0.7674\n",
      "Epoch: 3, Step: 1051/2949, Loss: 0.7948\n",
      "Epoch: 3, Step: 1052/2949, Loss: 0.8024\n",
      "Epoch: 3, Step: 1053/2949, Loss: 0.7970\n",
      "Epoch: 3, Step: 1054/2949, Loss: 0.7970\n",
      "Epoch: 3, Step: 1055/2949, Loss: 0.7875\n",
      "Epoch: 3, Step: 1056/2949, Loss: 0.7734\n",
      "Epoch: 3, Step: 1057/2949, Loss: 0.7697\n",
      "Epoch: 3, Step: 1058/2949, Loss: 0.7461\n",
      "Epoch: 3, Step: 1059/2949, Loss: 0.7957\n",
      "Epoch: 3, Step: 1060/2949, Loss: 0.7346\n",
      "Epoch: 3, Step: 1061/2949, Loss: 0.8119\n",
      "Epoch: 3, Step: 1062/2949, Loss: 0.7721\n",
      "Epoch: 3, Step: 1063/2949, Loss: 0.7822\n",
      "Epoch: 3, Step: 1064/2949, Loss: 0.7858\n",
      "Epoch: 3, Step: 1065/2949, Loss: 0.7726\n",
      "Epoch: 3, Step: 1066/2949, Loss: 0.8182\n",
      "Epoch: 3, Step: 1067/2949, Loss: 0.8419\n",
      "Epoch: 3, Step: 1068/2949, Loss: 0.7899\n",
      "Epoch: 3, Step: 1069/2949, Loss: 0.7095\n",
      "Epoch: 3, Step: 1070/2949, Loss: 0.7593\n",
      "Epoch: 3, Step: 1071/2949, Loss: 0.7924\n",
      "Epoch: 3, Step: 1072/2949, Loss: 0.8061\n",
      "Epoch: 3, Step: 1073/2949, Loss: 0.8099\n",
      "Epoch: 3, Step: 1074/2949, Loss: 0.7599\n",
      "Epoch: 3, Step: 1075/2949, Loss: 0.7611\n",
      "Epoch: 3, Step: 1076/2949, Loss: 0.7188\n",
      "Epoch: 3, Step: 1077/2949, Loss: 0.7372\n",
      "Epoch: 3, Step: 1078/2949, Loss: 0.7543\n",
      "Epoch: 3, Step: 1079/2949, Loss: 0.8011\n",
      "Epoch: 3, Step: 1080/2949, Loss: 0.7797\n",
      "Epoch: 3, Step: 1081/2949, Loss: 0.7783\n",
      "Epoch: 3, Step: 1082/2949, Loss: 0.7784\n",
      "Epoch: 3, Step: 1083/2949, Loss: 0.7706\n",
      "Epoch: 3, Step: 1084/2949, Loss: 0.7323\n",
      "Epoch: 3, Step: 1085/2949, Loss: 0.8034\n",
      "Epoch: 3, Step: 1086/2949, Loss: 0.7731\n",
      "Epoch: 3, Step: 1087/2949, Loss: 0.7937\n",
      "Epoch: 3, Step: 1088/2949, Loss: 0.7707\n",
      "Epoch: 3, Step: 1089/2949, Loss: 0.8019\n",
      "Epoch: 3, Step: 1090/2949, Loss: 0.7792\n",
      "Epoch: 3, Step: 1091/2949, Loss: 0.8323\n",
      "Epoch: 3, Step: 1092/2949, Loss: 0.7818\n",
      "Epoch: 3, Step: 1093/2949, Loss: 0.7681\n",
      "Epoch: 3, Step: 1094/2949, Loss: 0.7557\n",
      "Epoch: 3, Step: 1095/2949, Loss: 0.7988\n",
      "Epoch: 3, Step: 1096/2949, Loss: 0.7676\n",
      "Epoch: 3, Step: 1097/2949, Loss: 0.7595\n",
      "Epoch: 3, Step: 1098/2949, Loss: 0.7928\n",
      "Epoch: 3, Step: 1099/2949, Loss: 0.8126\n",
      "Epoch: 3, Step: 1100/2949, Loss: 0.7670\n",
      "Epoch: 3, Step: 1101/2949, Loss: 0.7762\n",
      "Epoch: 3, Step: 1102/2949, Loss: 0.7950\n",
      "Epoch: 3, Step: 1103/2949, Loss: 0.7480\n",
      "Epoch: 3, Step: 1104/2949, Loss: 0.7931\n",
      "Epoch: 3, Step: 1105/2949, Loss: 0.7292\n",
      "Epoch: 3, Step: 1106/2949, Loss: 0.7143\n",
      "Epoch: 3, Step: 1107/2949, Loss: 0.6950\n",
      "Epoch: 3, Step: 1108/2949, Loss: 0.6909\n",
      "Epoch: 3, Step: 1109/2949, Loss: 0.7514\n",
      "Epoch: 3, Step: 1110/2949, Loss: 0.7621\n",
      "Epoch: 3, Step: 1111/2949, Loss: 0.7783\n",
      "Epoch: 3, Step: 1112/2949, Loss: 0.8130\n",
      "Epoch: 3, Step: 1113/2949, Loss: 0.7699\n",
      "Epoch: 3, Step: 1114/2949, Loss: 0.7919\n",
      "Epoch: 3, Step: 1115/2949, Loss: 0.7959\n",
      "Epoch: 3, Step: 1116/2949, Loss: 0.7596\n",
      "Epoch: 3, Step: 1117/2949, Loss: 0.7293\n",
      "Epoch: 3, Step: 1118/2949, Loss: 0.7840\n",
      "Epoch: 3, Step: 1119/2949, Loss: 0.7608\n",
      "Epoch: 3, Step: 1120/2949, Loss: 0.7963\n",
      "Epoch: 3, Step: 1121/2949, Loss: 0.7893\n",
      "Epoch: 3, Step: 1122/2949, Loss: 0.7239\n",
      "Epoch: 3, Step: 1123/2949, Loss: 0.7473\n",
      "Epoch: 3, Step: 1124/2949, Loss: 0.7781\n",
      "Epoch: 3, Step: 1125/2949, Loss: 0.7704\n",
      "Epoch: 3, Step: 1126/2949, Loss: 0.7682\n",
      "Epoch: 3, Step: 1127/2949, Loss: 0.7873\n",
      "Epoch: 3, Step: 1128/2949, Loss: 0.7378\n",
      "Epoch: 3, Step: 1129/2949, Loss: 0.8058\n",
      "Epoch: 3, Step: 1130/2949, Loss: 0.7662\n",
      "Epoch: 3, Step: 1131/2949, Loss: 0.7529\n",
      "Epoch: 3, Step: 1132/2949, Loss: 0.8204\n",
      "Epoch: 3, Step: 1133/2949, Loss: 0.7737\n",
      "Epoch: 3, Step: 1134/2949, Loss: 0.8175\n",
      "Epoch: 3, Step: 1135/2949, Loss: 0.7903\n",
      "Epoch: 3, Step: 1136/2949, Loss: 0.8359\n",
      "Epoch: 3, Step: 1137/2949, Loss: 0.7084\n",
      "Epoch: 3, Step: 1138/2949, Loss: 0.8207\n",
      "Epoch: 3, Step: 1139/2949, Loss: 0.8095\n",
      "Epoch: 3, Step: 1140/2949, Loss: 0.7705\n",
      "Epoch: 3, Step: 1141/2949, Loss: 0.7678\n",
      "Epoch: 3, Step: 1142/2949, Loss: 0.7431\n",
      "Epoch: 3, Step: 1143/2949, Loss: 0.8089\n",
      "Epoch: 3, Step: 1144/2949, Loss: 0.7412\n",
      "Epoch: 3, Step: 1145/2949, Loss: 0.7911\n",
      "Epoch: 3, Step: 1146/2949, Loss: 0.7951\n",
      "Epoch: 3, Step: 1147/2949, Loss: 0.7883\n",
      "Epoch: 3, Step: 1148/2949, Loss: 0.7871\n",
      "Epoch: 3, Step: 1149/2949, Loss: 0.7779\n",
      "Epoch: 3, Step: 1150/2949, Loss: 0.7947\n",
      "Epoch: 3, Step: 1151/2949, Loss: 0.7689\n",
      "Epoch: 3, Step: 1152/2949, Loss: 0.7988\n",
      "Epoch: 3, Step: 1153/2949, Loss: 0.7536\n",
      "Epoch: 3, Step: 1154/2949, Loss: 0.7847\n",
      "Epoch: 3, Step: 1155/2949, Loss: 0.7557\n",
      "Epoch: 3, Step: 1156/2949, Loss: 0.7677\n",
      "Epoch: 3, Step: 1157/2949, Loss: 0.8026\n",
      "Epoch: 3, Step: 1158/2949, Loss: 0.7556\n",
      "Epoch: 3, Step: 1159/2949, Loss: 0.8035\n",
      "Epoch: 3, Step: 1160/2949, Loss: 0.7343\n",
      "Epoch: 3, Step: 1161/2949, Loss: 0.7978\n",
      "Epoch: 3, Step: 1162/2949, Loss: 0.7772\n",
      "Epoch: 3, Step: 1163/2949, Loss: 0.7316\n",
      "Epoch: 3, Step: 1164/2949, Loss: 0.7718\n",
      "Epoch: 3, Step: 1165/2949, Loss: 0.7481\n",
      "Epoch: 3, Step: 1166/2949, Loss: 0.7837\n",
      "Epoch: 3, Step: 1167/2949, Loss: 0.7712\n",
      "Epoch: 3, Step: 1168/2949, Loss: 0.7604\n",
      "Epoch: 3, Step: 1169/2949, Loss: 0.8028\n",
      "Epoch: 3, Step: 1170/2949, Loss: 0.7649\n",
      "Epoch: 3, Step: 1171/2949, Loss: 0.7453\n",
      "Epoch: 3, Step: 1172/2949, Loss: 0.7758\n",
      "Epoch: 3, Step: 1173/2949, Loss: 0.7884\n",
      "Epoch: 3, Step: 1174/2949, Loss: 0.7994\n",
      "Epoch: 3, Step: 1175/2949, Loss: 0.7862\n",
      "Epoch: 3, Step: 1176/2949, Loss: 0.7685\n",
      "Epoch: 3, Step: 1177/2949, Loss: 0.7931\n",
      "Epoch: 3, Step: 1178/2949, Loss: 0.7331\n",
      "Epoch: 3, Step: 1179/2949, Loss: 0.7743\n",
      "Epoch: 3, Step: 1180/2949, Loss: 0.7448\n",
      "Epoch: 3, Step: 1181/2949, Loss: 0.7852\n",
      "Epoch: 3, Step: 1182/2949, Loss: 0.7187\n",
      "Epoch: 3, Step: 1183/2949, Loss: 0.7792\n",
      "Epoch: 3, Step: 1184/2949, Loss: 0.7953\n",
      "Epoch: 3, Step: 1185/2949, Loss: 0.7676\n",
      "Epoch: 3, Step: 1186/2949, Loss: 0.7924\n",
      "Epoch: 3, Step: 1187/2949, Loss: 0.7601\n",
      "Epoch: 3, Step: 1188/2949, Loss: 0.7466\n",
      "Epoch: 3, Step: 1189/2949, Loss: 0.7677\n",
      "Epoch: 3, Step: 1190/2949, Loss: 0.7549\n",
      "Epoch: 3, Step: 1191/2949, Loss: 0.7947\n",
      "Epoch: 3, Step: 1192/2949, Loss: 0.7485\n",
      "Epoch: 3, Step: 1193/2949, Loss: 0.7940\n",
      "Epoch: 3, Step: 1194/2949, Loss: 0.7210\n",
      "Epoch: 3, Step: 1195/2949, Loss: 0.7866\n",
      "Epoch: 3, Step: 1196/2949, Loss: 0.7553\n",
      "Epoch: 3, Step: 1197/2949, Loss: 0.7622\n",
      "Epoch: 3, Step: 1198/2949, Loss: 0.7587\n",
      "Epoch: 3, Step: 1199/2949, Loss: 0.7907\n",
      "Epoch: 3, Step: 1200/2949, Loss: 0.7367\n",
      "Epoch: 3, Step: 1201/2949, Loss: 0.7655\n",
      "Epoch: 3, Step: 1202/2949, Loss: 0.7239\n",
      "Epoch: 3, Step: 1203/2949, Loss: 0.7661\n",
      "Epoch: 3, Step: 1204/2949, Loss: 0.7333\n",
      "Epoch: 3, Step: 1205/2949, Loss: 0.7809\n",
      "Epoch: 3, Step: 1206/2949, Loss: 0.7837\n",
      "Epoch: 3, Step: 1207/2949, Loss: 0.7615\n",
      "Epoch: 3, Step: 1208/2949, Loss: 0.7974\n",
      "Epoch: 3, Step: 1209/2949, Loss: 0.7833\n",
      "Epoch: 3, Step: 1210/2949, Loss: 0.7815\n",
      "Epoch: 3, Step: 1211/2949, Loss: 0.7554\n",
      "Epoch: 3, Step: 1212/2949, Loss: 0.7420\n",
      "Epoch: 3, Step: 1213/2949, Loss: 0.7967\n",
      "Epoch: 3, Step: 1214/2949, Loss: 0.7497\n",
      "Epoch: 3, Step: 1215/2949, Loss: 0.7790\n",
      "Epoch: 3, Step: 1216/2949, Loss: 0.7595\n",
      "Epoch: 3, Step: 1217/2949, Loss: 0.7507\n",
      "Epoch: 3, Step: 1218/2949, Loss: 0.7619\n",
      "Epoch: 3, Step: 1219/2949, Loss: 0.7603\n",
      "Epoch: 3, Step: 1220/2949, Loss: 0.7351\n",
      "Epoch: 3, Step: 1221/2949, Loss: 0.8123\n",
      "Epoch: 3, Step: 1222/2949, Loss: 0.8180\n",
      "Epoch: 3, Step: 1223/2949, Loss: 0.7649\n",
      "Epoch: 3, Step: 1224/2949, Loss: 0.7713\n",
      "Epoch: 3, Step: 1225/2949, Loss: 0.7437\n",
      "Epoch: 3, Step: 1226/2949, Loss: 0.7564\n",
      "Epoch: 3, Step: 1227/2949, Loss: 0.7371\n",
      "Epoch: 3, Step: 1228/2949, Loss: 0.8008\n",
      "Epoch: 3, Step: 1229/2949, Loss: 0.7333\n",
      "Epoch: 3, Step: 1230/2949, Loss: 0.7859\n",
      "Epoch: 3, Step: 1231/2949, Loss: 0.7463\n",
      "Epoch: 3, Step: 1232/2949, Loss: 0.8027\n",
      "Epoch: 3, Step: 1233/2949, Loss: 0.7747\n",
      "Epoch: 3, Step: 1234/2949, Loss: 0.7343\n",
      "Epoch: 3, Step: 1235/2949, Loss: 0.7518\n",
      "Epoch: 3, Step: 1236/2949, Loss: 0.7396\n",
      "Epoch: 3, Step: 1237/2949, Loss: 0.7815\n",
      "Epoch: 3, Step: 1238/2949, Loss: 0.7202\n",
      "Epoch: 3, Step: 1239/2949, Loss: 0.7799\n",
      "Epoch: 3, Step: 1240/2949, Loss: 0.8149\n",
      "Epoch: 3, Step: 1241/2949, Loss: 0.7651\n",
      "Epoch: 3, Step: 1242/2949, Loss: 0.7976\n",
      "Epoch: 3, Step: 1243/2949, Loss: 0.7637\n",
      "Epoch: 3, Step: 1244/2949, Loss: 0.7836\n",
      "Epoch: 3, Step: 1245/2949, Loss: 0.7802\n",
      "Epoch: 3, Step: 1246/2949, Loss: 0.7070\n",
      "Epoch: 3, Step: 1247/2949, Loss: 0.8192\n",
      "Epoch: 3, Step: 1248/2949, Loss: 0.7705\n",
      "Epoch: 3, Step: 1249/2949, Loss: 0.7805\n",
      "Epoch: 3, Step: 1250/2949, Loss: 0.7433\n",
      "Epoch: 3, Step: 1251/2949, Loss: 0.7421\n",
      "Epoch: 3, Step: 1252/2949, Loss: 0.7940\n",
      "Epoch: 3, Step: 1253/2949, Loss: 0.7769\n",
      "Epoch: 3, Step: 1254/2949, Loss: 0.7883\n",
      "Epoch: 3, Step: 1255/2949, Loss: 0.8037\n",
      "Epoch: 3, Step: 1256/2949, Loss: 0.7764\n",
      "Epoch: 3, Step: 1257/2949, Loss: 0.7433\n",
      "Epoch: 3, Step: 1258/2949, Loss: 0.7079\n",
      "Epoch: 3, Step: 1259/2949, Loss: 0.7672\n",
      "Epoch: 3, Step: 1260/2949, Loss: 0.8022\n",
      "Epoch: 3, Step: 1261/2949, Loss: 0.7368\n",
      "Epoch: 3, Step: 1262/2949, Loss: 0.7743\n",
      "Epoch: 3, Step: 1263/2949, Loss: 0.7265\n",
      "Epoch: 3, Step: 1264/2949, Loss: 0.7749\n",
      "Epoch: 3, Step: 1265/2949, Loss: 0.7790\n",
      "Epoch: 3, Step: 1266/2949, Loss: 0.7909\n",
      "Epoch: 3, Step: 1267/2949, Loss: 0.7579\n",
      "Epoch: 3, Step: 1268/2949, Loss: 0.7818\n",
      "Epoch: 3, Step: 1269/2949, Loss: 0.7340\n",
      "Epoch: 3, Step: 1270/2949, Loss: 0.7859\n",
      "Epoch: 3, Step: 1271/2949, Loss: 0.7578\n",
      "Epoch: 3, Step: 1272/2949, Loss: 0.8185\n",
      "Epoch: 3, Step: 1273/2949, Loss: 0.8317\n",
      "Epoch: 3, Step: 1274/2949, Loss: 0.8215\n",
      "Epoch: 3, Step: 1275/2949, Loss: 0.7965\n",
      "Epoch: 3, Step: 1276/2949, Loss: 0.7736\n",
      "Epoch: 3, Step: 1277/2949, Loss: 0.7949\n",
      "Epoch: 3, Step: 1278/2949, Loss: 0.7367\n",
      "Epoch: 3, Step: 1279/2949, Loss: 0.8016\n",
      "Epoch: 3, Step: 1280/2949, Loss: 0.7500\n",
      "Epoch: 3, Step: 1281/2949, Loss: 0.8106\n",
      "Epoch: 3, Step: 1282/2949, Loss: 0.7977\n",
      "Epoch: 3, Step: 1283/2949, Loss: 0.7590\n",
      "Epoch: 3, Step: 1284/2949, Loss: 0.7709\n",
      "Epoch: 3, Step: 1285/2949, Loss: 0.7721\n",
      "Epoch: 3, Step: 1286/2949, Loss: 0.7611\n",
      "Epoch: 3, Step: 1287/2949, Loss: 0.7269\n",
      "Epoch: 3, Step: 1288/2949, Loss: 0.7763\n",
      "Epoch: 3, Step: 1289/2949, Loss: 0.7670\n",
      "Epoch: 3, Step: 1290/2949, Loss: 0.7814\n",
      "Epoch: 3, Step: 1291/2949, Loss: 0.7690\n",
      "Epoch: 3, Step: 1292/2949, Loss: 0.7604\n",
      "Epoch: 3, Step: 1293/2949, Loss: 0.7194\n",
      "Epoch: 3, Step: 1294/2949, Loss: 0.7399\n",
      "Epoch: 3, Step: 1295/2949, Loss: 0.7752\n",
      "Epoch: 3, Step: 1296/2949, Loss: 0.7746\n",
      "Epoch: 3, Step: 1297/2949, Loss: 0.7158\n",
      "Epoch: 3, Step: 1298/2949, Loss: 0.7664\n",
      "Epoch: 3, Step: 1299/2949, Loss: 0.7744\n",
      "Epoch: 3, Step: 1300/2949, Loss: 0.7575\n",
      "Epoch: 3, Step: 1301/2949, Loss: 0.7242\n",
      "Epoch: 3, Step: 1302/2949, Loss: 0.7918\n",
      "Epoch: 3, Step: 1303/2949, Loss: 0.7864\n",
      "Epoch: 3, Step: 1304/2949, Loss: 0.7933\n",
      "Epoch: 3, Step: 1305/2949, Loss: 0.7575\n",
      "Epoch: 3, Step: 1306/2949, Loss: 0.7549\n",
      "Epoch: 3, Step: 1307/2949, Loss: 0.7649\n",
      "Epoch: 3, Step: 1308/2949, Loss: 0.7644\n",
      "Epoch: 3, Step: 1309/2949, Loss: 0.7710\n",
      "Epoch: 3, Step: 1310/2949, Loss: 0.7653\n",
      "Epoch: 3, Step: 1311/2949, Loss: 0.7612\n",
      "Epoch: 3, Step: 1312/2949, Loss: 0.7852\n",
      "Epoch: 3, Step: 1313/2949, Loss: 0.7366\n",
      "Epoch: 3, Step: 1314/2949, Loss: 0.7724\n",
      "Epoch: 3, Step: 1315/2949, Loss: 0.7796\n",
      "Epoch: 3, Step: 1316/2949, Loss: 0.8290\n",
      "Epoch: 3, Step: 1317/2949, Loss: 0.7392\n",
      "Epoch: 3, Step: 1318/2949, Loss: 0.7557\n",
      "Epoch: 3, Step: 1319/2949, Loss: 0.7974\n",
      "Epoch: 3, Step: 1320/2949, Loss: 0.7470\n",
      "Epoch: 3, Step: 1321/2949, Loss: 0.7344\n",
      "Epoch: 3, Step: 1322/2949, Loss: 0.8090\n",
      "Epoch: 3, Step: 1323/2949, Loss: 0.7754\n",
      "Epoch: 3, Step: 1324/2949, Loss: 0.7925\n",
      "Epoch: 3, Step: 1325/2949, Loss: 0.8066\n",
      "Epoch: 3, Step: 1326/2949, Loss: 0.7984\n",
      "Epoch: 3, Step: 1327/2949, Loss: 0.8131\n",
      "Epoch: 3, Step: 1328/2949, Loss: 0.7894\n",
      "Epoch: 3, Step: 1329/2949, Loss: 0.7912\n",
      "Epoch: 3, Step: 1330/2949, Loss: 0.8249\n",
      "Epoch: 3, Step: 1331/2949, Loss: 0.7504\n",
      "Epoch: 3, Step: 1332/2949, Loss: 0.7540\n",
      "Epoch: 3, Step: 1333/2949, Loss: 0.7862\n",
      "Epoch: 3, Step: 1334/2949, Loss: 0.8120\n",
      "Epoch: 3, Step: 1335/2949, Loss: 0.7993\n",
      "Epoch: 3, Step: 1336/2949, Loss: 0.7750\n",
      "Epoch: 3, Step: 1337/2949, Loss: 0.7749\n",
      "Epoch: 3, Step: 1338/2949, Loss: 0.7500\n",
      "Epoch: 3, Step: 1339/2949, Loss: 0.7288\n",
      "Epoch: 3, Step: 1340/2949, Loss: 0.7595\n",
      "Epoch: 3, Step: 1341/2949, Loss: 0.7674\n",
      "Epoch: 3, Step: 1342/2949, Loss: 0.7533\n",
      "Epoch: 3, Step: 1343/2949, Loss: 0.7758\n",
      "Epoch: 3, Step: 1344/2949, Loss: 0.7655\n",
      "Epoch: 3, Step: 1345/2949, Loss: 0.8050\n",
      "Epoch: 3, Step: 1346/2949, Loss: 0.7989\n",
      "Epoch: 3, Step: 1347/2949, Loss: 0.7521\n",
      "Epoch: 3, Step: 1348/2949, Loss: 0.8200\n",
      "Epoch: 3, Step: 1349/2949, Loss: 0.7750\n",
      "Epoch: 3, Step: 1350/2949, Loss: 0.7595\n",
      "Epoch: 3, Step: 1351/2949, Loss: 0.7519\n",
      "Epoch: 3, Step: 1352/2949, Loss: 0.7370\n",
      "Epoch: 3, Step: 1353/2949, Loss: 0.7516\n",
      "Epoch: 3, Step: 1354/2949, Loss: 0.7958\n",
      "Epoch: 3, Step: 1355/2949, Loss: 0.7393\n",
      "Epoch: 3, Step: 1356/2949, Loss: 0.7618\n",
      "Epoch: 3, Step: 1357/2949, Loss: 0.7942\n",
      "Epoch: 3, Step: 1358/2949, Loss: 0.7456\n",
      "Epoch: 3, Step: 1359/2949, Loss: 0.7667\n",
      "Epoch: 3, Step: 1360/2949, Loss: 0.7831\n",
      "Epoch: 3, Step: 1361/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 1362/2949, Loss: 0.7293\n",
      "Epoch: 3, Step: 1363/2949, Loss: 0.8044\n",
      "Epoch: 3, Step: 1364/2949, Loss: 0.7525\n",
      "Epoch: 3, Step: 1365/2949, Loss: 0.7736\n",
      "Epoch: 3, Step: 1366/2949, Loss: 0.7907\n",
      "Epoch: 3, Step: 1367/2949, Loss: 0.7876\n",
      "Epoch: 3, Step: 1368/2949, Loss: 0.7836\n",
      "Epoch: 3, Step: 1369/2949, Loss: 0.7021\n",
      "Epoch: 3, Step: 1370/2949, Loss: 0.8207\n",
      "Epoch: 3, Step: 1371/2949, Loss: 0.7783\n",
      "Epoch: 3, Step: 1372/2949, Loss: 0.8034\n",
      "Epoch: 3, Step: 1373/2949, Loss: 0.7879\n",
      "Epoch: 3, Step: 1374/2949, Loss: 0.8337\n",
      "Epoch: 3, Step: 1375/2949, Loss: 0.8033\n",
      "Epoch: 3, Step: 1376/2949, Loss: 0.7962\n",
      "Epoch: 3, Step: 1377/2949, Loss: 0.7480\n",
      "Epoch: 3, Step: 1378/2949, Loss: 0.7513\n",
      "Epoch: 3, Step: 1379/2949, Loss: 0.7805\n",
      "Epoch: 3, Step: 1380/2949, Loss: 0.7232\n",
      "Epoch: 3, Step: 1381/2949, Loss: 0.7709\n",
      "Epoch: 3, Step: 1382/2949, Loss: 0.7409\n",
      "Epoch: 3, Step: 1383/2949, Loss: 0.7425\n",
      "Epoch: 3, Step: 1384/2949, Loss: 0.8280\n",
      "Epoch: 3, Step: 1385/2949, Loss: 0.7382\n",
      "Epoch: 3, Step: 1386/2949, Loss: 0.7973\n",
      "Epoch: 3, Step: 1387/2949, Loss: 0.7165\n",
      "Epoch: 3, Step: 1388/2949, Loss: 0.7914\n",
      "Epoch: 3, Step: 1389/2949, Loss: 0.7391\n",
      "Epoch: 3, Step: 1390/2949, Loss: 0.7291\n",
      "Epoch: 3, Step: 1391/2949, Loss: 0.7641\n",
      "Epoch: 3, Step: 1392/2949, Loss: 0.7850\n",
      "Epoch: 3, Step: 1393/2949, Loss: 0.7751\n",
      "Epoch: 3, Step: 1394/2949, Loss: 0.7741\n",
      "Epoch: 3, Step: 1395/2949, Loss: 0.7956\n",
      "Epoch: 3, Step: 1396/2949, Loss: 0.7578\n",
      "Epoch: 3, Step: 1397/2949, Loss: 0.7567\n",
      "Epoch: 3, Step: 1398/2949, Loss: 0.7254\n",
      "Epoch: 3, Step: 1399/2949, Loss: 0.7854\n",
      "Epoch: 3, Step: 1400/2949, Loss: 0.7520\n",
      "Epoch: 3, Step: 1401/2949, Loss: 0.7732\n",
      "Epoch: 3, Step: 1402/2949, Loss: 0.7396\n",
      "Epoch: 3, Step: 1403/2949, Loss: 0.7652\n",
      "Epoch: 3, Step: 1404/2949, Loss: 0.7402\n",
      "Epoch: 3, Step: 1405/2949, Loss: 0.7878\n",
      "Epoch: 3, Step: 1406/2949, Loss: 0.7296\n",
      "Epoch: 3, Step: 1407/2949, Loss: 0.8117\n",
      "Epoch: 3, Step: 1408/2949, Loss: 0.7592\n",
      "Epoch: 3, Step: 1409/2949, Loss: 0.7782\n",
      "Epoch: 3, Step: 1410/2949, Loss: 0.7721\n",
      "Epoch: 3, Step: 1411/2949, Loss: 0.7414\n",
      "Epoch: 3, Step: 1412/2949, Loss: 0.8007\n",
      "Epoch: 3, Step: 1413/2949, Loss: 0.7839\n",
      "Epoch: 3, Step: 1414/2949, Loss: 0.7830\n",
      "Epoch: 3, Step: 1415/2949, Loss: 0.7692\n",
      "Epoch: 3, Step: 1416/2949, Loss: 0.7315\n",
      "Epoch: 3, Step: 1417/2949, Loss: 0.7930\n",
      "Epoch: 3, Step: 1418/2949, Loss: 0.7537\n",
      "Epoch: 3, Step: 1419/2949, Loss: 0.7839\n",
      "Epoch: 3, Step: 1420/2949, Loss: 0.7794\n",
      "Epoch: 3, Step: 1421/2949, Loss: 0.7586\n",
      "Epoch: 3, Step: 1422/2949, Loss: 0.7315\n",
      "Epoch: 3, Step: 1423/2949, Loss: 0.7897\n",
      "Epoch: 3, Step: 1424/2949, Loss: 0.7943\n",
      "Epoch: 3, Step: 1425/2949, Loss: 0.8005\n",
      "Epoch: 3, Step: 1426/2949, Loss: 0.7721\n",
      "Epoch: 3, Step: 1427/2949, Loss: 0.8404\n",
      "Epoch: 3, Step: 1428/2949, Loss: 0.7787\n",
      "Epoch: 3, Step: 1429/2949, Loss: 0.8356\n",
      "Epoch: 3, Step: 1430/2949, Loss: 0.7759\n",
      "Epoch: 3, Step: 1431/2949, Loss: 0.7387\n",
      "Epoch: 3, Step: 1432/2949, Loss: 0.7775\n",
      "Epoch: 3, Step: 1433/2949, Loss: 0.7902\n",
      "Epoch: 3, Step: 1434/2949, Loss: 0.7616\n",
      "Epoch: 3, Step: 1435/2949, Loss: 0.7648\n",
      "Epoch: 3, Step: 1436/2949, Loss: 0.7261\n",
      "Epoch: 3, Step: 1437/2949, Loss: 0.7854\n",
      "Epoch: 3, Step: 1438/2949, Loss: 0.7651\n",
      "Epoch: 3, Step: 1439/2949, Loss: 0.8007\n",
      "Epoch: 3, Step: 1440/2949, Loss: 0.7644\n",
      "Epoch: 3, Step: 1441/2949, Loss: 0.7992\n",
      "Epoch: 3, Step: 1442/2949, Loss: 0.7662\n",
      "Epoch: 3, Step: 1443/2949, Loss: 0.7862\n",
      "Epoch: 3, Step: 1444/2949, Loss: 0.7593\n",
      "Epoch: 3, Step: 1445/2949, Loss: 0.7616\n",
      "Epoch: 3, Step: 1446/2949, Loss: 0.7755\n",
      "Epoch: 3, Step: 1447/2949, Loss: 0.7329\n",
      "Epoch: 3, Step: 1448/2949, Loss: 0.7513\n",
      "Epoch: 3, Step: 1449/2949, Loss: 0.7392\n",
      "Epoch: 3, Step: 1450/2949, Loss: 0.7416\n",
      "Epoch: 3, Step: 1451/2949, Loss: 0.7699\n",
      "Epoch: 3, Step: 1452/2949, Loss: 0.8087\n",
      "Epoch: 3, Step: 1453/2949, Loss: 0.8095\n",
      "Epoch: 3, Step: 1454/2949, Loss: 0.7912\n",
      "Epoch: 3, Step: 1455/2949, Loss: 0.7779\n",
      "Epoch: 3, Step: 1456/2949, Loss: 0.7622\n",
      "Epoch: 3, Step: 1457/2949, Loss: 0.7636\n",
      "Epoch: 3, Step: 1458/2949, Loss: 0.7023\n",
      "Epoch: 3, Step: 1459/2949, Loss: 0.7474\n",
      "Epoch: 3, Step: 1460/2949, Loss: 0.7912\n",
      "Epoch: 3, Step: 1461/2949, Loss: 0.8157\n",
      "Epoch: 3, Step: 1462/2949, Loss: 0.7533\n",
      "Epoch: 3, Step: 1463/2949, Loss: 0.7593\n",
      "Epoch: 3, Step: 1464/2949, Loss: 0.7609\n",
      "Epoch: 3, Step: 1465/2949, Loss: 0.7755\n",
      "Epoch: 3, Step: 1466/2949, Loss: 0.8009\n",
      "Epoch: 3, Step: 1467/2949, Loss: 0.7357\n",
      "Epoch: 3, Step: 1468/2949, Loss: 0.7124\n",
      "Epoch: 3, Step: 1469/2949, Loss: 0.8015\n",
      "Epoch: 3, Step: 1470/2949, Loss: 0.7724\n",
      "Epoch: 3, Step: 1471/2949, Loss: 0.7453\n",
      "Epoch: 3, Step: 1472/2949, Loss: 0.8122\n",
      "Epoch: 3, Step: 1473/2949, Loss: 0.8176\n",
      "Epoch: 3, Step: 1474/2949, Loss: 0.7503\n",
      "Epoch: 3, Step: 1475/2949, Loss: 0.7826\n",
      "Epoch: 3, Step: 1476/2949, Loss: 0.7870\n",
      "Epoch: 3, Step: 1477/2949, Loss: 0.7836\n",
      "Epoch: 3, Step: 1478/2949, Loss: 0.7712\n",
      "Epoch: 3, Step: 1479/2949, Loss: 0.7847\n",
      "Epoch: 3, Step: 1480/2949, Loss: 0.7584\n",
      "Epoch: 3, Step: 1481/2949, Loss: 0.7684\n",
      "Epoch: 3, Step: 1482/2949, Loss: 0.7273\n",
      "Epoch: 3, Step: 1483/2949, Loss: 0.7666\n",
      "Epoch: 3, Step: 1484/2949, Loss: 0.8056\n",
      "Epoch: 3, Step: 1485/2949, Loss: 0.8202\n",
      "Epoch: 3, Step: 1486/2949, Loss: 0.7709\n",
      "Epoch: 3, Step: 1487/2949, Loss: 0.7205\n",
      "Epoch: 3, Step: 1488/2949, Loss: 0.7641\n",
      "Epoch: 3, Step: 1489/2949, Loss: 0.7748\n",
      "Epoch: 3, Step: 1490/2949, Loss: 0.7818\n",
      "Epoch: 3, Step: 1491/2949, Loss: 0.8047\n",
      "Epoch: 3, Step: 1492/2949, Loss: 0.7935\n",
      "Epoch: 3, Step: 1493/2949, Loss: 0.7488\n",
      "Epoch: 3, Step: 1494/2949, Loss: 0.7862\n",
      "Epoch: 3, Step: 1495/2949, Loss: 0.8254\n",
      "Epoch: 3, Step: 1496/2949, Loss: 0.7812\n",
      "Epoch: 3, Step: 1497/2949, Loss: 0.7518\n",
      "Epoch: 3, Step: 1498/2949, Loss: 0.8129\n",
      "Epoch: 3, Step: 1499/2949, Loss: 0.7272\n",
      "Epoch: 3, Step: 1500/2949, Loss: 0.7924\n",
      "Epoch: 3, Step: 1501/2949, Loss: 0.7558\n",
      "Epoch: 3, Step: 1502/2949, Loss: 0.7470\n",
      "Epoch: 3, Step: 1503/2949, Loss: 0.7582\n",
      "Epoch: 3, Step: 1504/2949, Loss: 0.7597\n",
      "Epoch: 3, Step: 1505/2949, Loss: 0.8148\n",
      "Epoch: 3, Step: 1506/2949, Loss: 0.7345\n",
      "Epoch: 3, Step: 1507/2949, Loss: 0.7722\n",
      "Epoch: 3, Step: 1508/2949, Loss: 0.7764\n",
      "Epoch: 3, Step: 1509/2949, Loss: 0.7957\n",
      "Epoch: 3, Step: 1510/2949, Loss: 0.7809\n",
      "Epoch: 3, Step: 1511/2949, Loss: 0.7654\n",
      "Epoch: 3, Step: 1512/2949, Loss: 0.7850\n",
      "Epoch: 3, Step: 1513/2949, Loss: 0.7342\n",
      "Epoch: 3, Step: 1514/2949, Loss: 0.7837\n",
      "Epoch: 3, Step: 1515/2949, Loss: 0.7700\n",
      "Epoch: 3, Step: 1516/2949, Loss: 0.7040\n",
      "Epoch: 3, Step: 1517/2949, Loss: 0.8123\n",
      "Epoch: 3, Step: 1518/2949, Loss: 0.8014\n",
      "Epoch: 3, Step: 1519/2949, Loss: 0.7672\n",
      "Epoch: 3, Step: 1520/2949, Loss: 0.7629\n",
      "Epoch: 3, Step: 1521/2949, Loss: 0.7664\n",
      "Epoch: 3, Step: 1522/2949, Loss: 0.7375\n",
      "Epoch: 3, Step: 1523/2949, Loss: 0.7340\n",
      "Epoch: 3, Step: 1524/2949, Loss: 0.7397\n",
      "Epoch: 3, Step: 1525/2949, Loss: 0.7066\n",
      "Epoch: 3, Step: 1526/2949, Loss: 0.7663\n",
      "Epoch: 3, Step: 1527/2949, Loss: 0.7728\n",
      "Epoch: 3, Step: 1528/2949, Loss: 0.7957\n",
      "Epoch: 3, Step: 1529/2949, Loss: 0.7636\n",
      "Epoch: 3, Step: 1530/2949, Loss: 0.7551\n",
      "Epoch: 3, Step: 1531/2949, Loss: 0.7956\n",
      "Epoch: 3, Step: 1532/2949, Loss: 0.7889\n",
      "Epoch: 3, Step: 1533/2949, Loss: 0.7946\n",
      "Epoch: 3, Step: 1534/2949, Loss: 0.7581\n",
      "Epoch: 3, Step: 1535/2949, Loss: 0.6784\n",
      "Epoch: 3, Step: 1536/2949, Loss: 0.7474\n",
      "Epoch: 3, Step: 1537/2949, Loss: 0.8160\n",
      "Epoch: 3, Step: 1538/2949, Loss: 0.7376\n",
      "Epoch: 3, Step: 1539/2949, Loss: 0.7766\n",
      "Epoch: 3, Step: 1540/2949, Loss: 0.7409\n",
      "Epoch: 3, Step: 1541/2949, Loss: 0.7449\n",
      "Epoch: 3, Step: 1542/2949, Loss: 0.8251\n",
      "Epoch: 3, Step: 1543/2949, Loss: 0.7511\n",
      "Epoch: 3, Step: 1544/2949, Loss: 0.7517\n",
      "Epoch: 3, Step: 1545/2949, Loss: 0.7966\n",
      "Epoch: 3, Step: 1546/2949, Loss: 0.8051\n",
      "Epoch: 3, Step: 1547/2949, Loss: 0.7501\n",
      "Epoch: 3, Step: 1548/2949, Loss: 0.7566\n",
      "Epoch: 3, Step: 1549/2949, Loss: 0.7231\n",
      "Epoch: 3, Step: 1550/2949, Loss: 0.7930\n",
      "Epoch: 3, Step: 1551/2949, Loss: 0.7795\n",
      "Epoch: 3, Step: 1552/2949, Loss: 0.7866\n",
      "Epoch: 3, Step: 1553/2949, Loss: 0.7962\n",
      "Epoch: 3, Step: 1554/2949, Loss: 0.7858\n",
      "Epoch: 3, Step: 1555/2949, Loss: 0.7326\n",
      "Epoch: 3, Step: 1556/2949, Loss: 0.7535\n",
      "Epoch: 3, Step: 1557/2949, Loss: 0.7670\n",
      "Epoch: 3, Step: 1558/2949, Loss: 0.7971\n",
      "Epoch: 3, Step: 1559/2949, Loss: 0.7922\n",
      "Epoch: 3, Step: 1560/2949, Loss: 0.7504\n",
      "Epoch: 3, Step: 1561/2949, Loss: 0.7715\n",
      "Epoch: 3, Step: 1562/2949, Loss: 0.7567\n",
      "Epoch: 3, Step: 1563/2949, Loss: 0.7604\n",
      "Epoch: 3, Step: 1564/2949, Loss: 0.7924\n",
      "Epoch: 3, Step: 1565/2949, Loss: 0.7732\n",
      "Epoch: 3, Step: 1566/2949, Loss: 0.8005\n",
      "Epoch: 3, Step: 1567/2949, Loss: 0.7783\n",
      "Epoch: 3, Step: 1568/2949, Loss: 0.8155\n",
      "Epoch: 3, Step: 1569/2949, Loss: 0.7805\n",
      "Epoch: 3, Step: 1570/2949, Loss: 0.7219\n",
      "Epoch: 3, Step: 1571/2949, Loss: 0.7520\n",
      "Epoch: 3, Step: 1572/2949, Loss: 0.7663\n",
      "Epoch: 3, Step: 1573/2949, Loss: 0.7705\n",
      "Epoch: 3, Step: 1574/2949, Loss: 0.7844\n",
      "Epoch: 3, Step: 1575/2949, Loss: 0.7579\n",
      "Epoch: 3, Step: 1576/2949, Loss: 0.8222\n",
      "Epoch: 3, Step: 1577/2949, Loss: 0.8024\n",
      "Epoch: 3, Step: 1578/2949, Loss: 0.7239\n",
      "Epoch: 3, Step: 1579/2949, Loss: 0.7967\n",
      "Epoch: 3, Step: 1580/2949, Loss: 0.7535\n",
      "Epoch: 3, Step: 1581/2949, Loss: 0.7766\n",
      "Epoch: 3, Step: 1582/2949, Loss: 0.8206\n",
      "Epoch: 3, Step: 1583/2949, Loss: 0.7509\n",
      "Epoch: 3, Step: 1584/2949, Loss: 0.7620\n",
      "Epoch: 3, Step: 1585/2949, Loss: 0.7490\n",
      "Epoch: 3, Step: 1586/2949, Loss: 0.7827\n",
      "Epoch: 3, Step: 1587/2949, Loss: 0.7562\n",
      "Epoch: 3, Step: 1588/2949, Loss: 0.7323\n",
      "Epoch: 3, Step: 1589/2949, Loss: 0.8074\n",
      "Epoch: 3, Step: 1590/2949, Loss: 0.7506\n",
      "Epoch: 3, Step: 1591/2949, Loss: 0.7399\n",
      "Epoch: 3, Step: 1592/2949, Loss: 0.7925\n",
      "Epoch: 3, Step: 1593/2949, Loss: 0.7914\n",
      "Epoch: 3, Step: 1594/2949, Loss: 0.7452\n",
      "Epoch: 3, Step: 1595/2949, Loss: 0.8035\n",
      "Epoch: 3, Step: 1596/2949, Loss: 0.7727\n",
      "Epoch: 3, Step: 1597/2949, Loss: 0.7965\n",
      "Epoch: 3, Step: 1598/2949, Loss: 0.7992\n",
      "Epoch: 3, Step: 1599/2949, Loss: 0.7820\n",
      "Epoch: 3, Step: 1600/2949, Loss: 0.7787\n",
      "Epoch: 3, Step: 1601/2949, Loss: 0.7532\n",
      "Epoch: 3, Step: 1602/2949, Loss: 0.8110\n",
      "Epoch: 3, Step: 1603/2949, Loss: 0.7860\n",
      "Epoch: 3, Step: 1604/2949, Loss: 0.8552\n",
      "Epoch: 3, Step: 1605/2949, Loss: 0.8112\n",
      "Epoch: 3, Step: 1606/2949, Loss: 0.7377\n",
      "Epoch: 3, Step: 1607/2949, Loss: 0.7287\n",
      "Epoch: 3, Step: 1608/2949, Loss: 0.7675\n",
      "Epoch: 3, Step: 1609/2949, Loss: 0.7368\n",
      "Epoch: 3, Step: 1610/2949, Loss: 0.7979\n",
      "Epoch: 3, Step: 1611/2949, Loss: 0.7692\n",
      "Epoch: 3, Step: 1612/2949, Loss: 0.7255\n",
      "Epoch: 3, Step: 1613/2949, Loss: 0.8092\n",
      "Epoch: 3, Step: 1614/2949, Loss: 0.7322\n",
      "Epoch: 3, Step: 1615/2949, Loss: 0.7366\n",
      "Epoch: 3, Step: 1616/2949, Loss: 0.7326\n",
      "Epoch: 3, Step: 1617/2949, Loss: 0.7221\n",
      "Epoch: 3, Step: 1618/2949, Loss: 0.7439\n",
      "Epoch: 3, Step: 1619/2949, Loss: 0.7429\n",
      "Epoch: 3, Step: 1620/2949, Loss: 0.7787\n",
      "Epoch: 3, Step: 1621/2949, Loss: 0.8140\n",
      "Epoch: 3, Step: 1622/2949, Loss: 0.8045\n",
      "Epoch: 3, Step: 1623/2949, Loss: 0.7614\n",
      "Epoch: 3, Step: 1624/2949, Loss: 0.7801\n",
      "Epoch: 3, Step: 1625/2949, Loss: 0.8005\n",
      "Epoch: 3, Step: 1626/2949, Loss: 0.8388\n",
      "Epoch: 3, Step: 1627/2949, Loss: 0.7348\n",
      "Epoch: 3, Step: 1628/2949, Loss: 0.7761\n",
      "Epoch: 3, Step: 1629/2949, Loss: 0.7696\n",
      "Epoch: 3, Step: 1630/2949, Loss: 0.8027\n",
      "Epoch: 3, Step: 1631/2949, Loss: 0.7601\n",
      "Epoch: 3, Step: 1632/2949, Loss: 0.7930\n",
      "Epoch: 3, Step: 1633/2949, Loss: 0.7798\n",
      "Epoch: 3, Step: 1634/2949, Loss: 0.7471\n",
      "Epoch: 3, Step: 1635/2949, Loss: 0.7775\n",
      "Epoch: 3, Step: 1636/2949, Loss: 0.8131\n",
      "Epoch: 3, Step: 1637/2949, Loss: 0.7481\n",
      "Epoch: 3, Step: 1638/2949, Loss: 0.7283\n",
      "Epoch: 3, Step: 1639/2949, Loss: 0.7751\n",
      "Epoch: 3, Step: 1640/2949, Loss: 0.7552\n",
      "Epoch: 3, Step: 1641/2949, Loss: 0.8116\n",
      "Epoch: 3, Step: 1642/2949, Loss: 0.7591\n",
      "Epoch: 3, Step: 1643/2949, Loss: 0.7824\n",
      "Epoch: 3, Step: 1644/2949, Loss: 0.8171\n",
      "Epoch: 3, Step: 1645/2949, Loss: 0.7217\n",
      "Epoch: 3, Step: 1646/2949, Loss: 0.6604\n",
      "Epoch: 3, Step: 1647/2949, Loss: 0.7505\n",
      "Epoch: 3, Step: 1648/2949, Loss: 0.8112\n",
      "Epoch: 3, Step: 1649/2949, Loss: 0.7619\n",
      "Epoch: 3, Step: 1650/2949, Loss: 0.7354\n",
      "Epoch: 3, Step: 1651/2949, Loss: 0.7675\n",
      "Epoch: 3, Step: 1652/2949, Loss: 0.7987\n",
      "Epoch: 3, Step: 1653/2949, Loss: 0.7685\n",
      "Epoch: 3, Step: 1654/2949, Loss: 0.7100\n",
      "Epoch: 3, Step: 1655/2949, Loss: 0.7846\n",
      "Epoch: 3, Step: 1656/2949, Loss: 0.7795\n",
      "Epoch: 3, Step: 1657/2949, Loss: 0.7639\n",
      "Epoch: 3, Step: 1658/2949, Loss: 0.7945\n",
      "Epoch: 3, Step: 1659/2949, Loss: 0.7406\n",
      "Epoch: 3, Step: 1660/2949, Loss: 0.7619\n",
      "Epoch: 3, Step: 1661/2949, Loss: 0.7879\n",
      "Epoch: 3, Step: 1662/2949, Loss: 0.7531\n",
      "Epoch: 3, Step: 1663/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 1664/2949, Loss: 0.8035\n",
      "Epoch: 3, Step: 1665/2949, Loss: 0.7685\n",
      "Epoch: 3, Step: 1666/2949, Loss: 0.7732\n",
      "Epoch: 3, Step: 1667/2949, Loss: 0.8371\n",
      "Epoch: 3, Step: 1668/2949, Loss: 0.8029\n",
      "Epoch: 3, Step: 1669/2949, Loss: 0.7415\n",
      "Epoch: 3, Step: 1670/2949, Loss: 0.7550\n",
      "Epoch: 3, Step: 1671/2949, Loss: 0.7747\n",
      "Epoch: 3, Step: 1672/2949, Loss: 0.8252\n",
      "Epoch: 3, Step: 1673/2949, Loss: 0.7798\n",
      "Epoch: 3, Step: 1674/2949, Loss: 0.7428\n",
      "Epoch: 3, Step: 1675/2949, Loss: 0.7420\n",
      "Epoch: 3, Step: 1676/2949, Loss: 0.7777\n",
      "Epoch: 3, Step: 1677/2949, Loss: 0.7676\n",
      "Epoch: 3, Step: 1678/2949, Loss: 0.7525\n",
      "Epoch: 3, Step: 1679/2949, Loss: 0.8022\n",
      "Epoch: 3, Step: 1680/2949, Loss: 0.7411\n",
      "Epoch: 3, Step: 1681/2949, Loss: 0.7574\n",
      "Epoch: 3, Step: 1682/2949, Loss: 0.8256\n",
      "Epoch: 3, Step: 1683/2949, Loss: 0.7644\n",
      "Epoch: 3, Step: 1684/2949, Loss: 0.7786\n",
      "Epoch: 3, Step: 1685/2949, Loss: 0.7885\n",
      "Epoch: 3, Step: 1686/2949, Loss: 0.7478\n",
      "Epoch: 3, Step: 1687/2949, Loss: 0.7544\n",
      "Epoch: 3, Step: 1688/2949, Loss: 0.7677\n",
      "Epoch: 3, Step: 1689/2949, Loss: 0.7738\n",
      "Epoch: 3, Step: 1690/2949, Loss: 0.7252\n",
      "Epoch: 3, Step: 1691/2949, Loss: 0.8193\n",
      "Epoch: 3, Step: 1692/2949, Loss: 0.7522\n",
      "Epoch: 3, Step: 1693/2949, Loss: 0.7186\n",
      "Epoch: 3, Step: 1694/2949, Loss: 0.7495\n",
      "Epoch: 3, Step: 1695/2949, Loss: 0.8096\n",
      "Epoch: 3, Step: 1696/2949, Loss: 0.7697\n",
      "Epoch: 3, Step: 1697/2949, Loss: 0.7936\n",
      "Epoch: 3, Step: 1698/2949, Loss: 0.7887\n",
      "Epoch: 3, Step: 1699/2949, Loss: 0.7646\n",
      "Epoch: 3, Step: 1700/2949, Loss: 0.7785\n",
      "Epoch: 3, Step: 1701/2949, Loss: 0.7810\n",
      "Epoch: 3, Step: 1702/2949, Loss: 0.8421\n",
      "Epoch: 3, Step: 1703/2949, Loss: 0.7752\n",
      "Epoch: 3, Step: 1704/2949, Loss: 0.7764\n",
      "Epoch: 3, Step: 1705/2949, Loss: 0.7043\n",
      "Epoch: 3, Step: 1706/2949, Loss: 0.7627\n",
      "Epoch: 3, Step: 1707/2949, Loss: 0.7485\n",
      "Epoch: 3, Step: 1708/2949, Loss: 0.7615\n",
      "Epoch: 3, Step: 1709/2949, Loss: 0.7261\n",
      "Epoch: 3, Step: 1710/2949, Loss: 0.7630\n",
      "Epoch: 3, Step: 1711/2949, Loss: 0.7849\n",
      "Epoch: 3, Step: 1712/2949, Loss: 0.7467\n",
      "Epoch: 3, Step: 1713/2949, Loss: 0.7586\n",
      "Epoch: 3, Step: 1714/2949, Loss: 0.7935\n",
      "Epoch: 3, Step: 1715/2949, Loss: 0.7698\n",
      "Epoch: 3, Step: 1716/2949, Loss: 0.7745\n",
      "Epoch: 3, Step: 1717/2949, Loss: 0.7854\n",
      "Epoch: 3, Step: 1718/2949, Loss: 0.7791\n",
      "Epoch: 3, Step: 1719/2949, Loss: 0.7784\n",
      "Epoch: 3, Step: 1720/2949, Loss: 0.7708\n",
      "Epoch: 3, Step: 1721/2949, Loss: 0.7773\n",
      "Epoch: 3, Step: 1722/2949, Loss: 0.7677\n",
      "Epoch: 3, Step: 1723/2949, Loss: 0.8194\n",
      "Epoch: 3, Step: 1724/2949, Loss: 0.7827\n",
      "Epoch: 3, Step: 1725/2949, Loss: 0.7330\n",
      "Epoch: 3, Step: 1726/2949, Loss: 0.8098\n",
      "Epoch: 3, Step: 1727/2949, Loss: 0.7450\n",
      "Epoch: 3, Step: 1728/2949, Loss: 0.7489\n",
      "Epoch: 3, Step: 1729/2949, Loss: 0.7314\n",
      "Epoch: 3, Step: 1730/2949, Loss: 0.7644\n",
      "Epoch: 3, Step: 1731/2949, Loss: 0.7829\n",
      "Epoch: 3, Step: 1732/2949, Loss: 0.7910\n",
      "Epoch: 3, Step: 1733/2949, Loss: 0.7450\n",
      "Epoch: 3, Step: 1734/2949, Loss: 0.7485\n",
      "Epoch: 3, Step: 1735/2949, Loss: 0.7911\n",
      "Epoch: 3, Step: 1736/2949, Loss: 0.7701\n",
      "Epoch: 3, Step: 1737/2949, Loss: 0.7733\n",
      "Epoch: 3, Step: 1738/2949, Loss: 0.8199\n",
      "Epoch: 3, Step: 1739/2949, Loss: 0.7679\n",
      "Epoch: 3, Step: 1740/2949, Loss: 0.7492\n",
      "Epoch: 3, Step: 1741/2949, Loss: 0.7671\n",
      "Epoch: 3, Step: 1742/2949, Loss: 0.7498\n",
      "Epoch: 3, Step: 1743/2949, Loss: 0.7638\n",
      "Epoch: 3, Step: 1744/2949, Loss: 0.8100\n",
      "Epoch: 3, Step: 1745/2949, Loss: 0.7923\n",
      "Epoch: 3, Step: 1746/2949, Loss: 0.7815\n",
      "Epoch: 3, Step: 1747/2949, Loss: 0.7905\n",
      "Epoch: 3, Step: 1748/2949, Loss: 0.8002\n",
      "Epoch: 3, Step: 1749/2949, Loss: 0.8088\n",
      "Epoch: 3, Step: 1750/2949, Loss: 0.7367\n",
      "Epoch: 3, Step: 1751/2949, Loss: 0.7604\n",
      "Epoch: 3, Step: 1752/2949, Loss: 0.6944\n",
      "Epoch: 3, Step: 1753/2949, Loss: 0.7296\n",
      "Epoch: 3, Step: 1754/2949, Loss: 0.7497\n",
      "Epoch: 3, Step: 1755/2949, Loss: 0.7671\n",
      "Epoch: 3, Step: 1756/2949, Loss: 0.7933\n",
      "Epoch: 3, Step: 1757/2949, Loss: 0.7653\n",
      "Epoch: 3, Step: 1758/2949, Loss: 0.7620\n",
      "Epoch: 3, Step: 1759/2949, Loss: 0.8150\n",
      "Epoch: 3, Step: 1760/2949, Loss: 0.7767\n",
      "Epoch: 3, Step: 1761/2949, Loss: 0.7371\n",
      "Epoch: 3, Step: 1762/2949, Loss: 0.7467\n",
      "Epoch: 3, Step: 1763/2949, Loss: 0.7475\n",
      "Epoch: 3, Step: 1764/2949, Loss: 0.7907\n",
      "Epoch: 3, Step: 1765/2949, Loss: 0.7457\n",
      "Epoch: 3, Step: 1766/2949, Loss: 0.7549\n",
      "Epoch: 3, Step: 1767/2949, Loss: 0.7331\n",
      "Epoch: 3, Step: 1768/2949, Loss: 0.7995\n",
      "Epoch: 3, Step: 1769/2949, Loss: 0.7545\n",
      "Epoch: 3, Step: 1770/2949, Loss: 0.7695\n",
      "Epoch: 3, Step: 1771/2949, Loss: 0.7567\n",
      "Epoch: 3, Step: 1772/2949, Loss: 0.7840\n",
      "Epoch: 3, Step: 1773/2949, Loss: 0.8041\n",
      "Epoch: 3, Step: 1774/2949, Loss: 0.7299\n",
      "Epoch: 3, Step: 1775/2949, Loss: 0.7688\n",
      "Epoch: 3, Step: 1776/2949, Loss: 0.7503\n",
      "Epoch: 3, Step: 1777/2949, Loss: 0.7259\n",
      "Epoch: 3, Step: 1778/2949, Loss: 0.7545\n",
      "Epoch: 3, Step: 1779/2949, Loss: 0.7907\n",
      "Epoch: 3, Step: 1780/2949, Loss: 0.7361\n",
      "Epoch: 3, Step: 1781/2949, Loss: 0.7680\n",
      "Epoch: 3, Step: 1782/2949, Loss: 0.7454\n",
      "Epoch: 3, Step: 1783/2949, Loss: 0.7283\n",
      "Epoch: 3, Step: 1784/2949, Loss: 0.8080\n",
      "Epoch: 3, Step: 1785/2949, Loss: 0.7545\n",
      "Epoch: 3, Step: 1786/2949, Loss: 0.8255\n",
      "Epoch: 3, Step: 1787/2949, Loss: 0.7059\n",
      "Epoch: 3, Step: 1788/2949, Loss: 0.8188\n",
      "Epoch: 3, Step: 1789/2949, Loss: 0.7302\n",
      "Epoch: 3, Step: 1790/2949, Loss: 0.7402\n",
      "Epoch: 3, Step: 1791/2949, Loss: 0.7710\n",
      "Epoch: 3, Step: 1792/2949, Loss: 0.8131\n",
      "Epoch: 3, Step: 1793/2949, Loss: 0.7978\n",
      "Epoch: 3, Step: 1794/2949, Loss: 0.8266\n",
      "Epoch: 3, Step: 1795/2949, Loss: 0.7673\n",
      "Epoch: 3, Step: 1796/2949, Loss: 0.7772\n",
      "Epoch: 3, Step: 1797/2949, Loss: 0.7691\n",
      "Epoch: 3, Step: 1798/2949, Loss: 0.7883\n",
      "Epoch: 3, Step: 1799/2949, Loss: 0.7875\n",
      "Epoch: 3, Step: 1800/2949, Loss: 0.7854\n",
      "Epoch: 3, Step: 1801/2949, Loss: 0.7418\n",
      "Epoch: 3, Step: 1802/2949, Loss: 0.7447\n",
      "Epoch: 3, Step: 1803/2949, Loss: 0.7728\n",
      "Epoch: 3, Step: 1804/2949, Loss: 0.7577\n",
      "Epoch: 3, Step: 1805/2949, Loss: 0.7894\n",
      "Epoch: 3, Step: 1806/2949, Loss: 0.8029\n",
      "Epoch: 3, Step: 1807/2949, Loss: 0.8179\n",
      "Epoch: 3, Step: 1808/2949, Loss: 0.7670\n",
      "Epoch: 3, Step: 1809/2949, Loss: 0.7734\n",
      "Epoch: 3, Step: 1810/2949, Loss: 0.7557\n",
      "Epoch: 3, Step: 1811/2949, Loss: 0.7765\n",
      "Epoch: 3, Step: 1812/2949, Loss: 0.7358\n",
      "Epoch: 3, Step: 1813/2949, Loss: 0.8072\n",
      "Epoch: 3, Step: 1814/2949, Loss: 0.7359\n",
      "Epoch: 3, Step: 1815/2949, Loss: 0.7258\n",
      "Epoch: 3, Step: 1816/2949, Loss: 0.8148\n",
      "Epoch: 3, Step: 1817/2949, Loss: 0.7384\n",
      "Epoch: 3, Step: 1818/2949, Loss: 0.7302\n",
      "Epoch: 3, Step: 1819/2949, Loss: 0.7179\n",
      "Epoch: 3, Step: 1820/2949, Loss: 0.7451\n",
      "Epoch: 3, Step: 1821/2949, Loss: 0.7515\n",
      "Epoch: 3, Step: 1822/2949, Loss: 0.8001\n",
      "Epoch: 3, Step: 1823/2949, Loss: 0.7415\n",
      "Epoch: 3, Step: 1824/2949, Loss: 0.7661\n",
      "Epoch: 3, Step: 1825/2949, Loss: 0.7758\n",
      "Epoch: 3, Step: 1826/2949, Loss: 0.7933\n",
      "Epoch: 3, Step: 1827/2949, Loss: 0.8272\n",
      "Epoch: 3, Step: 1828/2949, Loss: 0.7812\n",
      "Epoch: 3, Step: 1829/2949, Loss: 0.7473\n",
      "Epoch: 3, Step: 1830/2949, Loss: 0.7247\n",
      "Epoch: 3, Step: 1831/2949, Loss: 0.7468\n",
      "Epoch: 3, Step: 1832/2949, Loss: 0.7727\n",
      "Epoch: 3, Step: 1833/2949, Loss: 0.7584\n",
      "Epoch: 3, Step: 1834/2949, Loss: 0.7753\n",
      "Epoch: 3, Step: 1835/2949, Loss: 0.7553\n",
      "Epoch: 3, Step: 1836/2949, Loss: 0.7906\n",
      "Epoch: 3, Step: 1837/2949, Loss: 0.7686\n",
      "Epoch: 3, Step: 1838/2949, Loss: 0.7051\n",
      "Epoch: 3, Step: 1839/2949, Loss: 0.7422\n",
      "Epoch: 3, Step: 1840/2949, Loss: 0.7731\n",
      "Epoch: 3, Step: 1841/2949, Loss: 0.8109\n",
      "Epoch: 3, Step: 1842/2949, Loss: 0.7962\n",
      "Epoch: 3, Step: 1843/2949, Loss: 0.7788\n",
      "Epoch: 3, Step: 1844/2949, Loss: 0.7743\n",
      "Epoch: 3, Step: 1845/2949, Loss: 0.7561\n",
      "Epoch: 3, Step: 1846/2949, Loss: 0.7540\n",
      "Epoch: 3, Step: 1847/2949, Loss: 0.6910\n",
      "Epoch: 3, Step: 1848/2949, Loss: 0.7632\n",
      "Epoch: 3, Step: 1849/2949, Loss: 0.7547\n",
      "Epoch: 3, Step: 1850/2949, Loss: 0.7646\n",
      "Epoch: 3, Step: 1851/2949, Loss: 0.7485\n",
      "Epoch: 3, Step: 1852/2949, Loss: 0.8168\n",
      "Epoch: 3, Step: 1853/2949, Loss: 0.7703\n",
      "Epoch: 3, Step: 1854/2949, Loss: 0.7750\n",
      "Epoch: 3, Step: 1855/2949, Loss: 0.7284\n",
      "Epoch: 3, Step: 1856/2949, Loss: 0.7557\n",
      "Epoch: 3, Step: 1857/2949, Loss: 0.6856\n",
      "Epoch: 3, Step: 1858/2949, Loss: 0.7219\n",
      "Epoch: 3, Step: 1859/2949, Loss: 0.7761\n",
      "Epoch: 3, Step: 1860/2949, Loss: 0.7344\n",
      "Epoch: 3, Step: 1861/2949, Loss: 0.7507\n",
      "Epoch: 3, Step: 1862/2949, Loss: 0.8059\n",
      "Epoch: 3, Step: 1863/2949, Loss: 0.7557\n",
      "Epoch: 3, Step: 1864/2949, Loss: 0.7774\n",
      "Epoch: 3, Step: 1865/2949, Loss: 0.7798\n",
      "Epoch: 3, Step: 1866/2949, Loss: 0.7540\n",
      "Epoch: 3, Step: 1867/2949, Loss: 0.8019\n",
      "Epoch: 3, Step: 1868/2949, Loss: 0.8111\n",
      "Epoch: 3, Step: 1869/2949, Loss: 0.7622\n",
      "Epoch: 3, Step: 1870/2949, Loss: 0.7546\n",
      "Epoch: 3, Step: 1871/2949, Loss: 0.7818\n",
      "Epoch: 3, Step: 1872/2949, Loss: 0.7985\n",
      "Epoch: 3, Step: 1873/2949, Loss: 0.7928\n",
      "Epoch: 3, Step: 1874/2949, Loss: 0.7128\n",
      "Epoch: 3, Step: 1875/2949, Loss: 0.7238\n",
      "Epoch: 3, Step: 1876/2949, Loss: 0.8343\n",
      "Epoch: 3, Step: 1877/2949, Loss: 0.7993\n",
      "Epoch: 3, Step: 1878/2949, Loss: 0.7597\n",
      "Epoch: 3, Step: 1879/2949, Loss: 0.7719\n",
      "Epoch: 3, Step: 1880/2949, Loss: 0.8035\n",
      "Epoch: 3, Step: 1881/2949, Loss: 0.7624\n",
      "Epoch: 3, Step: 1882/2949, Loss: 0.8370\n",
      "Epoch: 3, Step: 1883/2949, Loss: 0.7425\n",
      "Epoch: 3, Step: 1884/2949, Loss: 0.8024\n",
      "Epoch: 3, Step: 1885/2949, Loss: 0.8440\n",
      "Epoch: 3, Step: 1886/2949, Loss: 0.7880\n",
      "Epoch: 3, Step: 1887/2949, Loss: 0.7269\n",
      "Epoch: 3, Step: 1888/2949, Loss: 0.7374\n",
      "Epoch: 3, Step: 1889/2949, Loss: 0.8241\n",
      "Epoch: 3, Step: 1890/2949, Loss: 0.7369\n",
      "Epoch: 3, Step: 1891/2949, Loss: 0.8257\n",
      "Epoch: 3, Step: 1892/2949, Loss: 0.7133\n",
      "Epoch: 3, Step: 1893/2949, Loss: 0.7025\n",
      "Epoch: 3, Step: 1894/2949, Loss: 0.8271\n",
      "Epoch: 3, Step: 1895/2949, Loss: 0.7727\n",
      "Epoch: 3, Step: 1896/2949, Loss: 0.7572\n",
      "Epoch: 3, Step: 1897/2949, Loss: 0.7776\n",
      "Epoch: 3, Step: 1898/2949, Loss: 0.7653\n",
      "Epoch: 3, Step: 1899/2949, Loss: 0.8098\n",
      "Epoch: 3, Step: 1900/2949, Loss: 0.7884\n",
      "Epoch: 3, Step: 1901/2949, Loss: 0.7391\n",
      "Epoch: 3, Step: 1902/2949, Loss: 0.7683\n",
      "Epoch: 3, Step: 1903/2949, Loss: 0.8174\n",
      "Epoch: 3, Step: 1904/2949, Loss: 0.7497\n",
      "Epoch: 3, Step: 1905/2949, Loss: 0.7571\n",
      "Epoch: 3, Step: 1906/2949, Loss: 0.7354\n",
      "Epoch: 3, Step: 1907/2949, Loss: 0.7736\n",
      "Epoch: 3, Step: 1908/2949, Loss: 0.7876\n",
      "Epoch: 3, Step: 1909/2949, Loss: 0.7673\n",
      "Epoch: 3, Step: 1910/2949, Loss: 0.7509\n",
      "Epoch: 3, Step: 1911/2949, Loss: 0.7671\n",
      "Epoch: 3, Step: 1912/2949, Loss: 0.7484\n",
      "Epoch: 3, Step: 1913/2949, Loss: 0.7876\n",
      "Epoch: 3, Step: 1914/2949, Loss: 0.8122\n",
      "Epoch: 3, Step: 1915/2949, Loss: 0.7603\n",
      "Epoch: 3, Step: 1916/2949, Loss: 0.7573\n",
      "Epoch: 3, Step: 1917/2949, Loss: 0.7969\n",
      "Epoch: 3, Step: 1918/2949, Loss: 0.7614\n",
      "Epoch: 3, Step: 1919/2949, Loss: 0.7703\n",
      "Epoch: 3, Step: 1920/2949, Loss: 0.7703\n",
      "Epoch: 3, Step: 1921/2949, Loss: 0.7639\n",
      "Epoch: 3, Step: 1922/2949, Loss: 0.7680\n",
      "Epoch: 3, Step: 1923/2949, Loss: 0.7988\n",
      "Epoch: 3, Step: 1924/2949, Loss: 0.7861\n",
      "Epoch: 3, Step: 1925/2949, Loss: 0.7620\n",
      "Epoch: 3, Step: 1926/2949, Loss: 0.8038\n",
      "Epoch: 3, Step: 1927/2949, Loss: 0.7581\n",
      "Epoch: 3, Step: 1928/2949, Loss: 0.7766\n",
      "Epoch: 3, Step: 1929/2949, Loss: 0.7786\n",
      "Epoch: 3, Step: 1930/2949, Loss: 0.7103\n",
      "Epoch: 3, Step: 1931/2949, Loss: 0.7918\n",
      "Epoch: 3, Step: 1932/2949, Loss: 0.7658\n",
      "Epoch: 3, Step: 1933/2949, Loss: 0.8073\n",
      "Epoch: 3, Step: 1934/2949, Loss: 0.7157\n",
      "Epoch: 3, Step: 1935/2949, Loss: 0.7498\n",
      "Epoch: 3, Step: 1936/2949, Loss: 0.7342\n",
      "Epoch: 3, Step: 1937/2949, Loss: 0.7283\n",
      "Epoch: 3, Step: 1938/2949, Loss: 0.7457\n",
      "Epoch: 3, Step: 1939/2949, Loss: 0.7804\n",
      "Epoch: 3, Step: 1940/2949, Loss: 0.7758\n",
      "Epoch: 3, Step: 1941/2949, Loss: 0.7382\n",
      "Epoch: 3, Step: 1942/2949, Loss: 0.7188\n",
      "Epoch: 3, Step: 1943/2949, Loss: 0.7951\n",
      "Epoch: 3, Step: 1944/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 1945/2949, Loss: 0.7909\n",
      "Epoch: 3, Step: 1946/2949, Loss: 0.7615\n",
      "Epoch: 3, Step: 1947/2949, Loss: 0.7856\n",
      "Epoch: 3, Step: 1948/2949, Loss: 0.7795\n",
      "Epoch: 3, Step: 1949/2949, Loss: 0.7186\n",
      "Epoch: 3, Step: 1950/2949, Loss: 0.7703\n",
      "Epoch: 3, Step: 1951/2949, Loss: 0.7199\n",
      "Epoch: 3, Step: 1952/2949, Loss: 0.8221\n",
      "Epoch: 3, Step: 1953/2949, Loss: 0.7403\n",
      "Epoch: 3, Step: 1954/2949, Loss: 0.7955\n",
      "Epoch: 3, Step: 1955/2949, Loss: 0.7738\n",
      "Epoch: 3, Step: 1956/2949, Loss: 0.7610\n",
      "Epoch: 3, Step: 1957/2949, Loss: 0.7082\n",
      "Epoch: 3, Step: 1958/2949, Loss: 0.7653\n",
      "Epoch: 3, Step: 1959/2949, Loss: 0.7487\n",
      "Epoch: 3, Step: 1960/2949, Loss: 0.7909\n",
      "Epoch: 3, Step: 1961/2949, Loss: 0.7264\n",
      "Epoch: 3, Step: 1962/2949, Loss: 0.7881\n",
      "Epoch: 3, Step: 1963/2949, Loss: 0.7593\n",
      "Epoch: 3, Step: 1964/2949, Loss: 0.8199\n",
      "Epoch: 3, Step: 1965/2949, Loss: 0.7619\n",
      "Epoch: 3, Step: 1966/2949, Loss: 0.7679\n",
      "Epoch: 3, Step: 1967/2949, Loss: 0.7693\n",
      "Epoch: 3, Step: 1968/2949, Loss: 0.7442\n",
      "Epoch: 3, Step: 1969/2949, Loss: 0.7675\n",
      "Epoch: 3, Step: 1970/2949, Loss: 0.7778\n",
      "Epoch: 3, Step: 1971/2949, Loss: 0.7427\n",
      "Epoch: 3, Step: 1972/2949, Loss: 0.7902\n",
      "Epoch: 3, Step: 1973/2949, Loss: 0.7832\n",
      "Epoch: 3, Step: 1974/2949, Loss: 0.7972\n",
      "Epoch: 3, Step: 1975/2949, Loss: 0.7743\n",
      "Epoch: 3, Step: 1976/2949, Loss: 0.7317\n",
      "Epoch: 3, Step: 1977/2949, Loss: 0.8057\n",
      "Epoch: 3, Step: 1978/2949, Loss: 0.7504\n",
      "Epoch: 3, Step: 1979/2949, Loss: 0.7688\n",
      "Epoch: 3, Step: 1980/2949, Loss: 0.8192\n",
      "Epoch: 3, Step: 1981/2949, Loss: 0.7762\n",
      "Epoch: 3, Step: 1982/2949, Loss: 0.8003\n",
      "Epoch: 3, Step: 1983/2949, Loss: 0.7414\n",
      "Epoch: 3, Step: 1984/2949, Loss: 0.8306\n",
      "Epoch: 3, Step: 1985/2949, Loss: 0.8010\n",
      "Epoch: 3, Step: 1986/2949, Loss: 0.7683\n",
      "Epoch: 3, Step: 1987/2949, Loss: 0.7937\n",
      "Epoch: 3, Step: 1988/2949, Loss: 0.7532\n",
      "Epoch: 3, Step: 1989/2949, Loss: 0.8155\n",
      "Epoch: 3, Step: 1990/2949, Loss: 0.7218\n",
      "Epoch: 3, Step: 1991/2949, Loss: 0.7707\n",
      "Epoch: 3, Step: 1992/2949, Loss: 0.7655\n",
      "Epoch: 3, Step: 1993/2949, Loss: 0.7732\n",
      "Epoch: 3, Step: 1994/2949, Loss: 0.7677\n",
      "Epoch: 3, Step: 1995/2949, Loss: 0.7746\n",
      "Epoch: 3, Step: 1996/2949, Loss: 0.7507\n",
      "Epoch: 3, Step: 1997/2949, Loss: 0.7952\n",
      "Epoch: 3, Step: 1998/2949, Loss: 0.7938\n",
      "Epoch: 3, Step: 1999/2949, Loss: 0.8079\n",
      "Epoch: 3, Step: 2000/2949, Loss: 0.7730\n",
      "Epoch: 3, Step: 2001/2949, Loss: 0.7841\n",
      "Epoch: 3, Step: 2002/2949, Loss: 0.7859\n",
      "Epoch: 3, Step: 2003/2949, Loss: 0.8138\n",
      "Epoch: 3, Step: 2004/2949, Loss: 0.7950\n",
      "Epoch: 3, Step: 2005/2949, Loss: 0.7237\n",
      "Epoch: 3, Step: 2006/2949, Loss: 0.7786\n",
      "Epoch: 3, Step: 2007/2949, Loss: 0.7382\n",
      "Epoch: 3, Step: 2008/2949, Loss: 0.7745\n",
      "Epoch: 3, Step: 2009/2949, Loss: 0.7611\n",
      "Epoch: 3, Step: 2010/2949, Loss: 0.7812\n",
      "Epoch: 3, Step: 2011/2949, Loss: 0.7530\n",
      "Epoch: 3, Step: 2012/2949, Loss: 0.8056\n",
      "Epoch: 3, Step: 2013/2949, Loss: 0.7689\n",
      "Epoch: 3, Step: 2014/2949, Loss: 0.7589\n",
      "Epoch: 3, Step: 2015/2949, Loss: 0.7367\n",
      "Epoch: 3, Step: 2016/2949, Loss: 0.7760\n",
      "Epoch: 3, Step: 2017/2949, Loss: 0.6966\n",
      "Epoch: 3, Step: 2018/2949, Loss: 0.7862\n",
      "Epoch: 3, Step: 2019/2949, Loss: 0.7976\n",
      "Epoch: 3, Step: 2020/2949, Loss: 0.7458\n",
      "Epoch: 3, Step: 2021/2949, Loss: 0.7903\n",
      "Epoch: 3, Step: 2022/2949, Loss: 0.7358\n",
      "Epoch: 3, Step: 2023/2949, Loss: 0.7960\n",
      "Epoch: 3, Step: 2024/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 2025/2949, Loss: 0.7751\n",
      "Epoch: 3, Step: 2026/2949, Loss: 0.7850\n",
      "Epoch: 3, Step: 2027/2949, Loss: 0.7892\n",
      "Epoch: 3, Step: 2028/2949, Loss: 0.7835\n",
      "Epoch: 3, Step: 2029/2949, Loss: 0.8033\n",
      "Epoch: 3, Step: 2030/2949, Loss: 0.7456\n",
      "Epoch: 3, Step: 2031/2949, Loss: 0.7831\n",
      "Epoch: 3, Step: 2032/2949, Loss: 0.7605\n",
      "Epoch: 3, Step: 2033/2949, Loss: 0.7238\n",
      "Epoch: 3, Step: 2034/2949, Loss: 0.7520\n",
      "Epoch: 3, Step: 2035/2949, Loss: 0.7666\n",
      "Epoch: 3, Step: 2036/2949, Loss: 0.8074\n",
      "Epoch: 3, Step: 2037/2949, Loss: 0.8010\n",
      "Epoch: 3, Step: 2038/2949, Loss: 0.7704\n",
      "Epoch: 3, Step: 2039/2949, Loss: 0.7639\n",
      "Epoch: 3, Step: 2040/2949, Loss: 0.7861\n",
      "Epoch: 3, Step: 2041/2949, Loss: 0.6941\n",
      "Epoch: 3, Step: 2042/2949, Loss: 0.8073\n",
      "Epoch: 3, Step: 2043/2949, Loss: 0.7628\n",
      "Epoch: 3, Step: 2044/2949, Loss: 0.7719\n",
      "Epoch: 3, Step: 2045/2949, Loss: 0.7039\n",
      "Epoch: 3, Step: 2046/2949, Loss: 0.8024\n",
      "Epoch: 3, Step: 2047/2949, Loss: 0.8224\n",
      "Epoch: 3, Step: 2048/2949, Loss: 0.7992\n",
      "Epoch: 3, Step: 2049/2949, Loss: 0.7496\n",
      "Epoch: 3, Step: 2050/2949, Loss: 0.7980\n",
      "Epoch: 3, Step: 2051/2949, Loss: 0.7836\n",
      "Epoch: 3, Step: 2052/2949, Loss: 0.7788\n",
      "Epoch: 3, Step: 2053/2949, Loss: 0.8014\n",
      "Epoch: 3, Step: 2054/2949, Loss: 0.7587\n",
      "Epoch: 3, Step: 2055/2949, Loss: 0.7746\n",
      "Epoch: 3, Step: 2056/2949, Loss: 0.7747\n",
      "Epoch: 3, Step: 2057/2949, Loss: 0.7617\n",
      "Epoch: 3, Step: 2058/2949, Loss: 0.7349\n",
      "Epoch: 3, Step: 2059/2949, Loss: 0.7847\n",
      "Epoch: 3, Step: 2060/2949, Loss: 0.7680\n",
      "Epoch: 3, Step: 2061/2949, Loss: 0.8313\n",
      "Epoch: 3, Step: 2062/2949, Loss: 0.7778\n",
      "Epoch: 3, Step: 2063/2949, Loss: 0.7814\n",
      "Epoch: 3, Step: 2064/2949, Loss: 0.7547\n",
      "Epoch: 3, Step: 2065/2949, Loss: 0.7387\n",
      "Epoch: 3, Step: 2066/2949, Loss: 0.7708\n",
      "Epoch: 3, Step: 2067/2949, Loss: 0.7889\n",
      "Epoch: 3, Step: 2068/2949, Loss: 0.8094\n",
      "Epoch: 3, Step: 2069/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 2070/2949, Loss: 0.7335\n",
      "Epoch: 3, Step: 2071/2949, Loss: 0.7398\n",
      "Epoch: 3, Step: 2072/2949, Loss: 0.7878\n",
      "Epoch: 3, Step: 2073/2949, Loss: 0.7775\n",
      "Epoch: 3, Step: 2074/2949, Loss: 0.8015\n",
      "Epoch: 3, Step: 2075/2949, Loss: 0.6905\n",
      "Epoch: 3, Step: 2076/2949, Loss: 0.7741\n",
      "Epoch: 3, Step: 2077/2949, Loss: 0.7760\n",
      "Epoch: 3, Step: 2078/2949, Loss: 0.7943\n",
      "Epoch: 3, Step: 2079/2949, Loss: 0.7532\n",
      "Epoch: 3, Step: 2080/2949, Loss: 0.7973\n",
      "Epoch: 3, Step: 2081/2949, Loss: 0.8030\n",
      "Epoch: 3, Step: 2082/2949, Loss: 0.7199\n",
      "Epoch: 3, Step: 2083/2949, Loss: 0.7407\n",
      "Epoch: 3, Step: 2084/2949, Loss: 0.7479\n",
      "Epoch: 3, Step: 2085/2949, Loss: 0.7398\n",
      "Epoch: 3, Step: 2086/2949, Loss: 0.7966\n",
      "Epoch: 3, Step: 2087/2949, Loss: 0.7865\n",
      "Epoch: 3, Step: 2088/2949, Loss: 0.7669\n",
      "Epoch: 3, Step: 2089/2949, Loss: 0.7683\n",
      "Epoch: 3, Step: 2090/2949, Loss: 0.7496\n",
      "Epoch: 3, Step: 2091/2949, Loss: 0.7932\n",
      "Epoch: 3, Step: 2092/2949, Loss: 0.7124\n",
      "Epoch: 3, Step: 2093/2949, Loss: 0.7639\n",
      "Epoch: 3, Step: 2094/2949, Loss: 0.7621\n",
      "Epoch: 3, Step: 2095/2949, Loss: 0.7673\n",
      "Epoch: 3, Step: 2096/2949, Loss: 0.7580\n",
      "Epoch: 3, Step: 2097/2949, Loss: 0.7668\n",
      "Epoch: 3, Step: 2098/2949, Loss: 0.7429\n",
      "Epoch: 3, Step: 2099/2949, Loss: 0.7692\n",
      "Epoch: 3, Step: 2100/2949, Loss: 0.7281\n",
      "Epoch: 3, Step: 2101/2949, Loss: 0.7417\n",
      "Epoch: 3, Step: 2102/2949, Loss: 0.8057\n",
      "Epoch: 3, Step: 2103/2949, Loss: 0.7700\n",
      "Epoch: 3, Step: 2104/2949, Loss: 0.7327\n",
      "Epoch: 3, Step: 2105/2949, Loss: 0.7673\n",
      "Epoch: 3, Step: 2106/2949, Loss: 0.7367\n",
      "Epoch: 3, Step: 2107/2949, Loss: 0.7866\n",
      "Epoch: 3, Step: 2108/2949, Loss: 0.7870\n",
      "Epoch: 3, Step: 2109/2949, Loss: 0.7499\n",
      "Epoch: 3, Step: 2110/2949, Loss: 0.8113\n",
      "Epoch: 3, Step: 2111/2949, Loss: 0.7737\n",
      "Epoch: 3, Step: 2112/2949, Loss: 0.8180\n",
      "Epoch: 3, Step: 2113/2949, Loss: 0.7827\n",
      "Epoch: 3, Step: 2114/2949, Loss: 0.7940\n",
      "Epoch: 3, Step: 2115/2949, Loss: 0.7681\n",
      "Epoch: 3, Step: 2116/2949, Loss: 0.7648\n",
      "Epoch: 3, Step: 2117/2949, Loss: 0.7901\n",
      "Epoch: 3, Step: 2118/2949, Loss: 0.7614\n",
      "Epoch: 3, Step: 2119/2949, Loss: 0.7365\n",
      "Epoch: 3, Step: 2120/2949, Loss: 0.8379\n",
      "Epoch: 3, Step: 2121/2949, Loss: 0.7863\n",
      "Epoch: 3, Step: 2122/2949, Loss: 0.7698\n",
      "Epoch: 3, Step: 2123/2949, Loss: 0.7221\n",
      "Epoch: 3, Step: 2124/2949, Loss: 0.7561\n",
      "Epoch: 3, Step: 2125/2949, Loss: 0.7428\n",
      "Epoch: 3, Step: 2126/2949, Loss: 0.7619\n",
      "Epoch: 3, Step: 2127/2949, Loss: 0.7476\n",
      "Epoch: 3, Step: 2128/2949, Loss: 0.7422\n",
      "Epoch: 3, Step: 2129/2949, Loss: 0.7471\n",
      "Epoch: 3, Step: 2130/2949, Loss: 0.7751\n",
      "Epoch: 3, Step: 2131/2949, Loss: 0.7742\n",
      "Epoch: 3, Step: 2132/2949, Loss: 0.7743\n",
      "Epoch: 3, Step: 2133/2949, Loss: 0.7686\n",
      "Epoch: 3, Step: 2134/2949, Loss: 0.8393\n",
      "Epoch: 3, Step: 2135/2949, Loss: 0.7438\n",
      "Epoch: 3, Step: 2136/2949, Loss: 0.8242\n",
      "Epoch: 3, Step: 2137/2949, Loss: 0.7771\n",
      "Epoch: 3, Step: 2138/2949, Loss: 0.7719\n",
      "Epoch: 3, Step: 2139/2949, Loss: 0.7600\n",
      "Epoch: 3, Step: 2140/2949, Loss: 0.8128\n",
      "Epoch: 3, Step: 2141/2949, Loss: 0.7763\n",
      "Epoch: 3, Step: 2142/2949, Loss: 0.7572\n",
      "Epoch: 3, Step: 2143/2949, Loss: 0.7341\n",
      "Epoch: 3, Step: 2144/2949, Loss: 0.7336\n",
      "Epoch: 3, Step: 2145/2949, Loss: 0.7516\n",
      "Epoch: 3, Step: 2146/2949, Loss: 0.7866\n",
      "Epoch: 3, Step: 2147/2949, Loss: 0.8053\n",
      "Epoch: 3, Step: 2148/2949, Loss: 0.6661\n",
      "Epoch: 3, Step: 2149/2949, Loss: 0.7158\n",
      "Epoch: 3, Step: 2150/2949, Loss: 0.7430\n",
      "Epoch: 3, Step: 2151/2949, Loss: 0.7523\n",
      "Epoch: 3, Step: 2152/2949, Loss: 0.8379\n",
      "Epoch: 3, Step: 2153/2949, Loss: 0.7288\n",
      "Epoch: 3, Step: 2154/2949, Loss: 0.7840\n",
      "Epoch: 3, Step: 2155/2949, Loss: 0.7801\n",
      "Epoch: 3, Step: 2156/2949, Loss: 0.7988\n",
      "Epoch: 3, Step: 2157/2949, Loss: 0.7788\n",
      "Epoch: 3, Step: 2158/2949, Loss: 0.8038\n",
      "Epoch: 3, Step: 2159/2949, Loss: 0.8079\n",
      "Epoch: 3, Step: 2160/2949, Loss: 0.7384\n",
      "Epoch: 3, Step: 2161/2949, Loss: 0.7506\n",
      "Epoch: 3, Step: 2162/2949, Loss: 0.7369\n",
      "Epoch: 3, Step: 2163/2949, Loss: 0.8387\n",
      "Epoch: 3, Step: 2164/2949, Loss: 0.7228\n",
      "Epoch: 3, Step: 2165/2949, Loss: 0.7804\n",
      "Epoch: 3, Step: 2166/2949, Loss: 0.8131\n",
      "Epoch: 3, Step: 2167/2949, Loss: 0.7796\n",
      "Epoch: 3, Step: 2168/2949, Loss: 0.7302\n",
      "Epoch: 3, Step: 2169/2949, Loss: 0.8472\n",
      "Epoch: 3, Step: 2170/2949, Loss: 0.7813\n",
      "Epoch: 3, Step: 2171/2949, Loss: 0.7702\n",
      "Epoch: 3, Step: 2172/2949, Loss: 0.7299\n",
      "Epoch: 3, Step: 2173/2949, Loss: 0.8179\n",
      "Epoch: 3, Step: 2174/2949, Loss: 0.8117\n",
      "Epoch: 3, Step: 2175/2949, Loss: 0.7625\n",
      "Epoch: 3, Step: 2176/2949, Loss: 0.7129\n",
      "Epoch: 3, Step: 2177/2949, Loss: 0.8176\n",
      "Epoch: 3, Step: 2178/2949, Loss: 0.7284\n",
      "Epoch: 3, Step: 2179/2949, Loss: 0.7782\n",
      "Epoch: 3, Step: 2180/2949, Loss: 0.7917\n",
      "Epoch: 3, Step: 2181/2949, Loss: 0.7371\n",
      "Epoch: 3, Step: 2182/2949, Loss: 0.7627\n",
      "Epoch: 3, Step: 2183/2949, Loss: 0.8177\n",
      "Epoch: 3, Step: 2184/2949, Loss: 0.7502\n",
      "Epoch: 3, Step: 2185/2949, Loss: 0.7222\n",
      "Epoch: 3, Step: 2186/2949, Loss: 0.8043\n",
      "Epoch: 3, Step: 2187/2949, Loss: 0.8166\n",
      "Epoch: 3, Step: 2188/2949, Loss: 0.7951\n",
      "Epoch: 3, Step: 2189/2949, Loss: 0.7686\n",
      "Epoch: 3, Step: 2190/2949, Loss: 0.7580\n",
      "Epoch: 3, Step: 2191/2949, Loss: 0.7471\n",
      "Epoch: 3, Step: 2192/2949, Loss: 0.7973\n",
      "Epoch: 3, Step: 2193/2949, Loss: 0.7491\n",
      "Epoch: 3, Step: 2194/2949, Loss: 0.7657\n",
      "Epoch: 3, Step: 2195/2949, Loss: 0.7759\n",
      "Epoch: 3, Step: 2196/2949, Loss: 0.8079\n",
      "Epoch: 3, Step: 2197/2949, Loss: 0.8006\n",
      "Epoch: 3, Step: 2198/2949, Loss: 0.7644\n",
      "Epoch: 3, Step: 2199/2949, Loss: 0.7612\n",
      "Epoch: 3, Step: 2200/2949, Loss: 0.7677\n",
      "Epoch: 3, Step: 2201/2949, Loss: 0.7718\n",
      "Epoch: 3, Step: 2202/2949, Loss: 0.7615\n",
      "Epoch: 3, Step: 2203/2949, Loss: 0.7497\n",
      "Epoch: 3, Step: 2204/2949, Loss: 0.7859\n",
      "Epoch: 3, Step: 2205/2949, Loss: 0.7420\n",
      "Epoch: 3, Step: 2206/2949, Loss: 0.8101\n",
      "Epoch: 3, Step: 2207/2949, Loss: 0.8243\n",
      "Epoch: 3, Step: 2208/2949, Loss: 0.7691\n",
      "Epoch: 3, Step: 2209/2949, Loss: 0.7516\n",
      "Epoch: 3, Step: 2210/2949, Loss: 0.7702\n",
      "Epoch: 3, Step: 2211/2949, Loss: 0.7748\n",
      "Epoch: 3, Step: 2212/2949, Loss: 0.7787\n",
      "Epoch: 3, Step: 2213/2949, Loss: 0.7653\n",
      "Epoch: 3, Step: 2214/2949, Loss: 0.7708\n",
      "Epoch: 3, Step: 2215/2949, Loss: 0.8079\n",
      "Epoch: 3, Step: 2216/2949, Loss: 0.7308\n",
      "Epoch: 3, Step: 2217/2949, Loss: 0.7594\n",
      "Epoch: 3, Step: 2218/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 2219/2949, Loss: 0.7256\n",
      "Epoch: 3, Step: 2220/2949, Loss: 0.7498\n",
      "Epoch: 3, Step: 2221/2949, Loss: 0.7650\n",
      "Epoch: 3, Step: 2222/2949, Loss: 0.7740\n",
      "Epoch: 3, Step: 2223/2949, Loss: 0.7620\n",
      "Epoch: 3, Step: 2224/2949, Loss: 0.7640\n",
      "Epoch: 3, Step: 2225/2949, Loss: 0.7803\n",
      "Epoch: 3, Step: 2226/2949, Loss: 0.7456\n",
      "Epoch: 3, Step: 2227/2949, Loss: 0.7723\n",
      "Epoch: 3, Step: 2228/2949, Loss: 0.7300\n",
      "Epoch: 3, Step: 2229/2949, Loss: 0.7880\n",
      "Epoch: 3, Step: 2230/2949, Loss: 0.7945\n",
      "Epoch: 3, Step: 2231/2949, Loss: 0.7818\n",
      "Epoch: 3, Step: 2232/2949, Loss: 0.7745\n",
      "Epoch: 3, Step: 2233/2949, Loss: 0.7737\n",
      "Epoch: 3, Step: 2234/2949, Loss: 0.7573\n",
      "Epoch: 3, Step: 2235/2949, Loss: 0.7760\n",
      "Epoch: 3, Step: 2236/2949, Loss: 0.7556\n",
      "Epoch: 3, Step: 2237/2949, Loss: 0.7664\n",
      "Epoch: 3, Step: 2238/2949, Loss: 0.7551\n",
      "Epoch: 3, Step: 2239/2949, Loss: 0.7923\n",
      "Epoch: 3, Step: 2240/2949, Loss: 0.8081\n",
      "Epoch: 3, Step: 2241/2949, Loss: 0.8010\n",
      "Epoch: 3, Step: 2242/2949, Loss: 0.7115\n",
      "Epoch: 3, Step: 2243/2949, Loss: 0.8026\n",
      "Epoch: 3, Step: 2244/2949, Loss: 0.7162\n",
      "Epoch: 3, Step: 2245/2949, Loss: 0.7552\n",
      "Epoch: 3, Step: 2246/2949, Loss: 0.7723\n",
      "Epoch: 3, Step: 2247/2949, Loss: 0.7500\n",
      "Epoch: 3, Step: 2248/2949, Loss: 0.7604\n",
      "Epoch: 3, Step: 2249/2949, Loss: 0.7232\n",
      "Epoch: 3, Step: 2250/2949, Loss: 0.7691\n",
      "Epoch: 3, Step: 2251/2949, Loss: 0.8013\n",
      "Epoch: 3, Step: 2252/2949, Loss: 0.7460\n",
      "Epoch: 3, Step: 2253/2949, Loss: 0.7491\n",
      "Epoch: 3, Step: 2254/2949, Loss: 0.8047\n",
      "Epoch: 3, Step: 2255/2949, Loss: 0.7441\n",
      "Epoch: 3, Step: 2256/2949, Loss: 0.7660\n",
      "Epoch: 3, Step: 2257/2949, Loss: 0.7311\n",
      "Epoch: 3, Step: 2258/2949, Loss: 0.7916\n",
      "Epoch: 3, Step: 2259/2949, Loss: 0.8064\n",
      "Epoch: 3, Step: 2260/2949, Loss: 0.7494\n",
      "Epoch: 3, Step: 2261/2949, Loss: 0.7380\n",
      "Epoch: 3, Step: 2262/2949, Loss: 0.7508\n",
      "Epoch: 3, Step: 2263/2949, Loss: 0.7570\n",
      "Epoch: 3, Step: 2264/2949, Loss: 0.7647\n",
      "Epoch: 3, Step: 2265/2949, Loss: 0.7792\n",
      "Epoch: 3, Step: 2266/2949, Loss: 0.7836\n",
      "Epoch: 3, Step: 2267/2949, Loss: 0.7779\n",
      "Epoch: 3, Step: 2268/2949, Loss: 0.7577\n",
      "Epoch: 3, Step: 2269/2949, Loss: 0.8188\n",
      "Epoch: 3, Step: 2270/2949, Loss: 0.6923\n",
      "Epoch: 3, Step: 2271/2949, Loss: 0.7781\n",
      "Epoch: 3, Step: 2272/2949, Loss: 0.7194\n",
      "Epoch: 3, Step: 2273/2949, Loss: 0.7975\n",
      "Epoch: 3, Step: 2274/2949, Loss: 0.8229\n",
      "Epoch: 3, Step: 2275/2949, Loss: 0.7290\n",
      "Epoch: 3, Step: 2276/2949, Loss: 0.7435\n",
      "Epoch: 3, Step: 2277/2949, Loss: 0.7786\n",
      "Epoch: 3, Step: 2278/2949, Loss: 0.7992\n",
      "Epoch: 3, Step: 2279/2949, Loss: 0.7150\n",
      "Epoch: 3, Step: 2280/2949, Loss: 0.7928\n",
      "Epoch: 3, Step: 2281/2949, Loss: 0.7870\n",
      "Epoch: 3, Step: 2282/2949, Loss: 0.7968\n",
      "Epoch: 3, Step: 2283/2949, Loss: 0.7671\n",
      "Epoch: 3, Step: 2284/2949, Loss: 0.7492\n",
      "Epoch: 3, Step: 2285/2949, Loss: 0.7479\n",
      "Epoch: 3, Step: 2286/2949, Loss: 0.7413\n",
      "Epoch: 3, Step: 2287/2949, Loss: 0.7697\n",
      "Epoch: 3, Step: 2288/2949, Loss: 0.8077\n",
      "Epoch: 3, Step: 2289/2949, Loss: 0.7645\n",
      "Epoch: 3, Step: 2290/2949, Loss: 0.7470\n",
      "Epoch: 3, Step: 2291/2949, Loss: 0.7392\n",
      "Epoch: 3, Step: 2292/2949, Loss: 0.7616\n",
      "Epoch: 3, Step: 2293/2949, Loss: 0.7805\n",
      "Epoch: 3, Step: 2294/2949, Loss: 0.7406\n",
      "Epoch: 3, Step: 2295/2949, Loss: 0.7711\n",
      "Epoch: 3, Step: 2296/2949, Loss: 0.7669\n",
      "Epoch: 3, Step: 2297/2949, Loss: 0.7608\n",
      "Epoch: 3, Step: 2298/2949, Loss: 0.7970\n",
      "Epoch: 3, Step: 2299/2949, Loss: 0.7442\n",
      "Epoch: 3, Step: 2300/2949, Loss: 0.7273\n",
      "Epoch: 3, Step: 2301/2949, Loss: 0.7687\n",
      "Epoch: 3, Step: 2302/2949, Loss: 0.7429\n",
      "Epoch: 3, Step: 2303/2949, Loss: 0.7970\n",
      "Epoch: 3, Step: 2304/2949, Loss: 0.7582\n",
      "Epoch: 3, Step: 2305/2949, Loss: 0.7755\n",
      "Epoch: 3, Step: 2306/2949, Loss: 0.8035\n",
      "Epoch: 3, Step: 2307/2949, Loss: 0.8128\n",
      "Epoch: 3, Step: 2308/2949, Loss: 0.7783\n",
      "Epoch: 3, Step: 2309/2949, Loss: 0.7439\n",
      "Epoch: 3, Step: 2310/2949, Loss: 0.7344\n",
      "Epoch: 3, Step: 2311/2949, Loss: 0.6964\n",
      "Epoch: 3, Step: 2312/2949, Loss: 0.7545\n",
      "Epoch: 3, Step: 2313/2949, Loss: 0.8113\n",
      "Epoch: 3, Step: 2314/2949, Loss: 0.7568\n",
      "Epoch: 3, Step: 2315/2949, Loss: 0.7583\n",
      "Epoch: 3, Step: 2316/2949, Loss: 0.7944\n",
      "Epoch: 3, Step: 2317/2949, Loss: 0.7427\n",
      "Epoch: 3, Step: 2318/2949, Loss: 0.7508\n",
      "Epoch: 3, Step: 2319/2949, Loss: 0.8241\n",
      "Epoch: 3, Step: 2320/2949, Loss: 0.7539\n",
      "Epoch: 3, Step: 2321/2949, Loss: 0.7296\n",
      "Epoch: 3, Step: 2322/2949, Loss: 0.7065\n",
      "Epoch: 3, Step: 2323/2949, Loss: 0.7922\n",
      "Epoch: 3, Step: 2324/2949, Loss: 0.7404\n",
      "Epoch: 3, Step: 2325/2949, Loss: 0.7660\n",
      "Epoch: 3, Step: 2326/2949, Loss: 0.7555\n",
      "Epoch: 3, Step: 2327/2949, Loss: 0.7491\n",
      "Epoch: 3, Step: 2328/2949, Loss: 0.7266\n",
      "Epoch: 3, Step: 2329/2949, Loss: 0.7699\n",
      "Epoch: 3, Step: 2330/2949, Loss: 0.7544\n",
      "Epoch: 3, Step: 2331/2949, Loss: 0.7751\n",
      "Epoch: 3, Step: 2332/2949, Loss: 0.7689\n",
      "Epoch: 3, Step: 2333/2949, Loss: 0.8211\n",
      "Epoch: 3, Step: 2334/2949, Loss: 0.7506\n",
      "Epoch: 3, Step: 2335/2949, Loss: 0.7459\n",
      "Epoch: 3, Step: 2336/2949, Loss: 0.7258\n",
      "Epoch: 3, Step: 2337/2949, Loss: 0.7563\n",
      "Epoch: 3, Step: 2338/2949, Loss: 0.7152\n",
      "Epoch: 3, Step: 2339/2949, Loss: 0.7538\n",
      "Epoch: 3, Step: 2340/2949, Loss: 0.7723\n",
      "Epoch: 3, Step: 2341/2949, Loss: 0.7350\n",
      "Epoch: 3, Step: 2342/2949, Loss: 0.7659\n",
      "Epoch: 3, Step: 2343/2949, Loss: 0.7650\n",
      "Epoch: 3, Step: 2344/2949, Loss: 0.7658\n",
      "Epoch: 3, Step: 2345/2949, Loss: 0.8022\n",
      "Epoch: 3, Step: 2346/2949, Loss: 0.7783\n",
      "Epoch: 3, Step: 2347/2949, Loss: 0.7497\n",
      "Epoch: 3, Step: 2348/2949, Loss: 0.7750\n",
      "Epoch: 3, Step: 2349/2949, Loss: 0.7475\n",
      "Epoch: 3, Step: 2350/2949, Loss: 0.7562\n",
      "Epoch: 3, Step: 2351/2949, Loss: 0.7357\n",
      "Epoch: 3, Step: 2352/2949, Loss: 0.8043\n",
      "Epoch: 3, Step: 2353/2949, Loss: 0.7799\n",
      "Epoch: 3, Step: 2354/2949, Loss: 0.7953\n",
      "Epoch: 3, Step: 2355/2949, Loss: 0.7894\n",
      "Epoch: 3, Step: 2356/2949, Loss: 0.7245\n",
      "Epoch: 3, Step: 2357/2949, Loss: 0.7836\n",
      "Epoch: 3, Step: 2358/2949, Loss: 0.7809\n",
      "Epoch: 3, Step: 2359/2949, Loss: 0.7626\n",
      "Epoch: 3, Step: 2360/2949, Loss: 0.7868\n",
      "Epoch: 3, Step: 2361/2949, Loss: 0.7532\n",
      "Epoch: 3, Step: 2362/2949, Loss: 0.7563\n",
      "Epoch: 3, Step: 2363/2949, Loss: 0.7544\n",
      "Epoch: 3, Step: 2364/2949, Loss: 0.8071\n",
      "Epoch: 3, Step: 2365/2949, Loss: 0.7384\n",
      "Epoch: 3, Step: 2366/2949, Loss: 0.7863\n",
      "Epoch: 3, Step: 2367/2949, Loss: 0.7179\n",
      "Epoch: 3, Step: 2368/2949, Loss: 0.7753\n",
      "Epoch: 3, Step: 2369/2949, Loss: 0.7827\n",
      "Epoch: 3, Step: 2370/2949, Loss: 0.7752\n",
      "Epoch: 3, Step: 2371/2949, Loss: 0.6789\n",
      "Epoch: 3, Step: 2372/2949, Loss: 0.7337\n",
      "Epoch: 3, Step: 2373/2949, Loss: 0.7632\n",
      "Epoch: 3, Step: 2374/2949, Loss: 0.7911\n",
      "Epoch: 3, Step: 2375/2949, Loss: 0.7571\n",
      "Epoch: 3, Step: 2376/2949, Loss: 0.7563\n",
      "Epoch: 3, Step: 2377/2949, Loss: 0.7507\n",
      "Epoch: 3, Step: 2378/2949, Loss: 0.7630\n",
      "Epoch: 3, Step: 2379/2949, Loss: 0.7798\n",
      "Epoch: 3, Step: 2380/2949, Loss: 0.7528\n",
      "Epoch: 3, Step: 2381/2949, Loss: 0.8039\n",
      "Epoch: 3, Step: 2382/2949, Loss: 0.7731\n",
      "Epoch: 3, Step: 2383/2949, Loss: 0.7731\n",
      "Epoch: 3, Step: 2384/2949, Loss: 0.7806\n",
      "Epoch: 3, Step: 2385/2949, Loss: 0.7666\n",
      "Epoch: 3, Step: 2386/2949, Loss: 0.7604\n",
      "Epoch: 3, Step: 2387/2949, Loss: 0.7109\n",
      "Epoch: 3, Step: 2388/2949, Loss: 0.7425\n",
      "Epoch: 3, Step: 2389/2949, Loss: 0.7585\n",
      "Epoch: 3, Step: 2390/2949, Loss: 0.7783\n",
      "Epoch: 3, Step: 2391/2949, Loss: 0.7775\n",
      "Epoch: 3, Step: 2392/2949, Loss: 0.7555\n",
      "Epoch: 3, Step: 2393/2949, Loss: 0.8005\n",
      "Epoch: 3, Step: 2394/2949, Loss: 0.7645\n",
      "Epoch: 3, Step: 2395/2949, Loss: 0.7771\n",
      "Epoch: 3, Step: 2396/2949, Loss: 0.7730\n",
      "Epoch: 3, Step: 2397/2949, Loss: 0.8117\n",
      "Epoch: 3, Step: 2398/2949, Loss: 0.7893\n",
      "Epoch: 3, Step: 2399/2949, Loss: 0.8115\n",
      "Epoch: 3, Step: 2400/2949, Loss: 0.7750\n",
      "Epoch: 3, Step: 2401/2949, Loss: 0.7548\n",
      "Epoch: 3, Step: 2402/2949, Loss: 0.7514\n",
      "Epoch: 3, Step: 2403/2949, Loss: 0.7421\n",
      "Epoch: 3, Step: 2404/2949, Loss: 0.7379\n",
      "Epoch: 3, Step: 2405/2949, Loss: 0.7252\n",
      "Epoch: 3, Step: 2406/2949, Loss: 0.7910\n",
      "Epoch: 3, Step: 2407/2949, Loss: 0.7952\n",
      "Epoch: 3, Step: 2408/2949, Loss: 0.7690\n",
      "Epoch: 3, Step: 2409/2949, Loss: 0.7676\n",
      "Epoch: 3, Step: 2410/2949, Loss: 0.7415\n",
      "Epoch: 3, Step: 2411/2949, Loss: 0.7778\n",
      "Epoch: 3, Step: 2412/2949, Loss: 0.7788\n",
      "Epoch: 3, Step: 2413/2949, Loss: 0.7573\n",
      "Epoch: 3, Step: 2414/2949, Loss: 0.8001\n",
      "Epoch: 3, Step: 2415/2949, Loss: 0.8059\n",
      "Epoch: 3, Step: 2416/2949, Loss: 0.7561\n",
      "Epoch: 3, Step: 2417/2949, Loss: 0.7797\n",
      "Epoch: 3, Step: 2418/2949, Loss: 0.7339\n",
      "Epoch: 3, Step: 2419/2949, Loss: 0.7781\n",
      "Epoch: 3, Step: 2420/2949, Loss: 0.7643\n",
      "Epoch: 3, Step: 2421/2949, Loss: 0.7832\n",
      "Epoch: 3, Step: 2422/2949, Loss: 0.7514\n",
      "Epoch: 3, Step: 2423/2949, Loss: 0.7640\n",
      "Epoch: 3, Step: 2424/2949, Loss: 0.7293\n",
      "Epoch: 3, Step: 2425/2949, Loss: 0.7198\n",
      "Epoch: 3, Step: 2426/2949, Loss: 0.7456\n",
      "Epoch: 3, Step: 2427/2949, Loss: 0.7276\n",
      "Epoch: 3, Step: 2428/2949, Loss: 0.8254\n",
      "Epoch: 3, Step: 2429/2949, Loss: 0.7466\n",
      "Epoch: 3, Step: 2430/2949, Loss: 0.7473\n",
      "Epoch: 3, Step: 2431/2949, Loss: 0.8043\n",
      "Epoch: 3, Step: 2432/2949, Loss: 0.6861\n",
      "Epoch: 3, Step: 2433/2949, Loss: 0.7591\n",
      "Epoch: 3, Step: 2434/2949, Loss: 0.8578\n",
      "Epoch: 3, Step: 2435/2949, Loss: 0.7534\n",
      "Epoch: 3, Step: 2436/2949, Loss: 0.7342\n",
      "Epoch: 3, Step: 2437/2949, Loss: 0.7422\n",
      "Epoch: 3, Step: 2438/2949, Loss: 0.7304\n",
      "Epoch: 3, Step: 2439/2949, Loss: 0.7384\n",
      "Epoch: 3, Step: 2440/2949, Loss: 0.7361\n",
      "Epoch: 3, Step: 2441/2949, Loss: 0.7453\n",
      "Epoch: 3, Step: 2442/2949, Loss: 0.8016\n",
      "Epoch: 3, Step: 2443/2949, Loss: 0.7555\n",
      "Epoch: 3, Step: 2444/2949, Loss: 0.7322\n",
      "Epoch: 3, Step: 2445/2949, Loss: 0.7807\n",
      "Epoch: 3, Step: 2446/2949, Loss: 0.7376\n",
      "Epoch: 3, Step: 2447/2949, Loss: 0.8022\n",
      "Epoch: 3, Step: 2448/2949, Loss: 0.6721\n",
      "Epoch: 3, Step: 2449/2949, Loss: 0.8089\n",
      "Epoch: 3, Step: 2450/2949, Loss: 0.8080\n",
      "Epoch: 3, Step: 2451/2949, Loss: 0.7808\n",
      "Epoch: 3, Step: 2452/2949, Loss: 0.7691\n",
      "Epoch: 3, Step: 2453/2949, Loss: 0.8024\n",
      "Epoch: 3, Step: 2454/2949, Loss: 0.7791\n",
      "Epoch: 3, Step: 2455/2949, Loss: 0.8354\n",
      "Epoch: 3, Step: 2456/2949, Loss: 0.7501\n",
      "Epoch: 3, Step: 2457/2949, Loss: 0.7512\n",
      "Epoch: 3, Step: 2458/2949, Loss: 0.7837\n",
      "Epoch: 3, Step: 2459/2949, Loss: 0.7376\n",
      "Epoch: 3, Step: 2460/2949, Loss: 0.7519\n",
      "Epoch: 3, Step: 2461/2949, Loss: 0.7639\n",
      "Epoch: 3, Step: 2462/2949, Loss: 0.7206\n",
      "Epoch: 3, Step: 2463/2949, Loss: 0.8120\n",
      "Epoch: 3, Step: 2464/2949, Loss: 0.7967\n",
      "Epoch: 3, Step: 2465/2949, Loss: 0.7659\n",
      "Epoch: 3, Step: 2466/2949, Loss: 0.7855\n",
      "Epoch: 3, Step: 2467/2949, Loss: 0.7944\n",
      "Epoch: 3, Step: 2468/2949, Loss: 0.7612\n",
      "Epoch: 3, Step: 2469/2949, Loss: 0.7473\n",
      "Epoch: 3, Step: 2470/2949, Loss: 0.7435\n",
      "Epoch: 3, Step: 2471/2949, Loss: 0.7326\n",
      "Epoch: 3, Step: 2472/2949, Loss: 0.7820\n",
      "Epoch: 3, Step: 2473/2949, Loss: 0.7712\n",
      "Epoch: 3, Step: 2474/2949, Loss: 0.8420\n",
      "Epoch: 3, Step: 2475/2949, Loss: 0.7433\n",
      "Epoch: 3, Step: 2476/2949, Loss: 0.7687\n",
      "Epoch: 3, Step: 2477/2949, Loss: 0.8340\n",
      "Epoch: 3, Step: 2478/2949, Loss: 0.8001\n",
      "Epoch: 3, Step: 2479/2949, Loss: 0.7347\n",
      "Epoch: 3, Step: 2480/2949, Loss: 0.7841\n",
      "Epoch: 3, Step: 2481/2949, Loss: 0.7553\n",
      "Epoch: 3, Step: 2482/2949, Loss: 0.7640\n",
      "Epoch: 3, Step: 2483/2949, Loss: 0.7889\n",
      "Epoch: 3, Step: 2484/2949, Loss: 0.7651\n",
      "Epoch: 3, Step: 2485/2949, Loss: 0.7681\n",
      "Epoch: 3, Step: 2486/2949, Loss: 0.7848\n",
      "Epoch: 3, Step: 2487/2949, Loss: 0.7917\n",
      "Epoch: 3, Step: 2488/2949, Loss: 0.7693\n",
      "Epoch: 3, Step: 2489/2949, Loss: 0.7832\n",
      "Epoch: 3, Step: 2490/2949, Loss: 0.7835\n",
      "Epoch: 3, Step: 2491/2949, Loss: 0.7751\n",
      "Epoch: 3, Step: 2492/2949, Loss: 0.7996\n",
      "Epoch: 3, Step: 2493/2949, Loss: 0.7685\n",
      "Epoch: 3, Step: 2494/2949, Loss: 0.8039\n",
      "Epoch: 3, Step: 2495/2949, Loss: 0.8183\n",
      "Epoch: 3, Step: 2496/2949, Loss: 0.7883\n",
      "Epoch: 3, Step: 2497/2949, Loss: 0.7970\n",
      "Epoch: 3, Step: 2498/2949, Loss: 0.7951\n",
      "Epoch: 3, Step: 2499/2949, Loss: 0.7557\n",
      "Epoch: 3, Step: 2500/2949, Loss: 0.7714\n",
      "Epoch: 3, Step: 2501/2949, Loss: 0.7987\n",
      "Epoch: 3, Step: 2502/2949, Loss: 0.7257\n",
      "Epoch: 3, Step: 2503/2949, Loss: 0.7793\n",
      "Epoch: 3, Step: 2504/2949, Loss: 0.8209\n",
      "Epoch: 3, Step: 2505/2949, Loss: 0.7971\n",
      "Epoch: 3, Step: 2506/2949, Loss: 0.8044\n",
      "Epoch: 3, Step: 2507/2949, Loss: 0.7203\n",
      "Epoch: 3, Step: 2508/2949, Loss: 0.6890\n",
      "Epoch: 3, Step: 2509/2949, Loss: 0.7707\n",
      "Epoch: 3, Step: 2510/2949, Loss: 0.7605\n",
      "Epoch: 3, Step: 2511/2949, Loss: 0.7403\n",
      "Epoch: 3, Step: 2512/2949, Loss: 0.7819\n",
      "Epoch: 3, Step: 2513/2949, Loss: 0.7144\n",
      "Epoch: 3, Step: 2514/2949, Loss: 0.7427\n",
      "Epoch: 3, Step: 2515/2949, Loss: 0.7520\n",
      "Epoch: 3, Step: 2516/2949, Loss: 0.7831\n",
      "Epoch: 3, Step: 2517/2949, Loss: 0.7306\n",
      "Epoch: 3, Step: 2518/2949, Loss: 0.7503\n",
      "Epoch: 3, Step: 2519/2949, Loss: 0.7481\n",
      "Epoch: 3, Step: 2520/2949, Loss: 0.7479\n",
      "Epoch: 3, Step: 2521/2949, Loss: 0.7783\n",
      "Epoch: 3, Step: 2522/2949, Loss: 0.7742\n",
      "Epoch: 3, Step: 2523/2949, Loss: 0.7798\n",
      "Epoch: 3, Step: 2524/2949, Loss: 0.7887\n",
      "Epoch: 3, Step: 2525/2949, Loss: 0.7588\n",
      "Epoch: 3, Step: 2526/2949, Loss: 0.7682\n",
      "Epoch: 3, Step: 2527/2949, Loss: 0.7343\n",
      "Epoch: 3, Step: 2528/2949, Loss: 0.7905\n",
      "Epoch: 3, Step: 2529/2949, Loss: 0.7679\n",
      "Epoch: 3, Step: 2530/2949, Loss: 0.7779\n",
      "Epoch: 3, Step: 2531/2949, Loss: 0.7836\n",
      "Epoch: 3, Step: 2532/2949, Loss: 0.7784\n",
      "Epoch: 3, Step: 2533/2949, Loss: 0.7209\n",
      "Epoch: 3, Step: 2534/2949, Loss: 0.7893\n",
      "Epoch: 3, Step: 2535/2949, Loss: 0.6945\n",
      "Epoch: 3, Step: 2536/2949, Loss: 0.7479\n",
      "Epoch: 3, Step: 2537/2949, Loss: 0.7481\n",
      "Epoch: 3, Step: 2538/2949, Loss: 0.8035\n",
      "Epoch: 3, Step: 2539/2949, Loss: 0.7430\n",
      "Epoch: 3, Step: 2540/2949, Loss: 0.7945\n",
      "Epoch: 3, Step: 2541/2949, Loss: 0.7520\n",
      "Epoch: 3, Step: 2542/2949, Loss: 0.7077\n",
      "Epoch: 3, Step: 2543/2949, Loss: 0.7873\n",
      "Epoch: 3, Step: 2544/2949, Loss: 0.7869\n",
      "Epoch: 3, Step: 2545/2949, Loss: 0.7332\n",
      "Epoch: 3, Step: 2546/2949, Loss: 0.8012\n",
      "Epoch: 3, Step: 2547/2949, Loss: 0.7456\n",
      "Epoch: 3, Step: 2548/2949, Loss: 0.7711\n",
      "Epoch: 3, Step: 2549/2949, Loss: 0.7736\n",
      "Epoch: 3, Step: 2550/2949, Loss: 0.7617\n",
      "Epoch: 3, Step: 2551/2949, Loss: 0.7723\n",
      "Epoch: 3, Step: 2552/2949, Loss: 0.7615\n",
      "Epoch: 3, Step: 2553/2949, Loss: 0.7486\n",
      "Epoch: 3, Step: 2554/2949, Loss: 0.7020\n",
      "Epoch: 3, Step: 2555/2949, Loss: 0.7288\n",
      "Epoch: 3, Step: 2556/2949, Loss: 0.7571\n",
      "Epoch: 3, Step: 2557/2949, Loss: 0.8112\n",
      "Epoch: 3, Step: 2558/2949, Loss: 0.7738\n",
      "Epoch: 3, Step: 2559/2949, Loss: 0.7510\n",
      "Epoch: 3, Step: 2560/2949, Loss: 0.7771\n",
      "Epoch: 3, Step: 2561/2949, Loss: 0.7677\n",
      "Epoch: 3, Step: 2562/2949, Loss: 0.7518\n",
      "Epoch: 3, Step: 2563/2949, Loss: 0.7674\n",
      "Epoch: 3, Step: 2564/2949, Loss: 0.7083\n",
      "Epoch: 3, Step: 2565/2949, Loss: 0.6837\n",
      "Epoch: 3, Step: 2566/2949, Loss: 0.7921\n",
      "Epoch: 3, Step: 2567/2949, Loss: 0.7756\n",
      "Epoch: 3, Step: 2568/2949, Loss: 0.7767\n",
      "Epoch: 3, Step: 2569/2949, Loss: 0.7510\n",
      "Epoch: 3, Step: 2570/2949, Loss: 0.8054\n",
      "Epoch: 3, Step: 2571/2949, Loss: 0.8030\n",
      "Epoch: 3, Step: 2572/2949, Loss: 0.7441\n",
      "Epoch: 3, Step: 2573/2949, Loss: 0.7570\n",
      "Epoch: 3, Step: 2574/2949, Loss: 0.7977\n",
      "Epoch: 3, Step: 2575/2949, Loss: 0.8446\n",
      "Epoch: 3, Step: 2576/2949, Loss: 0.7385\n",
      "Epoch: 3, Step: 2577/2949, Loss: 0.7501\n",
      "Epoch: 3, Step: 2578/2949, Loss: 0.7990\n",
      "Epoch: 3, Step: 2579/2949, Loss: 0.7865\n",
      "Epoch: 3, Step: 2580/2949, Loss: 0.7971\n",
      "Epoch: 3, Step: 2581/2949, Loss: 0.7944\n",
      "Epoch: 3, Step: 2582/2949, Loss: 0.7069\n",
      "Epoch: 3, Step: 2583/2949, Loss: 0.7661\n",
      "Epoch: 3, Step: 2584/2949, Loss: 0.7816\n",
      "Epoch: 3, Step: 2585/2949, Loss: 0.7743\n",
      "Epoch: 3, Step: 2586/2949, Loss: 0.7353\n",
      "Epoch: 3, Step: 2587/2949, Loss: 0.8026\n",
      "Epoch: 3, Step: 2588/2949, Loss: 0.7685\n",
      "Epoch: 3, Step: 2589/2949, Loss: 0.7720\n",
      "Epoch: 3, Step: 2590/2949, Loss: 0.7158\n",
      "Epoch: 3, Step: 2591/2949, Loss: 0.7637\n",
      "Epoch: 3, Step: 2592/2949, Loss: 0.7910\n",
      "Epoch: 3, Step: 2593/2949, Loss: 0.7418\n",
      "Epoch: 3, Step: 2594/2949, Loss: 0.8460\n",
      "Epoch: 3, Step: 2595/2949, Loss: 0.7899\n",
      "Epoch: 3, Step: 2596/2949, Loss: 0.7716\n",
      "Epoch: 3, Step: 2597/2949, Loss: 0.8017\n",
      "Epoch: 3, Step: 2598/2949, Loss: 0.7653\n",
      "Epoch: 3, Step: 2599/2949, Loss: 0.7649\n",
      "Epoch: 3, Step: 2600/2949, Loss: 0.7716\n",
      "Epoch: 3, Step: 2601/2949, Loss: 0.7907\n",
      "Epoch: 3, Step: 2602/2949, Loss: 0.8194\n",
      "Epoch: 3, Step: 2603/2949, Loss: 0.7693\n",
      "Epoch: 3, Step: 2604/2949, Loss: 0.7539\n",
      "Epoch: 3, Step: 2605/2949, Loss: 0.7172\n",
      "Epoch: 3, Step: 2606/2949, Loss: 0.7305\n",
      "Epoch: 3, Step: 2607/2949, Loss: 0.7426\n",
      "Epoch: 3, Step: 2608/2949, Loss: 0.7763\n",
      "Epoch: 3, Step: 2609/2949, Loss: 0.7507\n",
      "Epoch: 3, Step: 2610/2949, Loss: 0.7497\n",
      "Epoch: 3, Step: 2611/2949, Loss: 0.7175\n",
      "Epoch: 3, Step: 2612/2949, Loss: 0.7477\n",
      "Epoch: 3, Step: 2613/2949, Loss: 0.7152\n",
      "Epoch: 3, Step: 2614/2949, Loss: 0.7414\n",
      "Epoch: 3, Step: 2615/2949, Loss: 0.7503\n",
      "Epoch: 3, Step: 2616/2949, Loss: 0.7584\n",
      "Epoch: 3, Step: 2617/2949, Loss: 0.8315\n",
      "Epoch: 3, Step: 2618/2949, Loss: 0.7665\n",
      "Epoch: 3, Step: 2619/2949, Loss: 0.7582\n",
      "Epoch: 3, Step: 2620/2949, Loss: 0.7739\n",
      "Epoch: 3, Step: 2621/2949, Loss: 0.7718\n",
      "Epoch: 3, Step: 2622/2949, Loss: 0.7517\n",
      "Epoch: 3, Step: 2623/2949, Loss: 0.7553\n",
      "Epoch: 3, Step: 2624/2949, Loss: 0.7387\n",
      "Epoch: 3, Step: 2625/2949, Loss: 0.7391\n",
      "Epoch: 3, Step: 2626/2949, Loss: 0.7537\n",
      "Epoch: 3, Step: 2627/2949, Loss: 0.7645\n",
      "Epoch: 3, Step: 2628/2949, Loss: 0.7568\n",
      "Epoch: 3, Step: 2629/2949, Loss: 0.7744\n",
      "Epoch: 3, Step: 2630/2949, Loss: 0.7429\n",
      "Epoch: 3, Step: 2631/2949, Loss: 0.7615\n",
      "Epoch: 3, Step: 2632/2949, Loss: 0.7923\n",
      "Epoch: 3, Step: 2633/2949, Loss: 0.7327\n",
      "Epoch: 3, Step: 2634/2949, Loss: 0.7699\n",
      "Epoch: 3, Step: 2635/2949, Loss: 0.7420\n",
      "Epoch: 3, Step: 2636/2949, Loss: 0.7776\n",
      "Epoch: 3, Step: 2637/2949, Loss: 0.7319\n",
      "Epoch: 3, Step: 2638/2949, Loss: 0.7432\n",
      "Epoch: 3, Step: 2639/2949, Loss: 0.7346\n",
      "Epoch: 3, Step: 2640/2949, Loss: 0.7526\n",
      "Epoch: 3, Step: 2641/2949, Loss: 0.7547\n",
      "Epoch: 3, Step: 2642/2949, Loss: 0.7871\n",
      "Epoch: 3, Step: 2643/2949, Loss: 0.7792\n",
      "Epoch: 3, Step: 2644/2949, Loss: 0.7830\n",
      "Epoch: 3, Step: 2645/2949, Loss: 0.7287\n",
      "Epoch: 3, Step: 2646/2949, Loss: 0.7862\n",
      "Epoch: 3, Step: 2647/2949, Loss: 0.7896\n",
      "Epoch: 3, Step: 2648/2949, Loss: 0.7703\n",
      "Epoch: 3, Step: 2649/2949, Loss: 0.7813\n",
      "Epoch: 3, Step: 2650/2949, Loss: 0.7312\n",
      "Epoch: 3, Step: 2651/2949, Loss: 0.7559\n",
      "Epoch: 3, Step: 2652/2949, Loss: 0.8188\n",
      "Epoch: 3, Step: 2653/2949, Loss: 0.7841\n",
      "Epoch: 3, Step: 2654/2949, Loss: 0.7813\n",
      "Epoch: 3, Step: 2655/2949, Loss: 0.7237\n",
      "Epoch: 3, Step: 2656/2949, Loss: 0.8175\n",
      "Epoch: 3, Step: 2657/2949, Loss: 0.7926\n",
      "Epoch: 3, Step: 2658/2949, Loss: 0.7306\n",
      "Epoch: 3, Step: 2659/2949, Loss: 0.7855\n",
      "Epoch: 3, Step: 2660/2949, Loss: 0.7910\n",
      "Epoch: 3, Step: 2661/2949, Loss: 0.7478\n",
      "Epoch: 3, Step: 2662/2949, Loss: 0.8091\n",
      "Epoch: 3, Step: 2663/2949, Loss: 0.7521\n",
      "Epoch: 3, Step: 2664/2949, Loss: 0.7719\n",
      "Epoch: 3, Step: 2665/2949, Loss: 0.8117\n",
      "Epoch: 3, Step: 2666/2949, Loss: 0.7752\n",
      "Epoch: 3, Step: 2667/2949, Loss: 0.7564\n",
      "Epoch: 3, Step: 2668/2949, Loss: 0.7740\n",
      "Epoch: 3, Step: 2669/2949, Loss: 0.7567\n",
      "Epoch: 3, Step: 2670/2949, Loss: 0.7281\n",
      "Epoch: 3, Step: 2671/2949, Loss: 0.7348\n",
      "Epoch: 3, Step: 2672/2949, Loss: 0.7726\n",
      "Epoch: 3, Step: 2673/2949, Loss: 0.7941\n",
      "Epoch: 3, Step: 2674/2949, Loss: 0.7687\n",
      "Epoch: 3, Step: 2675/2949, Loss: 0.7602\n",
      "Epoch: 3, Step: 2676/2949, Loss: 0.8197\n",
      "Epoch: 3, Step: 2677/2949, Loss: 0.7612\n",
      "Epoch: 3, Step: 2678/2949, Loss: 0.7477\n",
      "Epoch: 3, Step: 2679/2949, Loss: 0.7091\n",
      "Epoch: 3, Step: 2680/2949, Loss: 0.7787\n",
      "Epoch: 3, Step: 2681/2949, Loss: 0.7555\n",
      "Epoch: 3, Step: 2682/2949, Loss: 0.7285\n",
      "Epoch: 3, Step: 2683/2949, Loss: 0.7990\n",
      "Epoch: 3, Step: 2684/2949, Loss: 0.7483\n",
      "Epoch: 3, Step: 2685/2949, Loss: 0.7612\n",
      "Epoch: 3, Step: 2686/2949, Loss: 0.7628\n",
      "Epoch: 3, Step: 2687/2949, Loss: 0.8031\n",
      "Epoch: 3, Step: 2688/2949, Loss: 0.7462\n",
      "Epoch: 3, Step: 2689/2949, Loss: 0.7627\n",
      "Epoch: 3, Step: 2690/2949, Loss: 0.7868\n",
      "Epoch: 3, Step: 2691/2949, Loss: 0.7240\n",
      "Epoch: 3, Step: 2692/2949, Loss: 0.8115\n",
      "Epoch: 3, Step: 2693/2949, Loss: 0.7111\n",
      "Epoch: 3, Step: 2694/2949, Loss: 0.8175\n",
      "Epoch: 3, Step: 2695/2949, Loss: 0.7649\n",
      "Epoch: 3, Step: 2696/2949, Loss: 0.7615\n",
      "Epoch: 3, Step: 2697/2949, Loss: 0.7963\n",
      "Epoch: 3, Step: 2698/2949, Loss: 0.7693\n",
      "Epoch: 3, Step: 2699/2949, Loss: 0.7602\n",
      "Epoch: 3, Step: 2700/2949, Loss: 0.7580\n",
      "Epoch: 3, Step: 2701/2949, Loss: 0.7438\n",
      "Epoch: 3, Step: 2702/2949, Loss: 0.7473\n",
      "Epoch: 3, Step: 2703/2949, Loss: 0.7486\n",
      "Epoch: 3, Step: 2704/2949, Loss: 0.7286\n",
      "Epoch: 3, Step: 2705/2949, Loss: 0.7583\n",
      "Epoch: 3, Step: 2706/2949, Loss: 0.7596\n",
      "Epoch: 3, Step: 2707/2949, Loss: 0.7597\n",
      "Epoch: 3, Step: 2708/2949, Loss: 0.7305\n",
      "Epoch: 3, Step: 2709/2949, Loss: 0.7970\n",
      "Epoch: 3, Step: 2710/2949, Loss: 0.7420\n",
      "Epoch: 3, Step: 2711/2949, Loss: 0.8049\n",
      "Epoch: 3, Step: 2712/2949, Loss: 0.7644\n",
      "Epoch: 3, Step: 2713/2949, Loss: 0.7307\n",
      "Epoch: 3, Step: 2714/2949, Loss: 0.7636\n",
      "Epoch: 3, Step: 2715/2949, Loss: 0.7314\n",
      "Epoch: 3, Step: 2716/2949, Loss: 0.7470\n",
      "Epoch: 3, Step: 2717/2949, Loss: 0.7182\n",
      "Epoch: 3, Step: 2718/2949, Loss: 0.7236\n",
      "Epoch: 3, Step: 2719/2949, Loss: 0.7985\n",
      "Epoch: 3, Step: 2720/2949, Loss: 0.7571\n",
      "Epoch: 3, Step: 2721/2949, Loss: 0.7738\n",
      "Epoch: 3, Step: 2722/2949, Loss: 0.8005\n",
      "Epoch: 3, Step: 2723/2949, Loss: 0.7822\n",
      "Epoch: 3, Step: 2724/2949, Loss: 0.8098\n",
      "Epoch: 3, Step: 2725/2949, Loss: 0.7473\n",
      "Epoch: 3, Step: 2726/2949, Loss: 0.7450\n",
      "Epoch: 3, Step: 2727/2949, Loss: 0.7415\n",
      "Epoch: 3, Step: 2728/2949, Loss: 0.7457\n",
      "Epoch: 3, Step: 2729/2949, Loss: 0.8054\n",
      "Epoch: 3, Step: 2730/2949, Loss: 0.7917\n",
      "Epoch: 3, Step: 2731/2949, Loss: 0.7608\n",
      "Epoch: 3, Step: 2732/2949, Loss: 0.7519\n",
      "Epoch: 3, Step: 2733/2949, Loss: 0.7631\n",
      "Epoch: 3, Step: 2734/2949, Loss: 0.7712\n",
      "Epoch: 3, Step: 2735/2949, Loss: 0.8294\n",
      "Epoch: 3, Step: 2736/2949, Loss: 0.7601\n",
      "Epoch: 3, Step: 2737/2949, Loss: 0.7884\n",
      "Epoch: 3, Step: 2738/2949, Loss: 0.8020\n",
      "Epoch: 3, Step: 2739/2949, Loss: 0.7843\n",
      "Epoch: 3, Step: 2740/2949, Loss: 0.6797\n",
      "Epoch: 3, Step: 2741/2949, Loss: 0.7553\n",
      "Epoch: 3, Step: 2742/2949, Loss: 0.8394\n",
      "Epoch: 3, Step: 2743/2949, Loss: 0.7716\n",
      "Epoch: 3, Step: 2744/2949, Loss: 0.7392\n",
      "Epoch: 3, Step: 2745/2949, Loss: 0.8083\n",
      "Epoch: 3, Step: 2746/2949, Loss: 0.7873\n",
      "Epoch: 3, Step: 2747/2949, Loss: 0.7078\n",
      "Epoch: 3, Step: 2748/2949, Loss: 0.7394\n",
      "Epoch: 3, Step: 2749/2949, Loss: 0.7224\n",
      "Epoch: 3, Step: 2750/2949, Loss: 0.7234\n",
      "Epoch: 3, Step: 2751/2949, Loss: 0.7247\n",
      "Epoch: 3, Step: 2752/2949, Loss: 0.7329\n",
      "Epoch: 3, Step: 2753/2949, Loss: 0.7390\n",
      "Epoch: 3, Step: 2754/2949, Loss: 0.7619\n",
      "Epoch: 3, Step: 2755/2949, Loss: 0.7439\n",
      "Epoch: 3, Step: 2756/2949, Loss: 0.7459\n",
      "Epoch: 3, Step: 2757/2949, Loss: 0.7500\n",
      "Epoch: 3, Step: 2758/2949, Loss: 0.7426\n",
      "Epoch: 3, Step: 2759/2949, Loss: 0.7874\n",
      "Epoch: 3, Step: 2760/2949, Loss: 0.7616\n",
      "Epoch: 3, Step: 2761/2949, Loss: 0.7945\n",
      "Epoch: 3, Step: 2762/2949, Loss: 0.7666\n",
      "Epoch: 3, Step: 2763/2949, Loss: 0.7620\n",
      "Epoch: 3, Step: 2764/2949, Loss: 0.7806\n",
      "Epoch: 3, Step: 2765/2949, Loss: 0.7742\n",
      "Epoch: 3, Step: 2766/2949, Loss: 0.8138\n",
      "Epoch: 3, Step: 2767/2949, Loss: 0.7872\n",
      "Epoch: 3, Step: 2768/2949, Loss: 0.7587\n",
      "Epoch: 3, Step: 2769/2949, Loss: 0.7621\n",
      "Epoch: 3, Step: 2770/2949, Loss: 0.7263\n",
      "Epoch: 3, Step: 2771/2949, Loss: 0.7608\n",
      "Epoch: 3, Step: 2772/2949, Loss: 0.7807\n",
      "Epoch: 3, Step: 2773/2949, Loss: 0.8121\n",
      "Epoch: 3, Step: 2774/2949, Loss: 0.7811\n",
      "Epoch: 3, Step: 2775/2949, Loss: 0.7474\n",
      "Epoch: 3, Step: 2776/2949, Loss: 0.7896\n",
      "Epoch: 3, Step: 2777/2949, Loss: 0.7671\n",
      "Epoch: 3, Step: 2778/2949, Loss: 0.7156\n",
      "Epoch: 3, Step: 2779/2949, Loss: 0.7936\n",
      "Epoch: 3, Step: 2780/2949, Loss: 0.7818\n",
      "Epoch: 3, Step: 2781/2949, Loss: 0.7244\n",
      "Epoch: 3, Step: 2782/2949, Loss: 0.8017\n",
      "Epoch: 3, Step: 2783/2949, Loss: 0.7646\n",
      "Epoch: 3, Step: 2784/2949, Loss: 0.7701\n",
      "Epoch: 3, Step: 2785/2949, Loss: 0.7851\n",
      "Epoch: 3, Step: 2786/2949, Loss: 0.7803\n",
      "Epoch: 3, Step: 2787/2949, Loss: 0.7685\n",
      "Epoch: 3, Step: 2788/2949, Loss: 0.7611\n",
      "Epoch: 3, Step: 2789/2949, Loss: 0.7757\n",
      "Epoch: 3, Step: 2790/2949, Loss: 0.7689\n",
      "Epoch: 3, Step: 2791/2949, Loss: 0.7573\n",
      "Epoch: 3, Step: 2792/2949, Loss: 0.7401\n",
      "Epoch: 3, Step: 2793/2949, Loss: 0.7725\n",
      "Epoch: 3, Step: 2794/2949, Loss: 0.8080\n",
      "Epoch: 3, Step: 2795/2949, Loss: 0.7719\n",
      "Epoch: 3, Step: 2796/2949, Loss: 0.7277\n",
      "Epoch: 3, Step: 2797/2949, Loss: 0.7658\n",
      "Epoch: 3, Step: 2798/2949, Loss: 0.6958\n",
      "Epoch: 3, Step: 2799/2949, Loss: 0.7411\n",
      "Epoch: 3, Step: 2800/2949, Loss: 0.7465\n",
      "Epoch: 3, Step: 2801/2949, Loss: 0.7809\n",
      "Epoch: 3, Step: 2802/2949, Loss: 0.7707\n",
      "Epoch: 3, Step: 2803/2949, Loss: 0.7569\n",
      "Epoch: 3, Step: 2804/2949, Loss: 0.7733\n",
      "Epoch: 3, Step: 2805/2949, Loss: 0.7843\n",
      "Epoch: 3, Step: 2806/2949, Loss: 0.7828\n",
      "Epoch: 3, Step: 2807/2949, Loss: 0.8149\n",
      "Epoch: 3, Step: 2808/2949, Loss: 0.8056\n",
      "Epoch: 3, Step: 2809/2949, Loss: 0.7852\n",
      "Epoch: 3, Step: 2810/2949, Loss: 0.7509\n",
      "Epoch: 3, Step: 2811/2949, Loss: 0.7271\n",
      "Epoch: 3, Step: 2812/2949, Loss: 0.7893\n",
      "Epoch: 3, Step: 2813/2949, Loss: 0.7815\n",
      "Epoch: 3, Step: 2814/2949, Loss: 0.7993\n",
      "Epoch: 3, Step: 2815/2949, Loss: 0.7850\n",
      "Epoch: 3, Step: 2816/2949, Loss: 0.7577\n",
      "Epoch: 3, Step: 2817/2949, Loss: 0.7821\n",
      "Epoch: 3, Step: 2818/2949, Loss: 0.7410\n",
      "Epoch: 3, Step: 2819/2949, Loss: 0.7798\n",
      "Epoch: 3, Step: 2820/2949, Loss: 0.7269\n",
      "Epoch: 3, Step: 2821/2949, Loss: 0.7678\n",
      "Epoch: 3, Step: 2822/2949, Loss: 0.8018\n",
      "Epoch: 3, Step: 2823/2949, Loss: 0.7786\n",
      "Epoch: 3, Step: 2824/2949, Loss: 0.7954\n",
      "Epoch: 3, Step: 2825/2949, Loss: 0.8499\n",
      "Epoch: 3, Step: 2826/2949, Loss: 0.7813\n",
      "Epoch: 3, Step: 2827/2949, Loss: 0.8049\n",
      "Epoch: 3, Step: 2828/2949, Loss: 0.7510\n",
      "Epoch: 3, Step: 2829/2949, Loss: 0.7628\n",
      "Epoch: 3, Step: 2830/2949, Loss: 0.7663\n",
      "Epoch: 3, Step: 2831/2949, Loss: 0.7647\n",
      "Epoch: 3, Step: 2832/2949, Loss: 0.7630\n",
      "Epoch: 3, Step: 2833/2949, Loss: 0.7957\n",
      "Epoch: 3, Step: 2834/2949, Loss: 0.7531\n",
      "Epoch: 3, Step: 2835/2949, Loss: 0.7655\n",
      "Epoch: 3, Step: 2836/2949, Loss: 0.7520\n",
      "Epoch: 3, Step: 2837/2949, Loss: 0.7833\n",
      "Epoch: 3, Step: 2838/2949, Loss: 0.7931\n",
      "Epoch: 3, Step: 2839/2949, Loss: 0.7252\n",
      "Epoch: 3, Step: 2840/2949, Loss: 0.7260\n",
      "Epoch: 3, Step: 2841/2949, Loss: 0.7565\n",
      "Epoch: 3, Step: 2842/2949, Loss: 0.7196\n",
      "Epoch: 3, Step: 2843/2949, Loss: 0.7281\n",
      "Epoch: 3, Step: 2844/2949, Loss: 0.7752\n",
      "Epoch: 3, Step: 2845/2949, Loss: 0.7565\n",
      "Epoch: 3, Step: 2846/2949, Loss: 0.7589\n",
      "Epoch: 3, Step: 2847/2949, Loss: 0.7788\n",
      "Epoch: 3, Step: 2848/2949, Loss: 0.7615\n",
      "Epoch: 3, Step: 2849/2949, Loss: 0.7152\n",
      "Epoch: 3, Step: 2850/2949, Loss: 0.7805\n",
      "Epoch: 3, Step: 2851/2949, Loss: 0.7608\n",
      "Epoch: 3, Step: 2852/2949, Loss: 0.7796\n",
      "Epoch: 3, Step: 2853/2949, Loss: 0.7599\n",
      "Epoch: 3, Step: 2854/2949, Loss: 0.7871\n",
      "Epoch: 3, Step: 2855/2949, Loss: 0.7470\n",
      "Epoch: 3, Step: 2856/2949, Loss: 0.8048\n",
      "Epoch: 3, Step: 2857/2949, Loss: 0.7606\n",
      "Epoch: 3, Step: 2858/2949, Loss: 0.7698\n",
      "Epoch: 3, Step: 2859/2949, Loss: 0.7705\n",
      "Epoch: 3, Step: 2860/2949, Loss: 0.7479\n",
      "Epoch: 3, Step: 2861/2949, Loss: 0.7670\n",
      "Epoch: 3, Step: 2862/2949, Loss: 0.7339\n",
      "Epoch: 3, Step: 2863/2949, Loss: 0.7361\n",
      "Epoch: 3, Step: 2864/2949, Loss: 0.7091\n",
      "Epoch: 3, Step: 2865/2949, Loss: 0.7824\n",
      "Epoch: 3, Step: 2866/2949, Loss: 0.6917\n",
      "Epoch: 3, Step: 2867/2949, Loss: 0.7553\n",
      "Epoch: 3, Step: 2868/2949, Loss: 0.8020\n",
      "Epoch: 3, Step: 2869/2949, Loss: 0.7680\n",
      "Epoch: 3, Step: 2870/2949, Loss: 0.7312\n",
      "Epoch: 3, Step: 2871/2949, Loss: 0.7511\n",
      "Epoch: 3, Step: 2872/2949, Loss: 0.7558\n",
      "Epoch: 3, Step: 2873/2949, Loss: 0.7500\n",
      "Epoch: 3, Step: 2874/2949, Loss: 0.8051\n",
      "Epoch: 3, Step: 2875/2949, Loss: 0.7983\n",
      "Epoch: 3, Step: 2876/2949, Loss: 0.7326\n",
      "Epoch: 3, Step: 2877/2949, Loss: 0.7661\n",
      "Epoch: 3, Step: 2878/2949, Loss: 0.7591\n",
      "Epoch: 3, Step: 2879/2949, Loss: 0.7601\n",
      "Epoch: 3, Step: 2880/2949, Loss: 0.7679\n",
      "Epoch: 3, Step: 2881/2949, Loss: 0.7491\n",
      "Epoch: 3, Step: 2882/2949, Loss: 0.8117\n",
      "Epoch: 3, Step: 2883/2949, Loss: 0.7948\n",
      "Epoch: 3, Step: 2884/2949, Loss: 0.7486\n",
      "Epoch: 3, Step: 2885/2949, Loss: 0.7249\n",
      "Epoch: 3, Step: 2886/2949, Loss: 0.7200\n",
      "Epoch: 3, Step: 2887/2949, Loss: 0.7372\n",
      "Epoch: 3, Step: 2888/2949, Loss: 0.7411\n",
      "Epoch: 3, Step: 2889/2949, Loss: 0.7901\n",
      "Epoch: 3, Step: 2890/2949, Loss: 0.7785\n",
      "Epoch: 3, Step: 2891/2949, Loss: 0.7635\n",
      "Epoch: 3, Step: 2892/2949, Loss: 0.7482\n",
      "Epoch: 3, Step: 2893/2949, Loss: 0.7852\n",
      "Epoch: 3, Step: 2894/2949, Loss: 0.7817\n",
      "Epoch: 3, Step: 2895/2949, Loss: 0.6897\n",
      "Epoch: 3, Step: 2896/2949, Loss: 0.7401\n",
      "Epoch: 3, Step: 2897/2949, Loss: 0.7326\n",
      "Epoch: 3, Step: 2898/2949, Loss: 0.7599\n",
      "Epoch: 3, Step: 2899/2949, Loss: 0.7596\n",
      "Epoch: 3, Step: 2900/2949, Loss: 0.7421\n",
      "Epoch: 3, Step: 2901/2949, Loss: 0.7841\n",
      "Epoch: 3, Step: 2902/2949, Loss: 0.7536\n",
      "Epoch: 3, Step: 2903/2949, Loss: 0.7346\n",
      "Epoch: 3, Step: 2904/2949, Loss: 0.8196\n",
      "Epoch: 3, Step: 2905/2949, Loss: 0.7439\n",
      "Epoch: 3, Step: 2906/2949, Loss: 0.7709\n",
      "Epoch: 3, Step: 2907/2949, Loss: 0.7671\n",
      "Epoch: 3, Step: 2908/2949, Loss: 0.7593\n",
      "Epoch: 3, Step: 2909/2949, Loss: 0.7732\n",
      "Epoch: 3, Step: 2910/2949, Loss: 0.7789\n",
      "Epoch: 3, Step: 2911/2949, Loss: 0.7822\n",
      "Epoch: 3, Step: 2912/2949, Loss: 0.7516\n",
      "Epoch: 3, Step: 2913/2949, Loss: 0.7748\n",
      "Epoch: 3, Step: 2914/2949, Loss: 0.8083\n",
      "Epoch: 3, Step: 2915/2949, Loss: 0.7842\n",
      "Epoch: 3, Step: 2916/2949, Loss: 0.7376\n",
      "Epoch: 3, Step: 2917/2949, Loss: 0.7583\n",
      "Epoch: 3, Step: 2918/2949, Loss: 0.7826\n",
      "Epoch: 3, Step: 2919/2949, Loss: 0.7802\n",
      "Epoch: 3, Step: 2920/2949, Loss: 0.7212\n",
      "Epoch: 3, Step: 2921/2949, Loss: 0.7483\n",
      "Epoch: 3, Step: 2922/2949, Loss: 0.7991\n",
      "Epoch: 3, Step: 2923/2949, Loss: 0.7963\n",
      "Epoch: 3, Step: 2924/2949, Loss: 0.7308\n",
      "Epoch: 3, Step: 2925/2949, Loss: 0.7543\n",
      "Epoch: 3, Step: 2926/2949, Loss: 0.8199\n",
      "Epoch: 3, Step: 2927/2949, Loss: 0.7892\n",
      "Epoch: 3, Step: 2928/2949, Loss: 0.7873\n",
      "Epoch: 3, Step: 2929/2949, Loss: 0.7777\n",
      "Epoch: 3, Step: 2930/2949, Loss: 0.7254\n",
      "Epoch: 3, Step: 2931/2949, Loss: 0.8081\n",
      "Epoch: 3, Step: 2932/2949, Loss: 0.7749\n",
      "Epoch: 3, Step: 2933/2949, Loss: 0.7873\n",
      "Epoch: 3, Step: 2934/2949, Loss: 0.7753\n",
      "Epoch: 3, Step: 2935/2949, Loss: 0.8011\n",
      "Epoch: 3, Step: 2936/2949, Loss: 0.7723\n",
      "Epoch: 3, Step: 2937/2949, Loss: 0.7847\n",
      "Epoch: 3, Step: 2938/2949, Loss: 0.7824\n",
      "Epoch: 3, Step: 2939/2949, Loss: 0.7323\n",
      "Epoch: 3, Step: 2940/2949, Loss: 0.7740\n",
      "Epoch: 3, Step: 2941/2949, Loss: 0.7410\n",
      "Epoch: 3, Step: 2942/2949, Loss: 0.7904\n",
      "Epoch: 3, Step: 2943/2949, Loss: 0.7790\n",
      "Epoch: 3, Step: 2944/2949, Loss: 0.7558\n",
      "Epoch: 3, Step: 2945/2949, Loss: 0.6733\n",
      "Epoch: 3, Step: 2946/2949, Loss: 0.7575\n",
      "Epoch: 3, Step: 2947/2949, Loss: 0.7330\n",
      "Epoch: 3, Step: 2948/2949, Loss: 0.7632\n",
      "Epoch: 3, Step: 2949/2949, Loss: 0.7169\n",
      "Test Accuracy (xgboost): 0.3724\n",
      "Epoch: 3, Accuracy: 0.3724\n",
      "Epoch: 4, Step: 001/2949, Loss: 0.7852\n",
      "Epoch: 4, Step: 002/2949, Loss: 0.6721\n",
      "Epoch: 4, Step: 003/2949, Loss: 0.8047\n",
      "Epoch: 4, Step: 004/2949, Loss: 0.7996\n",
      "Epoch: 4, Step: 005/2949, Loss: 0.7772\n",
      "Epoch: 4, Step: 006/2949, Loss: 0.7815\n",
      "Epoch: 4, Step: 007/2949, Loss: 0.7356\n",
      "Epoch: 4, Step: 008/2949, Loss: 0.7418\n",
      "Epoch: 4, Step: 009/2949, Loss: 0.7535\n",
      "Epoch: 4, Step: 010/2949, Loss: 0.7498\n",
      "Epoch: 4, Step: 011/2949, Loss: 0.7481\n",
      "Epoch: 4, Step: 012/2949, Loss: 0.7549\n",
      "Epoch: 4, Step: 013/2949, Loss: 0.7328\n",
      "Epoch: 4, Step: 014/2949, Loss: 0.7299\n",
      "Epoch: 4, Step: 015/2949, Loss: 0.7683\n",
      "Epoch: 4, Step: 016/2949, Loss: 0.7441\n",
      "Epoch: 4, Step: 017/2949, Loss: 0.7531\n",
      "Epoch: 4, Step: 018/2949, Loss: 0.7694\n",
      "Epoch: 4, Step: 019/2949, Loss: 0.7925\n",
      "Epoch: 4, Step: 020/2949, Loss: 0.7484\n",
      "Epoch: 4, Step: 021/2949, Loss: 0.7118\n",
      "Epoch: 4, Step: 022/2949, Loss: 0.7641\n",
      "Epoch: 4, Step: 023/2949, Loss: 0.7284\n",
      "Epoch: 4, Step: 024/2949, Loss: 0.7487\n",
      "Epoch: 4, Step: 025/2949, Loss: 0.7715\n",
      "Epoch: 4, Step: 026/2949, Loss: 0.7505\n",
      "Epoch: 4, Step: 027/2949, Loss: 0.7925\n",
      "Epoch: 4, Step: 028/2949, Loss: 0.7870\n",
      "Epoch: 4, Step: 029/2949, Loss: 0.7848\n",
      "Epoch: 4, Step: 030/2949, Loss: 0.7507\n",
      "Epoch: 4, Step: 031/2949, Loss: 0.7448\n",
      "Epoch: 4, Step: 032/2949, Loss: 0.7311\n",
      "Epoch: 4, Step: 033/2949, Loss: 0.7493\n",
      "Epoch: 4, Step: 034/2949, Loss: 0.7283\n",
      "Epoch: 4, Step: 035/2949, Loss: 0.7392\n",
      "Epoch: 4, Step: 036/2949, Loss: 0.7594\n",
      "Epoch: 4, Step: 037/2949, Loss: 0.7714\n",
      "Epoch: 4, Step: 038/2949, Loss: 0.7439\n",
      "Epoch: 4, Step: 039/2949, Loss: 0.7334\n",
      "Epoch: 4, Step: 040/2949, Loss: 0.7411\n",
      "Epoch: 4, Step: 041/2949, Loss: 0.7629\n",
      "Epoch: 4, Step: 042/2949, Loss: 0.7452\n",
      "Epoch: 4, Step: 043/2949, Loss: 0.7799\n",
      "Epoch: 4, Step: 044/2949, Loss: 0.7236\n",
      "Epoch: 4, Step: 045/2949, Loss: 0.7998\n",
      "Epoch: 4, Step: 046/2949, Loss: 0.7509\n",
      "Epoch: 4, Step: 047/2949, Loss: 0.7582\n",
      "Epoch: 4, Step: 048/2949, Loss: 0.7287\n",
      "Epoch: 4, Step: 049/2949, Loss: 0.7489\n",
      "Epoch: 4, Step: 050/2949, Loss: 0.7317\n",
      "Epoch: 4, Step: 051/2949, Loss: 0.7951\n",
      "Epoch: 4, Step: 052/2949, Loss: 0.7368\n",
      "Epoch: 4, Step: 053/2949, Loss: 0.7391\n",
      "Epoch: 4, Step: 054/2949, Loss: 0.7760\n",
      "Epoch: 4, Step: 055/2949, Loss: 0.7437\n",
      "Epoch: 4, Step: 056/2949, Loss: 0.7625\n",
      "Epoch: 4, Step: 057/2949, Loss: 0.7643\n",
      "Epoch: 4, Step: 058/2949, Loss: 0.7816\n",
      "Epoch: 4, Step: 059/2949, Loss: 0.7065\n",
      "Epoch: 4, Step: 060/2949, Loss: 0.7480\n",
      "Epoch: 4, Step: 061/2949, Loss: 0.7610\n",
      "Epoch: 4, Step: 062/2949, Loss: 0.7713\n",
      "Epoch: 4, Step: 063/2949, Loss: 0.7891\n",
      "Epoch: 4, Step: 064/2949, Loss: 0.8018\n",
      "Epoch: 4, Step: 065/2949, Loss: 0.7533\n",
      "Epoch: 4, Step: 066/2949, Loss: 0.7771\n",
      "Epoch: 4, Step: 067/2949, Loss: 0.7883\n",
      "Epoch: 4, Step: 068/2949, Loss: 0.7512\n",
      "Epoch: 4, Step: 069/2949, Loss: 0.8063\n",
      "Epoch: 4, Step: 070/2949, Loss: 0.7092\n",
      "Epoch: 4, Step: 071/2949, Loss: 0.7817\n",
      "Epoch: 4, Step: 072/2949, Loss: 0.7622\n",
      "Epoch: 4, Step: 073/2949, Loss: 0.7698\n",
      "Epoch: 4, Step: 074/2949, Loss: 0.7353\n",
      "Epoch: 4, Step: 075/2949, Loss: 0.8093\n",
      "Epoch: 4, Step: 076/2949, Loss: 0.7726\n",
      "Epoch: 4, Step: 077/2949, Loss: 0.7262\n",
      "Epoch: 4, Step: 078/2949, Loss: 0.7206\n",
      "Epoch: 4, Step: 079/2949, Loss: 0.7838\n",
      "Epoch: 4, Step: 080/2949, Loss: 0.7630\n",
      "Epoch: 4, Step: 081/2949, Loss: 0.7510\n",
      "Epoch: 4, Step: 082/2949, Loss: 0.7672\n",
      "Epoch: 4, Step: 083/2949, Loss: 0.7217\n",
      "Epoch: 4, Step: 084/2949, Loss: 0.7340\n",
      "Epoch: 4, Step: 085/2949, Loss: 0.7866\n",
      "Epoch: 4, Step: 086/2949, Loss: 0.7756\n",
      "Epoch: 4, Step: 087/2949, Loss: 0.7920\n",
      "Epoch: 4, Step: 088/2949, Loss: 0.7658\n",
      "Epoch: 4, Step: 089/2949, Loss: 0.7765\n",
      "Epoch: 4, Step: 090/2949, Loss: 0.7862\n",
      "Epoch: 4, Step: 091/2949, Loss: 0.7828\n",
      "Epoch: 4, Step: 092/2949, Loss: 0.7691\n",
      "Epoch: 4, Step: 093/2949, Loss: 0.7271\n",
      "Epoch: 4, Step: 094/2949, Loss: 0.7172\n",
      "Epoch: 4, Step: 095/2949, Loss: 0.7754\n",
      "Epoch: 4, Step: 096/2949, Loss: 0.7164\n",
      "Epoch: 4, Step: 097/2949, Loss: 0.7656\n",
      "Epoch: 4, Step: 098/2949, Loss: 0.7907\n",
      "Epoch: 4, Step: 099/2949, Loss: 0.7588\n",
      "Epoch: 4, Step: 100/2949, Loss: 0.7633\n",
      "Epoch: 4, Step: 101/2949, Loss: 0.7928\n",
      "Epoch: 4, Step: 102/2949, Loss: 0.7345\n",
      "Epoch: 4, Step: 103/2949, Loss: 0.8040\n",
      "Epoch: 4, Step: 104/2949, Loss: 0.7907\n",
      "Epoch: 4, Step: 105/2949, Loss: 0.7420\n",
      "Epoch: 4, Step: 106/2949, Loss: 0.7459\n",
      "Epoch: 4, Step: 107/2949, Loss: 0.7610\n",
      "Epoch: 4, Step: 108/2949, Loss: 0.7377\n",
      "Epoch: 4, Step: 109/2949, Loss: 0.7536\n",
      "Epoch: 4, Step: 110/2949, Loss: 0.7243\n",
      "Epoch: 4, Step: 111/2949, Loss: 0.7098\n",
      "Epoch: 4, Step: 112/2949, Loss: 0.8138\n",
      "Epoch: 4, Step: 113/2949, Loss: 0.7785\n",
      "Epoch: 4, Step: 114/2949, Loss: 0.7542\n",
      "Epoch: 4, Step: 115/2949, Loss: 0.6981\n",
      "Epoch: 4, Step: 116/2949, Loss: 0.7219\n",
      "Epoch: 4, Step: 117/2949, Loss: 0.7315\n",
      "Epoch: 4, Step: 118/2949, Loss: 0.7212\n",
      "Epoch: 4, Step: 119/2949, Loss: 0.7685\n",
      "Epoch: 4, Step: 120/2949, Loss: 0.7250\n",
      "Epoch: 4, Step: 121/2949, Loss: 0.7944\n",
      "Epoch: 4, Step: 122/2949, Loss: 0.7436\n",
      "Epoch: 4, Step: 123/2949, Loss: 0.7554\n",
      "Epoch: 4, Step: 124/2949, Loss: 0.7184\n",
      "Epoch: 4, Step: 125/2949, Loss: 0.7651\n",
      "Epoch: 4, Step: 126/2949, Loss: 0.7080\n",
      "Epoch: 4, Step: 127/2949, Loss: 0.7756\n",
      "Epoch: 4, Step: 128/2949, Loss: 0.7749\n",
      "Epoch: 4, Step: 129/2949, Loss: 0.7496\n",
      "Epoch: 4, Step: 130/2949, Loss: 0.7170\n",
      "Epoch: 4, Step: 131/2949, Loss: 0.7350\n",
      "Epoch: 4, Step: 132/2949, Loss: 0.7408\n",
      "Epoch: 4, Step: 133/2949, Loss: 0.7746\n",
      "Epoch: 4, Step: 134/2949, Loss: 0.7328\n",
      "Epoch: 4, Step: 135/2949, Loss: 0.7640\n",
      "Epoch: 4, Step: 136/2949, Loss: 0.7626\n",
      "Epoch: 4, Step: 137/2949, Loss: 0.7191\n",
      "Epoch: 4, Step: 138/2949, Loss: 0.7528\n",
      "Epoch: 4, Step: 139/2949, Loss: 0.7443\n",
      "Epoch: 4, Step: 140/2949, Loss: 0.7806\n",
      "Epoch: 4, Step: 141/2949, Loss: 0.8154\n",
      "Epoch: 4, Step: 142/2949, Loss: 0.7509\n",
      "Epoch: 4, Step: 143/2949, Loss: 0.7186\n",
      "Epoch: 4, Step: 144/2949, Loss: 0.7638\n",
      "Epoch: 4, Step: 145/2949, Loss: 0.7497\n",
      "Epoch: 4, Step: 146/2949, Loss: 0.7498\n",
      "Epoch: 4, Step: 147/2949, Loss: 0.7983\n",
      "Epoch: 4, Step: 148/2949, Loss: 0.7701\n",
      "Epoch: 4, Step: 149/2949, Loss: 0.7219\n",
      "Epoch: 4, Step: 150/2949, Loss: 0.7901\n",
      "Epoch: 4, Step: 151/2949, Loss: 0.7544\n",
      "Epoch: 4, Step: 152/2949, Loss: 0.7544\n",
      "Epoch: 4, Step: 153/2949, Loss: 0.7462\n",
      "Epoch: 4, Step: 154/2949, Loss: 0.7626\n",
      "Epoch: 4, Step: 155/2949, Loss: 0.7439\n",
      "Epoch: 4, Step: 156/2949, Loss: 0.7234\n",
      "Epoch: 4, Step: 157/2949, Loss: 0.7422\n",
      "Epoch: 4, Step: 158/2949, Loss: 0.7762\n",
      "Epoch: 4, Step: 159/2949, Loss: 0.7667\n",
      "Epoch: 4, Step: 160/2949, Loss: 0.7611\n",
      "Epoch: 4, Step: 161/2949, Loss: 0.7707\n",
      "Epoch: 4, Step: 162/2949, Loss: 0.7541\n",
      "Epoch: 4, Step: 163/2949, Loss: 0.7874\n",
      "Epoch: 4, Step: 164/2949, Loss: 0.7383\n",
      "Epoch: 4, Step: 165/2949, Loss: 0.7580\n",
      "Epoch: 4, Step: 166/2949, Loss: 0.7611\n",
      "Epoch: 4, Step: 167/2949, Loss: 0.7786\n",
      "Epoch: 4, Step: 168/2949, Loss: 0.7802\n",
      "Epoch: 4, Step: 169/2949, Loss: 0.6948\n",
      "Epoch: 4, Step: 170/2949, Loss: 0.7711\n",
      "Epoch: 4, Step: 171/2949, Loss: 0.7425\n",
      "Epoch: 4, Step: 172/2949, Loss: 0.7427\n",
      "Epoch: 4, Step: 173/2949, Loss: 0.7010\n",
      "Epoch: 4, Step: 174/2949, Loss: 0.7868\n",
      "Epoch: 4, Step: 175/2949, Loss: 0.7592\n",
      "Epoch: 4, Step: 176/2949, Loss: 0.7590\n",
      "Epoch: 4, Step: 177/2949, Loss: 0.7538\n",
      "Epoch: 4, Step: 178/2949, Loss: 0.7888\n",
      "Epoch: 4, Step: 179/2949, Loss: 0.7288\n",
      "Epoch: 4, Step: 180/2949, Loss: 0.7803\n",
      "Epoch: 4, Step: 181/2949, Loss: 0.7919\n",
      "Epoch: 4, Step: 182/2949, Loss: 0.7992\n",
      "Epoch: 4, Step: 183/2949, Loss: 0.7674\n",
      "Epoch: 4, Step: 184/2949, Loss: 0.7745\n",
      "Epoch: 4, Step: 185/2949, Loss: 0.8010\n",
      "Epoch: 4, Step: 186/2949, Loss: 0.7765\n",
      "Epoch: 4, Step: 187/2949, Loss: 0.7914\n",
      "Epoch: 4, Step: 188/2949, Loss: 0.7966\n",
      "Epoch: 4, Step: 189/2949, Loss: 0.7736\n",
      "Epoch: 4, Step: 190/2949, Loss: 0.8060\n",
      "Epoch: 4, Step: 191/2949, Loss: 0.7699\n",
      "Epoch: 4, Step: 192/2949, Loss: 0.8099\n",
      "Epoch: 4, Step: 193/2949, Loss: 0.7657\n",
      "Epoch: 4, Step: 194/2949, Loss: 0.7403\n",
      "Epoch: 4, Step: 195/2949, Loss: 0.7538\n",
      "Epoch: 4, Step: 196/2949, Loss: 0.7455\n",
      "Epoch: 4, Step: 197/2949, Loss: 0.7325\n",
      "Epoch: 4, Step: 198/2949, Loss: 0.7337\n",
      "Epoch: 4, Step: 199/2949, Loss: 0.7424\n",
      "Epoch: 4, Step: 200/2949, Loss: 0.8095\n",
      "Epoch: 4, Step: 201/2949, Loss: 0.7537\n",
      "Epoch: 4, Step: 202/2949, Loss: 0.7523\n",
      "Epoch: 4, Step: 203/2949, Loss: 0.7452\n",
      "Epoch: 4, Step: 204/2949, Loss: 0.7653\n",
      "Epoch: 4, Step: 205/2949, Loss: 0.7570\n",
      "Epoch: 4, Step: 206/2949, Loss: 0.7453\n",
      "Epoch: 4, Step: 207/2949, Loss: 0.7607\n",
      "Epoch: 4, Step: 208/2949, Loss: 0.7136\n",
      "Epoch: 4, Step: 209/2949, Loss: 0.7307\n",
      "Epoch: 4, Step: 210/2949, Loss: 0.7454\n",
      "Epoch: 4, Step: 211/2949, Loss: 0.7323\n",
      "Epoch: 4, Step: 212/2949, Loss: 0.7632\n",
      "Epoch: 4, Step: 213/2949, Loss: 0.7516\n",
      "Epoch: 4, Step: 214/2949, Loss: 0.6848\n",
      "Epoch: 4, Step: 215/2949, Loss: 0.7578\n",
      "Epoch: 4, Step: 216/2949, Loss: 0.7654\n",
      "Epoch: 4, Step: 217/2949, Loss: 0.6929\n",
      "Epoch: 4, Step: 218/2949, Loss: 0.7128\n",
      "Epoch: 4, Step: 219/2949, Loss: 0.7864\n",
      "Epoch: 4, Step: 220/2949, Loss: 0.7170\n",
      "Epoch: 4, Step: 221/2949, Loss: 0.7828\n",
      "Epoch: 4, Step: 222/2949, Loss: 0.7607\n",
      "Epoch: 4, Step: 223/2949, Loss: 0.7648\n",
      "Epoch: 4, Step: 224/2949, Loss: 0.7867\n",
      "Epoch: 4, Step: 225/2949, Loss: 0.7678\n",
      "Epoch: 4, Step: 226/2949, Loss: 0.7832\n",
      "Epoch: 4, Step: 227/2949, Loss: 0.7745\n",
      "Epoch: 4, Step: 228/2949, Loss: 0.7864\n",
      "Epoch: 4, Step: 229/2949, Loss: 0.7456\n",
      "Epoch: 4, Step: 230/2949, Loss: 0.8037\n",
      "Epoch: 4, Step: 231/2949, Loss: 0.7077\n",
      "Epoch: 4, Step: 232/2949, Loss: 0.7640\n",
      "Epoch: 4, Step: 233/2949, Loss: 0.7309\n",
      "Epoch: 4, Step: 234/2949, Loss: 0.7686\n",
      "Epoch: 4, Step: 235/2949, Loss: 0.7380\n",
      "Epoch: 4, Step: 236/2949, Loss: 0.7197\n",
      "Epoch: 4, Step: 237/2949, Loss: 0.7478\n",
      "Epoch: 4, Step: 238/2949, Loss: 0.6875\n",
      "Epoch: 4, Step: 239/2949, Loss: 0.7613\n",
      "Epoch: 4, Step: 240/2949, Loss: 0.7270\n",
      "Epoch: 4, Step: 241/2949, Loss: 0.7657\n",
      "Epoch: 4, Step: 242/2949, Loss: 0.7145\n",
      "Epoch: 4, Step: 243/2949, Loss: 0.7837\n",
      "Epoch: 4, Step: 244/2949, Loss: 0.7521\n",
      "Epoch: 4, Step: 245/2949, Loss: 0.7898\n",
      "Epoch: 4, Step: 246/2949, Loss: 0.7736\n",
      "Epoch: 4, Step: 247/2949, Loss: 0.7553\n",
      "Epoch: 4, Step: 248/2949, Loss: 0.7821\n",
      "Epoch: 4, Step: 249/2949, Loss: 0.7117\n",
      "Epoch: 4, Step: 250/2949, Loss: 0.8348\n",
      "Epoch: 4, Step: 251/2949, Loss: 0.7902\n",
      "Epoch: 4, Step: 252/2949, Loss: 0.7242\n",
      "Epoch: 4, Step: 253/2949, Loss: 0.7359\n",
      "Epoch: 4, Step: 254/2949, Loss: 0.7287\n",
      "Epoch: 4, Step: 255/2949, Loss: 0.7656\n",
      "Epoch: 4, Step: 256/2949, Loss: 0.7378\n",
      "Epoch: 4, Step: 257/2949, Loss: 0.8038\n",
      "Epoch: 4, Step: 258/2949, Loss: 0.7729\n",
      "Epoch: 4, Step: 259/2949, Loss: 0.7404\n",
      "Epoch: 4, Step: 260/2949, Loss: 0.7856\n",
      "Epoch: 4, Step: 261/2949, Loss: 0.7988\n",
      "Epoch: 4, Step: 262/2949, Loss: 0.7762\n",
      "Epoch: 4, Step: 263/2949, Loss: 0.7442\n",
      "Epoch: 4, Step: 264/2949, Loss: 0.7717\n",
      "Epoch: 4, Step: 265/2949, Loss: 0.7550\n",
      "Epoch: 4, Step: 266/2949, Loss: 0.7705\n",
      "Epoch: 4, Step: 267/2949, Loss: 0.6558\n",
      "Epoch: 4, Step: 268/2949, Loss: 0.7255\n",
      "Epoch: 4, Step: 269/2949, Loss: 0.8222\n",
      "Epoch: 4, Step: 270/2949, Loss: 0.7802\n",
      "Epoch: 4, Step: 271/2949, Loss: 0.7174\n",
      "Epoch: 4, Step: 272/2949, Loss: 0.7036\n",
      "Epoch: 4, Step: 273/2949, Loss: 0.7450\n",
      "Epoch: 4, Step: 274/2949, Loss: 0.7697\n",
      "Epoch: 4, Step: 275/2949, Loss: 0.7382\n",
      "Epoch: 4, Step: 276/2949, Loss: 0.6992\n",
      "Epoch: 4, Step: 277/2949, Loss: 0.7754\n",
      "Epoch: 4, Step: 278/2949, Loss: 0.7232\n",
      "Epoch: 4, Step: 279/2949, Loss: 0.7610\n",
      "Epoch: 4, Step: 280/2949, Loss: 0.7119\n",
      "Epoch: 4, Step: 281/2949, Loss: 0.7837\n",
      "Epoch: 4, Step: 282/2949, Loss: 0.7546\n",
      "Epoch: 4, Step: 283/2949, Loss: 0.6910\n",
      "Epoch: 4, Step: 284/2949, Loss: 0.7283\n",
      "Epoch: 4, Step: 285/2949, Loss: 0.7289\n",
      "Epoch: 4, Step: 286/2949, Loss: 0.7043\n",
      "Epoch: 4, Step: 287/2949, Loss: 0.7881\n",
      "Epoch: 4, Step: 288/2949, Loss: 0.7411\n",
      "Epoch: 4, Step: 289/2949, Loss: 0.7664\n",
      "Epoch: 4, Step: 290/2949, Loss: 0.7921\n",
      "Epoch: 4, Step: 291/2949, Loss: 0.6946\n",
      "Epoch: 4, Step: 292/2949, Loss: 0.7601\n",
      "Epoch: 4, Step: 293/2949, Loss: 0.7407\n",
      "Epoch: 4, Step: 294/2949, Loss: 0.7773\n",
      "Epoch: 4, Step: 295/2949, Loss: 0.7450\n",
      "Epoch: 4, Step: 296/2949, Loss: 0.7436\n",
      "Epoch: 4, Step: 297/2949, Loss: 0.7288\n",
      "Epoch: 4, Step: 298/2949, Loss: 0.7514\n",
      "Epoch: 4, Step: 299/2949, Loss: 0.7755\n",
      "Epoch: 4, Step: 300/2949, Loss: 0.7728\n",
      "Epoch: 4, Step: 301/2949, Loss: 0.7629\n",
      "Epoch: 4, Step: 302/2949, Loss: 0.7462\n",
      "Epoch: 4, Step: 303/2949, Loss: 0.7471\n",
      "Epoch: 4, Step: 304/2949, Loss: 0.7975\n",
      "Epoch: 4, Step: 305/2949, Loss: 0.7331\n",
      "Epoch: 4, Step: 306/2949, Loss: 0.7917\n",
      "Epoch: 4, Step: 307/2949, Loss: 0.7445\n",
      "Epoch: 4, Step: 308/2949, Loss: 0.7444\n",
      "Epoch: 4, Step: 309/2949, Loss: 0.7434\n",
      "Epoch: 4, Step: 310/2949, Loss: 0.7186\n",
      "Epoch: 4, Step: 311/2949, Loss: 0.7987\n",
      "Epoch: 4, Step: 312/2949, Loss: 0.7233\n",
      "Epoch: 4, Step: 313/2949, Loss: 0.7269\n",
      "Epoch: 4, Step: 314/2949, Loss: 0.8308\n",
      "Epoch: 4, Step: 315/2949, Loss: 0.7019\n",
      "Epoch: 4, Step: 316/2949, Loss: 0.7567\n",
      "Epoch: 4, Step: 317/2949, Loss: 0.7855\n",
      "Epoch: 4, Step: 318/2949, Loss: 0.7340\n",
      "Epoch: 4, Step: 319/2949, Loss: 0.7208\n",
      "Epoch: 4, Step: 320/2949, Loss: 0.7859\n",
      "Epoch: 4, Step: 321/2949, Loss: 0.7662\n",
      "Epoch: 4, Step: 322/2949, Loss: 0.7837\n",
      "Epoch: 4, Step: 323/2949, Loss: 0.7821\n",
      "Epoch: 4, Step: 324/2949, Loss: 0.7401\n",
      "Epoch: 4, Step: 325/2949, Loss: 0.7177\n",
      "Epoch: 4, Step: 326/2949, Loss: 0.7529\n",
      "Epoch: 4, Step: 327/2949, Loss: 0.7368\n",
      "Epoch: 4, Step: 328/2949, Loss: 0.7744\n",
      "Epoch: 4, Step: 329/2949, Loss: 0.7092\n",
      "Epoch: 4, Step: 330/2949, Loss: 0.7655\n",
      "Epoch: 4, Step: 331/2949, Loss: 0.7659\n",
      "Epoch: 4, Step: 332/2949, Loss: 0.7284\n",
      "Epoch: 4, Step: 333/2949, Loss: 0.7998\n",
      "Epoch: 4, Step: 334/2949, Loss: 0.7439\n",
      "Epoch: 4, Step: 335/2949, Loss: 0.7572\n",
      "Epoch: 4, Step: 336/2949, Loss: 0.7228\n",
      "Epoch: 4, Step: 337/2949, Loss: 0.7292\n",
      "Epoch: 4, Step: 338/2949, Loss: 0.7608\n",
      "Epoch: 4, Step: 339/2949, Loss: 0.7269\n",
      "Epoch: 4, Step: 340/2949, Loss: 0.7415\n",
      "Epoch: 4, Step: 341/2949, Loss: 0.7603\n",
      "Epoch: 4, Step: 342/2949, Loss: 0.7455\n",
      "Epoch: 4, Step: 343/2949, Loss: 0.7432\n",
      "Epoch: 4, Step: 344/2949, Loss: 0.7435\n",
      "Epoch: 4, Step: 345/2949, Loss: 0.7805\n",
      "Epoch: 4, Step: 346/2949, Loss: 0.7472\n",
      "Epoch: 4, Step: 347/2949, Loss: 0.7744\n",
      "Epoch: 4, Step: 348/2949, Loss: 0.7764\n",
      "Epoch: 4, Step: 349/2949, Loss: 0.7162\n",
      "Epoch: 4, Step: 350/2949, Loss: 0.7582\n",
      "Epoch: 4, Step: 351/2949, Loss: 0.7513\n",
      "Epoch: 4, Step: 352/2949, Loss: 0.7557\n",
      "Epoch: 4, Step: 353/2949, Loss: 0.7252\n",
      "Epoch: 4, Step: 354/2949, Loss: 0.7733\n",
      "Epoch: 4, Step: 355/2949, Loss: 0.7417\n",
      "Epoch: 4, Step: 356/2949, Loss: 0.7703\n",
      "Epoch: 4, Step: 357/2949, Loss: 0.7558\n",
      "Epoch: 4, Step: 358/2949, Loss: 0.7161\n",
      "Epoch: 4, Step: 359/2949, Loss: 0.7573\n",
      "Epoch: 4, Step: 360/2949, Loss: 0.7823\n",
      "Epoch: 4, Step: 361/2949, Loss: 0.7912\n",
      "Epoch: 4, Step: 362/2949, Loss: 0.7369\n",
      "Epoch: 4, Step: 363/2949, Loss: 0.7731\n",
      "Epoch: 4, Step: 364/2949, Loss: 0.8090\n",
      "Epoch: 4, Step: 365/2949, Loss: 0.7337\n",
      "Epoch: 4, Step: 366/2949, Loss: 0.7278\n",
      "Epoch: 4, Step: 367/2949, Loss: 0.7329\n",
      "Epoch: 4, Step: 368/2949, Loss: 0.7755\n",
      "Epoch: 4, Step: 369/2949, Loss: 0.7715\n",
      "Epoch: 4, Step: 370/2949, Loss: 0.7343\n",
      "Epoch: 4, Step: 371/2949, Loss: 0.7396\n",
      "Epoch: 4, Step: 372/2949, Loss: 0.7873\n",
      "Epoch: 4, Step: 373/2949, Loss: 0.7123\n",
      "Epoch: 4, Step: 374/2949, Loss: 0.7331\n",
      "Epoch: 4, Step: 375/2949, Loss: 0.8012\n",
      "Epoch: 4, Step: 376/2949, Loss: 0.7268\n",
      "Epoch: 4, Step: 377/2949, Loss: 0.7659\n",
      "Epoch: 4, Step: 378/2949, Loss: 0.6942\n",
      "Epoch: 4, Step: 379/2949, Loss: 0.7242\n",
      "Epoch: 4, Step: 380/2949, Loss: 0.7506\n",
      "Epoch: 4, Step: 381/2949, Loss: 0.6980\n",
      "Epoch: 4, Step: 382/2949, Loss: 0.7497\n",
      "Epoch: 4, Step: 383/2949, Loss: 0.7872\n",
      "Epoch: 4, Step: 384/2949, Loss: 0.7085\n",
      "Epoch: 4, Step: 385/2949, Loss: 0.7521\n",
      "Epoch: 4, Step: 386/2949, Loss: 0.7274\n",
      "Epoch: 4, Step: 387/2949, Loss: 0.7836\n",
      "Epoch: 4, Step: 388/2949, Loss: 0.7650\n",
      "Epoch: 4, Step: 389/2949, Loss: 0.7122\n",
      "Epoch: 4, Step: 390/2949, Loss: 0.7434\n",
      "Epoch: 4, Step: 391/2949, Loss: 0.7935\n",
      "Epoch: 4, Step: 392/2949, Loss: 0.7533\n",
      "Epoch: 4, Step: 393/2949, Loss: 0.7203\n",
      "Epoch: 4, Step: 394/2949, Loss: 0.7525\n",
      "Epoch: 4, Step: 395/2949, Loss: 0.8136\n",
      "Epoch: 4, Step: 396/2949, Loss: 0.7263\n",
      "Epoch: 4, Step: 397/2949, Loss: 0.7122\n",
      "Epoch: 4, Step: 398/2949, Loss: 0.7657\n",
      "Epoch: 4, Step: 399/2949, Loss: 0.7517\n",
      "Epoch: 4, Step: 400/2949, Loss: 0.7722\n",
      "Epoch: 4, Step: 401/2949, Loss: 0.7247\n",
      "Epoch: 4, Step: 402/2949, Loss: 0.7601\n",
      "Epoch: 4, Step: 403/2949, Loss: 0.7199\n",
      "Epoch: 4, Step: 404/2949, Loss: 0.7925\n",
      "Epoch: 4, Step: 405/2949, Loss: 0.7366\n",
      "Epoch: 4, Step: 406/2949, Loss: 0.7708\n",
      "Epoch: 4, Step: 407/2949, Loss: 0.7691\n",
      "Epoch: 4, Step: 408/2949, Loss: 0.7455\n",
      "Epoch: 4, Step: 409/2949, Loss: 0.7388\n",
      "Epoch: 4, Step: 410/2949, Loss: 0.7128\n",
      "Epoch: 4, Step: 411/2949, Loss: 0.7215\n",
      "Epoch: 4, Step: 412/2949, Loss: 0.8216\n",
      "Epoch: 4, Step: 413/2949, Loss: 0.7328\n",
      "Epoch: 4, Step: 414/2949, Loss: 0.7510\n",
      "Epoch: 4, Step: 415/2949, Loss: 0.7102\n",
      "Epoch: 4, Step: 416/2949, Loss: 0.7544\n",
      "Epoch: 4, Step: 417/2949, Loss: 0.7135\n",
      "Epoch: 4, Step: 418/2949, Loss: 0.7163\n",
      "Epoch: 4, Step: 419/2949, Loss: 0.7651\n",
      "Epoch: 4, Step: 420/2949, Loss: 0.7684\n",
      "Epoch: 4, Step: 421/2949, Loss: 0.7088\n",
      "Epoch: 4, Step: 422/2949, Loss: 0.7366\n",
      "Epoch: 4, Step: 423/2949, Loss: 0.7558\n",
      "Epoch: 4, Step: 424/2949, Loss: 0.7523\n",
      "Epoch: 4, Step: 425/2949, Loss: 0.7629\n",
      "Epoch: 4, Step: 426/2949, Loss: 0.7895\n",
      "Epoch: 4, Step: 427/2949, Loss: 0.7597\n",
      "Epoch: 4, Step: 428/2949, Loss: 0.8074\n",
      "Epoch: 4, Step: 429/2949, Loss: 0.7299\n",
      "Epoch: 4, Step: 430/2949, Loss: 0.7040\n",
      "Epoch: 4, Step: 431/2949, Loss: 0.7363\n",
      "Epoch: 4, Step: 432/2949, Loss: 0.7178\n",
      "Epoch: 4, Step: 433/2949, Loss: 0.7683\n",
      "Epoch: 4, Step: 434/2949, Loss: 0.7168\n",
      "Epoch: 4, Step: 435/2949, Loss: 0.7354\n",
      "Epoch: 4, Step: 436/2949, Loss: 0.7516\n",
      "Epoch: 4, Step: 437/2949, Loss: 0.8256\n",
      "Epoch: 4, Step: 438/2949, Loss: 0.7174\n",
      "Epoch: 4, Step: 439/2949, Loss: 0.7011\n",
      "Epoch: 4, Step: 440/2949, Loss: 0.7922\n",
      "Epoch: 4, Step: 441/2949, Loss: 0.7988\n",
      "Epoch: 4, Step: 442/2949, Loss: 0.7286\n",
      "Epoch: 4, Step: 443/2949, Loss: 0.7211\n",
      "Epoch: 4, Step: 444/2949, Loss: 0.7809\n",
      "Epoch: 4, Step: 445/2949, Loss: 0.7869\n",
      "Epoch: 4, Step: 446/2949, Loss: 0.7763\n",
      "Epoch: 4, Step: 447/2949, Loss: 0.7838\n",
      "Epoch: 4, Step: 448/2949, Loss: 0.7908\n",
      "Epoch: 4, Step: 449/2949, Loss: 0.7625\n",
      "Epoch: 4, Step: 450/2949, Loss: 0.7207\n",
      "Epoch: 4, Step: 451/2949, Loss: 0.7733\n",
      "Epoch: 4, Step: 452/2949, Loss: 0.8124\n",
      "Epoch: 4, Step: 453/2949, Loss: 0.7599\n",
      "Epoch: 4, Step: 454/2949, Loss: 0.7489\n",
      "Epoch: 4, Step: 455/2949, Loss: 0.7952\n",
      "Epoch: 4, Step: 456/2949, Loss: 0.7687\n",
      "Epoch: 4, Step: 457/2949, Loss: 0.7110\n",
      "Epoch: 4, Step: 458/2949, Loss: 0.7979\n",
      "Epoch: 4, Step: 459/2949, Loss: 0.7464\n",
      "Epoch: 4, Step: 460/2949, Loss: 0.6806\n",
      "Epoch: 4, Step: 461/2949, Loss: 0.7436\n",
      "Epoch: 4, Step: 462/2949, Loss: 0.7362\n",
      "Epoch: 4, Step: 463/2949, Loss: 0.7591\n",
      "Epoch: 4, Step: 464/2949, Loss: 0.7852\n",
      "Epoch: 4, Step: 465/2949, Loss: 0.7386\n",
      "Epoch: 4, Step: 466/2949, Loss: 0.7354\n",
      "Epoch: 4, Step: 467/2949, Loss: 0.7719\n",
      "Epoch: 4, Step: 468/2949, Loss: 0.7349\n",
      "Epoch: 4, Step: 469/2949, Loss: 0.7245\n",
      "Epoch: 4, Step: 470/2949, Loss: 0.7451\n",
      "Epoch: 4, Step: 471/2949, Loss: 0.7660\n",
      "Epoch: 4, Step: 472/2949, Loss: 0.7586\n",
      "Epoch: 4, Step: 473/2949, Loss: 0.7583\n",
      "Epoch: 4, Step: 474/2949, Loss: 0.7714\n",
      "Epoch: 4, Step: 475/2949, Loss: 0.7906\n",
      "Epoch: 4, Step: 476/2949, Loss: 0.7170\n",
      "Epoch: 4, Step: 477/2949, Loss: 0.7600\n",
      "Epoch: 4, Step: 478/2949, Loss: 0.7007\n",
      "Epoch: 4, Step: 479/2949, Loss: 0.7219\n",
      "Epoch: 4, Step: 480/2949, Loss: 0.7659\n",
      "Epoch: 4, Step: 481/2949, Loss: 0.7566\n",
      "Epoch: 4, Step: 482/2949, Loss: 0.7786\n",
      "Epoch: 4, Step: 483/2949, Loss: 0.7572\n",
      "Epoch: 4, Step: 484/2949, Loss: 0.7217\n",
      "Epoch: 4, Step: 485/2949, Loss: 0.7525\n",
      "Epoch: 4, Step: 486/2949, Loss: 0.7929\n",
      "Epoch: 4, Step: 487/2949, Loss: 0.7539\n",
      "Epoch: 4, Step: 488/2949, Loss: 0.7477\n",
      "Epoch: 4, Step: 489/2949, Loss: 0.7749\n",
      "Epoch: 4, Step: 490/2949, Loss: 0.7311\n",
      "Epoch: 4, Step: 491/2949, Loss: 0.7375\n",
      "Epoch: 4, Step: 492/2949, Loss: 0.7917\n",
      "Epoch: 4, Step: 493/2949, Loss: 0.7273\n",
      "Epoch: 4, Step: 494/2949, Loss: 0.7668\n",
      "Epoch: 4, Step: 495/2949, Loss: 0.7504\n",
      "Epoch: 4, Step: 496/2949, Loss: 0.7822\n",
      "Epoch: 4, Step: 497/2949, Loss: 0.8082\n",
      "Epoch: 4, Step: 498/2949, Loss: 0.7563\n",
      "Epoch: 4, Step: 499/2949, Loss: 0.7610\n",
      "Epoch: 4, Step: 500/2949, Loss: 0.7767\n",
      "Epoch: 4, Step: 501/2949, Loss: 0.7489\n",
      "Epoch: 4, Step: 502/2949, Loss: 0.7266\n",
      "Epoch: 4, Step: 503/2949, Loss: 0.7676\n",
      "Epoch: 4, Step: 504/2949, Loss: 0.7699\n",
      "Epoch: 4, Step: 505/2949, Loss: 0.7286\n",
      "Epoch: 4, Step: 506/2949, Loss: 0.8167\n",
      "Epoch: 4, Step: 507/2949, Loss: 0.7090\n",
      "Epoch: 4, Step: 508/2949, Loss: 0.6813\n",
      "Epoch: 4, Step: 509/2949, Loss: 0.7473\n",
      "Epoch: 4, Step: 510/2949, Loss: 0.8107\n",
      "Epoch: 4, Step: 511/2949, Loss: 0.7693\n",
      "Epoch: 4, Step: 512/2949, Loss: 0.7363\n",
      "Epoch: 4, Step: 513/2949, Loss: 0.7474\n",
      "Epoch: 4, Step: 514/2949, Loss: 0.7626\n",
      "Epoch: 4, Step: 515/2949, Loss: 0.7749\n",
      "Epoch: 4, Step: 516/2949, Loss: 0.7596\n",
      "Epoch: 4, Step: 517/2949, Loss: 0.7472\n",
      "Epoch: 4, Step: 518/2949, Loss: 0.7309\n",
      "Epoch: 4, Step: 519/2949, Loss: 0.7809\n",
      "Epoch: 4, Step: 520/2949, Loss: 0.7745\n",
      "Epoch: 4, Step: 521/2949, Loss: 0.8044\n",
      "Epoch: 4, Step: 522/2949, Loss: 0.7602\n",
      "Epoch: 4, Step: 523/2949, Loss: 0.7641\n",
      "Epoch: 4, Step: 524/2949, Loss: 0.7427\n",
      "Epoch: 4, Step: 525/2949, Loss: 0.7528\n",
      "Epoch: 4, Step: 526/2949, Loss: 0.6928\n",
      "Epoch: 4, Step: 527/2949, Loss: 0.7712\n",
      "Epoch: 4, Step: 528/2949, Loss: 0.7814\n",
      "Epoch: 4, Step: 529/2949, Loss: 0.7192\n",
      "Epoch: 4, Step: 530/2949, Loss: 0.7559\n",
      "Epoch: 4, Step: 531/2949, Loss: 0.7156\n",
      "Epoch: 4, Step: 532/2949, Loss: 0.7737\n",
      "Epoch: 4, Step: 533/2949, Loss: 0.7156\n",
      "Epoch: 4, Step: 534/2949, Loss: 0.7329\n",
      "Epoch: 4, Step: 535/2949, Loss: 0.7680\n",
      "Epoch: 4, Step: 536/2949, Loss: 0.7864\n",
      "Epoch: 4, Step: 537/2949, Loss: 0.7326\n",
      "Epoch: 4, Step: 538/2949, Loss: 0.7815\n",
      "Epoch: 4, Step: 539/2949, Loss: 0.7684\n",
      "Epoch: 4, Step: 540/2949, Loss: 0.7534\n",
      "Epoch: 4, Step: 541/2949, Loss: 0.7435\n",
      "Epoch: 4, Step: 542/2949, Loss: 0.7197\n",
      "Epoch: 4, Step: 543/2949, Loss: 0.7799\n",
      "Epoch: 4, Step: 544/2949, Loss: 0.7574\n",
      "Epoch: 4, Step: 545/2949, Loss: 0.7589\n",
      "Epoch: 4, Step: 546/2949, Loss: 0.7190\n",
      "Epoch: 4, Step: 547/2949, Loss: 0.7543\n",
      "Epoch: 4, Step: 548/2949, Loss: 0.7380\n",
      "Epoch: 4, Step: 549/2949, Loss: 0.6927\n",
      "Epoch: 4, Step: 550/2949, Loss: 0.8049\n",
      "Epoch: 4, Step: 551/2949, Loss: 0.7476\n",
      "Epoch: 4, Step: 552/2949, Loss: 0.7519\n",
      "Epoch: 4, Step: 553/2949, Loss: 0.7033\n",
      "Epoch: 4, Step: 554/2949, Loss: 0.7530\n",
      "Epoch: 4, Step: 555/2949, Loss: 0.7408\n",
      "Epoch: 4, Step: 556/2949, Loss: 0.7608\n",
      "Epoch: 4, Step: 557/2949, Loss: 0.7389\n",
      "Epoch: 4, Step: 558/2949, Loss: 0.7866\n",
      "Epoch: 4, Step: 559/2949, Loss: 0.7499\n",
      "Epoch: 4, Step: 560/2949, Loss: 0.7054\n",
      "Epoch: 4, Step: 561/2949, Loss: 0.7414\n",
      "Epoch: 4, Step: 562/2949, Loss: 0.7550\n",
      "Epoch: 4, Step: 563/2949, Loss: 0.7272\n",
      "Epoch: 4, Step: 564/2949, Loss: 0.8181\n",
      "Epoch: 4, Step: 565/2949, Loss: 0.7810\n",
      "Epoch: 4, Step: 566/2949, Loss: 0.7380\n",
      "Epoch: 4, Step: 567/2949, Loss: 0.7676\n",
      "Epoch: 4, Step: 568/2949, Loss: 0.7410\n",
      "Epoch: 4, Step: 569/2949, Loss: 0.7601\n",
      "Epoch: 4, Step: 570/2949, Loss: 0.7857\n",
      "Epoch: 4, Step: 571/2949, Loss: 0.8031\n",
      "Epoch: 4, Step: 572/2949, Loss: 0.7332\n",
      "Epoch: 4, Step: 573/2949, Loss: 0.7292\n",
      "Epoch: 4, Step: 574/2949, Loss: 0.6735\n",
      "Epoch: 4, Step: 575/2949, Loss: 0.7840\n",
      "Epoch: 4, Step: 576/2949, Loss: 0.7535\n",
      "Epoch: 4, Step: 577/2949, Loss: 0.7782\n",
      "Epoch: 4, Step: 578/2949, Loss: 0.7679\n",
      "Epoch: 4, Step: 579/2949, Loss: 0.7130\n",
      "Epoch: 4, Step: 580/2949, Loss: 0.7254\n",
      "Epoch: 4, Step: 581/2949, Loss: 0.7794\n",
      "Epoch: 4, Step: 582/2949, Loss: 0.7565\n",
      "Epoch: 4, Step: 583/2949, Loss: 0.7401\n",
      "Epoch: 4, Step: 584/2949, Loss: 0.7702\n",
      "Epoch: 4, Step: 585/2949, Loss: 0.7455\n",
      "Epoch: 4, Step: 586/2949, Loss: 0.7580\n",
      "Epoch: 4, Step: 587/2949, Loss: 0.7313\n",
      "Epoch: 4, Step: 588/2949, Loss: 0.7328\n",
      "Epoch: 4, Step: 589/2949, Loss: 0.7578\n",
      "Epoch: 4, Step: 590/2949, Loss: 0.7444\n",
      "Epoch: 4, Step: 591/2949, Loss: 0.7294\n",
      "Epoch: 4, Step: 592/2949, Loss: 0.7366\n",
      "Epoch: 4, Step: 593/2949, Loss: 0.7633\n",
      "Epoch: 4, Step: 594/2949, Loss: 0.7295\n",
      "Epoch: 4, Step: 595/2949, Loss: 0.7504\n",
      "Epoch: 4, Step: 596/2949, Loss: 0.7482\n",
      "Epoch: 4, Step: 597/2949, Loss: 0.7597\n",
      "Epoch: 4, Step: 598/2949, Loss: 0.7506\n",
      "Epoch: 4, Step: 599/2949, Loss: 0.7697\n",
      "Epoch: 4, Step: 600/2949, Loss: 0.7577\n",
      "Epoch: 4, Step: 601/2949, Loss: 0.7863\n",
      "Epoch: 4, Step: 602/2949, Loss: 0.7265\n",
      "Epoch: 4, Step: 603/2949, Loss: 0.7433\n",
      "Epoch: 4, Step: 604/2949, Loss: 0.7873\n",
      "Epoch: 4, Step: 605/2949, Loss: 0.7498\n",
      "Epoch: 4, Step: 606/2949, Loss: 0.7629\n",
      "Epoch: 4, Step: 607/2949, Loss: 0.7494\n",
      "Epoch: 4, Step: 608/2949, Loss: 0.7598\n",
      "Epoch: 4, Step: 609/2949, Loss: 0.7222\n",
      "Epoch: 4, Step: 610/2949, Loss: 0.8031\n",
      "Epoch: 4, Step: 611/2949, Loss: 0.7191\n",
      "Epoch: 4, Step: 612/2949, Loss: 0.7619\n",
      "Epoch: 4, Step: 613/2949, Loss: 0.7906\n",
      "Epoch: 4, Step: 614/2949, Loss: 0.7590\n",
      "Epoch: 4, Step: 615/2949, Loss: 0.7617\n",
      "Epoch: 4, Step: 616/2949, Loss: 0.7692\n",
      "Epoch: 4, Step: 617/2949, Loss: 0.7912\n",
      "Epoch: 4, Step: 618/2949, Loss: 0.7777\n",
      "Epoch: 4, Step: 619/2949, Loss: 0.7623\n",
      "Epoch: 4, Step: 620/2949, Loss: 0.7162\n",
      "Epoch: 4, Step: 621/2949, Loss: 0.8072\n",
      "Epoch: 4, Step: 622/2949, Loss: 0.7494\n",
      "Epoch: 4, Step: 623/2949, Loss: 0.7498\n",
      "Epoch: 4, Step: 624/2949, Loss: 0.7639\n",
      "Epoch: 4, Step: 625/2949, Loss: 0.7535\n",
      "Epoch: 4, Step: 626/2949, Loss: 0.7926\n",
      "Epoch: 4, Step: 627/2949, Loss: 0.7633\n",
      "Epoch: 4, Step: 628/2949, Loss: 0.7854\n",
      "Epoch: 4, Step: 629/2949, Loss: 0.7493\n",
      "Epoch: 4, Step: 630/2949, Loss: 0.7611\n",
      "Epoch: 4, Step: 631/2949, Loss: 0.7250\n",
      "Epoch: 4, Step: 632/2949, Loss: 0.8045\n",
      "Epoch: 4, Step: 633/2949, Loss: 0.7849\n",
      "Epoch: 4, Step: 634/2949, Loss: 0.7428\n",
      "Epoch: 4, Step: 635/2949, Loss: 0.7859\n",
      "Epoch: 4, Step: 636/2949, Loss: 0.7328\n",
      "Epoch: 4, Step: 637/2949, Loss: 0.7255\n",
      "Epoch: 4, Step: 638/2949, Loss: 0.7168\n",
      "Epoch: 4, Step: 639/2949, Loss: 0.7556\n",
      "Epoch: 4, Step: 640/2949, Loss: 0.7655\n",
      "Epoch: 4, Step: 641/2949, Loss: 0.7066\n",
      "Epoch: 4, Step: 642/2949, Loss: 0.7117\n",
      "Epoch: 4, Step: 643/2949, Loss: 0.7847\n",
      "Epoch: 4, Step: 644/2949, Loss: 0.8038\n",
      "Epoch: 4, Step: 645/2949, Loss: 0.7556\n",
      "Epoch: 4, Step: 646/2949, Loss: 0.7805\n",
      "Epoch: 4, Step: 647/2949, Loss: 0.7239\n",
      "Epoch: 4, Step: 648/2949, Loss: 0.7618\n",
      "Epoch: 4, Step: 649/2949, Loss: 0.7372\n",
      "Epoch: 4, Step: 650/2949, Loss: 0.7379\n",
      "Epoch: 4, Step: 651/2949, Loss: 0.7377\n",
      "Epoch: 4, Step: 652/2949, Loss: 0.7037\n",
      "Epoch: 4, Step: 653/2949, Loss: 0.7437\n",
      "Epoch: 4, Step: 654/2949, Loss: 0.6940\n",
      "Epoch: 4, Step: 655/2949, Loss: 0.7498\n",
      "Epoch: 4, Step: 656/2949, Loss: 0.7760\n",
      "Epoch: 4, Step: 657/2949, Loss: 0.7608\n",
      "Epoch: 4, Step: 658/2949, Loss: 0.7342\n",
      "Epoch: 4, Step: 659/2949, Loss: 0.7446\n",
      "Epoch: 4, Step: 660/2949, Loss: 0.7354\n",
      "Epoch: 4, Step: 661/2949, Loss: 0.8139\n",
      "Epoch: 4, Step: 662/2949, Loss: 0.7474\n",
      "Epoch: 4, Step: 663/2949, Loss: 0.7402\n",
      "Epoch: 4, Step: 664/2949, Loss: 0.7996\n",
      "Epoch: 4, Step: 665/2949, Loss: 0.7580\n",
      "Epoch: 4, Step: 666/2949, Loss: 0.8142\n",
      "Epoch: 4, Step: 667/2949, Loss: 0.7589\n",
      "Epoch: 4, Step: 668/2949, Loss: 0.7390\n",
      "Epoch: 4, Step: 669/2949, Loss: 0.7814\n",
      "Epoch: 4, Step: 670/2949, Loss: 0.7860\n",
      "Epoch: 4, Step: 671/2949, Loss: 0.8108\n",
      "Epoch: 4, Step: 672/2949, Loss: 0.6982\n",
      "Epoch: 4, Step: 673/2949, Loss: 0.7685\n",
      "Epoch: 4, Step: 674/2949, Loss: 0.7578\n",
      "Epoch: 4, Step: 675/2949, Loss: 0.7484\n",
      "Epoch: 4, Step: 676/2949, Loss: 0.7180\n",
      "Epoch: 4, Step: 677/2949, Loss: 0.7734\n",
      "Epoch: 4, Step: 678/2949, Loss: 0.7566\n",
      "Epoch: 4, Step: 679/2949, Loss: 0.7571\n",
      "Epoch: 4, Step: 680/2949, Loss: 0.7638\n",
      "Epoch: 4, Step: 681/2949, Loss: 0.7448\n",
      "Epoch: 4, Step: 682/2949, Loss: 0.7888\n",
      "Epoch: 4, Step: 683/2949, Loss: 0.7226\n",
      "Epoch: 4, Step: 684/2949, Loss: 0.7873\n",
      "Epoch: 4, Step: 685/2949, Loss: 0.7978\n",
      "Epoch: 4, Step: 686/2949, Loss: 0.7672\n",
      "Epoch: 4, Step: 687/2949, Loss: 0.7351\n",
      "Epoch: 4, Step: 688/2949, Loss: 0.7489\n",
      "Epoch: 4, Step: 689/2949, Loss: 0.7133\n",
      "Epoch: 4, Step: 690/2949, Loss: 0.7348\n",
      "Epoch: 4, Step: 691/2949, Loss: 0.7402\n",
      "Epoch: 4, Step: 692/2949, Loss: 0.7822\n",
      "Epoch: 4, Step: 693/2949, Loss: 0.7670\n",
      "Epoch: 4, Step: 694/2949, Loss: 0.7503\n",
      "Epoch: 4, Step: 695/2949, Loss: 0.7211\n",
      "Epoch: 4, Step: 696/2949, Loss: 0.7694\n",
      "Epoch: 4, Step: 697/2949, Loss: 0.7898\n",
      "Epoch: 4, Step: 698/2949, Loss: 0.7552\n",
      "Epoch: 4, Step: 699/2949, Loss: 0.7548\n",
      "Epoch: 4, Step: 700/2949, Loss: 0.8051\n",
      "Epoch: 4, Step: 701/2949, Loss: 0.7245\n",
      "Epoch: 4, Step: 702/2949, Loss: 0.7380\n",
      "Epoch: 4, Step: 703/2949, Loss: 0.7195\n",
      "Epoch: 4, Step: 704/2949, Loss: 0.7711\n",
      "Epoch: 4, Step: 705/2949, Loss: 0.7124\n",
      "Epoch: 4, Step: 706/2949, Loss: 0.7206\n",
      "Epoch: 4, Step: 707/2949, Loss: 0.7718\n",
      "Epoch: 4, Step: 708/2949, Loss: 0.7733\n",
      "Epoch: 4, Step: 709/2949, Loss: 0.8160\n",
      "Epoch: 4, Step: 710/2949, Loss: 0.7728\n",
      "Epoch: 4, Step: 711/2949, Loss: 0.7478\n",
      "Epoch: 4, Step: 712/2949, Loss: 0.7770\n",
      "Epoch: 4, Step: 713/2949, Loss: 0.7817\n",
      "Epoch: 4, Step: 714/2949, Loss: 0.7756\n",
      "Epoch: 4, Step: 715/2949, Loss: 0.7557\n",
      "Epoch: 4, Step: 716/2949, Loss: 0.7858\n",
      "Epoch: 4, Step: 717/2949, Loss: 0.8035\n",
      "Epoch: 4, Step: 718/2949, Loss: 0.7171\n",
      "Epoch: 4, Step: 719/2949, Loss: 0.8080\n",
      "Epoch: 4, Step: 720/2949, Loss: 0.7847\n",
      "Epoch: 4, Step: 721/2949, Loss: 0.6850\n",
      "Epoch: 4, Step: 722/2949, Loss: 0.6831\n",
      "Epoch: 4, Step: 723/2949, Loss: 0.7488\n",
      "Epoch: 4, Step: 724/2949, Loss: 0.7697\n",
      "Epoch: 4, Step: 725/2949, Loss: 0.8235\n",
      "Epoch: 4, Step: 726/2949, Loss: 0.7518\n",
      "Epoch: 4, Step: 727/2949, Loss: 0.7857\n",
      "Epoch: 4, Step: 728/2949, Loss: 0.7481\n",
      "Epoch: 4, Step: 729/2949, Loss: 0.8386\n",
      "Epoch: 4, Step: 730/2949, Loss: 0.7054\n",
      "Epoch: 4, Step: 731/2949, Loss: 0.7791\n",
      "Epoch: 4, Step: 732/2949, Loss: 0.7669\n",
      "Epoch: 4, Step: 733/2949, Loss: 0.7730\n",
      "Epoch: 4, Step: 734/2949, Loss: 0.7344\n",
      "Epoch: 4, Step: 735/2949, Loss: 0.7422\n",
      "Epoch: 4, Step: 736/2949, Loss: 0.7419\n",
      "Epoch: 4, Step: 737/2949, Loss: 0.7479\n",
      "Epoch: 4, Step: 738/2949, Loss: 0.7649\n",
      "Epoch: 4, Step: 739/2949, Loss: 0.8068\n",
      "Epoch: 4, Step: 740/2949, Loss: 0.7704\n",
      "Epoch: 4, Step: 741/2949, Loss: 0.7514\n",
      "Epoch: 4, Step: 742/2949, Loss: 0.7504\n",
      "Epoch: 4, Step: 743/2949, Loss: 0.7797\n",
      "Epoch: 4, Step: 744/2949, Loss: 0.7640\n",
      "Epoch: 4, Step: 745/2949, Loss: 0.7925\n",
      "Epoch: 4, Step: 746/2949, Loss: 0.7557\n",
      "Epoch: 4, Step: 747/2949, Loss: 0.7746\n",
      "Epoch: 4, Step: 748/2949, Loss: 0.7287\n",
      "Epoch: 4, Step: 749/2949, Loss: 0.7692\n",
      "Epoch: 4, Step: 750/2949, Loss: 0.7409\n",
      "Epoch: 4, Step: 751/2949, Loss: 0.7930\n",
      "Epoch: 4, Step: 752/2949, Loss: 0.7739\n",
      "Epoch: 4, Step: 753/2949, Loss: 0.7392\n",
      "Epoch: 4, Step: 754/2949, Loss: 0.7312\n",
      "Epoch: 4, Step: 755/2949, Loss: 0.7573\n",
      "Epoch: 4, Step: 756/2949, Loss: 0.6990\n",
      "Epoch: 4, Step: 757/2949, Loss: 0.7745\n",
      "Epoch: 4, Step: 758/2949, Loss: 0.7637\n",
      "Epoch: 4, Step: 759/2949, Loss: 0.7557\n",
      "Epoch: 4, Step: 760/2949, Loss: 0.7579\n",
      "Epoch: 4, Step: 761/2949, Loss: 0.8041\n",
      "Epoch: 4, Step: 762/2949, Loss: 0.7650\n",
      "Epoch: 4, Step: 763/2949, Loss: 0.7161\n",
      "Epoch: 4, Step: 764/2949, Loss: 0.7565\n",
      "Epoch: 4, Step: 765/2949, Loss: 0.7199\n",
      "Epoch: 4, Step: 766/2949, Loss: 0.7924\n",
      "Epoch: 4, Step: 767/2949, Loss: 0.7741\n",
      "Epoch: 4, Step: 768/2949, Loss: 0.7207\n",
      "Epoch: 4, Step: 769/2949, Loss: 0.7582\n",
      "Epoch: 4, Step: 770/2949, Loss: 0.7865\n",
      "Epoch: 4, Step: 771/2949, Loss: 0.8041\n",
      "Epoch: 4, Step: 772/2949, Loss: 0.7758\n",
      "Epoch: 4, Step: 773/2949, Loss: 0.7326\n",
      "Epoch: 4, Step: 774/2949, Loss: 0.7146\n",
      "Epoch: 4, Step: 775/2949, Loss: 0.7298\n",
      "Epoch: 4, Step: 776/2949, Loss: 0.7438\n",
      "Epoch: 4, Step: 777/2949, Loss: 0.7617\n",
      "Epoch: 4, Step: 778/2949, Loss: 0.7459\n",
      "Epoch: 4, Step: 779/2949, Loss: 0.7047\n",
      "Epoch: 4, Step: 780/2949, Loss: 0.7486\n",
      "Epoch: 4, Step: 781/2949, Loss: 0.7422\n",
      "Epoch: 4, Step: 782/2949, Loss: 0.7338\n",
      "Epoch: 4, Step: 783/2949, Loss: 0.7645\n",
      "Epoch: 4, Step: 784/2949, Loss: 0.7854\n",
      "Epoch: 4, Step: 785/2949, Loss: 0.7257\n",
      "Epoch: 4, Step: 786/2949, Loss: 0.7527\n",
      "Epoch: 4, Step: 787/2949, Loss: 0.7502\n",
      "Epoch: 4, Step: 788/2949, Loss: 0.7806\n",
      "Epoch: 4, Step: 789/2949, Loss: 0.7590\n",
      "Epoch: 4, Step: 790/2949, Loss: 0.7163\n",
      "Epoch: 4, Step: 791/2949, Loss: 0.7104\n",
      "Epoch: 4, Step: 792/2949, Loss: 0.7385\n",
      "Epoch: 4, Step: 793/2949, Loss: 0.7465\n",
      "Epoch: 4, Step: 794/2949, Loss: 0.7147\n",
      "Epoch: 4, Step: 795/2949, Loss: 0.7367\n",
      "Epoch: 4, Step: 796/2949, Loss: 0.7662\n",
      "Epoch: 4, Step: 797/2949, Loss: 0.7467\n",
      "Epoch: 4, Step: 798/2949, Loss: 0.7051\n",
      "Epoch: 4, Step: 799/2949, Loss: 0.7352\n",
      "Epoch: 4, Step: 800/2949, Loss: 0.7976\n",
      "Epoch: 4, Step: 801/2949, Loss: 0.7259\n",
      "Epoch: 4, Step: 802/2949, Loss: 0.7801\n",
      "Epoch: 4, Step: 803/2949, Loss: 0.7735\n",
      "Epoch: 4, Step: 804/2949, Loss: 0.7327\n",
      "Epoch: 4, Step: 805/2949, Loss: 0.7737\n",
      "Epoch: 4, Step: 806/2949, Loss: 0.8008\n",
      "Epoch: 4, Step: 807/2949, Loss: 0.7553\n",
      "Epoch: 4, Step: 808/2949, Loss: 0.7060\n",
      "Epoch: 4, Step: 809/2949, Loss: 0.7752\n",
      "Epoch: 4, Step: 810/2949, Loss: 0.7109\n",
      "Epoch: 4, Step: 811/2949, Loss: 0.7484\n",
      "Epoch: 4, Step: 812/2949, Loss: 0.7424\n",
      "Epoch: 4, Step: 813/2949, Loss: 0.8220\n",
      "Epoch: 4, Step: 814/2949, Loss: 0.7850\n",
      "Epoch: 4, Step: 815/2949, Loss: 0.7317\n",
      "Epoch: 4, Step: 816/2949, Loss: 0.7729\n",
      "Epoch: 4, Step: 817/2949, Loss: 0.7057\n",
      "Epoch: 4, Step: 818/2949, Loss: 0.7595\n",
      "Epoch: 4, Step: 819/2949, Loss: 0.7619\n",
      "Epoch: 4, Step: 820/2949, Loss: 0.7566\n",
      "Epoch: 4, Step: 821/2949, Loss: 0.7698\n",
      "Epoch: 4, Step: 822/2949, Loss: 0.7071\n",
      "Epoch: 4, Step: 823/2949, Loss: 0.7436\n",
      "Epoch: 4, Step: 824/2949, Loss: 0.7556\n",
      "Epoch: 4, Step: 825/2949, Loss: 0.7409\n",
      "Epoch: 4, Step: 826/2949, Loss: 0.7505\n",
      "Epoch: 4, Step: 827/2949, Loss: 0.7509\n",
      "Epoch: 4, Step: 828/2949, Loss: 0.6909\n",
      "Epoch: 4, Step: 829/2949, Loss: 0.7542\n",
      "Epoch: 4, Step: 830/2949, Loss: 0.7449\n",
      "Epoch: 4, Step: 831/2949, Loss: 0.7333\n",
      "Epoch: 4, Step: 832/2949, Loss: 0.7605\n",
      "Epoch: 4, Step: 833/2949, Loss: 0.7232\n",
      "Epoch: 4, Step: 834/2949, Loss: 0.6694\n",
      "Epoch: 4, Step: 835/2949, Loss: 0.7467\n",
      "Epoch: 4, Step: 836/2949, Loss: 0.7751\n",
      "Epoch: 4, Step: 837/2949, Loss: 0.7216\n",
      "Epoch: 4, Step: 838/2949, Loss: 0.7309\n",
      "Epoch: 4, Step: 839/2949, Loss: 0.7158\n",
      "Epoch: 4, Step: 840/2949, Loss: 0.7822\n",
      "Epoch: 4, Step: 841/2949, Loss: 0.7171\n",
      "Epoch: 4, Step: 842/2949, Loss: 0.7355\n",
      "Epoch: 4, Step: 843/2949, Loss: 0.7698\n",
      "Epoch: 4, Step: 844/2949, Loss: 0.7502\n",
      "Epoch: 4, Step: 845/2949, Loss: 0.7599\n",
      "Epoch: 4, Step: 846/2949, Loss: 0.8047\n",
      "Epoch: 4, Step: 847/2949, Loss: 0.7569\n",
      "Epoch: 4, Step: 848/2949, Loss: 0.7465\n",
      "Epoch: 4, Step: 849/2949, Loss: 0.7705\n",
      "Epoch: 4, Step: 850/2949, Loss: 0.7729\n",
      "Epoch: 4, Step: 851/2949, Loss: 0.7994\n",
      "Epoch: 4, Step: 852/2949, Loss: 0.7900\n",
      "Epoch: 4, Step: 853/2949, Loss: 0.7533\n",
      "Epoch: 4, Step: 854/2949, Loss: 0.7568\n",
      "Epoch: 4, Step: 855/2949, Loss: 0.7433\n",
      "Epoch: 4, Step: 856/2949, Loss: 0.7325\n",
      "Epoch: 4, Step: 857/2949, Loss: 0.7675\n",
      "Epoch: 4, Step: 858/2949, Loss: 0.7433\n",
      "Epoch: 4, Step: 859/2949, Loss: 0.7354\n",
      "Epoch: 4, Step: 860/2949, Loss: 0.7471\n",
      "Epoch: 4, Step: 861/2949, Loss: 0.7846\n",
      "Epoch: 4, Step: 862/2949, Loss: 0.7628\n",
      "Epoch: 4, Step: 863/2949, Loss: 0.7739\n",
      "Epoch: 4, Step: 864/2949, Loss: 0.7702\n",
      "Epoch: 4, Step: 865/2949, Loss: 0.7312\n",
      "Epoch: 4, Step: 866/2949, Loss: 0.7854\n",
      "Epoch: 4, Step: 867/2949, Loss: 0.7857\n",
      "Epoch: 4, Step: 868/2949, Loss: 0.7267\n",
      "Epoch: 4, Step: 869/2949, Loss: 0.7653\n",
      "Epoch: 4, Step: 870/2949, Loss: 0.7469\n",
      "Epoch: 4, Step: 871/2949, Loss: 0.7257\n",
      "Epoch: 4, Step: 872/2949, Loss: 0.7907\n",
      "Epoch: 4, Step: 873/2949, Loss: 0.7903\n",
      "Epoch: 4, Step: 874/2949, Loss: 0.7897\n",
      "Epoch: 4, Step: 875/2949, Loss: 0.7519\n",
      "Epoch: 4, Step: 876/2949, Loss: 0.7189\n",
      "Epoch: 4, Step: 877/2949, Loss: 0.7810\n",
      "Epoch: 4, Step: 878/2949, Loss: 0.7957\n",
      "Epoch: 4, Step: 879/2949, Loss: 0.7686\n",
      "Epoch: 4, Step: 880/2949, Loss: 0.7832\n",
      "Epoch: 4, Step: 881/2949, Loss: 0.8079\n",
      "Epoch: 4, Step: 882/2949, Loss: 0.7883\n",
      "Epoch: 4, Step: 883/2949, Loss: 0.7518\n",
      "Epoch: 4, Step: 884/2949, Loss: 0.7688\n",
      "Epoch: 4, Step: 885/2949, Loss: 0.7578\n",
      "Epoch: 4, Step: 886/2949, Loss: 0.7837\n",
      "Epoch: 4, Step: 887/2949, Loss: 0.7742\n",
      "Epoch: 4, Step: 888/2949, Loss: 0.7519\n",
      "Epoch: 4, Step: 889/2949, Loss: 0.8023\n",
      "Epoch: 4, Step: 890/2949, Loss: 0.7376\n",
      "Epoch: 4, Step: 891/2949, Loss: 0.7363\n",
      "Epoch: 4, Step: 892/2949, Loss: 0.7161\n",
      "Epoch: 4, Step: 893/2949, Loss: 0.7412\n",
      "Epoch: 4, Step: 894/2949, Loss: 0.7533\n",
      "Epoch: 4, Step: 895/2949, Loss: 0.7802\n",
      "Epoch: 4, Step: 896/2949, Loss: 0.7722\n",
      "Epoch: 4, Step: 897/2949, Loss: 0.7250\n",
      "Epoch: 4, Step: 898/2949, Loss: 0.7302\n",
      "Epoch: 4, Step: 899/2949, Loss: 0.7580\n",
      "Epoch: 4, Step: 900/2949, Loss: 0.7871\n",
      "Epoch: 4, Step: 901/2949, Loss: 0.7355\n",
      "Epoch: 4, Step: 902/2949, Loss: 0.7361\n",
      "Epoch: 4, Step: 903/2949, Loss: 0.7652\n",
      "Epoch: 4, Step: 904/2949, Loss: 0.7012\n",
      "Epoch: 4, Step: 905/2949, Loss: 0.7529\n",
      "Epoch: 4, Step: 906/2949, Loss: 0.8023\n",
      "Epoch: 4, Step: 907/2949, Loss: 0.7903\n",
      "Epoch: 4, Step: 908/2949, Loss: 0.7167\n",
      "Epoch: 4, Step: 909/2949, Loss: 0.7483\n",
      "Epoch: 4, Step: 910/2949, Loss: 0.7276\n",
      "Epoch: 4, Step: 911/2949, Loss: 0.6956\n",
      "Epoch: 4, Step: 912/2949, Loss: 0.7349\n",
      "Epoch: 4, Step: 913/2949, Loss: 0.7615\n",
      "Epoch: 4, Step: 914/2949, Loss: 0.7213\n",
      "Epoch: 4, Step: 915/2949, Loss: 0.7763\n",
      "Epoch: 4, Step: 916/2949, Loss: 0.7397\n",
      "Epoch: 4, Step: 917/2949, Loss: 0.7607\n",
      "Epoch: 4, Step: 918/2949, Loss: 0.7594\n",
      "Epoch: 4, Step: 919/2949, Loss: 0.8008\n",
      "Epoch: 4, Step: 920/2949, Loss: 0.8037\n",
      "Epoch: 4, Step: 921/2949, Loss: 0.7576\n",
      "Epoch: 4, Step: 922/2949, Loss: 0.7580\n",
      "Epoch: 4, Step: 923/2949, Loss: 0.7296\n",
      "Epoch: 4, Step: 924/2949, Loss: 0.7670\n",
      "Epoch: 4, Step: 925/2949, Loss: 0.7533\n",
      "Epoch: 4, Step: 926/2949, Loss: 0.7760\n",
      "Epoch: 4, Step: 927/2949, Loss: 0.7468\n",
      "Epoch: 4, Step: 928/2949, Loss: 0.7811\n",
      "Epoch: 4, Step: 929/2949, Loss: 0.7427\n",
      "Epoch: 4, Step: 930/2949, Loss: 0.7061\n",
      "Epoch: 4, Step: 931/2949, Loss: 0.7422\n",
      "Epoch: 4, Step: 932/2949, Loss: 0.7523\n",
      "Epoch: 4, Step: 933/2949, Loss: 0.7493\n",
      "Epoch: 4, Step: 934/2949, Loss: 0.7598\n",
      "Epoch: 4, Step: 935/2949, Loss: 0.7522\n",
      "Epoch: 4, Step: 936/2949, Loss: 0.7295\n",
      "Epoch: 4, Step: 937/2949, Loss: 0.7058\n",
      "Epoch: 4, Step: 938/2949, Loss: 0.8061\n",
      "Epoch: 4, Step: 939/2949, Loss: 0.7394\n",
      "Epoch: 4, Step: 940/2949, Loss: 0.7951\n",
      "Epoch: 4, Step: 941/2949, Loss: 0.7312\n",
      "Epoch: 4, Step: 942/2949, Loss: 0.7426\n",
      "Epoch: 4, Step: 943/2949, Loss: 0.7700\n",
      "Epoch: 4, Step: 944/2949, Loss: 0.7988\n",
      "Epoch: 4, Step: 945/2949, Loss: 0.8061\n",
      "Epoch: 4, Step: 946/2949, Loss: 0.7093\n",
      "Epoch: 4, Step: 947/2949, Loss: 0.7546\n",
      "Epoch: 4, Step: 948/2949, Loss: 0.7715\n",
      "Epoch: 4, Step: 949/2949, Loss: 0.7610\n",
      "Epoch: 4, Step: 950/2949, Loss: 0.7322\n",
      "Epoch: 4, Step: 951/2949, Loss: 0.7812\n",
      "Epoch: 4, Step: 952/2949, Loss: 0.7794\n",
      "Epoch: 4, Step: 953/2949, Loss: 0.7136\n",
      "Epoch: 4, Step: 954/2949, Loss: 0.7821\n",
      "Epoch: 4, Step: 955/2949, Loss: 0.7449\n",
      "Epoch: 4, Step: 956/2949, Loss: 0.7389\n",
      "Epoch: 4, Step: 957/2949, Loss: 0.7857\n",
      "Epoch: 4, Step: 958/2949, Loss: 0.7296\n",
      "Epoch: 4, Step: 959/2949, Loss: 0.7139\n",
      "Epoch: 4, Step: 960/2949, Loss: 0.8172\n",
      "Epoch: 4, Step: 961/2949, Loss: 0.7897\n",
      "Epoch: 4, Step: 962/2949, Loss: 0.7794\n",
      "Epoch: 4, Step: 963/2949, Loss: 0.7508\n",
      "Epoch: 4, Step: 964/2949, Loss: 0.7810\n",
      "Epoch: 4, Step: 965/2949, Loss: 0.7471\n",
      "Epoch: 4, Step: 966/2949, Loss: 0.8050\n",
      "Epoch: 4, Step: 967/2949, Loss: 0.8051\n",
      "Epoch: 4, Step: 968/2949, Loss: 0.7706\n",
      "Epoch: 4, Step: 969/2949, Loss: 0.7409\n",
      "Epoch: 4, Step: 970/2949, Loss: 0.7402\n",
      "Epoch: 4, Step: 971/2949, Loss: 0.7685\n",
      "Epoch: 4, Step: 972/2949, Loss: 0.7672\n",
      "Epoch: 4, Step: 973/2949, Loss: 0.7496\n",
      "Epoch: 4, Step: 974/2949, Loss: 0.7901\n",
      "Epoch: 4, Step: 975/2949, Loss: 0.7533\n",
      "Epoch: 4, Step: 976/2949, Loss: 0.7668\n",
      "Epoch: 4, Step: 977/2949, Loss: 0.7383\n",
      "Epoch: 4, Step: 978/2949, Loss: 0.7626\n",
      "Epoch: 4, Step: 979/2949, Loss: 0.7178\n",
      "Epoch: 4, Step: 980/2949, Loss: 0.7556\n",
      "Epoch: 4, Step: 981/2949, Loss: 0.7764\n",
      "Epoch: 4, Step: 982/2949, Loss: 0.7986\n",
      "Epoch: 4, Step: 983/2949, Loss: 0.7688\n",
      "Epoch: 4, Step: 984/2949, Loss: 0.7713\n",
      "Epoch: 4, Step: 985/2949, Loss: 0.7422\n",
      "Epoch: 4, Step: 986/2949, Loss: 0.7547\n",
      "Epoch: 4, Step: 987/2949, Loss: 0.7370\n",
      "Epoch: 4, Step: 988/2949, Loss: 0.7719\n",
      "Epoch: 4, Step: 989/2949, Loss: 0.7084\n",
      "Epoch: 4, Step: 990/2949, Loss: 0.8002\n",
      "Epoch: 4, Step: 991/2949, Loss: 0.7805\n",
      "Epoch: 4, Step: 992/2949, Loss: 0.7072\n",
      "Epoch: 4, Step: 993/2949, Loss: 0.7544\n",
      "Epoch: 4, Step: 994/2949, Loss: 0.7105\n",
      "Epoch: 4, Step: 995/2949, Loss: 0.7645\n",
      "Epoch: 4, Step: 996/2949, Loss: 0.7504\n",
      "Epoch: 4, Step: 997/2949, Loss: 0.7406\n",
      "Epoch: 4, Step: 998/2949, Loss: 0.7544\n",
      "Epoch: 4, Step: 999/2949, Loss: 0.7296\n",
      "Epoch: 4, Step: 1000/2949, Loss: 0.7385\n",
      "Epoch: 4, Step: 1001/2949, Loss: 0.8311\n",
      "Epoch: 4, Step: 1002/2949, Loss: 0.7233\n",
      "Epoch: 4, Step: 1003/2949, Loss: 0.7367\n",
      "Epoch: 4, Step: 1004/2949, Loss: 0.7312\n",
      "Epoch: 4, Step: 1005/2949, Loss: 0.7290\n",
      "Epoch: 4, Step: 1006/2949, Loss: 0.7431\n",
      "Epoch: 4, Step: 1007/2949, Loss: 0.8311\n",
      "Epoch: 4, Step: 1008/2949, Loss: 0.7647\n",
      "Epoch: 4, Step: 1009/2949, Loss: 0.7507\n",
      "Epoch: 4, Step: 1010/2949, Loss: 0.7680\n",
      "Epoch: 4, Step: 1011/2949, Loss: 0.7494\n",
      "Epoch: 4, Step: 1012/2949, Loss: 0.7403\n",
      "Epoch: 4, Step: 1013/2949, Loss: 0.7502\n",
      "Epoch: 4, Step: 1014/2949, Loss: 0.7358\n",
      "Epoch: 4, Step: 1015/2949, Loss: 0.7820\n",
      "Epoch: 4, Step: 1016/2949, Loss: 0.7383\n",
      "Epoch: 4, Step: 1017/2949, Loss: 0.7382\n",
      "Epoch: 4, Step: 1018/2949, Loss: 0.7783\n",
      "Epoch: 4, Step: 1019/2949, Loss: 0.7651\n",
      "Epoch: 4, Step: 1020/2949, Loss: 0.7619\n",
      "Epoch: 4, Step: 1021/2949, Loss: 0.7221\n",
      "Epoch: 4, Step: 1022/2949, Loss: 0.7777\n",
      "Epoch: 4, Step: 1023/2949, Loss: 0.7291\n",
      "Epoch: 4, Step: 1024/2949, Loss: 0.7639\n",
      "Epoch: 4, Step: 1025/2949, Loss: 0.7030\n",
      "Epoch: 4, Step: 1026/2949, Loss: 0.7328\n",
      "Epoch: 4, Step: 1027/2949, Loss: 0.7472\n",
      "Epoch: 4, Step: 1028/2949, Loss: 0.6999\n",
      "Epoch: 4, Step: 1029/2949, Loss: 0.7675\n",
      "Epoch: 4, Step: 1030/2949, Loss: 0.7491\n",
      "Epoch: 4, Step: 1031/2949, Loss: 0.7464\n",
      "Epoch: 4, Step: 1032/2949, Loss: 0.8107\n",
      "Epoch: 4, Step: 1033/2949, Loss: 0.6917\n",
      "Epoch: 4, Step: 1034/2949, Loss: 0.8018\n",
      "Epoch: 4, Step: 1035/2949, Loss: 0.7814\n",
      "Epoch: 4, Step: 1036/2949, Loss: 0.7141\n",
      "Epoch: 4, Step: 1037/2949, Loss: 0.7894\n",
      "Epoch: 4, Step: 1038/2949, Loss: 0.7786\n",
      "Epoch: 4, Step: 1039/2949, Loss: 0.7421\n",
      "Epoch: 4, Step: 1040/2949, Loss: 0.7894\n",
      "Epoch: 4, Step: 1041/2949, Loss: 0.7281\n",
      "Epoch: 4, Step: 1042/2949, Loss: 0.7308\n",
      "Epoch: 4, Step: 1043/2949, Loss: 0.7343\n",
      "Epoch: 4, Step: 1044/2949, Loss: 0.7453\n",
      "Epoch: 4, Step: 1045/2949, Loss: 0.7527\n",
      "Epoch: 4, Step: 1046/2949, Loss: 0.7640\n",
      "Epoch: 4, Step: 1047/2949, Loss: 0.7859\n",
      "Epoch: 4, Step: 1048/2949, Loss: 0.7073\n",
      "Epoch: 4, Step: 1049/2949, Loss: 0.7717\n",
      "Epoch: 4, Step: 1050/2949, Loss: 0.7454\n",
      "Epoch: 4, Step: 1051/2949, Loss: 0.7501\n",
      "Epoch: 4, Step: 1052/2949, Loss: 0.7510\n",
      "Epoch: 4, Step: 1053/2949, Loss: 0.7741\n",
      "Epoch: 4, Step: 1054/2949, Loss: 0.7106\n",
      "Epoch: 4, Step: 1055/2949, Loss: 0.7190\n",
      "Epoch: 4, Step: 1056/2949, Loss: 0.7263\n",
      "Epoch: 4, Step: 1057/2949, Loss: 0.7503\n",
      "Epoch: 4, Step: 1058/2949, Loss: 0.7680\n",
      "Epoch: 4, Step: 1059/2949, Loss: 0.7730\n",
      "Epoch: 4, Step: 1060/2949, Loss: 0.7640\n",
      "Epoch: 4, Step: 1061/2949, Loss: 0.6853\n",
      "Epoch: 4, Step: 1062/2949, Loss: 0.7423\n",
      "Epoch: 4, Step: 1063/2949, Loss: 0.7856\n",
      "Epoch: 4, Step: 1064/2949, Loss: 0.7134\n",
      "Epoch: 4, Step: 1065/2949, Loss: 0.7292\n",
      "Epoch: 4, Step: 1066/2949, Loss: 0.7932\n",
      "Epoch: 4, Step: 1067/2949, Loss: 0.7071\n",
      "Epoch: 4, Step: 1068/2949, Loss: 0.7825\n",
      "Epoch: 4, Step: 1069/2949, Loss: 0.7510\n",
      "Epoch: 4, Step: 1070/2949, Loss: 0.7517\n",
      "Epoch: 4, Step: 1071/2949, Loss: 0.8071\n",
      "Epoch: 4, Step: 1072/2949, Loss: 0.7062\n",
      "Epoch: 4, Step: 1073/2949, Loss: 0.7762\n",
      "Epoch: 4, Step: 1074/2949, Loss: 0.7207\n",
      "Epoch: 4, Step: 1075/2949, Loss: 0.7437\n",
      "Epoch: 4, Step: 1076/2949, Loss: 0.7502\n",
      "Epoch: 4, Step: 1077/2949, Loss: 0.7861\n",
      "Epoch: 4, Step: 1078/2949, Loss: 0.7252\n",
      "Epoch: 4, Step: 1079/2949, Loss: 0.7504\n",
      "Epoch: 4, Step: 1080/2949, Loss: 0.7483\n",
      "Epoch: 4, Step: 1081/2949, Loss: 0.7745\n",
      "Epoch: 4, Step: 1082/2949, Loss: 0.7371\n",
      "Epoch: 4, Step: 1083/2949, Loss: 0.7925\n",
      "Epoch: 4, Step: 1084/2949, Loss: 0.7566\n",
      "Epoch: 4, Step: 1085/2949, Loss: 0.7301\n",
      "Epoch: 4, Step: 1086/2949, Loss: 0.7566\n",
      "Epoch: 4, Step: 1087/2949, Loss: 0.7206\n",
      "Epoch: 4, Step: 1088/2949, Loss: 0.7563\n",
      "Epoch: 4, Step: 1089/2949, Loss: 0.7351\n",
      "Epoch: 4, Step: 1090/2949, Loss: 0.8161\n",
      "Epoch: 4, Step: 1091/2949, Loss: 0.7573\n",
      "Epoch: 4, Step: 1092/2949, Loss: 0.7445\n",
      "Epoch: 4, Step: 1093/2949, Loss: 0.7325\n",
      "Epoch: 4, Step: 1094/2949, Loss: 0.7331\n",
      "Epoch: 4, Step: 1095/2949, Loss: 0.7699\n",
      "Epoch: 4, Step: 1096/2949, Loss: 0.7508\n",
      "Epoch: 4, Step: 1097/2949, Loss: 0.7282\n",
      "Epoch: 4, Step: 1098/2949, Loss: 0.7355\n",
      "Epoch: 4, Step: 1099/2949, Loss: 0.7834\n",
      "Epoch: 4, Step: 1100/2949, Loss: 0.7473\n",
      "Epoch: 4, Step: 1101/2949, Loss: 0.7523\n",
      "Epoch: 4, Step: 1102/2949, Loss: 0.7600\n",
      "Epoch: 4, Step: 1103/2949, Loss: 0.7615\n",
      "Epoch: 4, Step: 1104/2949, Loss: 0.7647\n",
      "Epoch: 4, Step: 1105/2949, Loss: 0.7297\n",
      "Epoch: 4, Step: 1106/2949, Loss: 0.6982\n",
      "Epoch: 4, Step: 1107/2949, Loss: 0.7477\n",
      "Epoch: 4, Step: 1108/2949, Loss: 0.7275\n",
      "Epoch: 4, Step: 1109/2949, Loss: 0.7754\n",
      "Epoch: 4, Step: 1110/2949, Loss: 0.7243\n",
      "Epoch: 4, Step: 1111/2949, Loss: 0.7268\n",
      "Epoch: 4, Step: 1112/2949, Loss: 0.7748\n",
      "Epoch: 4, Step: 1113/2949, Loss: 0.7704\n",
      "Epoch: 4, Step: 1114/2949, Loss: 0.7849\n",
      "Epoch: 4, Step: 1115/2949, Loss: 0.8083\n",
      "Epoch: 4, Step: 1116/2949, Loss: 0.7529\n",
      "Epoch: 4, Step: 1117/2949, Loss: 0.7100\n",
      "Epoch: 4, Step: 1118/2949, Loss: 0.8042\n",
      "Epoch: 4, Step: 1119/2949, Loss: 0.7673\n",
      "Epoch: 4, Step: 1120/2949, Loss: 0.7341\n",
      "Epoch: 4, Step: 1121/2949, Loss: 0.7584\n",
      "Epoch: 4, Step: 1122/2949, Loss: 0.7859\n",
      "Epoch: 4, Step: 1123/2949, Loss: 0.7549\n",
      "Epoch: 4, Step: 1124/2949, Loss: 0.7467\n",
      "Epoch: 4, Step: 1125/2949, Loss: 0.7449\n",
      "Epoch: 4, Step: 1126/2949, Loss: 0.7754\n",
      "Epoch: 4, Step: 1127/2949, Loss: 0.7231\n",
      "Epoch: 4, Step: 1128/2949, Loss: 0.7697\n",
      "Epoch: 4, Step: 1129/2949, Loss: 0.7721\n",
      "Epoch: 4, Step: 1130/2949, Loss: 0.7189\n",
      "Epoch: 4, Step: 1131/2949, Loss: 0.7543\n",
      "Epoch: 4, Step: 1132/2949, Loss: 0.7005\n",
      "Epoch: 4, Step: 1133/2949, Loss: 0.7366\n",
      "Epoch: 4, Step: 1134/2949, Loss: 0.7539\n",
      "Epoch: 4, Step: 1135/2949, Loss: 0.6889\n",
      "Epoch: 4, Step: 1136/2949, Loss: 0.6841\n",
      "Epoch: 4, Step: 1137/2949, Loss: 0.7244\n",
      "Epoch: 4, Step: 1138/2949, Loss: 0.8051\n",
      "Epoch: 4, Step: 1139/2949, Loss: 0.7487\n",
      "Epoch: 4, Step: 1140/2949, Loss: 0.8082\n",
      "Epoch: 4, Step: 1141/2949, Loss: 0.7358\n",
      "Epoch: 4, Step: 1142/2949, Loss: 0.7896\n",
      "Epoch: 4, Step: 1143/2949, Loss: 0.7586\n",
      "Epoch: 4, Step: 1144/2949, Loss: 0.7765\n",
      "Epoch: 4, Step: 1145/2949, Loss: 0.7421\n",
      "Epoch: 4, Step: 1146/2949, Loss: 0.7673\n",
      "Epoch: 4, Step: 1147/2949, Loss: 0.8008\n",
      "Epoch: 4, Step: 1148/2949, Loss: 0.7814\n",
      "Epoch: 4, Step: 1149/2949, Loss: 0.7374\n",
      "Epoch: 4, Step: 1150/2949, Loss: 0.7955\n",
      "Epoch: 4, Step: 1151/2949, Loss: 0.6918\n",
      "Epoch: 4, Step: 1152/2949, Loss: 0.7409\n",
      "Epoch: 4, Step: 1153/2949, Loss: 0.7443\n",
      "Epoch: 4, Step: 1154/2949, Loss: 0.7512\n",
      "Epoch: 4, Step: 1155/2949, Loss: 0.7020\n",
      "Epoch: 4, Step: 1156/2949, Loss: 0.7677\n",
      "Epoch: 4, Step: 1157/2949, Loss: 0.7256\n",
      "Epoch: 4, Step: 1158/2949, Loss: 0.6825\n",
      "Epoch: 4, Step: 1159/2949, Loss: 0.7994\n",
      "Epoch: 4, Step: 1160/2949, Loss: 0.7557\n",
      "Epoch: 4, Step: 1161/2949, Loss: 0.7609\n",
      "Epoch: 4, Step: 1162/2949, Loss: 0.7222\n",
      "Epoch: 4, Step: 1163/2949, Loss: 0.7697\n",
      "Epoch: 4, Step: 1164/2949, Loss: 0.7572\n",
      "Epoch: 4, Step: 1165/2949, Loss: 0.7425\n",
      "Epoch: 4, Step: 1166/2949, Loss: 0.7133\n",
      "Epoch: 4, Step: 1167/2949, Loss: 0.7648\n",
      "Epoch: 4, Step: 1168/2949, Loss: 0.7458\n",
      "Epoch: 4, Step: 1169/2949, Loss: 0.7816\n",
      "Epoch: 4, Step: 1170/2949, Loss: 0.7844\n",
      "Epoch: 4, Step: 1171/2949, Loss: 0.7186\n",
      "Epoch: 4, Step: 1172/2949, Loss: 0.7196\n",
      "Epoch: 4, Step: 1173/2949, Loss: 0.7674\n",
      "Epoch: 4, Step: 1174/2949, Loss: 0.7029\n",
      "Epoch: 4, Step: 1175/2949, Loss: 0.7559\n",
      "Epoch: 4, Step: 1176/2949, Loss: 0.7843\n",
      "Epoch: 4, Step: 1177/2949, Loss: 0.7775\n",
      "Epoch: 4, Step: 1178/2949, Loss: 0.7761\n",
      "Epoch: 4, Step: 1179/2949, Loss: 0.7970\n",
      "Epoch: 4, Step: 1180/2949, Loss: 0.7583\n",
      "Epoch: 4, Step: 1181/2949, Loss: 0.7680\n",
      "Epoch: 4, Step: 1182/2949, Loss: 0.7867\n",
      "Epoch: 4, Step: 1183/2949, Loss: 0.7682\n",
      "Epoch: 4, Step: 1184/2949, Loss: 0.7560\n",
      "Epoch: 4, Step: 1185/2949, Loss: 0.7679\n",
      "Epoch: 4, Step: 1186/2949, Loss: 0.7200\n",
      "Epoch: 4, Step: 1187/2949, Loss: 0.7470\n",
      "Epoch: 4, Step: 1188/2949, Loss: 0.7494\n",
      "Epoch: 4, Step: 1189/2949, Loss: 0.7273\n",
      "Epoch: 4, Step: 1190/2949, Loss: 0.7256\n",
      "Epoch: 4, Step: 1191/2949, Loss: 0.7811\n",
      "Epoch: 4, Step: 1192/2949, Loss: 0.7588\n",
      "Epoch: 4, Step: 1193/2949, Loss: 0.7135\n",
      "Epoch: 4, Step: 1194/2949, Loss: 0.7586\n",
      "Epoch: 4, Step: 1195/2949, Loss: 0.7793\n",
      "Epoch: 4, Step: 1196/2949, Loss: 0.7141\n",
      "Epoch: 4, Step: 1197/2949, Loss: 0.7367\n",
      "Epoch: 4, Step: 1198/2949, Loss: 0.7548\n",
      "Epoch: 4, Step: 1199/2949, Loss: 0.6870\n",
      "Epoch: 4, Step: 1200/2949, Loss: 0.7420\n",
      "Epoch: 4, Step: 1201/2949, Loss: 0.7484\n",
      "Epoch: 4, Step: 1202/2949, Loss: 0.7478\n",
      "Epoch: 4, Step: 1203/2949, Loss: 0.7036\n",
      "Epoch: 4, Step: 1204/2949, Loss: 0.7049\n",
      "Epoch: 4, Step: 1205/2949, Loss: 0.7342\n",
      "Epoch: 4, Step: 1206/2949, Loss: 0.7248\n",
      "Epoch: 4, Step: 1207/2949, Loss: 0.7344\n",
      "Epoch: 4, Step: 1208/2949, Loss: 0.7473\n",
      "Epoch: 4, Step: 1209/2949, Loss: 0.7405\n",
      "Epoch: 4, Step: 1210/2949, Loss: 0.7490\n",
      "Epoch: 4, Step: 1211/2949, Loss: 0.7131\n",
      "Epoch: 4, Step: 1212/2949, Loss: 0.7087\n",
      "Epoch: 4, Step: 1213/2949, Loss: 0.7605\n",
      "Epoch: 4, Step: 1214/2949, Loss: 0.7665\n",
      "Epoch: 4, Step: 1215/2949, Loss: 0.7726\n",
      "Epoch: 4, Step: 1216/2949, Loss: 0.7418\n",
      "Epoch: 4, Step: 1217/2949, Loss: 0.7734\n",
      "Epoch: 4, Step: 1218/2949, Loss: 0.7649\n",
      "Epoch: 4, Step: 1219/2949, Loss: 0.7434\n",
      "Epoch: 4, Step: 1220/2949, Loss: 0.7078\n",
      "Epoch: 4, Step: 1221/2949, Loss: 0.7529\n",
      "Epoch: 4, Step: 1222/2949, Loss: 0.7275\n",
      "Epoch: 4, Step: 1223/2949, Loss: 0.7460\n",
      "Epoch: 4, Step: 1224/2949, Loss: 0.7434\n",
      "Epoch: 4, Step: 1225/2949, Loss: 0.7178\n",
      "Epoch: 4, Step: 1226/2949, Loss: 0.7972\n",
      "Epoch: 4, Step: 1227/2949, Loss: 0.7413\n",
      "Epoch: 4, Step: 1228/2949, Loss: 0.7476\n",
      "Epoch: 4, Step: 1229/2949, Loss: 0.7708\n",
      "Epoch: 4, Step: 1230/2949, Loss: 0.7005\n",
      "Epoch: 4, Step: 1231/2949, Loss: 0.7620\n",
      "Epoch: 4, Step: 1232/2949, Loss: 0.7034\n",
      "Epoch: 4, Step: 1233/2949, Loss: 0.7212\n",
      "Epoch: 4, Step: 1234/2949, Loss: 0.6963\n",
      "Epoch: 4, Step: 1235/2949, Loss: 0.7062\n",
      "Epoch: 4, Step: 1236/2949, Loss: 0.7519\n",
      "Epoch: 4, Step: 1237/2949, Loss: 0.7729\n",
      "Epoch: 4, Step: 1238/2949, Loss: 0.7706\n",
      "Epoch: 4, Step: 1239/2949, Loss: 0.7873\n",
      "Epoch: 4, Step: 1240/2949, Loss: 0.8022\n",
      "Epoch: 4, Step: 1241/2949, Loss: 0.7423\n",
      "Epoch: 4, Step: 1242/2949, Loss: 0.7284\n",
      "Epoch: 4, Step: 1243/2949, Loss: 0.8218\n",
      "Epoch: 4, Step: 1244/2949, Loss: 0.7690\n",
      "Epoch: 4, Step: 1245/2949, Loss: 0.7467\n",
      "Epoch: 4, Step: 1246/2949, Loss: 0.7522\n",
      "Epoch: 4, Step: 1247/2949, Loss: 0.7690\n",
      "Epoch: 4, Step: 1248/2949, Loss: 0.7074\n",
      "Epoch: 4, Step: 1249/2949, Loss: 0.7383\n",
      "Epoch: 4, Step: 1250/2949, Loss: 0.7588\n",
      "Epoch: 4, Step: 1251/2949, Loss: 0.7117\n",
      "Epoch: 4, Step: 1252/2949, Loss: 0.7530\n",
      "Epoch: 4, Step: 1253/2949, Loss: 0.7464\n",
      "Epoch: 4, Step: 1254/2949, Loss: 0.8151\n",
      "Epoch: 4, Step: 1255/2949, Loss: 0.7555\n",
      "Epoch: 4, Step: 1256/2949, Loss: 0.7470\n",
      "Epoch: 4, Step: 1257/2949, Loss: 0.7692\n",
      "Epoch: 4, Step: 1258/2949, Loss: 0.7281\n",
      "Epoch: 4, Step: 1259/2949, Loss: 0.7498\n",
      "Epoch: 4, Step: 1260/2949, Loss: 0.7358\n",
      "Epoch: 4, Step: 1261/2949, Loss: 0.7265\n",
      "Epoch: 4, Step: 1262/2949, Loss: 0.7739\n",
      "Epoch: 4, Step: 1263/2949, Loss: 0.7868\n",
      "Epoch: 4, Step: 1264/2949, Loss: 0.7333\n",
      "Epoch: 4, Step: 1265/2949, Loss: 0.7646\n",
      "Epoch: 4, Step: 1266/2949, Loss: 0.7529\n",
      "Epoch: 4, Step: 1267/2949, Loss: 0.7296\n",
      "Epoch: 4, Step: 1268/2949, Loss: 0.7422\n",
      "Epoch: 4, Step: 1269/2949, Loss: 0.7752\n",
      "Epoch: 4, Step: 1270/2949, Loss: 0.7321\n",
      "Epoch: 4, Step: 1271/2949, Loss: 0.6824\n",
      "Epoch: 4, Step: 1272/2949, Loss: 0.7592\n",
      "Epoch: 4, Step: 1273/2949, Loss: 0.7596\n",
      "Epoch: 4, Step: 1274/2949, Loss: 0.7716\n",
      "Epoch: 4, Step: 1275/2949, Loss: 0.7780\n",
      "Epoch: 4, Step: 1276/2949, Loss: 0.7150\n",
      "Epoch: 4, Step: 1277/2949, Loss: 0.7787\n",
      "Epoch: 4, Step: 1278/2949, Loss: 0.7387\n",
      "Epoch: 4, Step: 1279/2949, Loss: 0.7574\n",
      "Epoch: 4, Step: 1280/2949, Loss: 0.6934\n",
      "Epoch: 4, Step: 1281/2949, Loss: 0.7160\n",
      "Epoch: 4, Step: 1282/2949, Loss: 0.7491\n",
      "Epoch: 4, Step: 1283/2949, Loss: 0.7684\n",
      "Epoch: 4, Step: 1284/2949, Loss: 0.7327\n",
      "Epoch: 4, Step: 1285/2949, Loss: 0.7218\n",
      "Epoch: 4, Step: 1286/2949, Loss: 0.7565\n",
      "Epoch: 4, Step: 1287/2949, Loss: 0.7515\n",
      "Epoch: 4, Step: 1288/2949, Loss: 0.7784\n",
      "Epoch: 4, Step: 1289/2949, Loss: 0.8407\n",
      "Epoch: 4, Step: 1290/2949, Loss: 0.7238\n",
      "Epoch: 4, Step: 1291/2949, Loss: 0.8303\n",
      "Epoch: 4, Step: 1292/2949, Loss: 0.7227\n",
      "Epoch: 4, Step: 1293/2949, Loss: 0.7969\n",
      "Epoch: 4, Step: 1294/2949, Loss: 0.7295\n",
      "Epoch: 4, Step: 1295/2949, Loss: 0.8098\n",
      "Epoch: 4, Step: 1296/2949, Loss: 0.7552\n",
      "Epoch: 4, Step: 1297/2949, Loss: 0.7658\n",
      "Epoch: 4, Step: 1298/2949, Loss: 0.7302\n",
      "Epoch: 4, Step: 1299/2949, Loss: 0.7574\n",
      "Epoch: 4, Step: 1300/2949, Loss: 0.7438\n",
      "Epoch: 4, Step: 1301/2949, Loss: 0.7348\n",
      "Epoch: 4, Step: 1302/2949, Loss: 0.7211\n",
      "Epoch: 4, Step: 1303/2949, Loss: 0.7339\n",
      "Epoch: 4, Step: 1304/2949, Loss: 0.7224\n",
      "Epoch: 4, Step: 1305/2949, Loss: 0.7597\n",
      "Epoch: 4, Step: 1306/2949, Loss: 0.8062\n",
      "Epoch: 4, Step: 1307/2949, Loss: 0.8008\n",
      "Epoch: 4, Step: 1308/2949, Loss: 0.7556\n",
      "Epoch: 4, Step: 1309/2949, Loss: 0.8083\n",
      "Epoch: 4, Step: 1310/2949, Loss: 0.7192\n",
      "Epoch: 4, Step: 1311/2949, Loss: 0.7575\n",
      "Epoch: 4, Step: 1312/2949, Loss: 0.7787\n",
      "Epoch: 4, Step: 1313/2949, Loss: 0.6919\n",
      "Epoch: 4, Step: 1314/2949, Loss: 0.7775\n",
      "Epoch: 4, Step: 1315/2949, Loss: 0.7519\n",
      "Epoch: 4, Step: 1316/2949, Loss: 0.7298\n",
      "Epoch: 4, Step: 1317/2949, Loss: 0.7129\n",
      "Epoch: 4, Step: 1318/2949, Loss: 0.7409\n",
      "Epoch: 4, Step: 1319/2949, Loss: 0.7591\n",
      "Epoch: 4, Step: 1320/2949, Loss: 0.7207\n",
      "Epoch: 4, Step: 1321/2949, Loss: 0.7665\n",
      "Epoch: 4, Step: 1322/2949, Loss: 0.7631\n",
      "Epoch: 4, Step: 1323/2949, Loss: 0.7558\n",
      "Epoch: 4, Step: 1324/2949, Loss: 0.7616\n",
      "Epoch: 4, Step: 1325/2949, Loss: 0.7041\n",
      "Epoch: 4, Step: 1326/2949, Loss: 0.6878\n",
      "Epoch: 4, Step: 1327/2949, Loss: 0.7895\n",
      "Epoch: 4, Step: 1328/2949, Loss: 0.7994\n",
      "Epoch: 4, Step: 1329/2949, Loss: 0.7693\n",
      "Epoch: 4, Step: 1330/2949, Loss: 0.7310\n",
      "Epoch: 4, Step: 1331/2949, Loss: 0.7865\n",
      "Epoch: 4, Step: 1332/2949, Loss: 0.7950\n",
      "Epoch: 4, Step: 1333/2949, Loss: 0.7615\n",
      "Epoch: 4, Step: 1334/2949, Loss: 0.7194\n",
      "Epoch: 4, Step: 1335/2949, Loss: 0.7435\n",
      "Epoch: 4, Step: 1336/2949, Loss: 0.7362\n",
      "Epoch: 4, Step: 1337/2949, Loss: 0.7462\n",
      "Epoch: 4, Step: 1338/2949, Loss: 0.7792\n",
      "Epoch: 4, Step: 1339/2949, Loss: 0.7673\n",
      "Epoch: 4, Step: 1340/2949, Loss: 0.7612\n",
      "Epoch: 4, Step: 1341/2949, Loss: 0.7531\n",
      "Epoch: 4, Step: 1342/2949, Loss: 0.7645\n",
      "Epoch: 4, Step: 1343/2949, Loss: 0.7232\n",
      "Epoch: 4, Step: 1344/2949, Loss: 0.7932\n",
      "Epoch: 4, Step: 1345/2949, Loss: 0.7746\n",
      "Epoch: 4, Step: 1346/2949, Loss: 0.7481\n",
      "Epoch: 4, Step: 1347/2949, Loss: 0.7448\n",
      "Epoch: 4, Step: 1348/2949, Loss: 0.7352\n",
      "Epoch: 4, Step: 1349/2949, Loss: 0.7905\n",
      "Epoch: 4, Step: 1350/2949, Loss: 0.7811\n",
      "Epoch: 4, Step: 1351/2949, Loss: 0.7313\n",
      "Epoch: 4, Step: 1352/2949, Loss: 0.7792\n",
      "Epoch: 4, Step: 1353/2949, Loss: 0.7313\n",
      "Epoch: 4, Step: 1354/2949, Loss: 0.7826\n",
      "Epoch: 4, Step: 1355/2949, Loss: 0.8118\n",
      "Epoch: 4, Step: 1356/2949, Loss: 0.7171\n",
      "Epoch: 4, Step: 1357/2949, Loss: 0.7739\n",
      "Epoch: 4, Step: 1358/2949, Loss: 0.7431\n",
      "Epoch: 4, Step: 1359/2949, Loss: 0.7106\n",
      "Epoch: 4, Step: 1360/2949, Loss: 0.7890\n",
      "Epoch: 4, Step: 1361/2949, Loss: 0.7602\n",
      "Epoch: 4, Step: 1362/2949, Loss: 0.7317\n",
      "Epoch: 4, Step: 1363/2949, Loss: 0.7330\n",
      "Epoch: 4, Step: 1364/2949, Loss: 0.7837\n",
      "Epoch: 4, Step: 1365/2949, Loss: 0.8002\n",
      "Epoch: 4, Step: 1366/2949, Loss: 0.7591\n",
      "Epoch: 4, Step: 1367/2949, Loss: 0.7588\n",
      "Epoch: 4, Step: 1368/2949, Loss: 0.7583\n",
      "Epoch: 4, Step: 1369/2949, Loss: 0.7368\n",
      "Epoch: 4, Step: 1370/2949, Loss: 0.7634\n",
      "Epoch: 4, Step: 1371/2949, Loss: 0.7622\n",
      "Epoch: 4, Step: 1372/2949, Loss: 0.7198\n",
      "Epoch: 4, Step: 1373/2949, Loss: 0.7420\n",
      "Epoch: 4, Step: 1374/2949, Loss: 0.7809\n",
      "Epoch: 4, Step: 1375/2949, Loss: 0.7717\n",
      "Epoch: 4, Step: 1376/2949, Loss: 0.7172\n",
      "Epoch: 4, Step: 1377/2949, Loss: 0.7619\n",
      "Epoch: 4, Step: 1378/2949, Loss: 0.7797\n",
      "Epoch: 4, Step: 1379/2949, Loss: 0.7657\n",
      "Epoch: 4, Step: 1380/2949, Loss: 0.7876\n",
      "Epoch: 4, Step: 1381/2949, Loss: 0.7559\n",
      "Epoch: 4, Step: 1382/2949, Loss: 0.7899\n",
      "Epoch: 4, Step: 1383/2949, Loss: 0.7978\n",
      "Epoch: 4, Step: 1384/2949, Loss: 0.7563\n",
      "Epoch: 4, Step: 1385/2949, Loss: 0.7359\n",
      "Epoch: 4, Step: 1386/2949, Loss: 0.7564\n",
      "Epoch: 4, Step: 1387/2949, Loss: 0.6759\n",
      "Epoch: 4, Step: 1388/2949, Loss: 0.7157\n",
      "Epoch: 4, Step: 1389/2949, Loss: 0.7606\n",
      "Epoch: 4, Step: 1390/2949, Loss: 0.7132\n",
      "Epoch: 4, Step: 1391/2949, Loss: 0.7310\n",
      "Epoch: 4, Step: 1392/2949, Loss: 0.7641\n",
      "Epoch: 4, Step: 1393/2949, Loss: 0.7498\n",
      "Epoch: 4, Step: 1394/2949, Loss: 0.7295\n",
      "Epoch: 4, Step: 1395/2949, Loss: 0.8233\n",
      "Epoch: 4, Step: 1396/2949, Loss: 0.7454\n",
      "Epoch: 4, Step: 1397/2949, Loss: 0.7877\n",
      "Epoch: 4, Step: 1398/2949, Loss: 0.7580\n",
      "Epoch: 4, Step: 1399/2949, Loss: 0.7741\n",
      "Epoch: 4, Step: 1400/2949, Loss: 0.7493\n",
      "Epoch: 4, Step: 1401/2949, Loss: 0.7588\n",
      "Epoch: 4, Step: 1402/2949, Loss: 0.7893\n",
      "Epoch: 4, Step: 1403/2949, Loss: 0.7319\n",
      "Epoch: 4, Step: 1404/2949, Loss: 0.8001\n",
      "Epoch: 4, Step: 1405/2949, Loss: 0.7535\n",
      "Epoch: 4, Step: 1406/2949, Loss: 0.7658\n",
      "Epoch: 4, Step: 1407/2949, Loss: 0.6961\n",
      "Epoch: 4, Step: 1408/2949, Loss: 0.7921\n",
      "Epoch: 4, Step: 1409/2949, Loss: 0.7770\n",
      "Epoch: 4, Step: 1410/2949, Loss: 0.7160\n",
      "Epoch: 4, Step: 1411/2949, Loss: 0.8188\n",
      "Epoch: 4, Step: 1412/2949, Loss: 0.7511\n",
      "Epoch: 4, Step: 1413/2949, Loss: 0.7692\n",
      "Epoch: 4, Step: 1414/2949, Loss: 0.7237\n",
      "Epoch: 4, Step: 1415/2949, Loss: 0.7472\n",
      "Epoch: 4, Step: 1416/2949, Loss: 0.7184\n",
      "Epoch: 4, Step: 1417/2949, Loss: 0.7697\n",
      "Epoch: 4, Step: 1418/2949, Loss: 0.7878\n",
      "Epoch: 4, Step: 1419/2949, Loss: 0.7736\n",
      "Epoch: 4, Step: 1420/2949, Loss: 0.7593\n",
      "Epoch: 4, Step: 1421/2949, Loss: 0.7589\n",
      "Epoch: 4, Step: 1422/2949, Loss: 0.8006\n",
      "Epoch: 4, Step: 1423/2949, Loss: 0.7173\n",
      "Epoch: 4, Step: 1424/2949, Loss: 0.7615\n",
      "Epoch: 4, Step: 1425/2949, Loss: 0.7231\n",
      "Epoch: 4, Step: 1426/2949, Loss: 0.7725\n",
      "Epoch: 4, Step: 1427/2949, Loss: 0.8029\n",
      "Epoch: 4, Step: 1428/2949, Loss: 0.7716\n",
      "Epoch: 4, Step: 1429/2949, Loss: 0.7278\n",
      "Epoch: 4, Step: 1430/2949, Loss: 0.7702\n",
      "Epoch: 4, Step: 1431/2949, Loss: 0.7697\n",
      "Epoch: 4, Step: 1432/2949, Loss: 0.8042\n",
      "Epoch: 4, Step: 1433/2949, Loss: 0.7781\n",
      "Epoch: 4, Step: 1434/2949, Loss: 0.8121\n",
      "Epoch: 4, Step: 1435/2949, Loss: 0.7001\n",
      "Epoch: 4, Step: 1436/2949, Loss: 0.7577\n",
      "Epoch: 4, Step: 1437/2949, Loss: 0.7506\n",
      "Epoch: 4, Step: 1438/2949, Loss: 0.7466\n",
      "Epoch: 4, Step: 1439/2949, Loss: 0.7052\n",
      "Epoch: 4, Step: 1440/2949, Loss: 0.7310\n",
      "Epoch: 4, Step: 1441/2949, Loss: 0.7252\n",
      "Epoch: 4, Step: 1442/2949, Loss: 0.7496\n",
      "Epoch: 4, Step: 1443/2949, Loss: 0.7935\n",
      "Epoch: 4, Step: 1444/2949, Loss: 0.7233\n",
      "Epoch: 4, Step: 1445/2949, Loss: 0.8040\n",
      "Epoch: 4, Step: 1446/2949, Loss: 0.6793\n",
      "Epoch: 4, Step: 1447/2949, Loss: 0.7754\n",
      "Epoch: 4, Step: 1448/2949, Loss: 0.7884\n",
      "Epoch: 4, Step: 1449/2949, Loss: 0.7366\n",
      "Epoch: 4, Step: 1450/2949, Loss: 0.7205\n",
      "Epoch: 4, Step: 1451/2949, Loss: 0.7747\n",
      "Epoch: 4, Step: 1452/2949, Loss: 0.7289\n",
      "Epoch: 4, Step: 1453/2949, Loss: 0.7373\n",
      "Epoch: 4, Step: 1454/2949, Loss: 0.7201\n",
      "Epoch: 4, Step: 1455/2949, Loss: 0.7280\n",
      "Epoch: 4, Step: 1456/2949, Loss: 0.7740\n",
      "Epoch: 4, Step: 1457/2949, Loss: 0.7174\n",
      "Epoch: 4, Step: 1458/2949, Loss: 0.7205\n",
      "Epoch: 4, Step: 1459/2949, Loss: 0.7598\n",
      "Epoch: 4, Step: 1460/2949, Loss: 0.8155\n",
      "Epoch: 4, Step: 1461/2949, Loss: 0.7079\n",
      "Epoch: 4, Step: 1462/2949, Loss: 0.7304\n",
      "Epoch: 4, Step: 1463/2949, Loss: 0.7553\n",
      "Epoch: 4, Step: 1464/2949, Loss: 0.7801\n",
      "Epoch: 4, Step: 1465/2949, Loss: 0.7568\n",
      "Epoch: 4, Step: 1466/2949, Loss: 0.7513\n",
      "Epoch: 4, Step: 1467/2949, Loss: 0.7423\n",
      "Epoch: 4, Step: 1468/2949, Loss: 0.7145\n",
      "Epoch: 4, Step: 1469/2949, Loss: 0.7494\n",
      "Epoch: 4, Step: 1470/2949, Loss: 0.7886\n",
      "Epoch: 4, Step: 1471/2949, Loss: 0.7636\n",
      "Epoch: 4, Step: 1472/2949, Loss: 0.7571\n",
      "Epoch: 4, Step: 1473/2949, Loss: 0.7781\n",
      "Epoch: 4, Step: 1474/2949, Loss: 0.7318\n",
      "Epoch: 4, Step: 1475/2949, Loss: 0.7938\n",
      "Epoch: 4, Step: 1476/2949, Loss: 0.7594\n",
      "Epoch: 4, Step: 1477/2949, Loss: 0.7781\n",
      "Epoch: 4, Step: 1478/2949, Loss: 0.7647\n",
      "Epoch: 4, Step: 1479/2949, Loss: 0.8033\n",
      "Epoch: 4, Step: 1480/2949, Loss: 0.7615\n",
      "Epoch: 4, Step: 1481/2949, Loss: 0.7211\n",
      "Epoch: 4, Step: 1482/2949, Loss: 0.7488\n",
      "Epoch: 4, Step: 1483/2949, Loss: 0.7545\n",
      "Epoch: 4, Step: 1484/2949, Loss: 0.7284\n",
      "Epoch: 4, Step: 1485/2949, Loss: 0.7541\n",
      "Epoch: 4, Step: 1486/2949, Loss: 0.7332\n",
      "Epoch: 4, Step: 1487/2949, Loss: 0.7613\n",
      "Epoch: 4, Step: 1488/2949, Loss: 0.7730\n",
      "Epoch: 4, Step: 1489/2949, Loss: 0.6975\n",
      "Epoch: 4, Step: 1490/2949, Loss: 0.7507\n",
      "Epoch: 4, Step: 1491/2949, Loss: 0.7602\n",
      "Epoch: 4, Step: 1492/2949, Loss: 0.7154\n",
      "Epoch: 4, Step: 1493/2949, Loss: 0.7245\n",
      "Epoch: 4, Step: 1494/2949, Loss: 0.7843\n",
      "Epoch: 4, Step: 1495/2949, Loss: 0.7231\n",
      "Epoch: 4, Step: 1496/2949, Loss: 0.7565\n",
      "Epoch: 4, Step: 1497/2949, Loss: 0.7447\n",
      "Epoch: 4, Step: 1498/2949, Loss: 0.7528\n",
      "Epoch: 4, Step: 1499/2949, Loss: 0.7857\n",
      "Epoch: 4, Step: 1500/2949, Loss: 0.7489\n",
      "Epoch: 4, Step: 1501/2949, Loss: 0.7607\n",
      "Epoch: 4, Step: 1502/2949, Loss: 0.7409\n",
      "Epoch: 4, Step: 1503/2949, Loss: 0.7826\n",
      "Epoch: 4, Step: 1504/2949, Loss: 0.7420\n",
      "Epoch: 4, Step: 1505/2949, Loss: 0.7324\n",
      "Epoch: 4, Step: 1506/2949, Loss: 0.7303\n",
      "Epoch: 4, Step: 1507/2949, Loss: 0.7678\n",
      "Epoch: 4, Step: 1508/2949, Loss: 0.7396\n",
      "Epoch: 4, Step: 1509/2949, Loss: 0.7560\n",
      "Epoch: 4, Step: 1510/2949, Loss: 0.7823\n",
      "Epoch: 4, Step: 1511/2949, Loss: 0.7413\n",
      "Epoch: 4, Step: 1512/2949, Loss: 0.7595\n",
      "Epoch: 4, Step: 1513/2949, Loss: 0.7725\n",
      "Epoch: 4, Step: 1514/2949, Loss: 0.7221\n",
      "Epoch: 4, Step: 1515/2949, Loss: 0.7830\n",
      "Epoch: 4, Step: 1516/2949, Loss: 0.7492\n",
      "Epoch: 4, Step: 1517/2949, Loss: 0.7249\n",
      "Epoch: 4, Step: 1518/2949, Loss: 0.7665\n",
      "Epoch: 4, Step: 1519/2949, Loss: 0.7989\n",
      "Epoch: 4, Step: 1520/2949, Loss: 0.7677\n",
      "Epoch: 4, Step: 1521/2949, Loss: 0.8039\n",
      "Epoch: 4, Step: 1522/2949, Loss: 0.7443\n",
      "Epoch: 4, Step: 1523/2949, Loss: 0.7834\n",
      "Epoch: 4, Step: 1524/2949, Loss: 0.7541\n",
      "Epoch: 4, Step: 1525/2949, Loss: 0.7411\n",
      "Epoch: 4, Step: 1526/2949, Loss: 0.7107\n",
      "Epoch: 4, Step: 1527/2949, Loss: 0.8227\n",
      "Epoch: 4, Step: 1528/2949, Loss: 0.7852\n",
      "Epoch: 4, Step: 1529/2949, Loss: 0.7621\n",
      "Epoch: 4, Step: 1530/2949, Loss: 0.7244\n",
      "Epoch: 4, Step: 1531/2949, Loss: 0.7740\n",
      "Epoch: 4, Step: 1532/2949, Loss: 0.7796\n",
      "Epoch: 4, Step: 1533/2949, Loss: 0.7076\n",
      "Epoch: 4, Step: 1534/2949, Loss: 0.7375\n",
      "Epoch: 4, Step: 1535/2949, Loss: 0.7969\n",
      "Epoch: 4, Step: 1536/2949, Loss: 0.7358\n",
      "Epoch: 4, Step: 1537/2949, Loss: 0.7951\n",
      "Epoch: 4, Step: 1538/2949, Loss: 0.7740\n",
      "Epoch: 4, Step: 1539/2949, Loss: 0.7670\n",
      "Epoch: 4, Step: 1540/2949, Loss: 0.7908\n",
      "Epoch: 4, Step: 1541/2949, Loss: 0.7650\n",
      "Epoch: 4, Step: 1542/2949, Loss: 0.7491\n",
      "Epoch: 4, Step: 1543/2949, Loss: 0.7406\n",
      "Epoch: 4, Step: 1544/2949, Loss: 0.7106\n",
      "Epoch: 4, Step: 1545/2949, Loss: 0.7147\n",
      "Epoch: 4, Step: 1546/2949, Loss: 0.7405\n",
      "Epoch: 4, Step: 1547/2949, Loss: 0.7456\n",
      "Epoch: 4, Step: 1548/2949, Loss: 0.7324\n",
      "Epoch: 4, Step: 1549/2949, Loss: 0.7172\n",
      "Epoch: 4, Step: 1550/2949, Loss: 0.7714\n",
      "Epoch: 4, Step: 1551/2949, Loss: 0.7647\n",
      "Epoch: 4, Step: 1552/2949, Loss: 0.7518\n",
      "Epoch: 4, Step: 1553/2949, Loss: 0.7524\n",
      "Epoch: 4, Step: 1554/2949, Loss: 0.7439\n",
      "Epoch: 4, Step: 1555/2949, Loss: 0.7770\n",
      "Epoch: 4, Step: 1556/2949, Loss: 0.7848\n",
      "Epoch: 4, Step: 1557/2949, Loss: 0.7874\n",
      "Epoch: 4, Step: 1558/2949, Loss: 0.7388\n",
      "Epoch: 4, Step: 1559/2949, Loss: 0.7649\n",
      "Epoch: 4, Step: 1560/2949, Loss: 0.7563\n",
      "Epoch: 4, Step: 1561/2949, Loss: 0.7464\n",
      "Epoch: 4, Step: 1562/2949, Loss: 0.7365\n",
      "Epoch: 4, Step: 1563/2949, Loss: 0.7516\n",
      "Epoch: 4, Step: 1564/2949, Loss: 0.7316\n",
      "Epoch: 4, Step: 1565/2949, Loss: 0.7706\n",
      "Epoch: 4, Step: 1566/2949, Loss: 0.7047\n",
      "Epoch: 4, Step: 1567/2949, Loss: 0.7764\n",
      "Epoch: 4, Step: 1568/2949, Loss: 0.7489\n",
      "Epoch: 4, Step: 1569/2949, Loss: 0.7027\n",
      "Epoch: 4, Step: 1570/2949, Loss: 0.8037\n",
      "Epoch: 4, Step: 1571/2949, Loss: 0.7529\n",
      "Epoch: 4, Step: 1572/2949, Loss: 0.7749\n",
      "Epoch: 4, Step: 1573/2949, Loss: 0.7270\n",
      "Epoch: 4, Step: 1574/2949, Loss: 0.7614\n",
      "Epoch: 4, Step: 1575/2949, Loss: 0.7807\n",
      "Epoch: 4, Step: 1576/2949, Loss: 0.7567\n",
      "Epoch: 4, Step: 1577/2949, Loss: 0.7457\n",
      "Epoch: 4, Step: 1578/2949, Loss: 0.7587\n",
      "Epoch: 4, Step: 1579/2949, Loss: 0.7714\n",
      "Epoch: 4, Step: 1580/2949, Loss: 0.7463\n",
      "Epoch: 4, Step: 1581/2949, Loss: 0.7284\n",
      "Epoch: 4, Step: 1582/2949, Loss: 0.7452\n",
      "Epoch: 4, Step: 1583/2949, Loss: 0.7488\n",
      "Epoch: 4, Step: 1584/2949, Loss: 0.7933\n",
      "Epoch: 4, Step: 1585/2949, Loss: 0.7739\n",
      "Epoch: 4, Step: 1586/2949, Loss: 0.7294\n",
      "Epoch: 4, Step: 1587/2949, Loss: 0.7290\n",
      "Epoch: 4, Step: 1588/2949, Loss: 0.7740\n",
      "Epoch: 4, Step: 1589/2949, Loss: 0.7427\n",
      "Epoch: 4, Step: 1590/2949, Loss: 0.7806\n",
      "Epoch: 4, Step: 1591/2949, Loss: 0.7534\n",
      "Epoch: 4, Step: 1592/2949, Loss: 0.7661\n",
      "Epoch: 4, Step: 1593/2949, Loss: 0.7807\n",
      "Epoch: 4, Step: 1594/2949, Loss: 0.7465\n",
      "Epoch: 4, Step: 1595/2949, Loss: 0.7767\n",
      "Epoch: 4, Step: 1596/2949, Loss: 0.7406\n",
      "Epoch: 4, Step: 1597/2949, Loss: 0.7129\n",
      "Epoch: 4, Step: 1598/2949, Loss: 0.7320\n",
      "Epoch: 4, Step: 1599/2949, Loss: 0.7545\n",
      "Epoch: 4, Step: 1600/2949, Loss: 0.7405\n",
      "Epoch: 4, Step: 1601/2949, Loss: 0.7705\n",
      "Epoch: 4, Step: 1602/2949, Loss: 0.7884\n",
      "Epoch: 4, Step: 1603/2949, Loss: 0.7327\n",
      "Epoch: 4, Step: 1604/2949, Loss: 0.7258\n",
      "Epoch: 4, Step: 1605/2949, Loss: 0.7446\n",
      "Epoch: 4, Step: 1606/2949, Loss: 0.7514\n",
      "Epoch: 4, Step: 1607/2949, Loss: 0.7536\n",
      "Epoch: 4, Step: 1608/2949, Loss: 0.7908\n",
      "Epoch: 4, Step: 1609/2949, Loss: 0.7460\n",
      "Epoch: 4, Step: 1610/2949, Loss: 0.7637\n",
      "Epoch: 4, Step: 1611/2949, Loss: 0.7138\n",
      "Epoch: 4, Step: 1612/2949, Loss: 0.7803\n",
      "Epoch: 4, Step: 1613/2949, Loss: 0.7700\n",
      "Epoch: 4, Step: 1614/2949, Loss: 0.7739\n",
      "Epoch: 4, Step: 1615/2949, Loss: 0.7905\n",
      "Epoch: 4, Step: 1616/2949, Loss: 0.7610\n",
      "Epoch: 4, Step: 1617/2949, Loss: 0.7454\n",
      "Epoch: 4, Step: 1618/2949, Loss: 0.7468\n",
      "Epoch: 4, Step: 1619/2949, Loss: 0.7430\n",
      "Epoch: 4, Step: 1620/2949, Loss: 0.7916\n",
      "Epoch: 4, Step: 1621/2949, Loss: 0.7592\n",
      "Epoch: 4, Step: 1622/2949, Loss: 0.7548\n",
      "Epoch: 4, Step: 1623/2949, Loss: 0.7741\n",
      "Epoch: 4, Step: 1624/2949, Loss: 0.7866\n",
      "Epoch: 4, Step: 1625/2949, Loss: 0.8228\n",
      "Epoch: 4, Step: 1626/2949, Loss: 0.7572\n",
      "Epoch: 4, Step: 1627/2949, Loss: 0.7553\n",
      "Epoch: 4, Step: 1628/2949, Loss: 0.7239\n",
      "Epoch: 4, Step: 1629/2949, Loss: 0.7551\n",
      "Epoch: 4, Step: 1630/2949, Loss: 0.7620\n",
      "Epoch: 4, Step: 1631/2949, Loss: 0.7020\n",
      "Epoch: 4, Step: 1632/2949, Loss: 0.7677\n",
      "Epoch: 4, Step: 1633/2949, Loss: 0.7397\n",
      "Epoch: 4, Step: 1634/2949, Loss: 0.7877\n",
      "Epoch: 4, Step: 1635/2949, Loss: 0.7819\n",
      "Epoch: 4, Step: 1636/2949, Loss: 0.7487\n",
      "Epoch: 4, Step: 1637/2949, Loss: 0.7581\n",
      "Epoch: 4, Step: 1638/2949, Loss: 0.6406\n",
      "Epoch: 4, Step: 1639/2949, Loss: 0.7916\n",
      "Epoch: 4, Step: 1640/2949, Loss: 0.7763\n",
      "Epoch: 4, Step: 1641/2949, Loss: 0.7168\n",
      "Epoch: 4, Step: 1642/2949, Loss: 0.7423\n",
      "Epoch: 4, Step: 1643/2949, Loss: 0.7292\n",
      "Epoch: 4, Step: 1644/2949, Loss: 0.7353\n",
      "Epoch: 4, Step: 1645/2949, Loss: 0.7603\n",
      "Epoch: 4, Step: 1646/2949, Loss: 0.8075\n",
      "Epoch: 4, Step: 1647/2949, Loss: 0.7275\n",
      "Epoch: 4, Step: 1648/2949, Loss: 0.7404\n",
      "Epoch: 4, Step: 1649/2949, Loss: 0.7606\n",
      "Epoch: 4, Step: 1650/2949, Loss: 0.7305\n",
      "Epoch: 4, Step: 1651/2949, Loss: 0.7645\n",
      "Epoch: 4, Step: 1652/2949, Loss: 0.7778\n",
      "Epoch: 4, Step: 1653/2949, Loss: 0.7465\n",
      "Epoch: 4, Step: 1654/2949, Loss: 0.7569\n",
      "Epoch: 4, Step: 1655/2949, Loss: 0.7869\n",
      "Epoch: 4, Step: 1656/2949, Loss: 0.7581\n",
      "Epoch: 4, Step: 1657/2949, Loss: 0.7391\n",
      "Epoch: 4, Step: 1658/2949, Loss: 0.7433\n",
      "Epoch: 4, Step: 1659/2949, Loss: 0.7272\n",
      "Epoch: 4, Step: 1660/2949, Loss: 0.7321\n",
      "Epoch: 4, Step: 1661/2949, Loss: 0.7298\n",
      "Epoch: 4, Step: 1662/2949, Loss: 0.7363\n",
      "Epoch: 4, Step: 1663/2949, Loss: 0.8037\n",
      "Epoch: 4, Step: 1664/2949, Loss: 0.7151\n",
      "Epoch: 4, Step: 1665/2949, Loss: 0.7589\n",
      "Epoch: 4, Step: 1666/2949, Loss: 0.7877\n",
      "Epoch: 4, Step: 1667/2949, Loss: 0.7361\n",
      "Epoch: 4, Step: 1668/2949, Loss: 0.6834\n",
      "Epoch: 4, Step: 1669/2949, Loss: 0.7895\n",
      "Epoch: 4, Step: 1670/2949, Loss: 0.7509\n",
      "Epoch: 4, Step: 1671/2949, Loss: 0.7515\n",
      "Epoch: 4, Step: 1672/2949, Loss: 0.7654\n",
      "Epoch: 4, Step: 1673/2949, Loss: 0.7441\n",
      "Epoch: 4, Step: 1674/2949, Loss: 0.7403\n",
      "Epoch: 4, Step: 1675/2949, Loss: 0.6987\n",
      "Epoch: 4, Step: 1676/2949, Loss: 0.7194\n",
      "Epoch: 4, Step: 1677/2949, Loss: 0.7556\n",
      "Epoch: 4, Step: 1678/2949, Loss: 0.7569\n",
      "Epoch: 4, Step: 1679/2949, Loss: 0.7084\n",
      "Epoch: 4, Step: 1680/2949, Loss: 0.7315\n",
      "Epoch: 4, Step: 1681/2949, Loss: 0.7417\n",
      "Epoch: 4, Step: 1682/2949, Loss: 0.7579\n",
      "Epoch: 4, Step: 1683/2949, Loss: 0.7492\n",
      "Epoch: 4, Step: 1684/2949, Loss: 0.7653\n",
      "Epoch: 4, Step: 1685/2949, Loss: 0.7278\n",
      "Epoch: 4, Step: 1686/2949, Loss: 0.7529\n",
      "Epoch: 4, Step: 1687/2949, Loss: 0.7323\n",
      "Epoch: 4, Step: 1688/2949, Loss: 0.7331\n",
      "Epoch: 4, Step: 1689/2949, Loss: 0.7593\n",
      "Epoch: 4, Step: 1690/2949, Loss: 0.8040\n",
      "Epoch: 4, Step: 1691/2949, Loss: 0.7291\n",
      "Epoch: 4, Step: 1692/2949, Loss: 0.7461\n",
      "Epoch: 4, Step: 1693/2949, Loss: 0.7223\n",
      "Epoch: 4, Step: 1694/2949, Loss: 0.7511\n",
      "Epoch: 4, Step: 1695/2949, Loss: 0.7456\n",
      "Epoch: 4, Step: 1696/2949, Loss: 0.7681\n",
      "Epoch: 4, Step: 1697/2949, Loss: 0.7631\n",
      "Epoch: 4, Step: 1698/2949, Loss: 0.7406\n",
      "Epoch: 4, Step: 1699/2949, Loss: 0.7598\n",
      "Epoch: 4, Step: 1700/2949, Loss: 0.7165\n",
      "Epoch: 4, Step: 1701/2949, Loss: 0.7801\n",
      "Epoch: 4, Step: 1702/2949, Loss: 0.6743\n",
      "Epoch: 4, Step: 1703/2949, Loss: 0.7221\n",
      "Epoch: 4, Step: 1704/2949, Loss: 0.7181\n",
      "Epoch: 4, Step: 1705/2949, Loss: 0.7372\n",
      "Epoch: 4, Step: 1706/2949, Loss: 0.7841\n",
      "Epoch: 4, Step: 1707/2949, Loss: 0.7334\n",
      "Epoch: 4, Step: 1708/2949, Loss: 0.7305\n",
      "Epoch: 4, Step: 1709/2949, Loss: 0.7815\n",
      "Epoch: 4, Step: 1710/2949, Loss: 0.7509\n",
      "Epoch: 4, Step: 1711/2949, Loss: 0.7314\n",
      "Epoch: 4, Step: 1712/2949, Loss: 0.7942\n",
      "Epoch: 4, Step: 1713/2949, Loss: 0.7231\n",
      "Epoch: 4, Step: 1714/2949, Loss: 0.6736\n",
      "Epoch: 4, Step: 1715/2949, Loss: 0.8147\n",
      "Epoch: 4, Step: 1716/2949, Loss: 0.6901\n",
      "Epoch: 4, Step: 1717/2949, Loss: 0.7414\n",
      "Epoch: 4, Step: 1718/2949, Loss: 0.7311\n",
      "Epoch: 4, Step: 1719/2949, Loss: 0.7220\n",
      "Epoch: 4, Step: 1720/2949, Loss: 0.7135\n",
      "Epoch: 4, Step: 1721/2949, Loss: 0.7955\n",
      "Epoch: 4, Step: 1722/2949, Loss: 0.8239\n",
      "Epoch: 4, Step: 1723/2949, Loss: 0.7867\n",
      "Epoch: 4, Step: 1724/2949, Loss: 0.7422\n",
      "Epoch: 4, Step: 1725/2949, Loss: 0.7381\n",
      "Epoch: 4, Step: 1726/2949, Loss: 0.7196\n",
      "Epoch: 4, Step: 1727/2949, Loss: 0.8269\n",
      "Epoch: 4, Step: 1728/2949, Loss: 0.7401\n",
      "Epoch: 4, Step: 1729/2949, Loss: 0.7111\n",
      "Epoch: 4, Step: 1730/2949, Loss: 0.7878\n",
      "Epoch: 4, Step: 1731/2949, Loss: 0.8190\n",
      "Epoch: 4, Step: 1732/2949, Loss: 0.7534\n",
      "Epoch: 4, Step: 1733/2949, Loss: 0.7568\n",
      "Epoch: 4, Step: 1734/2949, Loss: 0.7576\n",
      "Epoch: 4, Step: 1735/2949, Loss: 0.7712\n",
      "Epoch: 4, Step: 1736/2949, Loss: 0.7708\n",
      "Epoch: 4, Step: 1737/2949, Loss: 0.7852\n",
      "Epoch: 4, Step: 1738/2949, Loss: 0.7849\n",
      "Epoch: 4, Step: 1739/2949, Loss: 0.7730\n",
      "Epoch: 4, Step: 1740/2949, Loss: 0.7552\n",
      "Epoch: 4, Step: 1741/2949, Loss: 0.8044\n",
      "Epoch: 4, Step: 1742/2949, Loss: 0.6981\n",
      "Epoch: 4, Step: 1743/2949, Loss: 0.7129\n",
      "Epoch: 4, Step: 1744/2949, Loss: 0.7734\n",
      "Epoch: 4, Step: 1745/2949, Loss: 0.7894\n",
      "Epoch: 4, Step: 1746/2949, Loss: 0.7139\n",
      "Epoch: 4, Step: 1747/2949, Loss: 0.6875\n",
      "Epoch: 4, Step: 1748/2949, Loss: 0.7084\n",
      "Epoch: 4, Step: 1749/2949, Loss: 0.7334\n",
      "Epoch: 4, Step: 1750/2949, Loss: 0.7576\n",
      "Epoch: 4, Step: 1751/2949, Loss: 0.7540\n",
      "Epoch: 4, Step: 1752/2949, Loss: 0.7689\n",
      "Epoch: 4, Step: 1753/2949, Loss: 0.7477\n",
      "Epoch: 4, Step: 1754/2949, Loss: 0.7272\n",
      "Epoch: 4, Step: 1755/2949, Loss: 0.7411\n",
      "Epoch: 4, Step: 1756/2949, Loss: 0.7551\n",
      "Epoch: 4, Step: 1757/2949, Loss: 0.7364\n",
      "Epoch: 4, Step: 1758/2949, Loss: 0.7603\n",
      "Epoch: 4, Step: 1759/2949, Loss: 0.7211\n",
      "Epoch: 4, Step: 1760/2949, Loss: 0.7552\n",
      "Epoch: 4, Step: 1761/2949, Loss: 0.8072\n",
      "Epoch: 4, Step: 1762/2949, Loss: 0.7512\n",
      "Epoch: 4, Step: 1763/2949, Loss: 0.7344\n",
      "Epoch: 4, Step: 1764/2949, Loss: 0.7226\n",
      "Epoch: 4, Step: 1765/2949, Loss: 0.7476\n",
      "Epoch: 4, Step: 1766/2949, Loss: 0.6869\n",
      "Epoch: 4, Step: 1767/2949, Loss: 0.7318\n",
      "Epoch: 4, Step: 1768/2949, Loss: 0.6928\n",
      "Epoch: 4, Step: 1769/2949, Loss: 0.7294\n",
      "Epoch: 4, Step: 1770/2949, Loss: 0.7242\n",
      "Epoch: 4, Step: 1771/2949, Loss: 0.7902\n",
      "Epoch: 4, Step: 1772/2949, Loss: 0.7465\n",
      "Epoch: 4, Step: 1773/2949, Loss: 0.7526\n",
      "Epoch: 4, Step: 1774/2949, Loss: 0.7639\n",
      "Epoch: 4, Step: 1775/2949, Loss: 0.6996\n",
      "Epoch: 4, Step: 1776/2949, Loss: 0.7338\n",
      "Epoch: 4, Step: 1777/2949, Loss: 0.7711\n",
      "Epoch: 4, Step: 1778/2949, Loss: 0.7850\n",
      "Epoch: 4, Step: 1779/2949, Loss: 0.7109\n",
      "Epoch: 4, Step: 1780/2949, Loss: 0.7207\n",
      "Epoch: 4, Step: 1781/2949, Loss: 0.7696\n",
      "Epoch: 4, Step: 1782/2949, Loss: 0.7545\n",
      "Epoch: 4, Step: 1783/2949, Loss: 0.7437\n",
      "Epoch: 4, Step: 1784/2949, Loss: 0.7243\n",
      "Epoch: 4, Step: 1785/2949, Loss: 0.7118\n",
      "Epoch: 4, Step: 1786/2949, Loss: 0.7299\n",
      "Epoch: 4, Step: 1787/2949, Loss: 0.7558\n",
      "Epoch: 4, Step: 1788/2949, Loss: 0.7406\n",
      "Epoch: 4, Step: 1789/2949, Loss: 0.7355\n",
      "Epoch: 4, Step: 1790/2949, Loss: 0.7792\n",
      "Epoch: 4, Step: 1791/2949, Loss: 0.7676\n",
      "Epoch: 4, Step: 1792/2949, Loss: 0.7473\n",
      "Epoch: 4, Step: 1793/2949, Loss: 0.7891\n",
      "Epoch: 4, Step: 1794/2949, Loss: 0.7696\n",
      "Epoch: 4, Step: 1795/2949, Loss: 0.7182\n",
      "Epoch: 4, Step: 1796/2949, Loss: 0.7299\n",
      "Epoch: 4, Step: 1797/2949, Loss: 0.7182\n",
      "Epoch: 4, Step: 1798/2949, Loss: 0.6829\n",
      "Epoch: 4, Step: 1799/2949, Loss: 0.7780\n",
      "Epoch: 4, Step: 1800/2949, Loss: 0.7695\n",
      "Epoch: 4, Step: 1801/2949, Loss: 0.7813\n",
      "Epoch: 4, Step: 1802/2949, Loss: 0.7883\n",
      "Epoch: 4, Step: 1803/2949, Loss: 0.7680\n",
      "Epoch: 4, Step: 1804/2949, Loss: 0.7396\n",
      "Epoch: 4, Step: 1805/2949, Loss: 0.7085\n",
      "Epoch: 4, Step: 1806/2949, Loss: 0.7300\n",
      "Epoch: 4, Step: 1807/2949, Loss: 0.7566\n",
      "Epoch: 4, Step: 1808/2949, Loss: 0.7502\n",
      "Epoch: 4, Step: 1809/2949, Loss: 0.8023\n",
      "Epoch: 4, Step: 1810/2949, Loss: 0.7700\n",
      "Epoch: 4, Step: 1811/2949, Loss: 0.7643\n",
      "Epoch: 4, Step: 1812/2949, Loss: 0.7714\n",
      "Epoch: 4, Step: 1813/2949, Loss: 0.7481\n",
      "Epoch: 4, Step: 1814/2949, Loss: 0.7331\n",
      "Epoch: 4, Step: 1815/2949, Loss: 0.7820\n",
      "Epoch: 4, Step: 1816/2949, Loss: 0.7332\n",
      "Epoch: 4, Step: 1817/2949, Loss: 0.7539\n",
      "Epoch: 4, Step: 1818/2949, Loss: 0.7296\n",
      "Epoch: 4, Step: 1819/2949, Loss: 0.7769\n",
      "Epoch: 4, Step: 1820/2949, Loss: 0.7660\n",
      "Epoch: 4, Step: 1821/2949, Loss: 0.7368\n",
      "Epoch: 4, Step: 1822/2949, Loss: 0.7189\n",
      "Epoch: 4, Step: 1823/2949, Loss: 0.7976\n",
      "Epoch: 4, Step: 1824/2949, Loss: 0.7472\n",
      "Epoch: 4, Step: 1825/2949, Loss: 0.7606\n",
      "Epoch: 4, Step: 1826/2949, Loss: 0.7682\n",
      "Epoch: 4, Step: 1827/2949, Loss: 0.7629\n",
      "Epoch: 4, Step: 1828/2949, Loss: 0.6722\n",
      "Epoch: 4, Step: 1829/2949, Loss: 0.7816\n",
      "Epoch: 4, Step: 1830/2949, Loss: 0.7614\n",
      "Epoch: 4, Step: 1831/2949, Loss: 0.7401\n",
      "Epoch: 4, Step: 1832/2949, Loss: 0.7659\n",
      "Epoch: 4, Step: 1833/2949, Loss: 0.7534\n",
      "Epoch: 4, Step: 1834/2949, Loss: 0.7227\n",
      "Epoch: 4, Step: 1835/2949, Loss: 0.7381\n",
      "Epoch: 4, Step: 1836/2949, Loss: 0.7679\n",
      "Epoch: 4, Step: 1837/2949, Loss: 0.7741\n",
      "Epoch: 4, Step: 1838/2949, Loss: 0.8144\n",
      "Epoch: 4, Step: 1839/2949, Loss: 0.7464\n",
      "Epoch: 4, Step: 1840/2949, Loss: 0.7916\n",
      "Epoch: 4, Step: 1841/2949, Loss: 0.7634\n",
      "Epoch: 4, Step: 1842/2949, Loss: 0.7679\n",
      "Epoch: 4, Step: 1843/2949, Loss: 0.7623\n",
      "Epoch: 4, Step: 1844/2949, Loss: 0.7683\n",
      "Epoch: 4, Step: 1845/2949, Loss: 0.7213\n",
      "Epoch: 4, Step: 1846/2949, Loss: 0.7315\n",
      "Epoch: 4, Step: 1847/2949, Loss: 0.7349\n",
      "Epoch: 4, Step: 1848/2949, Loss: 0.7470\n",
      "Epoch: 4, Step: 1849/2949, Loss: 0.7761\n",
      "Epoch: 4, Step: 1850/2949, Loss: 0.7848\n",
      "Epoch: 4, Step: 1851/2949, Loss: 0.7723\n",
      "Epoch: 4, Step: 1852/2949, Loss: 0.7386\n",
      "Epoch: 4, Step: 1853/2949, Loss: 0.7733\n",
      "Epoch: 4, Step: 1854/2949, Loss: 0.7224\n",
      "Epoch: 4, Step: 1855/2949, Loss: 0.7649\n",
      "Epoch: 4, Step: 1856/2949, Loss: 0.6658\n",
      "Epoch: 4, Step: 1857/2949, Loss: 0.7699\n",
      "Epoch: 4, Step: 1858/2949, Loss: 0.7665\n",
      "Epoch: 4, Step: 1859/2949, Loss: 0.7298\n",
      "Epoch: 4, Step: 1860/2949, Loss: 0.7518\n",
      "Epoch: 4, Step: 1861/2949, Loss: 0.7188\n",
      "Epoch: 4, Step: 1862/2949, Loss: 0.8034\n",
      "Epoch: 4, Step: 1863/2949, Loss: 0.7595\n",
      "Epoch: 4, Step: 1864/2949, Loss: 0.7896\n",
      "Epoch: 4, Step: 1865/2949, Loss: 0.7322\n",
      "Epoch: 4, Step: 1866/2949, Loss: 0.7398\n",
      "Epoch: 4, Step: 1867/2949, Loss: 0.7315\n",
      "Epoch: 4, Step: 1868/2949, Loss: 0.6918\n",
      "Epoch: 4, Step: 1869/2949, Loss: 0.7612\n",
      "Epoch: 4, Step: 1870/2949, Loss: 0.7526\n",
      "Epoch: 4, Step: 1871/2949, Loss: 0.7755\n",
      "Epoch: 4, Step: 1872/2949, Loss: 0.7481\n",
      "Epoch: 4, Step: 1873/2949, Loss: 0.7451\n",
      "Epoch: 4, Step: 1874/2949, Loss: 0.7702\n",
      "Epoch: 4, Step: 1875/2949, Loss: 0.7445\n",
      "Epoch: 4, Step: 1876/2949, Loss: 0.7387\n",
      "Epoch: 4, Step: 1877/2949, Loss: 0.7593\n",
      "Epoch: 4, Step: 1878/2949, Loss: 0.7650\n",
      "Epoch: 4, Step: 1879/2949, Loss: 0.7524\n",
      "Epoch: 4, Step: 1880/2949, Loss: 0.7322\n",
      "Epoch: 4, Step: 1881/2949, Loss: 0.7981\n",
      "Epoch: 4, Step: 1882/2949, Loss: 0.7572\n",
      "Epoch: 4, Step: 1883/2949, Loss: 0.7950\n",
      "Epoch: 4, Step: 1884/2949, Loss: 0.7224\n",
      "Epoch: 4, Step: 1885/2949, Loss: 0.7362\n",
      "Epoch: 4, Step: 1886/2949, Loss: 0.6809\n",
      "Epoch: 4, Step: 1887/2949, Loss: 0.6970\n",
      "Epoch: 4, Step: 1888/2949, Loss: 0.7821\n",
      "Epoch: 4, Step: 1889/2949, Loss: 0.7768\n",
      "Epoch: 4, Step: 1890/2949, Loss: 0.7484\n",
      "Epoch: 4, Step: 1891/2949, Loss: 0.7878\n",
      "Epoch: 4, Step: 1892/2949, Loss: 0.7553\n",
      "Epoch: 4, Step: 1893/2949, Loss: 0.7657\n",
      "Epoch: 4, Step: 1894/2949, Loss: 0.7619\n",
      "Epoch: 4, Step: 1895/2949, Loss: 0.7651\n",
      "Epoch: 4, Step: 1896/2949, Loss: 0.8050\n",
      "Epoch: 4, Step: 1897/2949, Loss: 0.6936\n",
      "Epoch: 4, Step: 1898/2949, Loss: 0.7184\n",
      "Epoch: 4, Step: 1899/2949, Loss: 0.7420\n",
      "Epoch: 4, Step: 1900/2949, Loss: 0.7347\n",
      "Epoch: 4, Step: 1901/2949, Loss: 0.7805\n",
      "Epoch: 4, Step: 1902/2949, Loss: 0.7502\n",
      "Epoch: 4, Step: 1903/2949, Loss: 0.7864\n",
      "Epoch: 4, Step: 1904/2949, Loss: 0.7569\n",
      "Epoch: 4, Step: 1905/2949, Loss: 0.7791\n",
      "Epoch: 4, Step: 1906/2949, Loss: 0.7692\n",
      "Epoch: 4, Step: 1907/2949, Loss: 0.7120\n",
      "Epoch: 4, Step: 1908/2949, Loss: 0.7725\n",
      "Epoch: 4, Step: 1909/2949, Loss: 0.7440\n",
      "Epoch: 4, Step: 1910/2949, Loss: 0.7860\n",
      "Epoch: 4, Step: 1911/2949, Loss: 0.7258\n",
      "Epoch: 4, Step: 1912/2949, Loss: 0.7628\n",
      "Epoch: 4, Step: 1913/2949, Loss: 0.7401\n",
      "Epoch: 4, Step: 1914/2949, Loss: 0.7009\n",
      "Epoch: 4, Step: 1915/2949, Loss: 0.7144\n",
      "Epoch: 4, Step: 1916/2949, Loss: 0.7781\n",
      "Epoch: 4, Step: 1917/2949, Loss: 0.7647\n",
      "Epoch: 4, Step: 1918/2949, Loss: 0.7153\n",
      "Epoch: 4, Step: 1919/2949, Loss: 0.7513\n",
      "Epoch: 4, Step: 1920/2949, Loss: 0.7455\n",
      "Epoch: 4, Step: 1921/2949, Loss: 0.7680\n",
      "Epoch: 4, Step: 1922/2949, Loss: 0.7899\n",
      "Epoch: 4, Step: 1923/2949, Loss: 0.7668\n",
      "Epoch: 4, Step: 1924/2949, Loss: 0.7681\n",
      "Epoch: 4, Step: 1925/2949, Loss: 0.7417\n",
      "Epoch: 4, Step: 1926/2949, Loss: 0.7129\n",
      "Epoch: 4, Step: 1927/2949, Loss: 0.7215\n",
      "Epoch: 4, Step: 1928/2949, Loss: 0.7420\n",
      "Epoch: 4, Step: 1929/2949, Loss: 0.7213\n",
      "Epoch: 4, Step: 1930/2949, Loss: 0.7526\n",
      "Epoch: 4, Step: 1931/2949, Loss: 0.7237\n",
      "Epoch: 4, Step: 1932/2949, Loss: 0.7596\n",
      "Epoch: 4, Step: 1933/2949, Loss: 0.7824\n",
      "Epoch: 4, Step: 1934/2949, Loss: 0.7535\n",
      "Epoch: 4, Step: 1935/2949, Loss: 0.7140\n",
      "Epoch: 4, Step: 1936/2949, Loss: 0.7575\n",
      "Epoch: 4, Step: 1937/2949, Loss: 0.7405\n",
      "Epoch: 4, Step: 1938/2949, Loss: 0.6983\n",
      "Epoch: 4, Step: 1939/2949, Loss: 0.7319\n",
      "Epoch: 4, Step: 1940/2949, Loss: 0.7801\n",
      "Epoch: 4, Step: 1941/2949, Loss: 0.6986\n",
      "Epoch: 4, Step: 1942/2949, Loss: 0.7432\n",
      "Epoch: 4, Step: 1943/2949, Loss: 0.7653\n",
      "Epoch: 4, Step: 1944/2949, Loss: 0.7584\n",
      "Epoch: 4, Step: 1945/2949, Loss: 0.7745\n",
      "Epoch: 4, Step: 1946/2949, Loss: 0.7095\n",
      "Epoch: 4, Step: 1947/2949, Loss: 0.7352\n",
      "Epoch: 4, Step: 1948/2949, Loss: 0.7343\n",
      "Epoch: 4, Step: 1949/2949, Loss: 0.7315\n",
      "Epoch: 4, Step: 1950/2949, Loss: 0.7055\n",
      "Epoch: 4, Step: 1951/2949, Loss: 0.7902\n",
      "Epoch: 4, Step: 1952/2949, Loss: 0.7282\n",
      "Epoch: 4, Step: 1953/2949, Loss: 0.7219\n",
      "Epoch: 4, Step: 1954/2949, Loss: 0.7361\n",
      "Epoch: 4, Step: 1955/2949, Loss: 0.7587\n",
      "Epoch: 4, Step: 1956/2949, Loss: 0.7993\n",
      "Epoch: 4, Step: 1957/2949, Loss: 0.7129\n",
      "Epoch: 4, Step: 1958/2949, Loss: 0.7320\n",
      "Epoch: 4, Step: 1959/2949, Loss: 0.7674\n",
      "Epoch: 4, Step: 1960/2949, Loss: 0.7317\n",
      "Epoch: 4, Step: 1961/2949, Loss: 0.7014\n",
      "Epoch: 4, Step: 1962/2949, Loss: 0.7607\n",
      "Epoch: 4, Step: 1963/2949, Loss: 0.7672\n",
      "Epoch: 4, Step: 1964/2949, Loss: 0.7564\n",
      "Epoch: 4, Step: 1965/2949, Loss: 0.7123\n",
      "Epoch: 4, Step: 1966/2949, Loss: 0.7287\n",
      "Epoch: 4, Step: 1967/2949, Loss: 0.7808\n",
      "Epoch: 4, Step: 1968/2949, Loss: 0.7213\n",
      "Epoch: 4, Step: 1969/2949, Loss: 0.7744\n",
      "Epoch: 4, Step: 1970/2949, Loss: 0.7965\n",
      "Epoch: 4, Step: 1971/2949, Loss: 0.7019\n",
      "Epoch: 4, Step: 1972/2949, Loss: 0.7025\n",
      "Epoch: 4, Step: 1973/2949, Loss: 0.7630\n",
      "Epoch: 4, Step: 1974/2949, Loss: 0.7803\n",
      "Epoch: 4, Step: 1975/2949, Loss: 0.7576\n",
      "Epoch: 4, Step: 1976/2949, Loss: 0.7766\n",
      "Epoch: 4, Step: 1977/2949, Loss: 0.7340\n",
      "Epoch: 4, Step: 1978/2949, Loss: 0.7253\n",
      "Epoch: 4, Step: 1979/2949, Loss: 0.6807\n",
      "Epoch: 4, Step: 1980/2949, Loss: 0.7786\n",
      "Epoch: 4, Step: 1981/2949, Loss: 0.7209\n",
      "Epoch: 4, Step: 1982/2949, Loss: 0.6965\n",
      "Epoch: 4, Step: 1983/2949, Loss: 0.7297\n",
      "Epoch: 4, Step: 1984/2949, Loss: 0.7833\n",
      "Epoch: 4, Step: 1985/2949, Loss: 0.7775\n",
      "Epoch: 4, Step: 1986/2949, Loss: 0.7344\n",
      "Epoch: 4, Step: 1987/2949, Loss: 0.7158\n",
      "Epoch: 4, Step: 1988/2949, Loss: 0.7371\n",
      "Epoch: 4, Step: 1989/2949, Loss: 0.7562\n",
      "Epoch: 4, Step: 1990/2949, Loss: 0.7670\n",
      "Epoch: 4, Step: 1991/2949, Loss: 0.7114\n",
      "Epoch: 4, Step: 1992/2949, Loss: 0.7454\n",
      "Epoch: 4, Step: 1993/2949, Loss: 0.7329\n",
      "Epoch: 4, Step: 1994/2949, Loss: 0.7410\n",
      "Epoch: 4, Step: 1995/2949, Loss: 0.7282\n",
      "Epoch: 4, Step: 1996/2949, Loss: 0.7073\n",
      "Epoch: 4, Step: 1997/2949, Loss: 0.7176\n",
      "Epoch: 4, Step: 1998/2949, Loss: 0.6922\n",
      "Epoch: 4, Step: 1999/2949, Loss: 0.7946\n",
      "Epoch: 4, Step: 2000/2949, Loss: 0.7157\n",
      "Epoch: 4, Step: 2001/2949, Loss: 0.7752\n",
      "Epoch: 4, Step: 2002/2949, Loss: 0.7529\n",
      "Epoch: 4, Step: 2003/2949, Loss: 0.7829\n",
      "Epoch: 4, Step: 2004/2949, Loss: 0.7194\n",
      "Epoch: 4, Step: 2005/2949, Loss: 0.7762\n",
      "Epoch: 4, Step: 2006/2949, Loss: 0.7545\n",
      "Epoch: 4, Step: 2007/2949, Loss: 0.7158\n",
      "Epoch: 4, Step: 2008/2949, Loss: 0.7976\n",
      "Epoch: 4, Step: 2009/2949, Loss: 0.7451\n",
      "Epoch: 4, Step: 2010/2949, Loss: 0.8096\n",
      "Epoch: 4, Step: 2011/2949, Loss: 0.7531\n",
      "Epoch: 4, Step: 2012/2949, Loss: 0.7525\n",
      "Epoch: 4, Step: 2013/2949, Loss: 0.7204\n",
      "Epoch: 4, Step: 2014/2949, Loss: 0.7674\n",
      "Epoch: 4, Step: 2015/2949, Loss: 0.7235\n",
      "Epoch: 4, Step: 2016/2949, Loss: 0.7697\n",
      "Epoch: 4, Step: 2017/2949, Loss: 0.7261\n",
      "Epoch: 4, Step: 2018/2949, Loss: 0.7690\n",
      "Epoch: 4, Step: 2019/2949, Loss: 0.7478\n",
      "Epoch: 4, Step: 2020/2949, Loss: 0.7690\n",
      "Epoch: 4, Step: 2021/2949, Loss: 0.7690\n",
      "Epoch: 4, Step: 2022/2949, Loss: 0.7768\n",
      "Epoch: 4, Step: 2023/2949, Loss: 0.7298\n",
      "Epoch: 4, Step: 2024/2949, Loss: 0.7870\n",
      "Epoch: 4, Step: 2025/2949, Loss: 0.7779\n",
      "Epoch: 4, Step: 2026/2949, Loss: 0.7671\n",
      "Epoch: 4, Step: 2027/2949, Loss: 0.7865\n",
      "Epoch: 4, Step: 2028/2949, Loss: 0.7723\n",
      "Epoch: 4, Step: 2029/2949, Loss: 0.7536\n",
      "Epoch: 4, Step: 2030/2949, Loss: 0.7215\n",
      "Epoch: 4, Step: 2031/2949, Loss: 0.7831\n",
      "Epoch: 4, Step: 2032/2949, Loss: 0.7506\n",
      "Epoch: 4, Step: 2033/2949, Loss: 0.7524\n",
      "Epoch: 4, Step: 2034/2949, Loss: 0.7735\n",
      "Epoch: 4, Step: 2035/2949, Loss: 0.6942\n",
      "Epoch: 4, Step: 2036/2949, Loss: 0.7218\n",
      "Epoch: 4, Step: 2037/2949, Loss: 0.7991\n",
      "Epoch: 4, Step: 2038/2949, Loss: 0.7604\n",
      "Epoch: 4, Step: 2039/2949, Loss: 0.8243\n",
      "Epoch: 4, Step: 2040/2949, Loss: 0.7793\n",
      "Epoch: 4, Step: 2041/2949, Loss: 0.7099\n",
      "Epoch: 4, Step: 2042/2949, Loss: 0.7215\n",
      "Epoch: 4, Step: 2043/2949, Loss: 0.7339\n",
      "Epoch: 4, Step: 2044/2949, Loss: 0.7288\n",
      "Epoch: 4, Step: 2045/2949, Loss: 0.7611\n",
      "Epoch: 4, Step: 2046/2949, Loss: 0.7670\n",
      "Epoch: 4, Step: 2047/2949, Loss: 0.7809\n",
      "Epoch: 4, Step: 2048/2949, Loss: 0.8094\n",
      "Epoch: 4, Step: 2049/2949, Loss: 0.7248\n",
      "Epoch: 4, Step: 2050/2949, Loss: 0.7582\n",
      "Epoch: 4, Step: 2051/2949, Loss: 0.8273\n",
      "Epoch: 4, Step: 2052/2949, Loss: 0.8208\n",
      "Epoch: 4, Step: 2053/2949, Loss: 0.7702\n",
      "Epoch: 4, Step: 2054/2949, Loss: 0.7642\n",
      "Epoch: 4, Step: 2055/2949, Loss: 0.7650\n",
      "Epoch: 4, Step: 2056/2949, Loss: 0.7491\n",
      "Epoch: 4, Step: 2057/2949, Loss: 0.7137\n",
      "Epoch: 4, Step: 2058/2949, Loss: 0.7235\n",
      "Epoch: 4, Step: 2059/2949, Loss: 0.7678\n",
      "Epoch: 4, Step: 2060/2949, Loss: 0.7379\n",
      "Epoch: 4, Step: 2061/2949, Loss: 0.7745\n",
      "Epoch: 4, Step: 2062/2949, Loss: 0.7267\n",
      "Epoch: 4, Step: 2063/2949, Loss: 0.7316\n",
      "Epoch: 4, Step: 2064/2949, Loss: 0.7416\n",
      "Epoch: 4, Step: 2065/2949, Loss: 0.7766\n",
      "Epoch: 4, Step: 2066/2949, Loss: 0.7182\n",
      "Epoch: 4, Step: 2067/2949, Loss: 0.7817\n",
      "Epoch: 4, Step: 2068/2949, Loss: 0.7649\n",
      "Epoch: 4, Step: 2069/2949, Loss: 0.7723\n",
      "Epoch: 4, Step: 2070/2949, Loss: 0.7575\n",
      "Epoch: 4, Step: 2071/2949, Loss: 0.7900\n",
      "Epoch: 4, Step: 2072/2949, Loss: 0.7944\n",
      "Epoch: 4, Step: 2073/2949, Loss: 0.7258\n",
      "Epoch: 4, Step: 2074/2949, Loss: 0.6766\n",
      "Epoch: 4, Step: 2075/2949, Loss: 0.7261\n",
      "Epoch: 4, Step: 2076/2949, Loss: 0.7512\n",
      "Epoch: 4, Step: 2077/2949, Loss: 0.7341\n",
      "Epoch: 4, Step: 2078/2949, Loss: 0.7542\n",
      "Epoch: 4, Step: 2079/2949, Loss: 0.7828\n",
      "Epoch: 4, Step: 2080/2949, Loss: 0.7515\n",
      "Epoch: 4, Step: 2081/2949, Loss: 0.7338\n",
      "Epoch: 4, Step: 2082/2949, Loss: 0.7856\n",
      "Epoch: 4, Step: 2083/2949, Loss: 0.7665\n",
      "Epoch: 4, Step: 2084/2949, Loss: 0.7182\n",
      "Epoch: 4, Step: 2085/2949, Loss: 0.7410\n",
      "Epoch: 4, Step: 2086/2949, Loss: 0.7631\n",
      "Epoch: 4, Step: 2087/2949, Loss: 0.7690\n",
      "Epoch: 4, Step: 2088/2949, Loss: 0.7685\n",
      "Epoch: 4, Step: 2089/2949, Loss: 0.7656\n",
      "Epoch: 4, Step: 2090/2949, Loss: 0.7414\n",
      "Epoch: 4, Step: 2091/2949, Loss: 0.7774\n",
      "Epoch: 4, Step: 2092/2949, Loss: 0.7588\n",
      "Epoch: 4, Step: 2093/2949, Loss: 0.7651\n",
      "Epoch: 4, Step: 2094/2949, Loss: 0.7745\n",
      "Epoch: 4, Step: 2095/2949, Loss: 0.7350\n",
      "Epoch: 4, Step: 2096/2949, Loss: 0.7537\n",
      "Epoch: 4, Step: 2097/2949, Loss: 0.7583\n",
      "Epoch: 4, Step: 2098/2949, Loss: 0.6852\n",
      "Epoch: 4, Step: 2099/2949, Loss: 0.7641\n",
      "Epoch: 4, Step: 2100/2949, Loss: 0.7485\n",
      "Epoch: 4, Step: 2101/2949, Loss: 0.6910\n",
      "Epoch: 4, Step: 2102/2949, Loss: 0.7461\n",
      "Epoch: 4, Step: 2103/2949, Loss: 0.7683\n",
      "Epoch: 4, Step: 2104/2949, Loss: 0.7671\n",
      "Epoch: 4, Step: 2105/2949, Loss: 0.7499\n",
      "Epoch: 4, Step: 2106/2949, Loss: 0.7328\n",
      "Epoch: 4, Step: 2107/2949, Loss: 0.7360\n",
      "Epoch: 4, Step: 2108/2949, Loss: 0.7703\n",
      "Epoch: 4, Step: 2109/2949, Loss: 0.7718\n",
      "Epoch: 4, Step: 2110/2949, Loss: 0.7344\n",
      "Epoch: 4, Step: 2111/2949, Loss: 0.7812\n",
      "Epoch: 4, Step: 2112/2949, Loss: 0.7778\n",
      "Epoch: 4, Step: 2113/2949, Loss: 0.7613\n",
      "Epoch: 4, Step: 2114/2949, Loss: 0.7204\n",
      "Epoch: 4, Step: 2115/2949, Loss: 0.7297\n",
      "Epoch: 4, Step: 2116/2949, Loss: 0.7702\n",
      "Epoch: 4, Step: 2117/2949, Loss: 0.7371\n",
      "Epoch: 4, Step: 2118/2949, Loss: 0.7861\n",
      "Epoch: 4, Step: 2119/2949, Loss: 0.7430\n",
      "Epoch: 4, Step: 2120/2949, Loss: 0.7503\n",
      "Epoch: 4, Step: 2121/2949, Loss: 0.7494\n",
      "Epoch: 4, Step: 2122/2949, Loss: 0.7601\n",
      "Epoch: 4, Step: 2123/2949, Loss: 0.7649\n",
      "Epoch: 4, Step: 2124/2949, Loss: 0.7331\n",
      "Epoch: 4, Step: 2125/2949, Loss: 0.7296\n",
      "Epoch: 4, Step: 2126/2949, Loss: 0.7221\n",
      "Epoch: 4, Step: 2127/2949, Loss: 0.7371\n",
      "Epoch: 4, Step: 2128/2949, Loss: 0.7499\n",
      "Epoch: 4, Step: 2129/2949, Loss: 0.8045\n",
      "Epoch: 4, Step: 2130/2949, Loss: 0.7436\n",
      "Epoch: 4, Step: 2131/2949, Loss: 0.7525\n",
      "Epoch: 4, Step: 2132/2949, Loss: 0.7591\n",
      "Epoch: 4, Step: 2133/2949, Loss: 0.7336\n",
      "Epoch: 4, Step: 2134/2949, Loss: 0.7440\n",
      "Epoch: 4, Step: 2135/2949, Loss: 0.7552\n",
      "Epoch: 4, Step: 2136/2949, Loss: 0.7581\n",
      "Epoch: 4, Step: 2137/2949, Loss: 0.7730\n",
      "Epoch: 4, Step: 2138/2949, Loss: 0.8093\n",
      "Epoch: 4, Step: 2139/2949, Loss: 0.7759\n",
      "Epoch: 4, Step: 2140/2949, Loss: 0.7775\n",
      "Epoch: 4, Step: 2141/2949, Loss: 0.7910\n",
      "Epoch: 4, Step: 2142/2949, Loss: 0.7864\n",
      "Epoch: 4, Step: 2143/2949, Loss: 0.8009\n",
      "Epoch: 4, Step: 2144/2949, Loss: 0.7884\n",
      "Epoch: 4, Step: 2145/2949, Loss: 0.7677\n",
      "Epoch: 4, Step: 2146/2949, Loss: 0.7388\n",
      "Epoch: 4, Step: 2147/2949, Loss: 0.7189\n",
      "Epoch: 4, Step: 2148/2949, Loss: 0.7671\n",
      "Epoch: 4, Step: 2149/2949, Loss: 0.7617\n",
      "Epoch: 4, Step: 2150/2949, Loss: 0.7482\n",
      "Epoch: 4, Step: 2151/2949, Loss: 0.7356\n",
      "Epoch: 4, Step: 2152/2949, Loss: 0.7255\n",
      "Epoch: 4, Step: 2153/2949, Loss: 0.6922\n",
      "Epoch: 4, Step: 2154/2949, Loss: 0.7392\n",
      "Epoch: 4, Step: 2155/2949, Loss: 0.7355\n",
      "Epoch: 4, Step: 2156/2949, Loss: 0.7997\n",
      "Epoch: 4, Step: 2157/2949, Loss: 0.7436\n",
      "Epoch: 4, Step: 2158/2949, Loss: 0.7219\n",
      "Epoch: 4, Step: 2159/2949, Loss: 0.7366\n",
      "Epoch: 4, Step: 2160/2949, Loss: 0.7356\n",
      "Epoch: 4, Step: 2161/2949, Loss: 0.7731\n",
      "Epoch: 4, Step: 2162/2949, Loss: 0.7000\n",
      "Epoch: 4, Step: 2163/2949, Loss: 0.7308\n",
      "Epoch: 4, Step: 2164/2949, Loss: 0.7440\n",
      "Epoch: 4, Step: 2165/2949, Loss: 0.7099\n",
      "Epoch: 4, Step: 2166/2949, Loss: 0.7717\n",
      "Epoch: 4, Step: 2167/2949, Loss: 0.7501\n",
      "Epoch: 4, Step: 2168/2949, Loss: 0.7447\n",
      "Epoch: 4, Step: 2169/2949, Loss: 0.7598\n",
      "Epoch: 4, Step: 2170/2949, Loss: 0.7406\n",
      "Epoch: 4, Step: 2171/2949, Loss: 0.7843\n",
      "Epoch: 4, Step: 2172/2949, Loss: 0.8255\n",
      "Epoch: 4, Step: 2173/2949, Loss: 0.7223\n",
      "Epoch: 4, Step: 2174/2949, Loss: 0.7912\n",
      "Epoch: 4, Step: 2175/2949, Loss: 0.7273\n",
      "Epoch: 4, Step: 2176/2949, Loss: 0.7602\n",
      "Epoch: 4, Step: 2177/2949, Loss: 0.7789\n",
      "Epoch: 4, Step: 2178/2949, Loss: 0.7646\n",
      "Epoch: 4, Step: 2179/2949, Loss: 0.7190\n",
      "Epoch: 4, Step: 2180/2949, Loss: 0.7322\n",
      "Epoch: 4, Step: 2181/2949, Loss: 0.8028\n",
      "Epoch: 4, Step: 2182/2949, Loss: 0.7410\n",
      "Epoch: 4, Step: 2183/2949, Loss: 0.7706\n",
      "Epoch: 4, Step: 2184/2949, Loss: 0.7441\n",
      "Epoch: 4, Step: 2185/2949, Loss: 0.7405\n",
      "Epoch: 4, Step: 2186/2949, Loss: 0.7395\n",
      "Epoch: 4, Step: 2187/2949, Loss: 0.6961\n",
      "Epoch: 4, Step: 2188/2949, Loss: 0.7617\n",
      "Epoch: 4, Step: 2189/2949, Loss: 0.7186\n",
      "Epoch: 4, Step: 2190/2949, Loss: 0.7560\n",
      "Epoch: 4, Step: 2191/2949, Loss: 0.7346\n",
      "Epoch: 4, Step: 2192/2949, Loss: 0.7540\n",
      "Epoch: 4, Step: 2193/2949, Loss: 0.7237\n",
      "Epoch: 4, Step: 2194/2949, Loss: 0.7693\n",
      "Epoch: 4, Step: 2195/2949, Loss: 0.7935\n",
      "Epoch: 4, Step: 2196/2949, Loss: 0.7468\n",
      "Epoch: 4, Step: 2197/2949, Loss: 0.7177\n",
      "Epoch: 4, Step: 2198/2949, Loss: 0.7463\n",
      "Epoch: 4, Step: 2199/2949, Loss: 0.7526\n",
      "Epoch: 4, Step: 2200/2949, Loss: 0.7447\n",
      "Epoch: 4, Step: 2201/2949, Loss: 0.7296\n",
      "Epoch: 4, Step: 2202/2949, Loss: 0.7540\n",
      "Epoch: 4, Step: 2203/2949, Loss: 0.7513\n",
      "Epoch: 4, Step: 2204/2949, Loss: 0.8191\n",
      "Epoch: 4, Step: 2205/2949, Loss: 0.7747\n",
      "Epoch: 4, Step: 2206/2949, Loss: 0.7779\n",
      "Epoch: 4, Step: 2207/2949, Loss: 0.6996\n",
      "Epoch: 4, Step: 2208/2949, Loss: 0.7186\n",
      "Epoch: 4, Step: 2209/2949, Loss: 0.7584\n",
      "Epoch: 4, Step: 2210/2949, Loss: 0.7780\n",
      "Epoch: 4, Step: 2211/2949, Loss: 0.7298\n",
      "Epoch: 4, Step: 2212/2949, Loss: 0.7107\n",
      "Epoch: 4, Step: 2213/2949, Loss: 0.7774\n",
      "Epoch: 4, Step: 2214/2949, Loss: 0.8025\n",
      "Epoch: 4, Step: 2215/2949, Loss: 0.7350\n",
      "Epoch: 4, Step: 2216/2949, Loss: 0.6927\n",
      "Epoch: 4, Step: 2217/2949, Loss: 0.7622\n",
      "Epoch: 4, Step: 2218/2949, Loss: 0.6659\n",
      "Epoch: 4, Step: 2219/2949, Loss: 0.7726\n",
      "Epoch: 4, Step: 2220/2949, Loss: 0.7349\n",
      "Epoch: 4, Step: 2221/2949, Loss: 0.7372\n",
      "Epoch: 4, Step: 2222/2949, Loss: 0.7413\n",
      "Epoch: 4, Step: 2223/2949, Loss: 0.7309\n",
      "Epoch: 4, Step: 2224/2949, Loss: 0.7575\n",
      "Epoch: 4, Step: 2225/2949, Loss: 0.6997\n",
      "Epoch: 4, Step: 2226/2949, Loss: 0.7985\n",
      "Epoch: 4, Step: 2227/2949, Loss: 0.7320\n",
      "Epoch: 4, Step: 2228/2949, Loss: 0.7349\n",
      "Epoch: 4, Step: 2229/2949, Loss: 0.7408\n",
      "Epoch: 4, Step: 2230/2949, Loss: 0.7518\n",
      "Epoch: 4, Step: 2231/2949, Loss: 0.7718\n",
      "Epoch: 4, Step: 2232/2949, Loss: 0.7978\n",
      "Epoch: 4, Step: 2233/2949, Loss: 0.8084\n",
      "Epoch: 4, Step: 2234/2949, Loss: 0.7493\n",
      "Epoch: 4, Step: 2235/2949, Loss: 0.8055\n",
      "Epoch: 4, Step: 2236/2949, Loss: 0.7295\n",
      "Epoch: 4, Step: 2237/2949, Loss: 0.7614\n",
      "Epoch: 4, Step: 2238/2949, Loss: 0.7796\n",
      "Epoch: 4, Step: 2239/2949, Loss: 0.7275\n",
      "Epoch: 4, Step: 2240/2949, Loss: 0.7226\n",
      "Epoch: 4, Step: 2241/2949, Loss: 0.7508\n",
      "Epoch: 4, Step: 2242/2949, Loss: 0.7739\n",
      "Epoch: 4, Step: 2243/2949, Loss: 0.8052\n",
      "Epoch: 4, Step: 2244/2949, Loss: 0.7440\n",
      "Epoch: 4, Step: 2245/2949, Loss: 0.7464\n",
      "Epoch: 4, Step: 2246/2949, Loss: 0.7452\n",
      "Epoch: 4, Step: 2247/2949, Loss: 0.7407\n",
      "Epoch: 4, Step: 2248/2949, Loss: 0.7593\n",
      "Epoch: 4, Step: 2249/2949, Loss: 0.7513\n",
      "Epoch: 4, Step: 2250/2949, Loss: 0.7268\n",
      "Epoch: 4, Step: 2251/2949, Loss: 0.8102\n",
      "Epoch: 4, Step: 2252/2949, Loss: 0.7744\n",
      "Epoch: 4, Step: 2253/2949, Loss: 0.7545\n",
      "Epoch: 4, Step: 2254/2949, Loss: 0.7769\n",
      "Epoch: 4, Step: 2255/2949, Loss: 0.7445\n",
      "Epoch: 4, Step: 2256/2949, Loss: 0.7394\n",
      "Epoch: 4, Step: 2257/2949, Loss: 0.7567\n",
      "Epoch: 4, Step: 2258/2949, Loss: 0.8081\n",
      "Epoch: 4, Step: 2259/2949, Loss: 0.7911\n",
      "Epoch: 4, Step: 2260/2949, Loss: 0.7108\n",
      "Epoch: 4, Step: 2261/2949, Loss: 0.7000\n",
      "Epoch: 4, Step: 2262/2949, Loss: 0.7850\n",
      "Epoch: 4, Step: 2263/2949, Loss: 0.7396\n",
      "Epoch: 4, Step: 2264/2949, Loss: 0.7364\n",
      "Epoch: 4, Step: 2265/2949, Loss: 0.7832\n",
      "Epoch: 4, Step: 2266/2949, Loss: 0.7638\n",
      "Epoch: 4, Step: 2267/2949, Loss: 0.7934\n",
      "Epoch: 4, Step: 2268/2949, Loss: 0.7564\n",
      "Epoch: 4, Step: 2269/2949, Loss: 0.6943\n",
      "Epoch: 4, Step: 2270/2949, Loss: 0.7164\n",
      "Epoch: 4, Step: 2271/2949, Loss: 0.7826\n",
      "Epoch: 4, Step: 2272/2949, Loss: 0.7435\n",
      "Epoch: 4, Step: 2273/2949, Loss: 0.7076\n",
      "Epoch: 4, Step: 2274/2949, Loss: 0.7791\n",
      "Epoch: 4, Step: 2275/2949, Loss: 0.7958\n",
      "Epoch: 4, Step: 2276/2949, Loss: 0.7869\n",
      "Epoch: 4, Step: 2277/2949, Loss: 0.7900\n",
      "Epoch: 4, Step: 2278/2949, Loss: 0.7086\n",
      "Epoch: 4, Step: 2279/2949, Loss: 0.7835\n",
      "Epoch: 4, Step: 2280/2949, Loss: 0.7766\n",
      "Epoch: 4, Step: 2281/2949, Loss: 0.7261\n",
      "Epoch: 4, Step: 2282/2949, Loss: 0.7595\n",
      "Epoch: 4, Step: 2283/2949, Loss: 0.7051\n",
      "Epoch: 4, Step: 2284/2949, Loss: 0.7266\n",
      "Epoch: 4, Step: 2285/2949, Loss: 0.7882\n",
      "Epoch: 4, Step: 2286/2949, Loss: 0.7524\n",
      "Epoch: 4, Step: 2287/2949, Loss: 0.6959\n",
      "Epoch: 4, Step: 2288/2949, Loss: 0.7273\n",
      "Epoch: 4, Step: 2289/2949, Loss: 0.7346\n",
      "Epoch: 4, Step: 2290/2949, Loss: 0.7301\n",
      "Epoch: 4, Step: 2291/2949, Loss: 0.7288\n",
      "Epoch: 4, Step: 2292/2949, Loss: 0.7230\n",
      "Epoch: 4, Step: 2293/2949, Loss: 0.7140\n",
      "Epoch: 4, Step: 2294/2949, Loss: 0.7607\n",
      "Epoch: 4, Step: 2295/2949, Loss: 0.7352\n",
      "Epoch: 4, Step: 2296/2949, Loss: 0.7474\n",
      "Epoch: 4, Step: 2297/2949, Loss: 0.7485\n",
      "Epoch: 4, Step: 2298/2949, Loss: 0.7925\n",
      "Epoch: 4, Step: 2299/2949, Loss: 0.7221\n",
      "Epoch: 4, Step: 2300/2949, Loss: 0.8026\n",
      "Epoch: 4, Step: 2301/2949, Loss: 0.7627\n",
      "Epoch: 4, Step: 2302/2949, Loss: 0.6954\n",
      "Epoch: 4, Step: 2303/2949, Loss: 0.7408\n",
      "Epoch: 4, Step: 2304/2949, Loss: 0.8146\n",
      "Epoch: 4, Step: 2305/2949, Loss: 0.7161\n",
      "Epoch: 4, Step: 2306/2949, Loss: 0.7988\n",
      "Epoch: 4, Step: 2307/2949, Loss: 0.7302\n",
      "Epoch: 4, Step: 2308/2949, Loss: 0.7513\n",
      "Epoch: 4, Step: 2309/2949, Loss: 0.7553\n",
      "Epoch: 4, Step: 2310/2949, Loss: 0.7731\n",
      "Epoch: 4, Step: 2311/2949, Loss: 0.7933\n",
      "Epoch: 4, Step: 2312/2949, Loss: 0.7493\n",
      "Epoch: 4, Step: 2313/2949, Loss: 0.7854\n",
      "Epoch: 4, Step: 2314/2949, Loss: 0.7274\n",
      "Epoch: 4, Step: 2315/2949, Loss: 0.7300\n",
      "Epoch: 4, Step: 2316/2949, Loss: 0.7393\n",
      "Epoch: 4, Step: 2317/2949, Loss: 0.7761\n",
      "Epoch: 4, Step: 2318/2949, Loss: 0.8193\n",
      "Epoch: 4, Step: 2319/2949, Loss: 0.7554\n",
      "Epoch: 4, Step: 2320/2949, Loss: 0.7417\n",
      "Epoch: 4, Step: 2321/2949, Loss: 0.6937\n",
      "Epoch: 4, Step: 2322/2949, Loss: 0.7562\n",
      "Epoch: 4, Step: 2323/2949, Loss: 0.7217\n",
      "Epoch: 4, Step: 2324/2949, Loss: 0.7877\n",
      "Epoch: 4, Step: 2325/2949, Loss: 0.8162\n",
      "Epoch: 4, Step: 2326/2949, Loss: 0.7412\n",
      "Epoch: 4, Step: 2327/2949, Loss: 0.7691\n",
      "Epoch: 4, Step: 2328/2949, Loss: 0.7199\n",
      "Epoch: 4, Step: 2329/2949, Loss: 0.7514\n",
      "Epoch: 4, Step: 2330/2949, Loss: 0.6828\n",
      "Epoch: 4, Step: 2331/2949, Loss: 0.7306\n",
      "Epoch: 4, Step: 2332/2949, Loss: 0.7676\n",
      "Epoch: 4, Step: 2333/2949, Loss: 0.7317\n",
      "Epoch: 4, Step: 2334/2949, Loss: 0.7811\n",
      "Epoch: 4, Step: 2335/2949, Loss: 0.7583\n",
      "Epoch: 4, Step: 2336/2949, Loss: 0.7315\n",
      "Epoch: 4, Step: 2337/2949, Loss: 0.7494\n",
      "Epoch: 4, Step: 2338/2949, Loss: 0.7279\n",
      "Epoch: 4, Step: 2339/2949, Loss: 0.7734\n",
      "Epoch: 4, Step: 2340/2949, Loss: 0.8264\n",
      "Epoch: 4, Step: 2341/2949, Loss: 0.7841\n",
      "Epoch: 4, Step: 2342/2949, Loss: 0.7278\n",
      "Epoch: 4, Step: 2343/2949, Loss: 0.7446\n",
      "Epoch: 4, Step: 2344/2949, Loss: 0.6923\n",
      "Epoch: 4, Step: 2345/2949, Loss: 0.7592\n",
      "Epoch: 4, Step: 2346/2949, Loss: 0.7625\n",
      "Epoch: 4, Step: 2347/2949, Loss: 0.7401\n",
      "Epoch: 4, Step: 2348/2949, Loss: 0.7675\n",
      "Epoch: 4, Step: 2349/2949, Loss: 0.7327\n",
      "Epoch: 4, Step: 2350/2949, Loss: 0.6943\n",
      "Epoch: 4, Step: 2351/2949, Loss: 0.8091\n",
      "Epoch: 4, Step: 2352/2949, Loss: 0.8197\n",
      "Epoch: 4, Step: 2353/2949, Loss: 0.7294\n",
      "Epoch: 4, Step: 2354/2949, Loss: 0.7094\n",
      "Epoch: 4, Step: 2355/2949, Loss: 0.7089\n",
      "Epoch: 4, Step: 2356/2949, Loss: 0.7469\n",
      "Epoch: 4, Step: 2357/2949, Loss: 0.7225\n",
      "Epoch: 4, Step: 2358/2949, Loss: 0.7641\n",
      "Epoch: 4, Step: 2359/2949, Loss: 0.7989\n",
      "Epoch: 4, Step: 2360/2949, Loss: 0.7069\n",
      "Epoch: 4, Step: 2361/2949, Loss: 0.7178\n",
      "Epoch: 4, Step: 2362/2949, Loss: 0.7595\n",
      "Epoch: 4, Step: 2363/2949, Loss: 0.7597\n",
      "Epoch: 4, Step: 2364/2949, Loss: 0.6969\n",
      "Epoch: 4, Step: 2365/2949, Loss: 0.7810\n",
      "Epoch: 4, Step: 2366/2949, Loss: 0.7534\n",
      "Epoch: 4, Step: 2367/2949, Loss: 0.7178\n",
      "Epoch: 4, Step: 2368/2949, Loss: 0.7800\n",
      "Epoch: 4, Step: 2369/2949, Loss: 0.7892\n",
      "Epoch: 4, Step: 2370/2949, Loss: 0.7639\n",
      "Epoch: 4, Step: 2371/2949, Loss: 0.7312\n",
      "Epoch: 4, Step: 2372/2949, Loss: 0.7675\n",
      "Epoch: 4, Step: 2373/2949, Loss: 0.7783\n",
      "Epoch: 4, Step: 2374/2949, Loss: 0.7452\n",
      "Epoch: 4, Step: 2375/2949, Loss: 0.7353\n",
      "Epoch: 4, Step: 2376/2949, Loss: 0.7783\n",
      "Epoch: 4, Step: 2377/2949, Loss: 0.7348\n",
      "Epoch: 4, Step: 2378/2949, Loss: 0.7637\n",
      "Epoch: 4, Step: 2379/2949, Loss: 0.7151\n",
      "Epoch: 4, Step: 2380/2949, Loss: 0.7088\n",
      "Epoch: 4, Step: 2381/2949, Loss: 0.7237\n",
      "Epoch: 4, Step: 2382/2949, Loss: 0.7294\n",
      "Epoch: 4, Step: 2383/2949, Loss: 0.7542\n",
      "Epoch: 4, Step: 2384/2949, Loss: 0.7723\n",
      "Epoch: 4, Step: 2385/2949, Loss: 0.7719\n",
      "Epoch: 4, Step: 2386/2949, Loss: 0.7357\n",
      "Epoch: 4, Step: 2387/2949, Loss: 0.7873\n",
      "Epoch: 4, Step: 2388/2949, Loss: 0.7140\n",
      "Epoch: 4, Step: 2389/2949, Loss: 0.7761\n",
      "Epoch: 4, Step: 2390/2949, Loss: 0.7424\n",
      "Epoch: 4, Step: 2391/2949, Loss: 0.7969\n",
      "Epoch: 4, Step: 2392/2949, Loss: 0.7606\n",
      "Epoch: 4, Step: 2393/2949, Loss: 0.7474\n",
      "Epoch: 4, Step: 2394/2949, Loss: 0.7071\n",
      "Epoch: 4, Step: 2395/2949, Loss: 0.7482\n",
      "Epoch: 4, Step: 2396/2949, Loss: 0.7419\n",
      "Epoch: 4, Step: 2397/2949, Loss: 0.7232\n",
      "Epoch: 4, Step: 2398/2949, Loss: 0.8151\n",
      "Epoch: 4, Step: 2399/2949, Loss: 0.7458\n",
      "Epoch: 4, Step: 2400/2949, Loss: 0.7786\n",
      "Epoch: 4, Step: 2401/2949, Loss: 0.7592\n",
      "Epoch: 4, Step: 2402/2949, Loss: 0.7719\n",
      "Epoch: 4, Step: 2403/2949, Loss: 0.7248\n",
      "Epoch: 4, Step: 2404/2949, Loss: 0.7239\n",
      "Epoch: 4, Step: 2405/2949, Loss: 0.7026\n",
      "Epoch: 4, Step: 2406/2949, Loss: 0.7183\n",
      "Epoch: 4, Step: 2407/2949, Loss: 0.7562\n",
      "Epoch: 4, Step: 2408/2949, Loss: 0.7440\n",
      "Epoch: 4, Step: 2409/2949, Loss: 0.7516\n",
      "Epoch: 4, Step: 2410/2949, Loss: 0.7660\n",
      "Epoch: 4, Step: 2411/2949, Loss: 0.7615\n",
      "Epoch: 4, Step: 2412/2949, Loss: 0.7321\n",
      "Epoch: 4, Step: 2413/2949, Loss: 0.7116\n",
      "Epoch: 4, Step: 2414/2949, Loss: 0.7547\n",
      "Epoch: 4, Step: 2415/2949, Loss: 0.7336\n",
      "Epoch: 4, Step: 2416/2949, Loss: 0.8204\n",
      "Epoch: 4, Step: 2417/2949, Loss: 0.7637\n",
      "Epoch: 4, Step: 2418/2949, Loss: 0.7988\n",
      "Epoch: 4, Step: 2419/2949, Loss: 0.6642\n",
      "Epoch: 4, Step: 2420/2949, Loss: 0.7511\n",
      "Epoch: 4, Step: 2421/2949, Loss: 0.7338\n",
      "Epoch: 4, Step: 2422/2949, Loss: 0.7582\n",
      "Epoch: 4, Step: 2423/2949, Loss: 0.7221\n",
      "Epoch: 4, Step: 2424/2949, Loss: 0.6817\n",
      "Epoch: 4, Step: 2425/2949, Loss: 0.7577\n",
      "Epoch: 4, Step: 2426/2949, Loss: 0.7874\n",
      "Epoch: 4, Step: 2427/2949, Loss: 0.8044\n",
      "Epoch: 4, Step: 2428/2949, Loss: 0.7786\n",
      "Epoch: 4, Step: 2429/2949, Loss: 0.7351\n",
      "Epoch: 4, Step: 2430/2949, Loss: 0.7598\n",
      "Epoch: 4, Step: 2431/2949, Loss: 0.7667\n",
      "Epoch: 4, Step: 2432/2949, Loss: 0.7549\n",
      "Epoch: 4, Step: 2433/2949, Loss: 0.7516\n",
      "Epoch: 4, Step: 2434/2949, Loss: 0.7097\n",
      "Epoch: 4, Step: 2435/2949, Loss: 0.7482\n",
      "Epoch: 4, Step: 2436/2949, Loss: 0.7747\n",
      "Epoch: 4, Step: 2437/2949, Loss: 0.6866\n",
      "Epoch: 4, Step: 2438/2949, Loss: 0.7609\n",
      "Epoch: 4, Step: 2439/2949, Loss: 0.7640\n",
      "Epoch: 4, Step: 2440/2949, Loss: 0.6981\n",
      "Epoch: 4, Step: 2441/2949, Loss: 0.6891\n",
      "Epoch: 4, Step: 2442/2949, Loss: 0.7225\n",
      "Epoch: 4, Step: 2443/2949, Loss: 0.7647\n",
      "Epoch: 4, Step: 2444/2949, Loss: 0.7319\n",
      "Epoch: 4, Step: 2445/2949, Loss: 0.7312\n",
      "Epoch: 4, Step: 2446/2949, Loss: 0.7306\n",
      "Epoch: 4, Step: 2447/2949, Loss: 0.7750\n",
      "Epoch: 4, Step: 2448/2949, Loss: 0.7423\n",
      "Epoch: 4, Step: 2449/2949, Loss: 0.7534\n",
      "Epoch: 4, Step: 2450/2949, Loss: 0.7276\n",
      "Epoch: 4, Step: 2451/2949, Loss: 0.7702\n",
      "Epoch: 4, Step: 2452/2949, Loss: 0.7181\n",
      "Epoch: 4, Step: 2453/2949, Loss: 0.7442\n",
      "Epoch: 4, Step: 2454/2949, Loss: 0.7078\n",
      "Epoch: 4, Step: 2455/2949, Loss: 0.7829\n",
      "Epoch: 4, Step: 2456/2949, Loss: 0.6979\n",
      "Epoch: 4, Step: 2457/2949, Loss: 0.7470\n",
      "Epoch: 4, Step: 2458/2949, Loss: 0.7470\n",
      "Epoch: 4, Step: 2459/2949, Loss: 0.7498\n",
      "Epoch: 4, Step: 2460/2949, Loss: 0.7257\n",
      "Epoch: 4, Step: 2461/2949, Loss: 0.7521\n",
      "Epoch: 4, Step: 2462/2949, Loss: 0.7266\n",
      "Epoch: 4, Step: 2463/2949, Loss: 0.8125\n",
      "Epoch: 4, Step: 2464/2949, Loss: 0.7086\n",
      "Epoch: 4, Step: 2465/2949, Loss: 0.7374\n",
      "Epoch: 4, Step: 2466/2949, Loss: 0.7701\n",
      "Epoch: 4, Step: 2467/2949, Loss: 0.8298\n",
      "Epoch: 4, Step: 2468/2949, Loss: 0.7543\n",
      "Epoch: 4, Step: 2469/2949, Loss: 0.7643\n",
      "Epoch: 4, Step: 2470/2949, Loss: 0.7397\n",
      "Epoch: 4, Step: 2471/2949, Loss: 0.7204\n",
      "Epoch: 4, Step: 2472/2949, Loss: 0.7434\n",
      "Epoch: 4, Step: 2473/2949, Loss: 0.7710\n",
      "Epoch: 4, Step: 2474/2949, Loss: 0.6676\n",
      "Epoch: 4, Step: 2475/2949, Loss: 0.7364\n",
      "Epoch: 4, Step: 2476/2949, Loss: 0.7219\n",
      "Epoch: 4, Step: 2477/2949, Loss: 0.7479\n",
      "Epoch: 4, Step: 2478/2949, Loss: 0.6990\n",
      "Epoch: 4, Step: 2479/2949, Loss: 0.7321\n",
      "Epoch: 4, Step: 2480/2949, Loss: 0.7816\n",
      "Epoch: 4, Step: 2481/2949, Loss: 0.7142\n",
      "Epoch: 4, Step: 2482/2949, Loss: 0.7329\n",
      "Epoch: 4, Step: 2483/2949, Loss: 0.7672\n",
      "Epoch: 4, Step: 2484/2949, Loss: 0.7793\n",
      "Epoch: 4, Step: 2485/2949, Loss: 0.7437\n",
      "Epoch: 4, Step: 2486/2949, Loss: 0.7745\n",
      "Epoch: 4, Step: 2487/2949, Loss: 0.7577\n",
      "Epoch: 4, Step: 2488/2949, Loss: 0.7996\n",
      "Epoch: 4, Step: 2489/2949, Loss: 0.7595\n",
      "Epoch: 4, Step: 2490/2949, Loss: 0.7519\n",
      "Epoch: 4, Step: 2491/2949, Loss: 0.7741\n",
      "Epoch: 4, Step: 2492/2949, Loss: 0.7250\n",
      "Epoch: 4, Step: 2493/2949, Loss: 0.7108\n",
      "Epoch: 4, Step: 2494/2949, Loss: 0.7803\n",
      "Epoch: 4, Step: 2495/2949, Loss: 0.6836\n",
      "Epoch: 4, Step: 2496/2949, Loss: 0.8433\n",
      "Epoch: 4, Step: 2497/2949, Loss: 0.7495\n",
      "Epoch: 4, Step: 2498/2949, Loss: 0.7754\n",
      "Epoch: 4, Step: 2499/2949, Loss: 0.7219\n",
      "Epoch: 4, Step: 2500/2949, Loss: 0.7405\n",
      "Epoch: 4, Step: 2501/2949, Loss: 0.7526\n",
      "Epoch: 4, Step: 2502/2949, Loss: 0.7253\n",
      "Epoch: 4, Step: 2503/2949, Loss: 0.7263\n",
      "Epoch: 4, Step: 2504/2949, Loss: 0.7451\n",
      "Epoch: 4, Step: 2505/2949, Loss: 0.7203\n",
      "Epoch: 4, Step: 2506/2949, Loss: 0.7440\n",
      "Epoch: 4, Step: 2507/2949, Loss: 0.7534\n",
      "Epoch: 4, Step: 2508/2949, Loss: 0.7937\n",
      "Epoch: 4, Step: 2509/2949, Loss: 0.7486\n",
      "Epoch: 4, Step: 2510/2949, Loss: 0.7121\n",
      "Epoch: 4, Step: 2511/2949, Loss: 0.7412\n",
      "Epoch: 4, Step: 2512/2949, Loss: 0.7051\n",
      "Epoch: 4, Step: 2513/2949, Loss: 0.7039\n",
      "Epoch: 4, Step: 2514/2949, Loss: 0.7418\n",
      "Epoch: 4, Step: 2515/2949, Loss: 0.7329\n",
      "Epoch: 4, Step: 2516/2949, Loss: 0.7615\n",
      "Epoch: 4, Step: 2517/2949, Loss: 0.7309\n",
      "Epoch: 4, Step: 2518/2949, Loss: 0.8166\n",
      "Epoch: 4, Step: 2519/2949, Loss: 0.7441\n",
      "Epoch: 4, Step: 2520/2949, Loss: 0.7379\n",
      "Epoch: 4, Step: 2521/2949, Loss: 0.7309\n",
      "Epoch: 4, Step: 2522/2949, Loss: 0.7385\n",
      "Epoch: 4, Step: 2523/2949, Loss: 0.7360\n",
      "Epoch: 4, Step: 2524/2949, Loss: 0.7769\n",
      "Epoch: 4, Step: 2525/2949, Loss: 0.7826\n",
      "Epoch: 4, Step: 2526/2949, Loss: 0.7361\n",
      "Epoch: 4, Step: 2527/2949, Loss: 0.8241\n",
      "Epoch: 4, Step: 2528/2949, Loss: 0.7795\n",
      "Epoch: 4, Step: 2529/2949, Loss: 0.7359\n",
      "Epoch: 4, Step: 2530/2949, Loss: 0.7350\n",
      "Epoch: 4, Step: 2531/2949, Loss: 0.7981\n",
      "Epoch: 4, Step: 2532/2949, Loss: 0.7314\n",
      "Epoch: 4, Step: 2533/2949, Loss: 0.7587\n",
      "Epoch: 4, Step: 2534/2949, Loss: 0.6967\n",
      "Epoch: 4, Step: 2535/2949, Loss: 0.7890\n",
      "Epoch: 4, Step: 2536/2949, Loss: 0.6753\n",
      "Epoch: 4, Step: 2537/2949, Loss: 0.7406\n",
      "Epoch: 4, Step: 2538/2949, Loss: 0.7359\n",
      "Epoch: 4, Step: 2539/2949, Loss: 0.7270\n",
      "Epoch: 4, Step: 2540/2949, Loss: 0.7462\n",
      "Epoch: 4, Step: 2541/2949, Loss: 0.7042\n",
      "Epoch: 4, Step: 2542/2949, Loss: 0.7547\n",
      "Epoch: 4, Step: 2543/2949, Loss: 0.8020\n",
      "Epoch: 4, Step: 2544/2949, Loss: 0.7690\n",
      "Epoch: 4, Step: 2545/2949, Loss: 0.7372\n",
      "Epoch: 4, Step: 2546/2949, Loss: 0.7804\n",
      "Epoch: 4, Step: 2547/2949, Loss: 0.7927\n",
      "Epoch: 4, Step: 2548/2949, Loss: 0.8085\n",
      "Epoch: 4, Step: 2549/2949, Loss: 0.7288\n",
      "Epoch: 4, Step: 2550/2949, Loss: 0.7412\n",
      "Epoch: 4, Step: 2551/2949, Loss: 0.7814\n",
      "Epoch: 4, Step: 2552/2949, Loss: 0.7332\n",
      "Epoch: 4, Step: 2553/2949, Loss: 0.7352\n",
      "Epoch: 4, Step: 2554/2949, Loss: 0.7017\n",
      "Epoch: 4, Step: 2555/2949, Loss: 0.7562\n",
      "Epoch: 4, Step: 2556/2949, Loss: 0.7835\n",
      "Epoch: 4, Step: 2557/2949, Loss: 0.7450\n",
      "Epoch: 4, Step: 2558/2949, Loss: 0.6867\n",
      "Epoch: 4, Step: 2559/2949, Loss: 0.7187\n",
      "Epoch: 4, Step: 2560/2949, Loss: 0.7399\n",
      "Epoch: 4, Step: 2561/2949, Loss: 0.7255\n",
      "Epoch: 4, Step: 2562/2949, Loss: 0.7599\n",
      "Epoch: 4, Step: 2563/2949, Loss: 0.6788\n",
      "Epoch: 4, Step: 2564/2949, Loss: 0.7638\n",
      "Epoch: 4, Step: 2565/2949, Loss: 0.7880\n",
      "Epoch: 4, Step: 2566/2949, Loss: 0.7120\n",
      "Epoch: 4, Step: 2567/2949, Loss: 0.7402\n",
      "Epoch: 4, Step: 2568/2949, Loss: 0.7225\n",
      "Epoch: 4, Step: 2569/2949, Loss: 0.7301\n",
      "Epoch: 4, Step: 2570/2949, Loss: 0.7653\n",
      "Epoch: 4, Step: 2571/2949, Loss: 0.7447\n",
      "Epoch: 4, Step: 2572/2949, Loss: 0.7062\n",
      "Epoch: 4, Step: 2573/2949, Loss: 0.7276\n",
      "Epoch: 4, Step: 2574/2949, Loss: 0.7134\n",
      "Epoch: 4, Step: 2575/2949, Loss: 0.7638\n",
      "Epoch: 4, Step: 2576/2949, Loss: 0.7554\n",
      "Epoch: 4, Step: 2577/2949, Loss: 0.6888\n",
      "Epoch: 4, Step: 2578/2949, Loss: 0.7699\n",
      "Epoch: 4, Step: 2579/2949, Loss: 0.7630\n",
      "Epoch: 4, Step: 2580/2949, Loss: 0.6854\n",
      "Epoch: 4, Step: 2581/2949, Loss: 0.7658\n",
      "Epoch: 4, Step: 2582/2949, Loss: 0.7700\n",
      "Epoch: 4, Step: 2583/2949, Loss: 0.7490\n",
      "Epoch: 4, Step: 2584/2949, Loss: 0.7357\n",
      "Epoch: 4, Step: 2585/2949, Loss: 0.7203\n",
      "Epoch: 4, Step: 2586/2949, Loss: 0.7754\n",
      "Epoch: 4, Step: 2587/2949, Loss: 0.7648\n",
      "Epoch: 4, Step: 2588/2949, Loss: 0.7235\n",
      "Epoch: 4, Step: 2589/2949, Loss: 0.7321\n",
      "Epoch: 4, Step: 2590/2949, Loss: 0.7652\n",
      "Epoch: 4, Step: 2591/2949, Loss: 0.7743\n",
      "Epoch: 4, Step: 2592/2949, Loss: 0.7817\n",
      "Epoch: 4, Step: 2593/2949, Loss: 0.7406\n",
      "Epoch: 4, Step: 2594/2949, Loss: 0.7446\n",
      "Epoch: 4, Step: 2595/2949, Loss: 0.7180\n",
      "Epoch: 4, Step: 2596/2949, Loss: 0.7344\n",
      "Epoch: 4, Step: 2597/2949, Loss: 0.6929\n",
      "Epoch: 4, Step: 2598/2949, Loss: 0.8033\n",
      "Epoch: 4, Step: 2599/2949, Loss: 0.7095\n",
      "Epoch: 4, Step: 2600/2949, Loss: 0.7688\n",
      "Epoch: 4, Step: 2601/2949, Loss: 0.7900\n",
      "Epoch: 4, Step: 2602/2949, Loss: 0.7939\n",
      "Epoch: 4, Step: 2603/2949, Loss: 0.7624\n",
      "Epoch: 4, Step: 2604/2949, Loss: 0.7083\n",
      "Epoch: 4, Step: 2605/2949, Loss: 0.7316\n",
      "Epoch: 4, Step: 2606/2949, Loss: 0.7359\n",
      "Epoch: 4, Step: 2607/2949, Loss: 0.7937\n",
      "Epoch: 4, Step: 2608/2949, Loss: 0.7815\n",
      "Epoch: 4, Step: 2609/2949, Loss: 0.7203\n",
      "Epoch: 4, Step: 2610/2949, Loss: 0.7372\n",
      "Epoch: 4, Step: 2611/2949, Loss: 0.7627\n",
      "Epoch: 4, Step: 2612/2949, Loss: 0.7805\n",
      "Epoch: 4, Step: 2613/2949, Loss: 0.7994\n",
      "Epoch: 4, Step: 2614/2949, Loss: 0.7188\n",
      "Epoch: 4, Step: 2615/2949, Loss: 0.7983\n",
      "Epoch: 4, Step: 2616/2949, Loss: 0.6924\n",
      "Epoch: 4, Step: 2617/2949, Loss: 0.7034\n",
      "Epoch: 4, Step: 2618/2949, Loss: 0.7484\n",
      "Epoch: 4, Step: 2619/2949, Loss: 0.6973\n",
      "Epoch: 4, Step: 2620/2949, Loss: 0.7749\n",
      "Epoch: 4, Step: 2621/2949, Loss: 0.7609\n",
      "Epoch: 4, Step: 2622/2949, Loss: 0.7419\n",
      "Epoch: 4, Step: 2623/2949, Loss: 0.7651\n",
      "Epoch: 4, Step: 2624/2949, Loss: 0.7763\n",
      "Epoch: 4, Step: 2625/2949, Loss: 0.7653\n",
      "Epoch: 4, Step: 2626/2949, Loss: 0.7775\n",
      "Epoch: 4, Step: 2627/2949, Loss: 0.7395\n",
      "Epoch: 4, Step: 2628/2949, Loss: 0.7687\n",
      "Epoch: 4, Step: 2629/2949, Loss: 0.7453\n",
      "Epoch: 4, Step: 2630/2949, Loss: 0.7876\n",
      "Epoch: 4, Step: 2631/2949, Loss: 0.7092\n",
      "Epoch: 4, Step: 2632/2949, Loss: 0.7510\n",
      "Epoch: 4, Step: 2633/2949, Loss: 0.7682\n",
      "Epoch: 4, Step: 2634/2949, Loss: 0.7594\n",
      "Epoch: 4, Step: 2635/2949, Loss: 0.7321\n",
      "Epoch: 4, Step: 2636/2949, Loss: 0.6990\n",
      "Epoch: 4, Step: 2637/2949, Loss: 0.7996\n",
      "Epoch: 4, Step: 2638/2949, Loss: 0.7476\n",
      "Epoch: 4, Step: 2639/2949, Loss: 0.7639\n",
      "Epoch: 4, Step: 2640/2949, Loss: 0.7151\n",
      "Epoch: 4, Step: 2641/2949, Loss: 0.7405\n",
      "Epoch: 4, Step: 2642/2949, Loss: 0.7169\n",
      "Epoch: 4, Step: 2643/2949, Loss: 0.7270\n",
      "Epoch: 4, Step: 2644/2949, Loss: 0.7769\n",
      "Epoch: 4, Step: 2645/2949, Loss: 0.7644\n",
      "Epoch: 4, Step: 2646/2949, Loss: 0.7467\n",
      "Epoch: 4, Step: 2647/2949, Loss: 0.8134\n",
      "Epoch: 4, Step: 2648/2949, Loss: 0.7568\n",
      "Epoch: 4, Step: 2649/2949, Loss: 0.7755\n",
      "Epoch: 4, Step: 2650/2949, Loss: 0.7627\n",
      "Epoch: 4, Step: 2651/2949, Loss: 0.8090\n",
      "Epoch: 4, Step: 2652/2949, Loss: 0.8085\n",
      "Epoch: 4, Step: 2653/2949, Loss: 0.7779\n",
      "Epoch: 4, Step: 2654/2949, Loss: 0.7254\n",
      "Epoch: 4, Step: 2655/2949, Loss: 0.7135\n",
      "Epoch: 4, Step: 2656/2949, Loss: 0.7572\n",
      "Epoch: 4, Step: 2657/2949, Loss: 0.7380\n",
      "Epoch: 4, Step: 2658/2949, Loss: 0.7769\n",
      "Epoch: 4, Step: 2659/2949, Loss: 0.7627\n",
      "Epoch: 4, Step: 2660/2949, Loss: 0.7284\n",
      "Epoch: 4, Step: 2661/2949, Loss: 0.7744\n",
      "Epoch: 4, Step: 2662/2949, Loss: 0.7518\n",
      "Epoch: 4, Step: 2663/2949, Loss: 0.6844\n",
      "Epoch: 4, Step: 2664/2949, Loss: 0.7426\n",
      "Epoch: 4, Step: 2665/2949, Loss: 0.6761\n",
      "Epoch: 4, Step: 2666/2949, Loss: 0.7449\n",
      "Epoch: 4, Step: 2667/2949, Loss: 0.7779\n",
      "Epoch: 4, Step: 2668/2949, Loss: 0.7306\n",
      "Epoch: 4, Step: 2669/2949, Loss: 0.7525\n",
      "Epoch: 4, Step: 2670/2949, Loss: 0.7136\n",
      "Epoch: 4, Step: 2671/2949, Loss: 0.7280\n",
      "Epoch: 4, Step: 2672/2949, Loss: 0.7746\n",
      "Epoch: 4, Step: 2673/2949, Loss: 0.7759\n",
      "Epoch: 4, Step: 2674/2949, Loss: 0.7400\n",
      "Epoch: 4, Step: 2675/2949, Loss: 0.7211\n",
      "Epoch: 4, Step: 2676/2949, Loss: 0.7129\n",
      "Epoch: 4, Step: 2677/2949, Loss: 0.7642\n",
      "Epoch: 4, Step: 2678/2949, Loss: 0.7388\n",
      "Epoch: 4, Step: 2679/2949, Loss: 0.7740\n",
      "Epoch: 4, Step: 2680/2949, Loss: 0.7646\n",
      "Epoch: 4, Step: 2681/2949, Loss: 0.7477\n",
      "Epoch: 4, Step: 2682/2949, Loss: 0.7680\n",
      "Epoch: 4, Step: 2683/2949, Loss: 0.7257\n",
      "Epoch: 4, Step: 2684/2949, Loss: 0.7461\n",
      "Epoch: 4, Step: 2685/2949, Loss: 0.7538\n",
      "Epoch: 4, Step: 2686/2949, Loss: 0.7974\n",
      "Epoch: 4, Step: 2687/2949, Loss: 0.7368\n",
      "Epoch: 4, Step: 2688/2949, Loss: 0.7304\n",
      "Epoch: 4, Step: 2689/2949, Loss: 0.6876\n",
      "Epoch: 4, Step: 2690/2949, Loss: 0.7260\n",
      "Epoch: 4, Step: 2691/2949, Loss: 0.7810\n",
      "Epoch: 4, Step: 2692/2949, Loss: 0.7001\n",
      "Epoch: 4, Step: 2693/2949, Loss: 0.7378\n",
      "Epoch: 4, Step: 2694/2949, Loss: 0.7746\n",
      "Epoch: 4, Step: 2695/2949, Loss: 0.7134\n",
      "Epoch: 4, Step: 2696/2949, Loss: 0.7632\n",
      "Epoch: 4, Step: 2697/2949, Loss: 0.7036\n",
      "Epoch: 4, Step: 2698/2949, Loss: 0.7833\n",
      "Epoch: 4, Step: 2699/2949, Loss: 0.7546\n",
      "Epoch: 4, Step: 2700/2949, Loss: 0.7252\n",
      "Epoch: 4, Step: 2701/2949, Loss: 0.7409\n",
      "Epoch: 4, Step: 2702/2949, Loss: 0.7437\n",
      "Epoch: 4, Step: 2703/2949, Loss: 0.7939\n",
      "Epoch: 4, Step: 2704/2949, Loss: 0.8113\n",
      "Epoch: 4, Step: 2705/2949, Loss: 0.7750\n",
      "Epoch: 4, Step: 2706/2949, Loss: 0.6951\n",
      "Epoch: 4, Step: 2707/2949, Loss: 0.7238\n",
      "Epoch: 4, Step: 2708/2949, Loss: 0.7642\n",
      "Epoch: 4, Step: 2709/2949, Loss: 0.7497\n",
      "Epoch: 4, Step: 2710/2949, Loss: 0.7259\n",
      "Epoch: 4, Step: 2711/2949, Loss: 0.7381\n",
      "Epoch: 4, Step: 2712/2949, Loss: 0.7656\n",
      "Epoch: 4, Step: 2713/2949, Loss: 0.7182\n",
      "Epoch: 4, Step: 2714/2949, Loss: 0.7148\n",
      "Epoch: 4, Step: 2715/2949, Loss: 0.7449\n",
      "Epoch: 4, Step: 2716/2949, Loss: 0.7039\n",
      "Epoch: 4, Step: 2717/2949, Loss: 0.7540\n",
      "Epoch: 4, Step: 2718/2949, Loss: 0.7784\n",
      "Epoch: 4, Step: 2719/2949, Loss: 0.7667\n",
      "Epoch: 4, Step: 2720/2949, Loss: 0.7593\n",
      "Epoch: 4, Step: 2721/2949, Loss: 0.7525\n",
      "Epoch: 4, Step: 2722/2949, Loss: 0.7208\n",
      "Epoch: 4, Step: 2723/2949, Loss: 0.7213\n",
      "Epoch: 4, Step: 2724/2949, Loss: 0.7190\n",
      "Epoch: 4, Step: 2725/2949, Loss: 0.7131\n",
      "Epoch: 4, Step: 2726/2949, Loss: 0.7305\n",
      "Epoch: 4, Step: 2727/2949, Loss: 0.7623\n",
      "Epoch: 4, Step: 2728/2949, Loss: 0.7146\n",
      "Epoch: 4, Step: 2729/2949, Loss: 0.7606\n",
      "Epoch: 4, Step: 2730/2949, Loss: 0.7790\n",
      "Epoch: 4, Step: 2731/2949, Loss: 0.7472\n",
      "Epoch: 4, Step: 2732/2949, Loss: 0.7406\n",
      "Epoch: 4, Step: 2733/2949, Loss: 0.7677\n",
      "Epoch: 4, Step: 2734/2949, Loss: 0.8160\n",
      "Epoch: 4, Step: 2735/2949, Loss: 0.7307\n",
      "Epoch: 4, Step: 2736/2949, Loss: 0.7552\n",
      "Epoch: 4, Step: 2737/2949, Loss: 0.7769\n",
      "Epoch: 4, Step: 2738/2949, Loss: 0.7083\n",
      "Epoch: 4, Step: 2739/2949, Loss: 0.7417\n",
      "Epoch: 4, Step: 2740/2949, Loss: 0.7673\n",
      "Epoch: 4, Step: 2741/2949, Loss: 0.7290\n",
      "Epoch: 4, Step: 2742/2949, Loss: 0.7807\n",
      "Epoch: 4, Step: 2743/2949, Loss: 0.7605\n",
      "Epoch: 4, Step: 2744/2949, Loss: 0.7656\n",
      "Epoch: 4, Step: 2745/2949, Loss: 0.7040\n",
      "Epoch: 4, Step: 2746/2949, Loss: 0.7492\n",
      "Epoch: 4, Step: 2747/2949, Loss: 0.7664\n",
      "Epoch: 4, Step: 2748/2949, Loss: 0.7676\n",
      "Epoch: 4, Step: 2749/2949, Loss: 0.7730\n",
      "Epoch: 4, Step: 2750/2949, Loss: 0.7823\n",
      "Epoch: 4, Step: 2751/2949, Loss: 0.7463\n",
      "Epoch: 4, Step: 2752/2949, Loss: 0.7798\n",
      "Epoch: 4, Step: 2753/2949, Loss: 0.7643\n",
      "Epoch: 4, Step: 2754/2949, Loss: 0.7457\n",
      "Epoch: 4, Step: 2755/2949, Loss: 0.7872\n",
      "Epoch: 4, Step: 2756/2949, Loss: 0.7160\n",
      "Epoch: 4, Step: 2757/2949, Loss: 0.7262\n",
      "Epoch: 4, Step: 2758/2949, Loss: 0.7833\n",
      "Epoch: 4, Step: 2759/2949, Loss: 0.7729\n",
      "Epoch: 4, Step: 2760/2949, Loss: 0.7459\n",
      "Epoch: 4, Step: 2761/2949, Loss: 0.7597\n",
      "Epoch: 4, Step: 2762/2949, Loss: 0.6727\n",
      "Epoch: 4, Step: 2763/2949, Loss: 0.7672\n",
      "Epoch: 4, Step: 2764/2949, Loss: 0.7541\n",
      "Epoch: 4, Step: 2765/2949, Loss: 0.7425\n",
      "Epoch: 4, Step: 2766/2949, Loss: 0.6944\n",
      "Epoch: 4, Step: 2767/2949, Loss: 0.7590\n",
      "Epoch: 4, Step: 2768/2949, Loss: 0.7224\n",
      "Epoch: 4, Step: 2769/2949, Loss: 0.7375\n",
      "Epoch: 4, Step: 2770/2949, Loss: 0.7884\n",
      "Epoch: 4, Step: 2771/2949, Loss: 0.7537\n",
      "Epoch: 4, Step: 2772/2949, Loss: 0.7280\n",
      "Epoch: 4, Step: 2773/2949, Loss: 0.7612\n",
      "Epoch: 4, Step: 2774/2949, Loss: 0.7814\n",
      "Epoch: 4, Step: 2775/2949, Loss: 0.7399\n",
      "Epoch: 4, Step: 2776/2949, Loss: 0.7647\n",
      "Epoch: 4, Step: 2777/2949, Loss: 0.7800\n",
      "Epoch: 4, Step: 2778/2949, Loss: 0.7445\n",
      "Epoch: 4, Step: 2779/2949, Loss: 0.7241\n",
      "Epoch: 4, Step: 2780/2949, Loss: 0.7328\n",
      "Epoch: 4, Step: 2781/2949, Loss: 0.7285\n",
      "Epoch: 4, Step: 2782/2949, Loss: 0.7826\n",
      "Epoch: 4, Step: 2783/2949, Loss: 0.7587\n",
      "Epoch: 4, Step: 2784/2949, Loss: 0.7322\n",
      "Epoch: 4, Step: 2785/2949, Loss: 0.7128\n",
      "Epoch: 4, Step: 2786/2949, Loss: 0.7134\n",
      "Epoch: 4, Step: 2787/2949, Loss: 0.6939\n",
      "Epoch: 4, Step: 2788/2949, Loss: 0.7959\n",
      "Epoch: 4, Step: 2789/2949, Loss: 0.7456\n",
      "Epoch: 4, Step: 2790/2949, Loss: 0.7882\n",
      "Epoch: 4, Step: 2791/2949, Loss: 0.7120\n",
      "Epoch: 4, Step: 2792/2949, Loss: 0.7971\n",
      "Epoch: 4, Step: 2793/2949, Loss: 0.7750\n",
      "Epoch: 4, Step: 2794/2949, Loss: 0.7123\n",
      "Epoch: 4, Step: 2795/2949, Loss: 0.7541\n",
      "Epoch: 4, Step: 2796/2949, Loss: 0.7332\n",
      "Epoch: 4, Step: 2797/2949, Loss: 0.7152\n",
      "Epoch: 4, Step: 2798/2949, Loss: 0.7755\n",
      "Epoch: 4, Step: 2799/2949, Loss: 0.7292\n",
      "Epoch: 4, Step: 2800/2949, Loss: 0.7448\n",
      "Epoch: 4, Step: 2801/2949, Loss: 0.8067\n",
      "Epoch: 4, Step: 2802/2949, Loss: 0.7301\n",
      "Epoch: 4, Step: 2803/2949, Loss: 0.7375\n",
      "Epoch: 4, Step: 2804/2949, Loss: 0.7708\n",
      "Epoch: 4, Step: 2805/2949, Loss: 0.7678\n",
      "Epoch: 4, Step: 2806/2949, Loss: 0.7529\n",
      "Epoch: 4, Step: 2807/2949, Loss: 0.7727\n",
      "Epoch: 4, Step: 2808/2949, Loss: 0.7191\n",
      "Epoch: 4, Step: 2809/2949, Loss: 0.7300\n",
      "Epoch: 4, Step: 2810/2949, Loss: 0.7615\n",
      "Epoch: 4, Step: 2811/2949, Loss: 0.7540\n",
      "Epoch: 4, Step: 2812/2949, Loss: 0.6845\n",
      "Epoch: 4, Step: 2813/2949, Loss: 0.7286\n",
      "Epoch: 4, Step: 2814/2949, Loss: 0.7479\n",
      "Epoch: 4, Step: 2815/2949, Loss: 0.7652\n",
      "Epoch: 4, Step: 2816/2949, Loss: 0.6966\n",
      "Epoch: 4, Step: 2817/2949, Loss: 0.7552\n",
      "Epoch: 4, Step: 2818/2949, Loss: 0.7291\n",
      "Epoch: 4, Step: 2819/2949, Loss: 0.7221\n",
      "Epoch: 4, Step: 2820/2949, Loss: 0.7660\n",
      "Epoch: 4, Step: 2821/2949, Loss: 0.7618\n",
      "Epoch: 4, Step: 2822/2949, Loss: 0.8025\n",
      "Epoch: 4, Step: 2823/2949, Loss: 0.7389\n",
      "Epoch: 4, Step: 2824/2949, Loss: 0.7491\n",
      "Epoch: 4, Step: 2825/2949, Loss: 0.7311\n",
      "Epoch: 4, Step: 2826/2949, Loss: 0.7950\n",
      "Epoch: 4, Step: 2827/2949, Loss: 0.7157\n",
      "Epoch: 4, Step: 2828/2949, Loss: 0.7738\n",
      "Epoch: 4, Step: 2829/2949, Loss: 0.7899\n",
      "Epoch: 4, Step: 2830/2949, Loss: 0.7313\n",
      "Epoch: 4, Step: 2831/2949, Loss: 0.7771\n",
      "Epoch: 4, Step: 2832/2949, Loss: 0.7268\n",
      "Epoch: 4, Step: 2833/2949, Loss: 0.7355\n",
      "Epoch: 4, Step: 2834/2949, Loss: 0.7289\n",
      "Epoch: 4, Step: 2835/2949, Loss: 0.7436\n",
      "Epoch: 4, Step: 2836/2949, Loss: 0.7164\n",
      "Epoch: 4, Step: 2837/2949, Loss: 0.7870\n",
      "Epoch: 4, Step: 2838/2949, Loss: 0.7609\n",
      "Epoch: 4, Step: 2839/2949, Loss: 0.7349\n",
      "Epoch: 4, Step: 2840/2949, Loss: 0.7758\n",
      "Epoch: 4, Step: 2841/2949, Loss: 0.7288\n",
      "Epoch: 4, Step: 2842/2949, Loss: 0.7361\n",
      "Epoch: 4, Step: 2843/2949, Loss: 0.7497\n",
      "Epoch: 4, Step: 2844/2949, Loss: 0.7753\n",
      "Epoch: 4, Step: 2845/2949, Loss: 0.8112\n",
      "Epoch: 4, Step: 2846/2949, Loss: 0.7589\n",
      "Epoch: 4, Step: 2847/2949, Loss: 0.7148\n",
      "Epoch: 4, Step: 2848/2949, Loss: 0.7624\n",
      "Epoch: 4, Step: 2849/2949, Loss: 0.7432\n",
      "Epoch: 4, Step: 2850/2949, Loss: 0.7550\n",
      "Epoch: 4, Step: 2851/2949, Loss: 0.7739\n",
      "Epoch: 4, Step: 2852/2949, Loss: 0.7924\n",
      "Epoch: 4, Step: 2853/2949, Loss: 0.7641\n",
      "Epoch: 4, Step: 2854/2949, Loss: 0.7217\n",
      "Epoch: 4, Step: 2855/2949, Loss: 0.7537\n",
      "Epoch: 4, Step: 2856/2949, Loss: 0.7952\n",
      "Epoch: 4, Step: 2857/2949, Loss: 0.7122\n",
      "Epoch: 4, Step: 2858/2949, Loss: 0.7301\n",
      "Epoch: 4, Step: 2859/2949, Loss: 0.7536\n",
      "Epoch: 4, Step: 2860/2949, Loss: 0.8178\n",
      "Epoch: 4, Step: 2861/2949, Loss: 0.7995\n",
      "Epoch: 4, Step: 2862/2949, Loss: 0.7725\n",
      "Epoch: 4, Step: 2863/2949, Loss: 0.7636\n",
      "Epoch: 4, Step: 2864/2949, Loss: 0.7342\n",
      "Epoch: 4, Step: 2865/2949, Loss: 0.7581\n",
      "Epoch: 4, Step: 2866/2949, Loss: 0.7737\n",
      "Epoch: 4, Step: 2867/2949, Loss: 0.7478\n",
      "Epoch: 4, Step: 2868/2949, Loss: 0.7470\n",
      "Epoch: 4, Step: 2869/2949, Loss: 0.7445\n",
      "Epoch: 4, Step: 2870/2949, Loss: 0.7514\n",
      "Epoch: 4, Step: 2871/2949, Loss: 0.7448\n",
      "Epoch: 4, Step: 2872/2949, Loss: 0.7535\n",
      "Epoch: 4, Step: 2873/2949, Loss: 0.7623\n",
      "Epoch: 4, Step: 2874/2949, Loss: 0.7334\n",
      "Epoch: 4, Step: 2875/2949, Loss: 0.7412\n",
      "Epoch: 4, Step: 2876/2949, Loss: 0.7616\n",
      "Epoch: 4, Step: 2877/2949, Loss: 0.7323\n",
      "Epoch: 4, Step: 2878/2949, Loss: 0.7536\n",
      "Epoch: 4, Step: 2879/2949, Loss: 0.7335\n",
      "Epoch: 4, Step: 2880/2949, Loss: 0.7493\n",
      "Epoch: 4, Step: 2881/2949, Loss: 0.7381\n",
      "Epoch: 4, Step: 2882/2949, Loss: 0.7396\n",
      "Epoch: 4, Step: 2883/2949, Loss: 0.7054\n",
      "Epoch: 4, Step: 2884/2949, Loss: 0.7476\n",
      "Epoch: 4, Step: 2885/2949, Loss: 0.7434\n",
      "Epoch: 4, Step: 2886/2949, Loss: 0.7755\n",
      "Epoch: 4, Step: 2887/2949, Loss: 0.7447\n",
      "Epoch: 4, Step: 2888/2949, Loss: 0.7758\n",
      "Epoch: 4, Step: 2889/2949, Loss: 0.7235\n",
      "Epoch: 4, Step: 2890/2949, Loss: 0.7394\n",
      "Epoch: 4, Step: 2891/2949, Loss: 0.7113\n",
      "Epoch: 4, Step: 2892/2949, Loss: 0.7634\n",
      "Epoch: 4, Step: 2893/2949, Loss: 0.7732\n",
      "Epoch: 4, Step: 2894/2949, Loss: 0.7806\n",
      "Epoch: 4, Step: 2895/2949, Loss: 0.7522\n",
      "Epoch: 4, Step: 2896/2949, Loss: 0.7495\n",
      "Epoch: 4, Step: 2897/2949, Loss: 0.7440\n",
      "Epoch: 4, Step: 2898/2949, Loss: 0.7071\n",
      "Epoch: 4, Step: 2899/2949, Loss: 0.7251\n",
      "Epoch: 4, Step: 2900/2949, Loss: 0.7103\n",
      "Epoch: 4, Step: 2901/2949, Loss: 0.7400\n",
      "Epoch: 4, Step: 2902/2949, Loss: 0.7090\n",
      "Epoch: 4, Step: 2903/2949, Loss: 0.7421\n",
      "Epoch: 4, Step: 2904/2949, Loss: 0.7400\n",
      "Epoch: 4, Step: 2905/2949, Loss: 0.7405\n",
      "Epoch: 4, Step: 2906/2949, Loss: 0.7632\n",
      "Epoch: 4, Step: 2907/2949, Loss: 0.8211\n",
      "Epoch: 4, Step: 2908/2949, Loss: 0.7742\n",
      "Epoch: 4, Step: 2909/2949, Loss: 0.6702\n",
      "Epoch: 4, Step: 2910/2949, Loss: 0.7506\n",
      "Epoch: 4, Step: 2911/2949, Loss: 0.7853\n",
      "Epoch: 4, Step: 2912/2949, Loss: 0.8136\n",
      "Epoch: 4, Step: 2913/2949, Loss: 0.7318\n",
      "Epoch: 4, Step: 2914/2949, Loss: 0.7007\n",
      "Epoch: 4, Step: 2915/2949, Loss: 0.7333\n",
      "Epoch: 4, Step: 2916/2949, Loss: 0.7300\n",
      "Epoch: 4, Step: 2917/2949, Loss: 0.7886\n",
      "Epoch: 4, Step: 2918/2949, Loss: 0.7622\n",
      "Epoch: 4, Step: 2919/2949, Loss: 0.7847\n",
      "Epoch: 4, Step: 2920/2949, Loss: 0.7581\n",
      "Epoch: 4, Step: 2921/2949, Loss: 0.7138\n",
      "Epoch: 4, Step: 2922/2949, Loss: 0.7768\n",
      "Epoch: 4, Step: 2923/2949, Loss: 0.7976\n",
      "Epoch: 4, Step: 2924/2949, Loss: 0.7407\n",
      "Epoch: 4, Step: 2925/2949, Loss: 0.7617\n",
      "Epoch: 4, Step: 2926/2949, Loss: 0.7833\n",
      "Epoch: 4, Step: 2927/2949, Loss: 0.7738\n",
      "Epoch: 4, Step: 2928/2949, Loss: 0.7211\n",
      "Epoch: 4, Step: 2929/2949, Loss: 0.7663\n",
      "Epoch: 4, Step: 2930/2949, Loss: 0.7339\n",
      "Epoch: 4, Step: 2931/2949, Loss: 0.7196\n",
      "Epoch: 4, Step: 2932/2949, Loss: 0.7838\n",
      "Epoch: 4, Step: 2933/2949, Loss: 0.7496\n",
      "Epoch: 4, Step: 2934/2949, Loss: 0.7646\n",
      "Epoch: 4, Step: 2935/2949, Loss: 0.7339\n",
      "Epoch: 4, Step: 2936/2949, Loss: 0.7648\n",
      "Epoch: 4, Step: 2937/2949, Loss: 0.7277\n",
      "Epoch: 4, Step: 2938/2949, Loss: 0.7780\n",
      "Epoch: 4, Step: 2939/2949, Loss: 0.7631\n",
      "Epoch: 4, Step: 2940/2949, Loss: 0.7517\n",
      "Epoch: 4, Step: 2941/2949, Loss: 0.7047\n",
      "Epoch: 4, Step: 2942/2949, Loss: 0.7369\n",
      "Epoch: 4, Step: 2943/2949, Loss: 0.7870\n",
      "Epoch: 4, Step: 2944/2949, Loss: 0.7411\n",
      "Epoch: 4, Step: 2945/2949, Loss: 0.7069\n",
      "Epoch: 4, Step: 2946/2949, Loss: 0.7914\n",
      "Epoch: 4, Step: 2947/2949, Loss: 0.7341\n",
      "Epoch: 4, Step: 2948/2949, Loss: 0.7387\n",
      "Epoch: 4, Step: 2949/2949, Loss: 0.7581\n",
      "Test Accuracy (xgboost): 0.3700\n",
      "Epoch: 4, Accuracy: 0.3700\n",
      "Epoch: 5, Step: 001/2949, Loss: 0.7220\n",
      "Epoch: 5, Step: 002/2949, Loss: 0.7312\n",
      "Epoch: 5, Step: 003/2949, Loss: 0.7517\n",
      "Epoch: 5, Step: 004/2949, Loss: 0.7907\n",
      "Epoch: 5, Step: 005/2949, Loss: 0.7628\n",
      "Epoch: 5, Step: 006/2949, Loss: 0.7573\n",
      "Epoch: 5, Step: 007/2949, Loss: 0.7828\n",
      "Epoch: 5, Step: 008/2949, Loss: 0.7219\n",
      "Epoch: 5, Step: 009/2949, Loss: 0.7821\n",
      "Epoch: 5, Step: 010/2949, Loss: 0.7785\n",
      "Epoch: 5, Step: 011/2949, Loss: 0.7844\n",
      "Epoch: 5, Step: 012/2949, Loss: 0.6961\n",
      "Epoch: 5, Step: 013/2949, Loss: 0.7102\n",
      "Epoch: 5, Step: 014/2949, Loss: 0.7525\n",
      "Epoch: 5, Step: 015/2949, Loss: 0.7532\n",
      "Epoch: 5, Step: 016/2949, Loss: 0.7374\n",
      "Epoch: 5, Step: 017/2949, Loss: 0.8276\n",
      "Epoch: 5, Step: 018/2949, Loss: 0.7577\n",
      "Epoch: 5, Step: 019/2949, Loss: 0.7649\n",
      "Epoch: 5, Step: 020/2949, Loss: 0.7232\n",
      "Epoch: 5, Step: 021/2949, Loss: 0.7735\n",
      "Epoch: 5, Step: 022/2949, Loss: 0.7693\n",
      "Epoch: 5, Step: 023/2949, Loss: 0.7149\n",
      "Epoch: 5, Step: 024/2949, Loss: 0.7418\n",
      "Epoch: 5, Step: 025/2949, Loss: 0.7373\n",
      "Epoch: 5, Step: 026/2949, Loss: 0.7401\n",
      "Epoch: 5, Step: 027/2949, Loss: 0.7295\n",
      "Epoch: 5, Step: 028/2949, Loss: 0.7040\n",
      "Epoch: 5, Step: 029/2949, Loss: 0.7295\n",
      "Epoch: 5, Step: 030/2949, Loss: 0.7807\n",
      "Epoch: 5, Step: 031/2949, Loss: 0.7699\n",
      "Epoch: 5, Step: 032/2949, Loss: 0.7224\n",
      "Epoch: 5, Step: 033/2949, Loss: 0.7245\n",
      "Epoch: 5, Step: 034/2949, Loss: 0.7223\n",
      "Epoch: 5, Step: 035/2949, Loss: 0.7335\n",
      "Epoch: 5, Step: 036/2949, Loss: 0.7325\n",
      "Epoch: 5, Step: 037/2949, Loss: 0.8014\n",
      "Epoch: 5, Step: 038/2949, Loss: 0.7418\n",
      "Epoch: 5, Step: 039/2949, Loss: 0.7683\n",
      "Epoch: 5, Step: 040/2949, Loss: 0.7169\n",
      "Epoch: 5, Step: 041/2949, Loss: 0.7896\n",
      "Epoch: 5, Step: 042/2949, Loss: 0.7873\n",
      "Epoch: 5, Step: 043/2949, Loss: 0.7458\n",
      "Epoch: 5, Step: 044/2949, Loss: 0.7303\n",
      "Epoch: 5, Step: 045/2949, Loss: 0.7817\n",
      "Epoch: 5, Step: 046/2949, Loss: 0.7461\n",
      "Epoch: 5, Step: 047/2949, Loss: 0.7552\n",
      "Epoch: 5, Step: 048/2949, Loss: 0.7703\n",
      "Epoch: 5, Step: 049/2949, Loss: 0.7973\n",
      "Epoch: 5, Step: 050/2949, Loss: 0.7522\n",
      "Epoch: 5, Step: 051/2949, Loss: 0.7317\n",
      "Epoch: 5, Step: 052/2949, Loss: 0.7291\n",
      "Epoch: 5, Step: 053/2949, Loss: 0.7133\n",
      "Epoch: 5, Step: 054/2949, Loss: 0.7338\n",
      "Epoch: 5, Step: 055/2949, Loss: 0.7372\n",
      "Epoch: 5, Step: 056/2949, Loss: 0.7466\n",
      "Epoch: 5, Step: 057/2949, Loss: 0.7518\n",
      "Epoch: 5, Step: 058/2949, Loss: 0.6675\n",
      "Epoch: 5, Step: 059/2949, Loss: 0.7040\n",
      "Epoch: 5, Step: 060/2949, Loss: 0.7349\n",
      "Epoch: 5, Step: 061/2949, Loss: 0.7892\n",
      "Epoch: 5, Step: 062/2949, Loss: 0.7525\n",
      "Epoch: 5, Step: 063/2949, Loss: 0.7722\n",
      "Epoch: 5, Step: 064/2949, Loss: 0.6985\n",
      "Epoch: 5, Step: 065/2949, Loss: 0.7534\n",
      "Epoch: 5, Step: 066/2949, Loss: 0.6723\n",
      "Epoch: 5, Step: 067/2949, Loss: 0.7301\n",
      "Epoch: 5, Step: 068/2949, Loss: 0.7568\n",
      "Epoch: 5, Step: 069/2949, Loss: 0.6755\n",
      "Epoch: 5, Step: 070/2949, Loss: 0.7688\n",
      "Epoch: 5, Step: 071/2949, Loss: 0.7564\n",
      "Epoch: 5, Step: 072/2949, Loss: 0.7424\n",
      "Epoch: 5, Step: 073/2949, Loss: 0.7574\n",
      "Epoch: 5, Step: 074/2949, Loss: 0.6951\n",
      "Epoch: 5, Step: 075/2949, Loss: 0.8174\n",
      "Epoch: 5, Step: 076/2949, Loss: 0.7720\n",
      "Epoch: 5, Step: 077/2949, Loss: 0.7350\n",
      "Epoch: 5, Step: 078/2949, Loss: 0.7841\n",
      "Epoch: 5, Step: 079/2949, Loss: 0.7254\n",
      "Epoch: 5, Step: 080/2949, Loss: 0.7192\n",
      "Epoch: 5, Step: 081/2949, Loss: 0.7752\n",
      "Epoch: 5, Step: 082/2949, Loss: 0.7177\n",
      "Epoch: 5, Step: 083/2949, Loss: 0.7875\n",
      "Epoch: 5, Step: 084/2949, Loss: 0.7451\n",
      "Epoch: 5, Step: 085/2949, Loss: 0.7197\n",
      "Epoch: 5, Step: 086/2949, Loss: 0.7355\n",
      "Epoch: 5, Step: 087/2949, Loss: 0.7427\n",
      "Epoch: 5, Step: 088/2949, Loss: 0.6879\n",
      "Epoch: 5, Step: 089/2949, Loss: 0.7799\n",
      "Epoch: 5, Step: 090/2949, Loss: 0.7523\n",
      "Epoch: 5, Step: 091/2949, Loss: 0.7443\n",
      "Epoch: 5, Step: 092/2949, Loss: 0.7153\n",
      "Epoch: 5, Step: 093/2949, Loss: 0.7031\n",
      "Epoch: 5, Step: 094/2949, Loss: 0.7131\n",
      "Epoch: 5, Step: 095/2949, Loss: 0.7933\n",
      "Epoch: 5, Step: 096/2949, Loss: 0.7525\n",
      "Epoch: 5, Step: 097/2949, Loss: 0.7158\n",
      "Epoch: 5, Step: 098/2949, Loss: 0.7864\n",
      "Epoch: 5, Step: 099/2949, Loss: 0.8690\n",
      "Epoch: 5, Step: 100/2949, Loss: 0.7190\n",
      "Epoch: 5, Step: 101/2949, Loss: 0.7139\n",
      "Epoch: 5, Step: 102/2949, Loss: 0.6966\n",
      "Epoch: 5, Step: 103/2949, Loss: 0.7753\n",
      "Epoch: 5, Step: 104/2949, Loss: 0.7232\n",
      "Epoch: 5, Step: 105/2949, Loss: 0.7589\n",
      "Epoch: 5, Step: 106/2949, Loss: 0.7053\n",
      "Epoch: 5, Step: 107/2949, Loss: 0.7545\n",
      "Epoch: 5, Step: 108/2949, Loss: 0.7566\n",
      "Epoch: 5, Step: 109/2949, Loss: 0.7322\n",
      "Epoch: 5, Step: 110/2949, Loss: 0.7561\n",
      "Epoch: 5, Step: 111/2949, Loss: 0.7695\n",
      "Epoch: 5, Step: 112/2949, Loss: 0.7804\n",
      "Epoch: 5, Step: 113/2949, Loss: 0.7369\n",
      "Epoch: 5, Step: 114/2949, Loss: 0.7698\n",
      "Epoch: 5, Step: 115/2949, Loss: 0.7049\n",
      "Epoch: 5, Step: 116/2949, Loss: 0.7437\n",
      "Epoch: 5, Step: 117/2949, Loss: 0.6985\n",
      "Epoch: 5, Step: 118/2949, Loss: 0.7194\n",
      "Epoch: 5, Step: 119/2949, Loss: 0.7586\n",
      "Epoch: 5, Step: 120/2949, Loss: 0.7587\n",
      "Epoch: 5, Step: 121/2949, Loss: 0.7964\n",
      "Epoch: 5, Step: 122/2949, Loss: 0.7294\n",
      "Epoch: 5, Step: 123/2949, Loss: 0.7520\n",
      "Epoch: 5, Step: 124/2949, Loss: 0.7089\n",
      "Epoch: 5, Step: 125/2949, Loss: 0.7127\n",
      "Epoch: 5, Step: 126/2949, Loss: 0.7486\n",
      "Epoch: 5, Step: 127/2949, Loss: 0.7679\n",
      "Epoch: 5, Step: 128/2949, Loss: 0.7527\n",
      "Epoch: 5, Step: 129/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 130/2949, Loss: 0.7145\n",
      "Epoch: 5, Step: 131/2949, Loss: 0.7332\n",
      "Epoch: 5, Step: 132/2949, Loss: 0.7273\n",
      "Epoch: 5, Step: 133/2949, Loss: 0.7193\n",
      "Epoch: 5, Step: 134/2949, Loss: 0.7730\n",
      "Epoch: 5, Step: 135/2949, Loss: 0.8172\n",
      "Epoch: 5, Step: 136/2949, Loss: 0.7506\n",
      "Epoch: 5, Step: 137/2949, Loss: 0.7237\n",
      "Epoch: 5, Step: 138/2949, Loss: 0.7428\n",
      "Epoch: 5, Step: 139/2949, Loss: 0.7624\n",
      "Epoch: 5, Step: 140/2949, Loss: 0.7016\n",
      "Epoch: 5, Step: 141/2949, Loss: 0.7495\n",
      "Epoch: 5, Step: 142/2949, Loss: 0.7643\n",
      "Epoch: 5, Step: 143/2949, Loss: 0.7417\n",
      "Epoch: 5, Step: 144/2949, Loss: 0.7675\n",
      "Epoch: 5, Step: 145/2949, Loss: 0.7193\n",
      "Epoch: 5, Step: 146/2949, Loss: 0.7067\n",
      "Epoch: 5, Step: 147/2949, Loss: 0.7951\n",
      "Epoch: 5, Step: 148/2949, Loss: 0.7477\n",
      "Epoch: 5, Step: 149/2949, Loss: 0.7356\n",
      "Epoch: 5, Step: 150/2949, Loss: 0.7557\n",
      "Epoch: 5, Step: 151/2949, Loss: 0.7685\n",
      "Epoch: 5, Step: 152/2949, Loss: 0.7369\n",
      "Epoch: 5, Step: 153/2949, Loss: 0.7546\n",
      "Epoch: 5, Step: 154/2949, Loss: 0.7415\n",
      "Epoch: 5, Step: 155/2949, Loss: 0.7241\n",
      "Epoch: 5, Step: 156/2949, Loss: 0.7197\n",
      "Epoch: 5, Step: 157/2949, Loss: 0.7385\n",
      "Epoch: 5, Step: 158/2949, Loss: 0.7568\n",
      "Epoch: 5, Step: 159/2949, Loss: 0.7117\n",
      "Epoch: 5, Step: 160/2949, Loss: 0.7522\n",
      "Epoch: 5, Step: 161/2949, Loss: 0.7072\n",
      "Epoch: 5, Step: 162/2949, Loss: 0.7802\n",
      "Epoch: 5, Step: 163/2949, Loss: 0.7159\n",
      "Epoch: 5, Step: 164/2949, Loss: 0.7564\n",
      "Epoch: 5, Step: 165/2949, Loss: 0.7814\n",
      "Epoch: 5, Step: 166/2949, Loss: 0.7584\n",
      "Epoch: 5, Step: 167/2949, Loss: 0.7797\n",
      "Epoch: 5, Step: 168/2949, Loss: 0.7378\n",
      "Epoch: 5, Step: 169/2949, Loss: 0.7567\n",
      "Epoch: 5, Step: 170/2949, Loss: 0.7699\n",
      "Epoch: 5, Step: 171/2949, Loss: 0.7022\n",
      "Epoch: 5, Step: 172/2949, Loss: 0.7485\n",
      "Epoch: 5, Step: 173/2949, Loss: 0.7146\n",
      "Epoch: 5, Step: 174/2949, Loss: 0.7271\n",
      "Epoch: 5, Step: 175/2949, Loss: 0.7760\n",
      "Epoch: 5, Step: 176/2949, Loss: 0.7234\n",
      "Epoch: 5, Step: 177/2949, Loss: 0.7417\n",
      "Epoch: 5, Step: 178/2949, Loss: 0.7253\n",
      "Epoch: 5, Step: 179/2949, Loss: 0.7506\n",
      "Epoch: 5, Step: 180/2949, Loss: 0.7134\n",
      "Epoch: 5, Step: 181/2949, Loss: 0.7781\n",
      "Epoch: 5, Step: 182/2949, Loss: 0.7597\n",
      "Epoch: 5, Step: 183/2949, Loss: 0.7237\n",
      "Epoch: 5, Step: 184/2949, Loss: 0.6945\n",
      "Epoch: 5, Step: 185/2949, Loss: 0.7225\n",
      "Epoch: 5, Step: 186/2949, Loss: 0.7189\n",
      "Epoch: 5, Step: 187/2949, Loss: 0.7317\n",
      "Epoch: 5, Step: 188/2949, Loss: 0.7439\n",
      "Epoch: 5, Step: 189/2949, Loss: 0.7348\n",
      "Epoch: 5, Step: 190/2949, Loss: 0.6551\n",
      "Epoch: 5, Step: 191/2949, Loss: 0.7213\n",
      "Epoch: 5, Step: 192/2949, Loss: 0.7287\n",
      "Epoch: 5, Step: 193/2949, Loss: 0.7271\n",
      "Epoch: 5, Step: 194/2949, Loss: 0.7341\n",
      "Epoch: 5, Step: 195/2949, Loss: 0.7095\n",
      "Epoch: 5, Step: 196/2949, Loss: 0.7582\n",
      "Epoch: 5, Step: 197/2949, Loss: 0.7621\n",
      "Epoch: 5, Step: 198/2949, Loss: 0.7380\n",
      "Epoch: 5, Step: 199/2949, Loss: 0.7146\n",
      "Epoch: 5, Step: 200/2949, Loss: 0.7604\n",
      "Epoch: 5, Step: 201/2949, Loss: 0.7237\n",
      "Epoch: 5, Step: 202/2949, Loss: 0.7624\n",
      "Epoch: 5, Step: 203/2949, Loss: 0.7466\n",
      "Epoch: 5, Step: 204/2949, Loss: 0.7537\n",
      "Epoch: 5, Step: 205/2949, Loss: 0.7162\n",
      "Epoch: 5, Step: 206/2949, Loss: 0.7090\n",
      "Epoch: 5, Step: 207/2949, Loss: 0.7623\n",
      "Epoch: 5, Step: 208/2949, Loss: 0.7556\n",
      "Epoch: 5, Step: 209/2949, Loss: 0.7422\n",
      "Epoch: 5, Step: 210/2949, Loss: 0.7455\n",
      "Epoch: 5, Step: 211/2949, Loss: 0.7357\n",
      "Epoch: 5, Step: 212/2949, Loss: 0.7617\n",
      "Epoch: 5, Step: 213/2949, Loss: 0.7483\n",
      "Epoch: 5, Step: 214/2949, Loss: 0.7558\n",
      "Epoch: 5, Step: 215/2949, Loss: 0.7388\n",
      "Epoch: 5, Step: 216/2949, Loss: 0.6903\n",
      "Epoch: 5, Step: 217/2949, Loss: 0.6946\n",
      "Epoch: 5, Step: 218/2949, Loss: 0.7795\n",
      "Epoch: 5, Step: 219/2949, Loss: 0.7224\n",
      "Epoch: 5, Step: 220/2949, Loss: 0.7485\n",
      "Epoch: 5, Step: 221/2949, Loss: 0.7505\n",
      "Epoch: 5, Step: 222/2949, Loss: 0.7310\n",
      "Epoch: 5, Step: 223/2949, Loss: 0.7440\n",
      "Epoch: 5, Step: 224/2949, Loss: 0.7266\n",
      "Epoch: 5, Step: 225/2949, Loss: 0.7842\n",
      "Epoch: 5, Step: 226/2949, Loss: 0.7470\n",
      "Epoch: 5, Step: 227/2949, Loss: 0.7221\n",
      "Epoch: 5, Step: 228/2949, Loss: 0.6795\n",
      "Epoch: 5, Step: 229/2949, Loss: 0.7677\n",
      "Epoch: 5, Step: 230/2949, Loss: 0.7854\n",
      "Epoch: 5, Step: 231/2949, Loss: 0.7545\n",
      "Epoch: 5, Step: 232/2949, Loss: 0.7386\n",
      "Epoch: 5, Step: 233/2949, Loss: 0.7486\n",
      "Epoch: 5, Step: 234/2949, Loss: 0.7670\n",
      "Epoch: 5, Step: 235/2949, Loss: 0.7242\n",
      "Epoch: 5, Step: 236/2949, Loss: 0.7633\n",
      "Epoch: 5, Step: 237/2949, Loss: 0.6840\n",
      "Epoch: 5, Step: 238/2949, Loss: 0.7629\n",
      "Epoch: 5, Step: 239/2949, Loss: 0.7505\n",
      "Epoch: 5, Step: 240/2949, Loss: 0.7184\n",
      "Epoch: 5, Step: 241/2949, Loss: 0.6948\n",
      "Epoch: 5, Step: 242/2949, Loss: 0.7185\n",
      "Epoch: 5, Step: 243/2949, Loss: 0.7666\n",
      "Epoch: 5, Step: 244/2949, Loss: 0.7664\n",
      "Epoch: 5, Step: 245/2949, Loss: 0.7446\n",
      "Epoch: 5, Step: 246/2949, Loss: 0.6776\n",
      "Epoch: 5, Step: 247/2949, Loss: 0.7002\n",
      "Epoch: 5, Step: 248/2949, Loss: 0.7405\n",
      "Epoch: 5, Step: 249/2949, Loss: 0.7217\n",
      "Epoch: 5, Step: 250/2949, Loss: 0.7955\n",
      "Epoch: 5, Step: 251/2949, Loss: 0.6617\n",
      "Epoch: 5, Step: 252/2949, Loss: 0.8092\n",
      "Epoch: 5, Step: 253/2949, Loss: 0.7443\n",
      "Epoch: 5, Step: 254/2949, Loss: 0.7475\n",
      "Epoch: 5, Step: 255/2949, Loss: 0.6896\n",
      "Epoch: 5, Step: 256/2949, Loss: 0.7183\n",
      "Epoch: 5, Step: 257/2949, Loss: 0.7732\n",
      "Epoch: 5, Step: 258/2949, Loss: 0.7620\n",
      "Epoch: 5, Step: 259/2949, Loss: 0.7378\n",
      "Epoch: 5, Step: 260/2949, Loss: 0.7503\n",
      "Epoch: 5, Step: 261/2949, Loss: 0.7294\n",
      "Epoch: 5, Step: 262/2949, Loss: 0.7910\n",
      "Epoch: 5, Step: 263/2949, Loss: 0.7397\n",
      "Epoch: 5, Step: 264/2949, Loss: 0.7277\n",
      "Epoch: 5, Step: 265/2949, Loss: 0.6948\n",
      "Epoch: 5, Step: 266/2949, Loss: 0.7252\n",
      "Epoch: 5, Step: 267/2949, Loss: 0.7479\n",
      "Epoch: 5, Step: 268/2949, Loss: 0.7276\n",
      "Epoch: 5, Step: 269/2949, Loss: 0.8085\n",
      "Epoch: 5, Step: 270/2949, Loss: 0.7188\n",
      "Epoch: 5, Step: 271/2949, Loss: 0.7296\n",
      "Epoch: 5, Step: 272/2949, Loss: 0.7315\n",
      "Epoch: 5, Step: 273/2949, Loss: 0.7683\n",
      "Epoch: 5, Step: 274/2949, Loss: 0.7854\n",
      "Epoch: 5, Step: 275/2949, Loss: 0.7324\n",
      "Epoch: 5, Step: 276/2949, Loss: 0.6746\n",
      "Epoch: 5, Step: 277/2949, Loss: 0.7623\n",
      "Epoch: 5, Step: 278/2949, Loss: 0.7628\n",
      "Epoch: 5, Step: 279/2949, Loss: 0.6813\n",
      "Epoch: 5, Step: 280/2949, Loss: 0.7053\n",
      "Epoch: 5, Step: 281/2949, Loss: 0.7472\n",
      "Epoch: 5, Step: 282/2949, Loss: 0.8139\n",
      "Epoch: 5, Step: 283/2949, Loss: 0.7555\n",
      "Epoch: 5, Step: 284/2949, Loss: 0.7351\n",
      "Epoch: 5, Step: 285/2949, Loss: 0.7559\n",
      "Epoch: 5, Step: 286/2949, Loss: 0.7288\n",
      "Epoch: 5, Step: 287/2949, Loss: 0.7155\n",
      "Epoch: 5, Step: 288/2949, Loss: 0.7441\n",
      "Epoch: 5, Step: 289/2949, Loss: 0.7526\n",
      "Epoch: 5, Step: 290/2949, Loss: 0.7109\n",
      "Epoch: 5, Step: 291/2949, Loss: 0.7780\n",
      "Epoch: 5, Step: 292/2949, Loss: 0.7633\n",
      "Epoch: 5, Step: 293/2949, Loss: 0.7269\n",
      "Epoch: 5, Step: 294/2949, Loss: 0.7510\n",
      "Epoch: 5, Step: 295/2949, Loss: 0.7403\n",
      "Epoch: 5, Step: 296/2949, Loss: 0.7589\n",
      "Epoch: 5, Step: 297/2949, Loss: 0.7228\n",
      "Epoch: 5, Step: 298/2949, Loss: 0.7614\n",
      "Epoch: 5, Step: 299/2949, Loss: 0.7275\n",
      "Epoch: 5, Step: 300/2949, Loss: 0.6954\n",
      "Epoch: 5, Step: 301/2949, Loss: 0.7578\n",
      "Epoch: 5, Step: 302/2949, Loss: 0.7736\n",
      "Epoch: 5, Step: 303/2949, Loss: 0.6889\n",
      "Epoch: 5, Step: 304/2949, Loss: 0.7257\n",
      "Epoch: 5, Step: 305/2949, Loss: 0.8098\n",
      "Epoch: 5, Step: 306/2949, Loss: 0.7192\n",
      "Epoch: 5, Step: 307/2949, Loss: 0.7634\n",
      "Epoch: 5, Step: 308/2949, Loss: 0.7355\n",
      "Epoch: 5, Step: 309/2949, Loss: 0.7690\n",
      "Epoch: 5, Step: 310/2949, Loss: 0.7310\n",
      "Epoch: 5, Step: 311/2949, Loss: 0.6690\n",
      "Epoch: 5, Step: 312/2949, Loss: 0.7534\n",
      "Epoch: 5, Step: 313/2949, Loss: 0.7497\n",
      "Epoch: 5, Step: 314/2949, Loss: 0.7037\n",
      "Epoch: 5, Step: 315/2949, Loss: 0.7715\n",
      "Epoch: 5, Step: 316/2949, Loss: 0.7505\n",
      "Epoch: 5, Step: 317/2949, Loss: 0.7768\n",
      "Epoch: 5, Step: 318/2949, Loss: 0.7569\n",
      "Epoch: 5, Step: 319/2949, Loss: 0.7399\n",
      "Epoch: 5, Step: 320/2949, Loss: 0.7119\n",
      "Epoch: 5, Step: 321/2949, Loss: 0.7812\n",
      "Epoch: 5, Step: 322/2949, Loss: 0.7317\n",
      "Epoch: 5, Step: 323/2949, Loss: 0.7618\n",
      "Epoch: 5, Step: 324/2949, Loss: 0.7582\n",
      "Epoch: 5, Step: 325/2949, Loss: 0.6875\n",
      "Epoch: 5, Step: 326/2949, Loss: 0.7749\n",
      "Epoch: 5, Step: 327/2949, Loss: 0.7575\n",
      "Epoch: 5, Step: 328/2949, Loss: 0.7576\n",
      "Epoch: 5, Step: 329/2949, Loss: 0.7352\n",
      "Epoch: 5, Step: 330/2949, Loss: 0.7145\n",
      "Epoch: 5, Step: 331/2949, Loss: 0.7250\n",
      "Epoch: 5, Step: 332/2949, Loss: 0.7918\n",
      "Epoch: 5, Step: 333/2949, Loss: 0.7477\n",
      "Epoch: 5, Step: 334/2949, Loss: 0.7369\n",
      "Epoch: 5, Step: 335/2949, Loss: 0.7401\n",
      "Epoch: 5, Step: 336/2949, Loss: 0.7572\n",
      "Epoch: 5, Step: 337/2949, Loss: 0.6907\n",
      "Epoch: 5, Step: 338/2949, Loss: 0.7570\n",
      "Epoch: 5, Step: 339/2949, Loss: 0.7100\n",
      "Epoch: 5, Step: 340/2949, Loss: 0.7609\n",
      "Epoch: 5, Step: 341/2949, Loss: 0.7600\n",
      "Epoch: 5, Step: 342/2949, Loss: 0.7738\n",
      "Epoch: 5, Step: 343/2949, Loss: 0.6702\n",
      "Epoch: 5, Step: 344/2949, Loss: 0.7050\n",
      "Epoch: 5, Step: 345/2949, Loss: 0.7111\n",
      "Epoch: 5, Step: 346/2949, Loss: 0.7723\n",
      "Epoch: 5, Step: 347/2949, Loss: 0.7305\n",
      "Epoch: 5, Step: 348/2949, Loss: 0.7241\n",
      "Epoch: 5, Step: 349/2949, Loss: 0.7498\n",
      "Epoch: 5, Step: 350/2949, Loss: 0.7528\n",
      "Epoch: 5, Step: 351/2949, Loss: 0.7023\n",
      "Epoch: 5, Step: 352/2949, Loss: 0.7356\n",
      "Epoch: 5, Step: 353/2949, Loss: 0.7648\n",
      "Epoch: 5, Step: 354/2949, Loss: 0.7529\n",
      "Epoch: 5, Step: 355/2949, Loss: 0.7696\n",
      "Epoch: 5, Step: 356/2949, Loss: 0.6851\n",
      "Epoch: 5, Step: 357/2949, Loss: 0.7238\n",
      "Epoch: 5, Step: 358/2949, Loss: 0.7544\n",
      "Epoch: 5, Step: 359/2949, Loss: 0.7671\n",
      "Epoch: 5, Step: 360/2949, Loss: 0.7279\n",
      "Epoch: 5, Step: 361/2949, Loss: 0.7814\n",
      "Epoch: 5, Step: 362/2949, Loss: 0.7263\n",
      "Epoch: 5, Step: 363/2949, Loss: 0.6744\n",
      "Epoch: 5, Step: 364/2949, Loss: 0.7027\n",
      "Epoch: 5, Step: 365/2949, Loss: 0.7964\n",
      "Epoch: 5, Step: 366/2949, Loss: 0.7381\n",
      "Epoch: 5, Step: 367/2949, Loss: 0.7787\n",
      "Epoch: 5, Step: 368/2949, Loss: 0.7221\n",
      "Epoch: 5, Step: 369/2949, Loss: 0.7425\n",
      "Epoch: 5, Step: 370/2949, Loss: 0.7625\n",
      "Epoch: 5, Step: 371/2949, Loss: 0.7021\n",
      "Epoch: 5, Step: 372/2949, Loss: 0.7509\n",
      "Epoch: 5, Step: 373/2949, Loss: 0.7440\n",
      "Epoch: 5, Step: 374/2949, Loss: 0.7270\n",
      "Epoch: 5, Step: 375/2949, Loss: 0.7142\n",
      "Epoch: 5, Step: 376/2949, Loss: 0.7020\n",
      "Epoch: 5, Step: 377/2949, Loss: 0.7046\n",
      "Epoch: 5, Step: 378/2949, Loss: 0.7415\n",
      "Epoch: 5, Step: 379/2949, Loss: 0.7571\n",
      "Epoch: 5, Step: 380/2949, Loss: 0.7598\n",
      "Epoch: 5, Step: 381/2949, Loss: 0.6741\n",
      "Epoch: 5, Step: 382/2949, Loss: 0.7903\n",
      "Epoch: 5, Step: 383/2949, Loss: 0.7471\n",
      "Epoch: 5, Step: 384/2949, Loss: 0.8000\n",
      "Epoch: 5, Step: 385/2949, Loss: 0.7582\n",
      "Epoch: 5, Step: 386/2949, Loss: 0.7314\n",
      "Epoch: 5, Step: 387/2949, Loss: 0.7384\n",
      "Epoch: 5, Step: 388/2949, Loss: 0.7461\n",
      "Epoch: 5, Step: 389/2949, Loss: 0.7099\n",
      "Epoch: 5, Step: 390/2949, Loss: 0.7699\n",
      "Epoch: 5, Step: 391/2949, Loss: 0.7100\n",
      "Epoch: 5, Step: 392/2949, Loss: 0.7602\n",
      "Epoch: 5, Step: 393/2949, Loss: 0.7288\n",
      "Epoch: 5, Step: 394/2949, Loss: 0.7280\n",
      "Epoch: 5, Step: 395/2949, Loss: 0.7892\n",
      "Epoch: 5, Step: 396/2949, Loss: 0.7159\n",
      "Epoch: 5, Step: 397/2949, Loss: 0.7164\n",
      "Epoch: 5, Step: 398/2949, Loss: 0.7104\n",
      "Epoch: 5, Step: 399/2949, Loss: 0.7431\n",
      "Epoch: 5, Step: 400/2949, Loss: 0.7503\n",
      "Epoch: 5, Step: 401/2949, Loss: 0.7091\n",
      "Epoch: 5, Step: 402/2949, Loss: 0.7116\n",
      "Epoch: 5, Step: 403/2949, Loss: 0.7098\n",
      "Epoch: 5, Step: 404/2949, Loss: 0.7254\n",
      "Epoch: 5, Step: 405/2949, Loss: 0.7896\n",
      "Epoch: 5, Step: 406/2949, Loss: 0.7557\n",
      "Epoch: 5, Step: 407/2949, Loss: 0.6866\n",
      "Epoch: 5, Step: 408/2949, Loss: 0.7543\n",
      "Epoch: 5, Step: 409/2949, Loss: 0.7772\n",
      "Epoch: 5, Step: 410/2949, Loss: 0.6759\n",
      "Epoch: 5, Step: 411/2949, Loss: 0.7390\n",
      "Epoch: 5, Step: 412/2949, Loss: 0.7440\n",
      "Epoch: 5, Step: 413/2949, Loss: 0.7443\n",
      "Epoch: 5, Step: 414/2949, Loss: 0.7543\n",
      "Epoch: 5, Step: 415/2949, Loss: 0.6708\n",
      "Epoch: 5, Step: 416/2949, Loss: 0.7545\n",
      "Epoch: 5, Step: 417/2949, Loss: 0.7468\n",
      "Epoch: 5, Step: 418/2949, Loss: 0.7181\n",
      "Epoch: 5, Step: 419/2949, Loss: 0.7530\n",
      "Epoch: 5, Step: 420/2949, Loss: 0.7771\n",
      "Epoch: 5, Step: 421/2949, Loss: 0.7381\n",
      "Epoch: 5, Step: 422/2949, Loss: 0.7656\n",
      "Epoch: 5, Step: 423/2949, Loss: 0.7205\n",
      "Epoch: 5, Step: 424/2949, Loss: 0.7994\n",
      "Epoch: 5, Step: 425/2949, Loss: 0.7555\n",
      "Epoch: 5, Step: 426/2949, Loss: 0.7593\n",
      "Epoch: 5, Step: 427/2949, Loss: 0.7387\n",
      "Epoch: 5, Step: 428/2949, Loss: 0.6814\n",
      "Epoch: 5, Step: 429/2949, Loss: 0.7042\n",
      "Epoch: 5, Step: 430/2949, Loss: 0.7647\n",
      "Epoch: 5, Step: 431/2949, Loss: 0.7061\n",
      "Epoch: 5, Step: 432/2949, Loss: 0.7756\n",
      "Epoch: 5, Step: 433/2949, Loss: 0.7538\n",
      "Epoch: 5, Step: 434/2949, Loss: 0.7081\n",
      "Epoch: 5, Step: 435/2949, Loss: 0.7469\n",
      "Epoch: 5, Step: 436/2949, Loss: 0.7595\n",
      "Epoch: 5, Step: 437/2949, Loss: 0.6955\n",
      "Epoch: 5, Step: 438/2949, Loss: 0.7485\n",
      "Epoch: 5, Step: 439/2949, Loss: 0.7466\n",
      "Epoch: 5, Step: 440/2949, Loss: 0.7709\n",
      "Epoch: 5, Step: 441/2949, Loss: 0.7169\n",
      "Epoch: 5, Step: 442/2949, Loss: 0.7455\n",
      "Epoch: 5, Step: 443/2949, Loss: 0.7484\n",
      "Epoch: 5, Step: 444/2949, Loss: 0.7460\n",
      "Epoch: 5, Step: 445/2949, Loss: 0.7221\n",
      "Epoch: 5, Step: 446/2949, Loss: 0.7192\n",
      "Epoch: 5, Step: 447/2949, Loss: 0.7201\n",
      "Epoch: 5, Step: 448/2949, Loss: 0.7718\n",
      "Epoch: 5, Step: 449/2949, Loss: 0.6935\n",
      "Epoch: 5, Step: 450/2949, Loss: 0.7480\n",
      "Epoch: 5, Step: 451/2949, Loss: 0.7389\n",
      "Epoch: 5, Step: 452/2949, Loss: 0.7172\n",
      "Epoch: 5, Step: 453/2949, Loss: 0.7182\n",
      "Epoch: 5, Step: 454/2949, Loss: 0.7153\n",
      "Epoch: 5, Step: 455/2949, Loss: 0.7235\n",
      "Epoch: 5, Step: 456/2949, Loss: 0.7547\n",
      "Epoch: 5, Step: 457/2949, Loss: 0.7721\n",
      "Epoch: 5, Step: 458/2949, Loss: 0.7582\n",
      "Epoch: 5, Step: 459/2949, Loss: 0.7162\n",
      "Epoch: 5, Step: 460/2949, Loss: 0.7278\n",
      "Epoch: 5, Step: 461/2949, Loss: 0.7852\n",
      "Epoch: 5, Step: 462/2949, Loss: 0.7364\n",
      "Epoch: 5, Step: 463/2949, Loss: 0.7424\n",
      "Epoch: 5, Step: 464/2949, Loss: 0.7712\n",
      "Epoch: 5, Step: 465/2949, Loss: 0.8100\n",
      "Epoch: 5, Step: 466/2949, Loss: 0.7340\n",
      "Epoch: 5, Step: 467/2949, Loss: 0.7606\n",
      "Epoch: 5, Step: 468/2949, Loss: 0.7581\n",
      "Epoch: 5, Step: 469/2949, Loss: 0.7598\n",
      "Epoch: 5, Step: 470/2949, Loss: 0.7245\n",
      "Epoch: 5, Step: 471/2949, Loss: 0.7175\n",
      "Epoch: 5, Step: 472/2949, Loss: 0.7259\n",
      "Epoch: 5, Step: 473/2949, Loss: 0.7536\n",
      "Epoch: 5, Step: 474/2949, Loss: 0.7761\n",
      "Epoch: 5, Step: 475/2949, Loss: 0.7258\n",
      "Epoch: 5, Step: 476/2949, Loss: 0.7793\n",
      "Epoch: 5, Step: 477/2949, Loss: 0.7073\n",
      "Epoch: 5, Step: 478/2949, Loss: 0.7627\n",
      "Epoch: 5, Step: 479/2949, Loss: 0.7268\n",
      "Epoch: 5, Step: 480/2949, Loss: 0.7039\n",
      "Epoch: 5, Step: 481/2949, Loss: 0.7810\n",
      "Epoch: 5, Step: 482/2949, Loss: 0.7500\n",
      "Epoch: 5, Step: 483/2949, Loss: 0.6966\n",
      "Epoch: 5, Step: 484/2949, Loss: 0.7325\n",
      "Epoch: 5, Step: 485/2949, Loss: 0.7647\n",
      "Epoch: 5, Step: 486/2949, Loss: 0.7582\n",
      "Epoch: 5, Step: 487/2949, Loss: 0.7283\n",
      "Epoch: 5, Step: 488/2949, Loss: 0.7305\n",
      "Epoch: 5, Step: 489/2949, Loss: 0.7527\n",
      "Epoch: 5, Step: 490/2949, Loss: 0.7225\n",
      "Epoch: 5, Step: 491/2949, Loss: 0.7387\n",
      "Epoch: 5, Step: 492/2949, Loss: 0.7257\n",
      "Epoch: 5, Step: 493/2949, Loss: 0.7380\n",
      "Epoch: 5, Step: 494/2949, Loss: 0.7387\n",
      "Epoch: 5, Step: 495/2949, Loss: 0.7401\n",
      "Epoch: 5, Step: 496/2949, Loss: 0.7013\n",
      "Epoch: 5, Step: 497/2949, Loss: 0.7916\n",
      "Epoch: 5, Step: 498/2949, Loss: 0.7266\n",
      "Epoch: 5, Step: 499/2949, Loss: 0.7688\n",
      "Epoch: 5, Step: 500/2949, Loss: 0.7263\n",
      "Epoch: 5, Step: 501/2949, Loss: 0.7821\n",
      "Epoch: 5, Step: 502/2949, Loss: 0.7124\n",
      "Epoch: 5, Step: 503/2949, Loss: 0.7509\n",
      "Epoch: 5, Step: 504/2949, Loss: 0.7305\n",
      "Epoch: 5, Step: 505/2949, Loss: 0.7270\n",
      "Epoch: 5, Step: 506/2949, Loss: 0.6939\n",
      "Epoch: 5, Step: 507/2949, Loss: 0.7572\n",
      "Epoch: 5, Step: 508/2949, Loss: 0.7157\n",
      "Epoch: 5, Step: 509/2949, Loss: 0.7876\n",
      "Epoch: 5, Step: 510/2949, Loss: 0.7445\n",
      "Epoch: 5, Step: 511/2949, Loss: 0.7394\n",
      "Epoch: 5, Step: 512/2949, Loss: 0.7615\n",
      "Epoch: 5, Step: 513/2949, Loss: 0.7941\n",
      "Epoch: 5, Step: 514/2949, Loss: 0.8165\n",
      "Epoch: 5, Step: 515/2949, Loss: 0.7301\n",
      "Epoch: 5, Step: 516/2949, Loss: 0.7178\n",
      "Epoch: 5, Step: 517/2949, Loss: 0.6790\n",
      "Epoch: 5, Step: 518/2949, Loss: 0.7570\n",
      "Epoch: 5, Step: 519/2949, Loss: 0.7200\n",
      "Epoch: 5, Step: 520/2949, Loss: 0.7198\n",
      "Epoch: 5, Step: 521/2949, Loss: 0.7359\n",
      "Epoch: 5, Step: 522/2949, Loss: 0.7206\n",
      "Epoch: 5, Step: 523/2949, Loss: 0.6792\n",
      "Epoch: 5, Step: 524/2949, Loss: 0.7340\n",
      "Epoch: 5, Step: 525/2949, Loss: 0.7152\n",
      "Epoch: 5, Step: 526/2949, Loss: 0.7718\n",
      "Epoch: 5, Step: 527/2949, Loss: 0.7465\n",
      "Epoch: 5, Step: 528/2949, Loss: 0.7159\n",
      "Epoch: 5, Step: 529/2949, Loss: 0.7537\n",
      "Epoch: 5, Step: 530/2949, Loss: 0.7350\n",
      "Epoch: 5, Step: 531/2949, Loss: 0.7380\n",
      "Epoch: 5, Step: 532/2949, Loss: 0.7341\n",
      "Epoch: 5, Step: 533/2949, Loss: 0.7687\n",
      "Epoch: 5, Step: 534/2949, Loss: 0.7710\n",
      "Epoch: 5, Step: 535/2949, Loss: 0.7646\n",
      "Epoch: 5, Step: 536/2949, Loss: 0.7291\n",
      "Epoch: 5, Step: 537/2949, Loss: 0.6912\n",
      "Epoch: 5, Step: 538/2949, Loss: 0.6813\n",
      "Epoch: 5, Step: 539/2949, Loss: 0.7569\n",
      "Epoch: 5, Step: 540/2949, Loss: 0.7427\n",
      "Epoch: 5, Step: 541/2949, Loss: 0.7289\n",
      "Epoch: 5, Step: 542/2949, Loss: 0.7855\n",
      "Epoch: 5, Step: 543/2949, Loss: 0.7517\n",
      "Epoch: 5, Step: 544/2949, Loss: 0.7232\n",
      "Epoch: 5, Step: 545/2949, Loss: 0.7567\n",
      "Epoch: 5, Step: 546/2949, Loss: 0.7563\n",
      "Epoch: 5, Step: 547/2949, Loss: 0.7703\n",
      "Epoch: 5, Step: 548/2949, Loss: 0.7550\n",
      "Epoch: 5, Step: 549/2949, Loss: 0.7850\n",
      "Epoch: 5, Step: 550/2949, Loss: 0.7521\n",
      "Epoch: 5, Step: 551/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 552/2949, Loss: 0.7262\n",
      "Epoch: 5, Step: 553/2949, Loss: 0.7840\n",
      "Epoch: 5, Step: 554/2949, Loss: 0.7035\n",
      "Epoch: 5, Step: 555/2949, Loss: 0.7172\n",
      "Epoch: 5, Step: 556/2949, Loss: 0.7822\n",
      "Epoch: 5, Step: 557/2949, Loss: 0.7622\n",
      "Epoch: 5, Step: 558/2949, Loss: 0.7611\n",
      "Epoch: 5, Step: 559/2949, Loss: 0.7301\n",
      "Epoch: 5, Step: 560/2949, Loss: 0.7021\n",
      "Epoch: 5, Step: 561/2949, Loss: 0.8032\n",
      "Epoch: 5, Step: 562/2949, Loss: 0.7430\n",
      "Epoch: 5, Step: 563/2949, Loss: 0.7339\n",
      "Epoch: 5, Step: 564/2949, Loss: 0.7021\n",
      "Epoch: 5, Step: 565/2949, Loss: 0.7298\n",
      "Epoch: 5, Step: 566/2949, Loss: 0.7448\n",
      "Epoch: 5, Step: 567/2949, Loss: 0.7844\n",
      "Epoch: 5, Step: 568/2949, Loss: 0.7613\n",
      "Epoch: 5, Step: 569/2949, Loss: 0.7366\n",
      "Epoch: 5, Step: 570/2949, Loss: 0.7011\n",
      "Epoch: 5, Step: 571/2949, Loss: 0.7734\n",
      "Epoch: 5, Step: 572/2949, Loss: 0.7473\n",
      "Epoch: 5, Step: 573/2949, Loss: 0.7811\n",
      "Epoch: 5, Step: 574/2949, Loss: 0.7451\n",
      "Epoch: 5, Step: 575/2949, Loss: 0.7311\n",
      "Epoch: 5, Step: 576/2949, Loss: 0.7616\n",
      "Epoch: 5, Step: 577/2949, Loss: 0.6935\n",
      "Epoch: 5, Step: 578/2949, Loss: 0.7452\n",
      "Epoch: 5, Step: 579/2949, Loss: 0.7579\n",
      "Epoch: 5, Step: 580/2949, Loss: 0.7734\n",
      "Epoch: 5, Step: 581/2949, Loss: 0.7737\n",
      "Epoch: 5, Step: 582/2949, Loss: 0.7070\n",
      "Epoch: 5, Step: 583/2949, Loss: 0.7619\n",
      "Epoch: 5, Step: 584/2949, Loss: 0.7026\n",
      "Epoch: 5, Step: 585/2949, Loss: 0.7781\n",
      "Epoch: 5, Step: 586/2949, Loss: 0.7405\n",
      "Epoch: 5, Step: 587/2949, Loss: 0.7563\n",
      "Epoch: 5, Step: 588/2949, Loss: 0.7347\n",
      "Epoch: 5, Step: 589/2949, Loss: 0.7605\n",
      "Epoch: 5, Step: 590/2949, Loss: 0.7412\n",
      "Epoch: 5, Step: 591/2949, Loss: 0.6966\n",
      "Epoch: 5, Step: 592/2949, Loss: 0.7604\n",
      "Epoch: 5, Step: 593/2949, Loss: 0.7992\n",
      "Epoch: 5, Step: 594/2949, Loss: 0.7666\n",
      "Epoch: 5, Step: 595/2949, Loss: 0.7795\n",
      "Epoch: 5, Step: 596/2949, Loss: 0.7437\n",
      "Epoch: 5, Step: 597/2949, Loss: 0.7123\n",
      "Epoch: 5, Step: 598/2949, Loss: 0.7515\n",
      "Epoch: 5, Step: 599/2949, Loss: 0.7659\n",
      "Epoch: 5, Step: 600/2949, Loss: 0.7477\n",
      "Epoch: 5, Step: 601/2949, Loss: 0.7826\n",
      "Epoch: 5, Step: 602/2949, Loss: 0.7191\n",
      "Epoch: 5, Step: 603/2949, Loss: 0.7363\n",
      "Epoch: 5, Step: 604/2949, Loss: 0.7180\n",
      "Epoch: 5, Step: 605/2949, Loss: 0.7361\n",
      "Epoch: 5, Step: 606/2949, Loss: 0.7450\n",
      "Epoch: 5, Step: 607/2949, Loss: 0.7299\n",
      "Epoch: 5, Step: 608/2949, Loss: 0.7299\n",
      "Epoch: 5, Step: 609/2949, Loss: 0.7580\n",
      "Epoch: 5, Step: 610/2949, Loss: 0.7471\n",
      "Epoch: 5, Step: 611/2949, Loss: 0.7535\n",
      "Epoch: 5, Step: 612/2949, Loss: 0.7962\n",
      "Epoch: 5, Step: 613/2949, Loss: 0.7842\n",
      "Epoch: 5, Step: 614/2949, Loss: 0.7510\n",
      "Epoch: 5, Step: 615/2949, Loss: 0.7447\n",
      "Epoch: 5, Step: 616/2949, Loss: 0.7682\n",
      "Epoch: 5, Step: 617/2949, Loss: 0.7395\n",
      "Epoch: 5, Step: 618/2949, Loss: 0.7269\n",
      "Epoch: 5, Step: 619/2949, Loss: 0.7617\n",
      "Epoch: 5, Step: 620/2949, Loss: 0.7328\n",
      "Epoch: 5, Step: 621/2949, Loss: 0.7664\n",
      "Epoch: 5, Step: 622/2949, Loss: 0.7621\n",
      "Epoch: 5, Step: 623/2949, Loss: 0.6936\n",
      "Epoch: 5, Step: 624/2949, Loss: 0.7526\n",
      "Epoch: 5, Step: 625/2949, Loss: 0.7533\n",
      "Epoch: 5, Step: 626/2949, Loss: 0.7108\n",
      "Epoch: 5, Step: 627/2949, Loss: 0.7818\n",
      "Epoch: 5, Step: 628/2949, Loss: 0.7909\n",
      "Epoch: 5, Step: 629/2949, Loss: 0.7229\n",
      "Epoch: 5, Step: 630/2949, Loss: 0.7034\n",
      "Epoch: 5, Step: 631/2949, Loss: 0.7315\n",
      "Epoch: 5, Step: 632/2949, Loss: 0.7477\n",
      "Epoch: 5, Step: 633/2949, Loss: 0.7129\n",
      "Epoch: 5, Step: 634/2949, Loss: 0.6904\n",
      "Epoch: 5, Step: 635/2949, Loss: 0.7613\n",
      "Epoch: 5, Step: 636/2949, Loss: 0.7550\n",
      "Epoch: 5, Step: 637/2949, Loss: 0.7504\n",
      "Epoch: 5, Step: 638/2949, Loss: 0.7343\n",
      "Epoch: 5, Step: 639/2949, Loss: 0.7275\n",
      "Epoch: 5, Step: 640/2949, Loss: 0.7005\n",
      "Epoch: 5, Step: 641/2949, Loss: 0.7582\n",
      "Epoch: 5, Step: 642/2949, Loss: 0.7579\n",
      "Epoch: 5, Step: 643/2949, Loss: 0.7286\n",
      "Epoch: 5, Step: 644/2949, Loss: 0.7346\n",
      "Epoch: 5, Step: 645/2949, Loss: 0.7137\n",
      "Epoch: 5, Step: 646/2949, Loss: 0.7139\n",
      "Epoch: 5, Step: 647/2949, Loss: 0.7259\n",
      "Epoch: 5, Step: 648/2949, Loss: 0.8041\n",
      "Epoch: 5, Step: 649/2949, Loss: 0.7332\n",
      "Epoch: 5, Step: 650/2949, Loss: 0.7122\n",
      "Epoch: 5, Step: 651/2949, Loss: 0.7441\n",
      "Epoch: 5, Step: 652/2949, Loss: 0.7594\n",
      "Epoch: 5, Step: 653/2949, Loss: 0.7383\n",
      "Epoch: 5, Step: 654/2949, Loss: 0.7128\n",
      "Epoch: 5, Step: 655/2949, Loss: 0.7658\n",
      "Epoch: 5, Step: 656/2949, Loss: 0.7073\n",
      "Epoch: 5, Step: 657/2949, Loss: 0.7408\n",
      "Epoch: 5, Step: 658/2949, Loss: 0.7535\n",
      "Epoch: 5, Step: 659/2949, Loss: 0.6968\n",
      "Epoch: 5, Step: 660/2949, Loss: 0.7710\n",
      "Epoch: 5, Step: 661/2949, Loss: 0.7607\n",
      "Epoch: 5, Step: 662/2949, Loss: 0.7545\n",
      "Epoch: 5, Step: 663/2949, Loss: 0.7824\n",
      "Epoch: 5, Step: 664/2949, Loss: 0.7420\n",
      "Epoch: 5, Step: 665/2949, Loss: 0.7997\n",
      "Epoch: 5, Step: 666/2949, Loss: 0.7177\n",
      "Epoch: 5, Step: 667/2949, Loss: 0.7571\n",
      "Epoch: 5, Step: 668/2949, Loss: 0.7163\n",
      "Epoch: 5, Step: 669/2949, Loss: 0.6989\n",
      "Epoch: 5, Step: 670/2949, Loss: 0.7144\n",
      "Epoch: 5, Step: 671/2949, Loss: 0.7687\n",
      "Epoch: 5, Step: 672/2949, Loss: 0.7835\n",
      "Epoch: 5, Step: 673/2949, Loss: 0.7125\n",
      "Epoch: 5, Step: 674/2949, Loss: 0.7283\n",
      "Epoch: 5, Step: 675/2949, Loss: 0.7228\n",
      "Epoch: 5, Step: 676/2949, Loss: 0.7345\n",
      "Epoch: 5, Step: 677/2949, Loss: 0.7307\n",
      "Epoch: 5, Step: 678/2949, Loss: 0.7505\n",
      "Epoch: 5, Step: 679/2949, Loss: 0.7119\n",
      "Epoch: 5, Step: 680/2949, Loss: 0.7881\n",
      "Epoch: 5, Step: 681/2949, Loss: 0.7333\n",
      "Epoch: 5, Step: 682/2949, Loss: 0.7026\n",
      "Epoch: 5, Step: 683/2949, Loss: 0.6970\n",
      "Epoch: 5, Step: 684/2949, Loss: 0.7427\n",
      "Epoch: 5, Step: 685/2949, Loss: 0.7637\n",
      "Epoch: 5, Step: 686/2949, Loss: 0.6595\n",
      "Epoch: 5, Step: 687/2949, Loss: 0.6875\n",
      "Epoch: 5, Step: 688/2949, Loss: 0.7083\n",
      "Epoch: 5, Step: 689/2949, Loss: 0.7175\n",
      "Epoch: 5, Step: 690/2949, Loss: 0.7034\n",
      "Epoch: 5, Step: 691/2949, Loss: 0.7308\n",
      "Epoch: 5, Step: 692/2949, Loss: 0.7393\n",
      "Epoch: 5, Step: 693/2949, Loss: 0.7372\n",
      "Epoch: 5, Step: 694/2949, Loss: 0.7694\n",
      "Epoch: 5, Step: 695/2949, Loss: 0.8071\n",
      "Epoch: 5, Step: 696/2949, Loss: 0.7546\n",
      "Epoch: 5, Step: 697/2949, Loss: 0.7301\n",
      "Epoch: 5, Step: 698/2949, Loss: 0.7335\n",
      "Epoch: 5, Step: 699/2949, Loss: 0.7447\n",
      "Epoch: 5, Step: 700/2949, Loss: 0.7385\n",
      "Epoch: 5, Step: 701/2949, Loss: 0.7545\n",
      "Epoch: 5, Step: 702/2949, Loss: 0.7219\n",
      "Epoch: 5, Step: 703/2949, Loss: 0.7210\n",
      "Epoch: 5, Step: 704/2949, Loss: 0.7158\n",
      "Epoch: 5, Step: 705/2949, Loss: 0.7787\n",
      "Epoch: 5, Step: 706/2949, Loss: 0.7199\n",
      "Epoch: 5, Step: 707/2949, Loss: 0.7914\n",
      "Epoch: 5, Step: 708/2949, Loss: 0.7305\n",
      "Epoch: 5, Step: 709/2949, Loss: 0.7298\n",
      "Epoch: 5, Step: 710/2949, Loss: 0.7352\n",
      "Epoch: 5, Step: 711/2949, Loss: 0.7889\n",
      "Epoch: 5, Step: 712/2949, Loss: 0.7413\n",
      "Epoch: 5, Step: 713/2949, Loss: 0.7133\n",
      "Epoch: 5, Step: 714/2949, Loss: 0.7313\n",
      "Epoch: 5, Step: 715/2949, Loss: 0.6809\n",
      "Epoch: 5, Step: 716/2949, Loss: 0.7437\n",
      "Epoch: 5, Step: 717/2949, Loss: 0.7501\n",
      "Epoch: 5, Step: 718/2949, Loss: 0.7565\n",
      "Epoch: 5, Step: 719/2949, Loss: 0.7369\n",
      "Epoch: 5, Step: 720/2949, Loss: 0.7442\n",
      "Epoch: 5, Step: 721/2949, Loss: 0.7645\n",
      "Epoch: 5, Step: 722/2949, Loss: 0.7804\n",
      "Epoch: 5, Step: 723/2949, Loss: 0.7695\n",
      "Epoch: 5, Step: 724/2949, Loss: 0.7196\n",
      "Epoch: 5, Step: 725/2949, Loss: 0.7184\n",
      "Epoch: 5, Step: 726/2949, Loss: 0.7289\n",
      "Epoch: 5, Step: 727/2949, Loss: 0.7379\n",
      "Epoch: 5, Step: 728/2949, Loss: 0.7276\n",
      "Epoch: 5, Step: 729/2949, Loss: 0.7206\n",
      "Epoch: 5, Step: 730/2949, Loss: 0.7320\n",
      "Epoch: 5, Step: 731/2949, Loss: 0.8126\n",
      "Epoch: 5, Step: 732/2949, Loss: 0.7654\n",
      "Epoch: 5, Step: 733/2949, Loss: 0.7759\n",
      "Epoch: 5, Step: 734/2949, Loss: 0.6981\n",
      "Epoch: 5, Step: 735/2949, Loss: 0.7244\n",
      "Epoch: 5, Step: 736/2949, Loss: 0.7398\n",
      "Epoch: 5, Step: 737/2949, Loss: 0.7719\n",
      "Epoch: 5, Step: 738/2949, Loss: 0.6645\n",
      "Epoch: 5, Step: 739/2949, Loss: 0.7794\n",
      "Epoch: 5, Step: 740/2949, Loss: 0.7822\n",
      "Epoch: 5, Step: 741/2949, Loss: 0.7474\n",
      "Epoch: 5, Step: 742/2949, Loss: 0.6882\n",
      "Epoch: 5, Step: 743/2949, Loss: 0.6805\n",
      "Epoch: 5, Step: 744/2949, Loss: 0.7379\n",
      "Epoch: 5, Step: 745/2949, Loss: 0.7498\n",
      "Epoch: 5, Step: 746/2949, Loss: 0.6927\n",
      "Epoch: 5, Step: 747/2949, Loss: 0.7790\n",
      "Epoch: 5, Step: 748/2949, Loss: 0.7438\n",
      "Epoch: 5, Step: 749/2949, Loss: 0.7547\n",
      "Epoch: 5, Step: 750/2949, Loss: 0.6675\n",
      "Epoch: 5, Step: 751/2949, Loss: 0.7293\n",
      "Epoch: 5, Step: 752/2949, Loss: 0.7560\n",
      "Epoch: 5, Step: 753/2949, Loss: 0.7552\n",
      "Epoch: 5, Step: 754/2949, Loss: 0.7681\n",
      "Epoch: 5, Step: 755/2949, Loss: 0.7617\n",
      "Epoch: 5, Step: 756/2949, Loss: 0.7636\n",
      "Epoch: 5, Step: 757/2949, Loss: 0.6920\n",
      "Epoch: 5, Step: 758/2949, Loss: 0.7829\n",
      "Epoch: 5, Step: 759/2949, Loss: 0.7405\n",
      "Epoch: 5, Step: 760/2949, Loss: 0.7547\n",
      "Epoch: 5, Step: 761/2949, Loss: 0.6810\n",
      "Epoch: 5, Step: 762/2949, Loss: 0.7495\n",
      "Epoch: 5, Step: 763/2949, Loss: 0.7136\n",
      "Epoch: 5, Step: 764/2949, Loss: 0.7191\n",
      "Epoch: 5, Step: 765/2949, Loss: 0.7596\n",
      "Epoch: 5, Step: 766/2949, Loss: 0.7041\n",
      "Epoch: 5, Step: 767/2949, Loss: 0.7258\n",
      "Epoch: 5, Step: 768/2949, Loss: 0.7539\n",
      "Epoch: 5, Step: 769/2949, Loss: 0.7281\n",
      "Epoch: 5, Step: 770/2949, Loss: 0.6851\n",
      "Epoch: 5, Step: 771/2949, Loss: 0.7276\n",
      "Epoch: 5, Step: 772/2949, Loss: 0.7654\n",
      "Epoch: 5, Step: 773/2949, Loss: 0.7337\n",
      "Epoch: 5, Step: 774/2949, Loss: 0.7586\n",
      "Epoch: 5, Step: 775/2949, Loss: 0.7688\n",
      "Epoch: 5, Step: 776/2949, Loss: 0.7121\n",
      "Epoch: 5, Step: 777/2949, Loss: 0.7290\n",
      "Epoch: 5, Step: 778/2949, Loss: 0.7663\n",
      "Epoch: 5, Step: 779/2949, Loss: 0.7370\n",
      "Epoch: 5, Step: 780/2949, Loss: 0.7334\n",
      "Epoch: 5, Step: 781/2949, Loss: 0.7345\n",
      "Epoch: 5, Step: 782/2949, Loss: 0.6897\n",
      "Epoch: 5, Step: 783/2949, Loss: 0.7905\n",
      "Epoch: 5, Step: 784/2949, Loss: 0.7428\n",
      "Epoch: 5, Step: 785/2949, Loss: 0.7185\n",
      "Epoch: 5, Step: 786/2949, Loss: 0.7596\n",
      "Epoch: 5, Step: 787/2949, Loss: 0.7588\n",
      "Epoch: 5, Step: 788/2949, Loss: 0.7176\n",
      "Epoch: 5, Step: 789/2949, Loss: 0.7306\n",
      "Epoch: 5, Step: 790/2949, Loss: 0.7321\n",
      "Epoch: 5, Step: 791/2949, Loss: 0.7108\n",
      "Epoch: 5, Step: 792/2949, Loss: 0.7307\n",
      "Epoch: 5, Step: 793/2949, Loss: 0.7427\n",
      "Epoch: 5, Step: 794/2949, Loss: 0.6941\n",
      "Epoch: 5, Step: 795/2949, Loss: 0.6947\n",
      "Epoch: 5, Step: 796/2949, Loss: 0.6867\n",
      "Epoch: 5, Step: 797/2949, Loss: 0.7804\n",
      "Epoch: 5, Step: 798/2949, Loss: 0.7062\n",
      "Epoch: 5, Step: 799/2949, Loss: 0.7506\n",
      "Epoch: 5, Step: 800/2949, Loss: 0.7627\n",
      "Epoch: 5, Step: 801/2949, Loss: 0.7371\n",
      "Epoch: 5, Step: 802/2949, Loss: 0.7056\n",
      "Epoch: 5, Step: 803/2949, Loss: 0.7055\n",
      "Epoch: 5, Step: 804/2949, Loss: 0.7876\n",
      "Epoch: 5, Step: 805/2949, Loss: 0.7324\n",
      "Epoch: 5, Step: 806/2949, Loss: 0.7352\n",
      "Epoch: 5, Step: 807/2949, Loss: 0.7041\n",
      "Epoch: 5, Step: 808/2949, Loss: 0.7701\n",
      "Epoch: 5, Step: 809/2949, Loss: 0.7438\n",
      "Epoch: 5, Step: 810/2949, Loss: 0.6741\n",
      "Epoch: 5, Step: 811/2949, Loss: 0.7618\n",
      "Epoch: 5, Step: 812/2949, Loss: 0.7548\n",
      "Epoch: 5, Step: 813/2949, Loss: 0.7440\n",
      "Epoch: 5, Step: 814/2949, Loss: 0.7347\n",
      "Epoch: 5, Step: 815/2949, Loss: 0.7417\n",
      "Epoch: 5, Step: 816/2949, Loss: 0.7420\n",
      "Epoch: 5, Step: 817/2949, Loss: 0.7783\n",
      "Epoch: 5, Step: 818/2949, Loss: 0.7353\n",
      "Epoch: 5, Step: 819/2949, Loss: 0.7473\n",
      "Epoch: 5, Step: 820/2949, Loss: 0.7840\n",
      "Epoch: 5, Step: 821/2949, Loss: 0.7063\n",
      "Epoch: 5, Step: 822/2949, Loss: 0.7348\n",
      "Epoch: 5, Step: 823/2949, Loss: 0.6826\n",
      "Epoch: 5, Step: 824/2949, Loss: 0.7420\n",
      "Epoch: 5, Step: 825/2949, Loss: 0.7535\n",
      "Epoch: 5, Step: 826/2949, Loss: 0.7527\n",
      "Epoch: 5, Step: 827/2949, Loss: 0.7138\n",
      "Epoch: 5, Step: 828/2949, Loss: 0.7426\n",
      "Epoch: 5, Step: 829/2949, Loss: 0.7589\n",
      "Epoch: 5, Step: 830/2949, Loss: 0.7521\n",
      "Epoch: 5, Step: 831/2949, Loss: 0.7189\n",
      "Epoch: 5, Step: 832/2949, Loss: 0.7782\n",
      "Epoch: 5, Step: 833/2949, Loss: 0.7173\n",
      "Epoch: 5, Step: 834/2949, Loss: 0.7057\n",
      "Epoch: 5, Step: 835/2949, Loss: 0.7222\n",
      "Epoch: 5, Step: 836/2949, Loss: 0.7417\n",
      "Epoch: 5, Step: 837/2949, Loss: 0.7430\n",
      "Epoch: 5, Step: 838/2949, Loss: 0.7511\n",
      "Epoch: 5, Step: 839/2949, Loss: 0.7550\n",
      "Epoch: 5, Step: 840/2949, Loss: 0.7881\n",
      "Epoch: 5, Step: 841/2949, Loss: 0.7872\n",
      "Epoch: 5, Step: 842/2949, Loss: 0.7632\n",
      "Epoch: 5, Step: 843/2949, Loss: 0.7496\n",
      "Epoch: 5, Step: 844/2949, Loss: 0.7636\n",
      "Epoch: 5, Step: 845/2949, Loss: 0.7071\n",
      "Epoch: 5, Step: 846/2949, Loss: 0.7169\n",
      "Epoch: 5, Step: 847/2949, Loss: 0.7580\n",
      "Epoch: 5, Step: 848/2949, Loss: 0.7937\n",
      "Epoch: 5, Step: 849/2949, Loss: 0.7526\n",
      "Epoch: 5, Step: 850/2949, Loss: 0.7730\n",
      "Epoch: 5, Step: 851/2949, Loss: 0.7552\n",
      "Epoch: 5, Step: 852/2949, Loss: 0.7389\n",
      "Epoch: 5, Step: 853/2949, Loss: 0.7230\n",
      "Epoch: 5, Step: 854/2949, Loss: 0.7206\n",
      "Epoch: 5, Step: 855/2949, Loss: 0.6815\n",
      "Epoch: 5, Step: 856/2949, Loss: 0.7734\n",
      "Epoch: 5, Step: 857/2949, Loss: 0.7525\n",
      "Epoch: 5, Step: 858/2949, Loss: 0.7679\n",
      "Epoch: 5, Step: 859/2949, Loss: 0.7243\n",
      "Epoch: 5, Step: 860/2949, Loss: 0.7191\n",
      "Epoch: 5, Step: 861/2949, Loss: 0.7387\n",
      "Epoch: 5, Step: 862/2949, Loss: 0.7697\n",
      "Epoch: 5, Step: 863/2949, Loss: 0.7473\n",
      "Epoch: 5, Step: 864/2949, Loss: 0.7416\n",
      "Epoch: 5, Step: 865/2949, Loss: 0.8245\n",
      "Epoch: 5, Step: 866/2949, Loss: 0.7562\n",
      "Epoch: 5, Step: 867/2949, Loss: 0.7481\n",
      "Epoch: 5, Step: 868/2949, Loss: 0.7211\n",
      "Epoch: 5, Step: 869/2949, Loss: 0.7800\n",
      "Epoch: 5, Step: 870/2949, Loss: 0.7246\n",
      "Epoch: 5, Step: 871/2949, Loss: 0.7174\n",
      "Epoch: 5, Step: 872/2949, Loss: 0.7691\n",
      "Epoch: 5, Step: 873/2949, Loss: 0.7342\n",
      "Epoch: 5, Step: 874/2949, Loss: 0.7096\n",
      "Epoch: 5, Step: 875/2949, Loss: 0.7872\n",
      "Epoch: 5, Step: 876/2949, Loss: 0.7381\n",
      "Epoch: 5, Step: 877/2949, Loss: 0.7657\n",
      "Epoch: 5, Step: 878/2949, Loss: 0.6958\n",
      "Epoch: 5, Step: 879/2949, Loss: 0.6813\n",
      "Epoch: 5, Step: 880/2949, Loss: 0.7529\n",
      "Epoch: 5, Step: 881/2949, Loss: 0.7620\n",
      "Epoch: 5, Step: 882/2949, Loss: 0.7309\n",
      "Epoch: 5, Step: 883/2949, Loss: 0.7567\n",
      "Epoch: 5, Step: 884/2949, Loss: 0.7000\n",
      "Epoch: 5, Step: 885/2949, Loss: 0.7421\n",
      "Epoch: 5, Step: 886/2949, Loss: 0.7709\n",
      "Epoch: 5, Step: 887/2949, Loss: 0.7267\n",
      "Epoch: 5, Step: 888/2949, Loss: 0.7553\n",
      "Epoch: 5, Step: 889/2949, Loss: 0.7536\n",
      "Epoch: 5, Step: 890/2949, Loss: 0.7374\n",
      "Epoch: 5, Step: 891/2949, Loss: 0.7388\n",
      "Epoch: 5, Step: 892/2949, Loss: 0.7359\n",
      "Epoch: 5, Step: 893/2949, Loss: 0.7373\n",
      "Epoch: 5, Step: 894/2949, Loss: 0.7286\n",
      "Epoch: 5, Step: 895/2949, Loss: 0.6951\n",
      "Epoch: 5, Step: 896/2949, Loss: 0.7232\n",
      "Epoch: 5, Step: 897/2949, Loss: 0.7170\n",
      "Epoch: 5, Step: 898/2949, Loss: 0.7090\n",
      "Epoch: 5, Step: 899/2949, Loss: 0.6783\n",
      "Epoch: 5, Step: 900/2949, Loss: 0.7509\n",
      "Epoch: 5, Step: 901/2949, Loss: 0.7248\n",
      "Epoch: 5, Step: 902/2949, Loss: 0.7501\n",
      "Epoch: 5, Step: 903/2949, Loss: 0.7420\n",
      "Epoch: 5, Step: 904/2949, Loss: 0.7539\n",
      "Epoch: 5, Step: 905/2949, Loss: 0.7552\n",
      "Epoch: 5, Step: 906/2949, Loss: 0.7160\n",
      "Epoch: 5, Step: 907/2949, Loss: 0.7609\n",
      "Epoch: 5, Step: 908/2949, Loss: 0.7330\n",
      "Epoch: 5, Step: 909/2949, Loss: 0.7112\n",
      "Epoch: 5, Step: 910/2949, Loss: 0.7217\n",
      "Epoch: 5, Step: 911/2949, Loss: 0.7325\n",
      "Epoch: 5, Step: 912/2949, Loss: 0.7779\n",
      "Epoch: 5, Step: 913/2949, Loss: 0.7595\n",
      "Epoch: 5, Step: 914/2949, Loss: 0.7796\n",
      "Epoch: 5, Step: 915/2949, Loss: 0.7843\n",
      "Epoch: 5, Step: 916/2949, Loss: 0.7144\n",
      "Epoch: 5, Step: 917/2949, Loss: 0.7306\n",
      "Epoch: 5, Step: 918/2949, Loss: 0.7324\n",
      "Epoch: 5, Step: 919/2949, Loss: 0.6966\n",
      "Epoch: 5, Step: 920/2949, Loss: 0.7174\n",
      "Epoch: 5, Step: 921/2949, Loss: 0.6771\n",
      "Epoch: 5, Step: 922/2949, Loss: 0.7261\n",
      "Epoch: 5, Step: 923/2949, Loss: 0.7514\n",
      "Epoch: 5, Step: 924/2949, Loss: 0.7012\n",
      "Epoch: 5, Step: 925/2949, Loss: 0.7278\n",
      "Epoch: 5, Step: 926/2949, Loss: 0.7291\n",
      "Epoch: 5, Step: 927/2949, Loss: 0.7309\n",
      "Epoch: 5, Step: 928/2949, Loss: 0.7131\n",
      "Epoch: 5, Step: 929/2949, Loss: 0.7607\n",
      "Epoch: 5, Step: 930/2949, Loss: 0.7425\n",
      "Epoch: 5, Step: 931/2949, Loss: 0.7363\n",
      "Epoch: 5, Step: 932/2949, Loss: 0.7459\n",
      "Epoch: 5, Step: 933/2949, Loss: 0.7095\n",
      "Epoch: 5, Step: 934/2949, Loss: 0.7400\n",
      "Epoch: 5, Step: 935/2949, Loss: 0.6962\n",
      "Epoch: 5, Step: 936/2949, Loss: 0.7213\n",
      "Epoch: 5, Step: 937/2949, Loss: 0.7418\n",
      "Epoch: 5, Step: 938/2949, Loss: 0.7064\n",
      "Epoch: 5, Step: 939/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 940/2949, Loss: 0.7310\n",
      "Epoch: 5, Step: 941/2949, Loss: 0.7277\n",
      "Epoch: 5, Step: 942/2949, Loss: 0.7011\n",
      "Epoch: 5, Step: 943/2949, Loss: 0.7699\n",
      "Epoch: 5, Step: 944/2949, Loss: 0.7639\n",
      "Epoch: 5, Step: 945/2949, Loss: 0.7312\n",
      "Epoch: 5, Step: 946/2949, Loss: 0.6719\n",
      "Epoch: 5, Step: 947/2949, Loss: 0.7793\n",
      "Epoch: 5, Step: 948/2949, Loss: 0.7510\n",
      "Epoch: 5, Step: 949/2949, Loss: 0.6852\n",
      "Epoch: 5, Step: 950/2949, Loss: 0.7181\n",
      "Epoch: 5, Step: 951/2949, Loss: 0.7261\n",
      "Epoch: 5, Step: 952/2949, Loss: 0.6945\n",
      "Epoch: 5, Step: 953/2949, Loss: 0.8022\n",
      "Epoch: 5, Step: 954/2949, Loss: 0.7729\n",
      "Epoch: 5, Step: 955/2949, Loss: 0.7024\n",
      "Epoch: 5, Step: 956/2949, Loss: 0.7417\n",
      "Epoch: 5, Step: 957/2949, Loss: 0.7211\n",
      "Epoch: 5, Step: 958/2949, Loss: 0.7626\n",
      "Epoch: 5, Step: 959/2949, Loss: 0.7487\n",
      "Epoch: 5, Step: 960/2949, Loss: 0.7291\n",
      "Epoch: 5, Step: 961/2949, Loss: 0.7347\n",
      "Epoch: 5, Step: 962/2949, Loss: 0.7293\n",
      "Epoch: 5, Step: 963/2949, Loss: 0.7767\n",
      "Epoch: 5, Step: 964/2949, Loss: 0.7826\n",
      "Epoch: 5, Step: 965/2949, Loss: 0.7297\n",
      "Epoch: 5, Step: 966/2949, Loss: 0.7228\n",
      "Epoch: 5, Step: 967/2949, Loss: 0.7076\n",
      "Epoch: 5, Step: 968/2949, Loss: 0.7638\n",
      "Epoch: 5, Step: 969/2949, Loss: 0.7937\n",
      "Epoch: 5, Step: 970/2949, Loss: 0.6957\n",
      "Epoch: 5, Step: 971/2949, Loss: 0.7907\n",
      "Epoch: 5, Step: 972/2949, Loss: 0.7284\n",
      "Epoch: 5, Step: 973/2949, Loss: 0.7147\n",
      "Epoch: 5, Step: 974/2949, Loss: 0.7520\n",
      "Epoch: 5, Step: 975/2949, Loss: 0.7570\n",
      "Epoch: 5, Step: 976/2949, Loss: 0.7023\n",
      "Epoch: 5, Step: 977/2949, Loss: 0.7561\n",
      "Epoch: 5, Step: 978/2949, Loss: 0.7625\n",
      "Epoch: 5, Step: 979/2949, Loss: 0.7367\n",
      "Epoch: 5, Step: 980/2949, Loss: 0.7200\n",
      "Epoch: 5, Step: 981/2949, Loss: 0.7035\n",
      "Epoch: 5, Step: 982/2949, Loss: 0.7559\n",
      "Epoch: 5, Step: 983/2949, Loss: 0.7572\n",
      "Epoch: 5, Step: 984/2949, Loss: 0.7540\n",
      "Epoch: 5, Step: 985/2949, Loss: 0.7888\n",
      "Epoch: 5, Step: 986/2949, Loss: 0.7291\n",
      "Epoch: 5, Step: 987/2949, Loss: 0.7341\n",
      "Epoch: 5, Step: 988/2949, Loss: 0.7038\n",
      "Epoch: 5, Step: 989/2949, Loss: 0.7075\n",
      "Epoch: 5, Step: 990/2949, Loss: 0.7476\n",
      "Epoch: 5, Step: 991/2949, Loss: 0.7253\n",
      "Epoch: 5, Step: 992/2949, Loss: 0.7278\n",
      "Epoch: 5, Step: 993/2949, Loss: 0.7427\n",
      "Epoch: 5, Step: 994/2949, Loss: 0.7906\n",
      "Epoch: 5, Step: 995/2949, Loss: 0.7021\n",
      "Epoch: 5, Step: 996/2949, Loss: 0.8124\n",
      "Epoch: 5, Step: 997/2949, Loss: 0.7240\n",
      "Epoch: 5, Step: 998/2949, Loss: 0.7387\n",
      "Epoch: 5, Step: 999/2949, Loss: 0.7209\n",
      "Epoch: 5, Step: 1000/2949, Loss: 0.8145\n",
      "Epoch: 5, Step: 1001/2949, Loss: 0.7361\n",
      "Epoch: 5, Step: 1002/2949, Loss: 0.7729\n",
      "Epoch: 5, Step: 1003/2949, Loss: 0.7687\n",
      "Epoch: 5, Step: 1004/2949, Loss: 0.7103\n",
      "Epoch: 5, Step: 1005/2949, Loss: 0.7199\n",
      "Epoch: 5, Step: 1006/2949, Loss: 0.7439\n",
      "Epoch: 5, Step: 1007/2949, Loss: 0.7185\n",
      "Epoch: 5, Step: 1008/2949, Loss: 0.7368\n",
      "Epoch: 5, Step: 1009/2949, Loss: 0.7687\n",
      "Epoch: 5, Step: 1010/2949, Loss: 0.7608\n",
      "Epoch: 5, Step: 1011/2949, Loss: 0.6968\n",
      "Epoch: 5, Step: 1012/2949, Loss: 0.7588\n",
      "Epoch: 5, Step: 1013/2949, Loss: 0.7807\n",
      "Epoch: 5, Step: 1014/2949, Loss: 0.7943\n",
      "Epoch: 5, Step: 1015/2949, Loss: 0.7835\n",
      "Epoch: 5, Step: 1016/2949, Loss: 0.7669\n",
      "Epoch: 5, Step: 1017/2949, Loss: 0.7562\n",
      "Epoch: 5, Step: 1018/2949, Loss: 0.7523\n",
      "Epoch: 5, Step: 1019/2949, Loss: 0.7576\n",
      "Epoch: 5, Step: 1020/2949, Loss: 0.7826\n",
      "Epoch: 5, Step: 1021/2949, Loss: 0.7375\n",
      "Epoch: 5, Step: 1022/2949, Loss: 0.7419\n",
      "Epoch: 5, Step: 1023/2949, Loss: 0.7670\n",
      "Epoch: 5, Step: 1024/2949, Loss: 0.7651\n",
      "Epoch: 5, Step: 1025/2949, Loss: 0.7920\n",
      "Epoch: 5, Step: 1026/2949, Loss: 0.7583\n",
      "Epoch: 5, Step: 1027/2949, Loss: 0.7440\n",
      "Epoch: 5, Step: 1028/2949, Loss: 0.7431\n",
      "Epoch: 5, Step: 1029/2949, Loss: 0.7487\n",
      "Epoch: 5, Step: 1030/2949, Loss: 0.7147\n",
      "Epoch: 5, Step: 1031/2949, Loss: 0.7196\n",
      "Epoch: 5, Step: 1032/2949, Loss: 0.6862\n",
      "Epoch: 5, Step: 1033/2949, Loss: 0.7820\n",
      "Epoch: 5, Step: 1034/2949, Loss: 0.7448\n",
      "Epoch: 5, Step: 1035/2949, Loss: 0.7465\n",
      "Epoch: 5, Step: 1036/2949, Loss: 0.7396\n",
      "Epoch: 5, Step: 1037/2949, Loss: 0.8237\n",
      "Epoch: 5, Step: 1038/2949, Loss: 0.7177\n",
      "Epoch: 5, Step: 1039/2949, Loss: 0.6961\n",
      "Epoch: 5, Step: 1040/2949, Loss: 0.7019\n",
      "Epoch: 5, Step: 1041/2949, Loss: 0.7127\n",
      "Epoch: 5, Step: 1042/2949, Loss: 0.7669\n",
      "Epoch: 5, Step: 1043/2949, Loss: 0.6870\n",
      "Epoch: 5, Step: 1044/2949, Loss: 0.7751\n",
      "Epoch: 5, Step: 1045/2949, Loss: 0.7507\n",
      "Epoch: 5, Step: 1046/2949, Loss: 0.7109\n",
      "Epoch: 5, Step: 1047/2949, Loss: 0.7281\n",
      "Epoch: 5, Step: 1048/2949, Loss: 0.7047\n",
      "Epoch: 5, Step: 1049/2949, Loss: 0.7241\n",
      "Epoch: 5, Step: 1050/2949, Loss: 0.7249\n",
      "Epoch: 5, Step: 1051/2949, Loss: 0.7586\n",
      "Epoch: 5, Step: 1052/2949, Loss: 0.7354\n",
      "Epoch: 5, Step: 1053/2949, Loss: 0.7514\n",
      "Epoch: 5, Step: 1054/2949, Loss: 0.7185\n",
      "Epoch: 5, Step: 1055/2949, Loss: 0.7913\n",
      "Epoch: 5, Step: 1056/2949, Loss: 0.7435\n",
      "Epoch: 5, Step: 1057/2949, Loss: 0.7130\n",
      "Epoch: 5, Step: 1058/2949, Loss: 0.7822\n",
      "Epoch: 5, Step: 1059/2949, Loss: 0.7495\n",
      "Epoch: 5, Step: 1060/2949, Loss: 0.8085\n",
      "Epoch: 5, Step: 1061/2949, Loss: 0.7310\n",
      "Epoch: 5, Step: 1062/2949, Loss: 0.7699\n",
      "Epoch: 5, Step: 1063/2949, Loss: 0.7151\n",
      "Epoch: 5, Step: 1064/2949, Loss: 0.7481\n",
      "Epoch: 5, Step: 1065/2949, Loss: 0.7698\n",
      "Epoch: 5, Step: 1066/2949, Loss: 0.7359\n",
      "Epoch: 5, Step: 1067/2949, Loss: 0.7420\n",
      "Epoch: 5, Step: 1068/2949, Loss: 0.6807\n",
      "Epoch: 5, Step: 1069/2949, Loss: 0.7365\n",
      "Epoch: 5, Step: 1070/2949, Loss: 0.6976\n",
      "Epoch: 5, Step: 1071/2949, Loss: 0.7676\n",
      "Epoch: 5, Step: 1072/2949, Loss: 0.7737\n",
      "Epoch: 5, Step: 1073/2949, Loss: 0.8028\n",
      "Epoch: 5, Step: 1074/2949, Loss: 0.7566\n",
      "Epoch: 5, Step: 1075/2949, Loss: 0.7145\n",
      "Epoch: 5, Step: 1076/2949, Loss: 0.7432\n",
      "Epoch: 5, Step: 1077/2949, Loss: 0.7362\n",
      "Epoch: 5, Step: 1078/2949, Loss: 0.7252\n",
      "Epoch: 5, Step: 1079/2949, Loss: 0.7760\n",
      "Epoch: 5, Step: 1080/2949, Loss: 0.6789\n",
      "Epoch: 5, Step: 1081/2949, Loss: 0.7553\n",
      "Epoch: 5, Step: 1082/2949, Loss: 0.7299\n",
      "Epoch: 5, Step: 1083/2949, Loss: 0.7216\n",
      "Epoch: 5, Step: 1084/2949, Loss: 0.7447\n",
      "Epoch: 5, Step: 1085/2949, Loss: 0.7131\n",
      "Epoch: 5, Step: 1086/2949, Loss: 0.7712\n",
      "Epoch: 5, Step: 1087/2949, Loss: 0.7635\n",
      "Epoch: 5, Step: 1088/2949, Loss: 0.7219\n",
      "Epoch: 5, Step: 1089/2949, Loss: 0.7563\n",
      "Epoch: 5, Step: 1090/2949, Loss: 0.7587\n",
      "Epoch: 5, Step: 1091/2949, Loss: 0.7230\n",
      "Epoch: 5, Step: 1092/2949, Loss: 0.7534\n",
      "Epoch: 5, Step: 1093/2949, Loss: 0.7553\n",
      "Epoch: 5, Step: 1094/2949, Loss: 0.7490\n",
      "Epoch: 5, Step: 1095/2949, Loss: 0.7041\n",
      "Epoch: 5, Step: 1096/2949, Loss: 0.7505\n",
      "Epoch: 5, Step: 1097/2949, Loss: 0.7736\n",
      "Epoch: 5, Step: 1098/2949, Loss: 0.7174\n",
      "Epoch: 5, Step: 1099/2949, Loss: 0.7843\n",
      "Epoch: 5, Step: 1100/2949, Loss: 0.7408\n",
      "Epoch: 5, Step: 1101/2949, Loss: 0.7579\n",
      "Epoch: 5, Step: 1102/2949, Loss: 0.7184\n",
      "Epoch: 5, Step: 1103/2949, Loss: 0.7710\n",
      "Epoch: 5, Step: 1104/2949, Loss: 0.7557\n",
      "Epoch: 5, Step: 1105/2949, Loss: 0.8122\n",
      "Epoch: 5, Step: 1106/2949, Loss: 0.7184\n",
      "Epoch: 5, Step: 1107/2949, Loss: 0.7395\n",
      "Epoch: 5, Step: 1108/2949, Loss: 0.7392\n",
      "Epoch: 5, Step: 1109/2949, Loss: 0.7485\n",
      "Epoch: 5, Step: 1110/2949, Loss: 0.7588\n",
      "Epoch: 5, Step: 1111/2949, Loss: 0.7618\n",
      "Epoch: 5, Step: 1112/2949, Loss: 0.7809\n",
      "Epoch: 5, Step: 1113/2949, Loss: 0.7872\n",
      "Epoch: 5, Step: 1114/2949, Loss: 0.7413\n",
      "Epoch: 5, Step: 1115/2949, Loss: 0.7115\n",
      "Epoch: 5, Step: 1116/2949, Loss: 0.7199\n",
      "Epoch: 5, Step: 1117/2949, Loss: 0.7148\n",
      "Epoch: 5, Step: 1118/2949, Loss: 0.7704\n",
      "Epoch: 5, Step: 1119/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 1120/2949, Loss: 0.7702\n",
      "Epoch: 5, Step: 1121/2949, Loss: 0.7481\n",
      "Epoch: 5, Step: 1122/2949, Loss: 0.7467\n",
      "Epoch: 5, Step: 1123/2949, Loss: 0.7263\n",
      "Epoch: 5, Step: 1124/2949, Loss: 0.7349\n",
      "Epoch: 5, Step: 1125/2949, Loss: 0.7497\n",
      "Epoch: 5, Step: 1126/2949, Loss: 0.7527\n",
      "Epoch: 5, Step: 1127/2949, Loss: 0.7149\n",
      "Epoch: 5, Step: 1128/2949, Loss: 0.7012\n",
      "Epoch: 5, Step: 1129/2949, Loss: 0.7540\n",
      "Epoch: 5, Step: 1130/2949, Loss: 0.7206\n",
      "Epoch: 5, Step: 1131/2949, Loss: 0.7418\n",
      "Epoch: 5, Step: 1132/2949, Loss: 0.7240\n",
      "Epoch: 5, Step: 1133/2949, Loss: 0.7089\n",
      "Epoch: 5, Step: 1134/2949, Loss: 0.8026\n",
      "Epoch: 5, Step: 1135/2949, Loss: 0.7671\n",
      "Epoch: 5, Step: 1136/2949, Loss: 0.7429\n",
      "Epoch: 5, Step: 1137/2949, Loss: 0.7353\n",
      "Epoch: 5, Step: 1138/2949, Loss: 0.7479\n",
      "Epoch: 5, Step: 1139/2949, Loss: 0.7321\n",
      "Epoch: 5, Step: 1140/2949, Loss: 0.6632\n",
      "Epoch: 5, Step: 1141/2949, Loss: 0.7686\n",
      "Epoch: 5, Step: 1142/2949, Loss: 0.7464\n",
      "Epoch: 5, Step: 1143/2949, Loss: 0.7508\n",
      "Epoch: 5, Step: 1144/2949, Loss: 0.7087\n",
      "Epoch: 5, Step: 1145/2949, Loss: 0.7177\n",
      "Epoch: 5, Step: 1146/2949, Loss: 0.7590\n",
      "Epoch: 5, Step: 1147/2949, Loss: 0.7567\n",
      "Epoch: 5, Step: 1148/2949, Loss: 0.7074\n",
      "Epoch: 5, Step: 1149/2949, Loss: 0.7764\n",
      "Epoch: 5, Step: 1150/2949, Loss: 0.7615\n",
      "Epoch: 5, Step: 1151/2949, Loss: 0.7188\n",
      "Epoch: 5, Step: 1152/2949, Loss: 0.7374\n",
      "Epoch: 5, Step: 1153/2949, Loss: 0.7351\n",
      "Epoch: 5, Step: 1154/2949, Loss: 0.7289\n",
      "Epoch: 5, Step: 1155/2949, Loss: 0.7361\n",
      "Epoch: 5, Step: 1156/2949, Loss: 0.7356\n",
      "Epoch: 5, Step: 1157/2949, Loss: 0.7853\n",
      "Epoch: 5, Step: 1158/2949, Loss: 0.7221\n",
      "Epoch: 5, Step: 1159/2949, Loss: 0.7715\n",
      "Epoch: 5, Step: 1160/2949, Loss: 0.7470\n",
      "Epoch: 5, Step: 1161/2949, Loss: 0.7214\n",
      "Epoch: 5, Step: 1162/2949, Loss: 0.7022\n",
      "Epoch: 5, Step: 1163/2949, Loss: 0.7408\n",
      "Epoch: 5, Step: 1164/2949, Loss: 0.7355\n",
      "Epoch: 5, Step: 1165/2949, Loss: 0.7626\n",
      "Epoch: 5, Step: 1166/2949, Loss: 0.7519\n",
      "Epoch: 5, Step: 1167/2949, Loss: 0.6967\n",
      "Epoch: 5, Step: 1168/2949, Loss: 0.7467\n",
      "Epoch: 5, Step: 1169/2949, Loss: 0.7446\n",
      "Epoch: 5, Step: 1170/2949, Loss: 0.7329\n",
      "Epoch: 5, Step: 1171/2949, Loss: 0.7462\n",
      "Epoch: 5, Step: 1172/2949, Loss: 0.7120\n",
      "Epoch: 5, Step: 1173/2949, Loss: 0.7413\n",
      "Epoch: 5, Step: 1174/2949, Loss: 0.7415\n",
      "Epoch: 5, Step: 1175/2949, Loss: 0.7148\n",
      "Epoch: 5, Step: 1176/2949, Loss: 0.7427\n",
      "Epoch: 5, Step: 1177/2949, Loss: 0.6891\n",
      "Epoch: 5, Step: 1178/2949, Loss: 0.7677\n",
      "Epoch: 5, Step: 1179/2949, Loss: 0.7481\n",
      "Epoch: 5, Step: 1180/2949, Loss: 0.7324\n",
      "Epoch: 5, Step: 1181/2949, Loss: 0.7706\n",
      "Epoch: 5, Step: 1182/2949, Loss: 0.7721\n",
      "Epoch: 5, Step: 1183/2949, Loss: 0.6990\n",
      "Epoch: 5, Step: 1184/2949, Loss: 0.7186\n",
      "Epoch: 5, Step: 1185/2949, Loss: 0.7094\n",
      "Epoch: 5, Step: 1186/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 1187/2949, Loss: 0.7244\n",
      "Epoch: 5, Step: 1188/2949, Loss: 0.7359\n",
      "Epoch: 5, Step: 1189/2949, Loss: 0.7650\n",
      "Epoch: 5, Step: 1190/2949, Loss: 0.7341\n",
      "Epoch: 5, Step: 1191/2949, Loss: 0.7352\n",
      "Epoch: 5, Step: 1192/2949, Loss: 0.7316\n",
      "Epoch: 5, Step: 1193/2949, Loss: 0.7491\n",
      "Epoch: 5, Step: 1194/2949, Loss: 0.7235\n",
      "Epoch: 5, Step: 1195/2949, Loss: 0.7591\n",
      "Epoch: 5, Step: 1196/2949, Loss: 0.8208\n",
      "Epoch: 5, Step: 1197/2949, Loss: 0.6971\n",
      "Epoch: 5, Step: 1198/2949, Loss: 0.7422\n",
      "Epoch: 5, Step: 1199/2949, Loss: 0.7290\n",
      "Epoch: 5, Step: 1200/2949, Loss: 0.7731\n",
      "Epoch: 5, Step: 1201/2949, Loss: 0.7714\n",
      "Epoch: 5, Step: 1202/2949, Loss: 0.6984\n",
      "Epoch: 5, Step: 1203/2949, Loss: 0.7739\n",
      "Epoch: 5, Step: 1204/2949, Loss: 0.6832\n",
      "Epoch: 5, Step: 1205/2949, Loss: 0.6662\n",
      "Epoch: 5, Step: 1206/2949, Loss: 0.8038\n",
      "Epoch: 5, Step: 1207/2949, Loss: 0.7410\n",
      "Epoch: 5, Step: 1208/2949, Loss: 0.7632\n",
      "Epoch: 5, Step: 1209/2949, Loss: 0.7554\n",
      "Epoch: 5, Step: 1210/2949, Loss: 0.6914\n",
      "Epoch: 5, Step: 1211/2949, Loss: 0.7420\n",
      "Epoch: 5, Step: 1212/2949, Loss: 0.7544\n",
      "Epoch: 5, Step: 1213/2949, Loss: 0.7975\n",
      "Epoch: 5, Step: 1214/2949, Loss: 0.7127\n",
      "Epoch: 5, Step: 1215/2949, Loss: 0.7267\n",
      "Epoch: 5, Step: 1216/2949, Loss: 0.7010\n",
      "Epoch: 5, Step: 1217/2949, Loss: 0.7472\n",
      "Epoch: 5, Step: 1218/2949, Loss: 0.7468\n",
      "Epoch: 5, Step: 1219/2949, Loss: 0.7324\n",
      "Epoch: 5, Step: 1220/2949, Loss: 0.7945\n",
      "Epoch: 5, Step: 1221/2949, Loss: 0.7303\n",
      "Epoch: 5, Step: 1222/2949, Loss: 0.7717\n",
      "Epoch: 5, Step: 1223/2949, Loss: 0.7660\n",
      "Epoch: 5, Step: 1224/2949, Loss: 0.7207\n",
      "Epoch: 5, Step: 1225/2949, Loss: 0.7284\n",
      "Epoch: 5, Step: 1226/2949, Loss: 0.7632\n",
      "Epoch: 5, Step: 1227/2949, Loss: 0.7971\n",
      "Epoch: 5, Step: 1228/2949, Loss: 0.7553\n",
      "Epoch: 5, Step: 1229/2949, Loss: 0.7076\n",
      "Epoch: 5, Step: 1230/2949, Loss: 0.7963\n",
      "Epoch: 5, Step: 1231/2949, Loss: 0.7676\n",
      "Epoch: 5, Step: 1232/2949, Loss: 0.7153\n",
      "Epoch: 5, Step: 1233/2949, Loss: 0.7503\n",
      "Epoch: 5, Step: 1234/2949, Loss: 0.7539\n",
      "Epoch: 5, Step: 1235/2949, Loss: 0.7590\n",
      "Epoch: 5, Step: 1236/2949, Loss: 0.7602\n",
      "Epoch: 5, Step: 1237/2949, Loss: 0.7065\n",
      "Epoch: 5, Step: 1238/2949, Loss: 0.7694\n",
      "Epoch: 5, Step: 1239/2949, Loss: 0.7448\n",
      "Epoch: 5, Step: 1240/2949, Loss: 0.7431\n",
      "Epoch: 5, Step: 1241/2949, Loss: 0.7315\n",
      "Epoch: 5, Step: 1242/2949, Loss: 0.7057\n",
      "Epoch: 5, Step: 1243/2949, Loss: 0.7162\n",
      "Epoch: 5, Step: 1244/2949, Loss: 0.7034\n",
      "Epoch: 5, Step: 1245/2949, Loss: 0.6838\n",
      "Epoch: 5, Step: 1246/2949, Loss: 0.7342\n",
      "Epoch: 5, Step: 1247/2949, Loss: 0.6969\n",
      "Epoch: 5, Step: 1248/2949, Loss: 0.7207\n",
      "Epoch: 5, Step: 1249/2949, Loss: 0.7480\n",
      "Epoch: 5, Step: 1250/2949, Loss: 0.7450\n",
      "Epoch: 5, Step: 1251/2949, Loss: 0.6869\n",
      "Epoch: 5, Step: 1252/2949, Loss: 0.7517\n",
      "Epoch: 5, Step: 1253/2949, Loss: 0.7931\n",
      "Epoch: 5, Step: 1254/2949, Loss: 0.7271\n",
      "Epoch: 5, Step: 1255/2949, Loss: 0.7636\n",
      "Epoch: 5, Step: 1256/2949, Loss: 0.6917\n",
      "Epoch: 5, Step: 1257/2949, Loss: 0.7118\n",
      "Epoch: 5, Step: 1258/2949, Loss: 0.7072\n",
      "Epoch: 5, Step: 1259/2949, Loss: 0.7116\n",
      "Epoch: 5, Step: 1260/2949, Loss: 0.7547\n",
      "Epoch: 5, Step: 1261/2949, Loss: 0.7750\n",
      "Epoch: 5, Step: 1262/2949, Loss: 0.7572\n",
      "Epoch: 5, Step: 1263/2949, Loss: 0.7780\n",
      "Epoch: 5, Step: 1264/2949, Loss: 0.6893\n",
      "Epoch: 5, Step: 1265/2949, Loss: 0.7602\n",
      "Epoch: 5, Step: 1266/2949, Loss: 0.7480\n",
      "Epoch: 5, Step: 1267/2949, Loss: 0.7746\n",
      "Epoch: 5, Step: 1268/2949, Loss: 0.7475\n",
      "Epoch: 5, Step: 1269/2949, Loss: 0.7499\n",
      "Epoch: 5, Step: 1270/2949, Loss: 0.7408\n",
      "Epoch: 5, Step: 1271/2949, Loss: 0.7461\n",
      "Epoch: 5, Step: 1272/2949, Loss: 0.7533\n",
      "Epoch: 5, Step: 1273/2949, Loss: 0.7051\n",
      "Epoch: 5, Step: 1274/2949, Loss: 0.7020\n",
      "Epoch: 5, Step: 1275/2949, Loss: 0.7561\n",
      "Epoch: 5, Step: 1276/2949, Loss: 0.7976\n",
      "Epoch: 5, Step: 1277/2949, Loss: 0.7349\n",
      "Epoch: 5, Step: 1278/2949, Loss: 0.7672\n",
      "Epoch: 5, Step: 1279/2949, Loss: 0.6871\n",
      "Epoch: 5, Step: 1280/2949, Loss: 0.7196\n",
      "Epoch: 5, Step: 1281/2949, Loss: 0.7321\n",
      "Epoch: 5, Step: 1282/2949, Loss: 0.7212\n",
      "Epoch: 5, Step: 1283/2949, Loss: 0.7834\n",
      "Epoch: 5, Step: 1284/2949, Loss: 0.7754\n",
      "Epoch: 5, Step: 1285/2949, Loss: 0.7113\n",
      "Epoch: 5, Step: 1286/2949, Loss: 0.7270\n",
      "Epoch: 5, Step: 1287/2949, Loss: 0.7518\n",
      "Epoch: 5, Step: 1288/2949, Loss: 0.7454\n",
      "Epoch: 5, Step: 1289/2949, Loss: 0.7691\n",
      "Epoch: 5, Step: 1290/2949, Loss: 0.7231\n",
      "Epoch: 5, Step: 1291/2949, Loss: 0.7521\n",
      "Epoch: 5, Step: 1292/2949, Loss: 0.7507\n",
      "Epoch: 5, Step: 1293/2949, Loss: 0.7623\n",
      "Epoch: 5, Step: 1294/2949, Loss: 0.7399\n",
      "Epoch: 5, Step: 1295/2949, Loss: 0.7583\n",
      "Epoch: 5, Step: 1296/2949, Loss: 0.7385\n",
      "Epoch: 5, Step: 1297/2949, Loss: 0.7403\n",
      "Epoch: 5, Step: 1298/2949, Loss: 0.7487\n",
      "Epoch: 5, Step: 1299/2949, Loss: 0.7433\n",
      "Epoch: 5, Step: 1300/2949, Loss: 0.7122\n",
      "Epoch: 5, Step: 1301/2949, Loss: 0.7463\n",
      "Epoch: 5, Step: 1302/2949, Loss: 0.7743\n",
      "Epoch: 5, Step: 1303/2949, Loss: 0.7594\n",
      "Epoch: 5, Step: 1304/2949, Loss: 0.7613\n",
      "Epoch: 5, Step: 1305/2949, Loss: 0.7477\n",
      "Epoch: 5, Step: 1306/2949, Loss: 0.7172\n",
      "Epoch: 5, Step: 1307/2949, Loss: 0.7403\n",
      "Epoch: 5, Step: 1308/2949, Loss: 0.7511\n",
      "Epoch: 5, Step: 1309/2949, Loss: 0.7138\n",
      "Epoch: 5, Step: 1310/2949, Loss: 0.7307\n",
      "Epoch: 5, Step: 1311/2949, Loss: 0.7131\n",
      "Epoch: 5, Step: 1312/2949, Loss: 0.7465\n",
      "Epoch: 5, Step: 1313/2949, Loss: 0.7440\n",
      "Epoch: 5, Step: 1314/2949, Loss: 0.6699\n",
      "Epoch: 5, Step: 1315/2949, Loss: 0.7382\n",
      "Epoch: 5, Step: 1316/2949, Loss: 0.7614\n",
      "Epoch: 5, Step: 1317/2949, Loss: 0.7386\n",
      "Epoch: 5, Step: 1318/2949, Loss: 0.7436\n",
      "Epoch: 5, Step: 1319/2949, Loss: 0.7681\n",
      "Epoch: 5, Step: 1320/2949, Loss: 0.6915\n",
      "Epoch: 5, Step: 1321/2949, Loss: 0.7572\n",
      "Epoch: 5, Step: 1322/2949, Loss: 0.6937\n",
      "Epoch: 5, Step: 1323/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 1324/2949, Loss: 0.7392\n",
      "Epoch: 5, Step: 1325/2949, Loss: 0.7638\n",
      "Epoch: 5, Step: 1326/2949, Loss: 0.7377\n",
      "Epoch: 5, Step: 1327/2949, Loss: 0.7243\n",
      "Epoch: 5, Step: 1328/2949, Loss: 0.7582\n",
      "Epoch: 5, Step: 1329/2949, Loss: 0.6922\n",
      "Epoch: 5, Step: 1330/2949, Loss: 0.7388\n",
      "Epoch: 5, Step: 1331/2949, Loss: 0.7016\n",
      "Epoch: 5, Step: 1332/2949, Loss: 0.7588\n",
      "Epoch: 5, Step: 1333/2949, Loss: 0.7379\n",
      "Epoch: 5, Step: 1334/2949, Loss: 0.7072\n",
      "Epoch: 5, Step: 1335/2949, Loss: 0.7361\n",
      "Epoch: 5, Step: 1336/2949, Loss: 0.7441\n",
      "Epoch: 5, Step: 1337/2949, Loss: 0.7661\n",
      "Epoch: 5, Step: 1338/2949, Loss: 0.7614\n",
      "Epoch: 5, Step: 1339/2949, Loss: 0.6825\n",
      "Epoch: 5, Step: 1340/2949, Loss: 0.6924\n",
      "Epoch: 5, Step: 1341/2949, Loss: 0.7123\n",
      "Epoch: 5, Step: 1342/2949, Loss: 0.7201\n",
      "Epoch: 5, Step: 1343/2949, Loss: 0.7054\n",
      "Epoch: 5, Step: 1344/2949, Loss: 0.7329\n",
      "Epoch: 5, Step: 1345/2949, Loss: 0.7513\n",
      "Epoch: 5, Step: 1346/2949, Loss: 0.7789\n",
      "Epoch: 5, Step: 1347/2949, Loss: 0.6960\n",
      "Epoch: 5, Step: 1348/2949, Loss: 0.7934\n",
      "Epoch: 5, Step: 1349/2949, Loss: 0.7222\n",
      "Epoch: 5, Step: 1350/2949, Loss: 0.7578\n",
      "Epoch: 5, Step: 1351/2949, Loss: 0.7776\n",
      "Epoch: 5, Step: 1352/2949, Loss: 0.7374\n",
      "Epoch: 5, Step: 1353/2949, Loss: 0.6719\n",
      "Epoch: 5, Step: 1354/2949, Loss: 0.7607\n",
      "Epoch: 5, Step: 1355/2949, Loss: 0.6682\n",
      "Epoch: 5, Step: 1356/2949, Loss: 0.7372\n",
      "Epoch: 5, Step: 1357/2949, Loss: 0.7144\n",
      "Epoch: 5, Step: 1358/2949, Loss: 0.7510\n",
      "Epoch: 5, Step: 1359/2949, Loss: 0.7028\n",
      "Epoch: 5, Step: 1360/2949, Loss: 0.7556\n",
      "Epoch: 5, Step: 1361/2949, Loss: 0.7732\n",
      "Epoch: 5, Step: 1362/2949, Loss: 0.7264\n",
      "Epoch: 5, Step: 1363/2949, Loss: 0.7188\n",
      "Epoch: 5, Step: 1364/2949, Loss: 0.7203\n",
      "Epoch: 5, Step: 1365/2949, Loss: 0.7081\n",
      "Epoch: 5, Step: 1366/2949, Loss: 0.7312\n",
      "Epoch: 5, Step: 1367/2949, Loss: 0.7642\n",
      "Epoch: 5, Step: 1368/2949, Loss: 0.7389\n",
      "Epoch: 5, Step: 1369/2949, Loss: 0.7176\n",
      "Epoch: 5, Step: 1370/2949, Loss: 0.6732\n",
      "Epoch: 5, Step: 1371/2949, Loss: 0.7411\n",
      "Epoch: 5, Step: 1372/2949, Loss: 0.7773\n",
      "Epoch: 5, Step: 1373/2949, Loss: 0.7478\n",
      "Epoch: 5, Step: 1374/2949, Loss: 0.6777\n",
      "Epoch: 5, Step: 1375/2949, Loss: 0.7090\n",
      "Epoch: 5, Step: 1376/2949, Loss: 0.7503\n",
      "Epoch: 5, Step: 1377/2949, Loss: 0.7814\n",
      "Epoch: 5, Step: 1378/2949, Loss: 0.6999\n",
      "Epoch: 5, Step: 1379/2949, Loss: 0.7484\n",
      "Epoch: 5, Step: 1380/2949, Loss: 0.7056\n",
      "Epoch: 5, Step: 1381/2949, Loss: 0.7649\n",
      "Epoch: 5, Step: 1382/2949, Loss: 0.7430\n",
      "Epoch: 5, Step: 1383/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 1384/2949, Loss: 0.7651\n",
      "Epoch: 5, Step: 1385/2949, Loss: 0.7112\n",
      "Epoch: 5, Step: 1386/2949, Loss: 0.7359\n",
      "Epoch: 5, Step: 1387/2949, Loss: 0.7190\n",
      "Epoch: 5, Step: 1388/2949, Loss: 0.6827\n",
      "Epoch: 5, Step: 1389/2949, Loss: 0.7105\n",
      "Epoch: 5, Step: 1390/2949, Loss: 0.7456\n",
      "Epoch: 5, Step: 1391/2949, Loss: 0.7706\n",
      "Epoch: 5, Step: 1392/2949, Loss: 0.7344\n",
      "Epoch: 5, Step: 1393/2949, Loss: 0.6966\n",
      "Epoch: 5, Step: 1394/2949, Loss: 0.7300\n",
      "Epoch: 5, Step: 1395/2949, Loss: 0.7161\n",
      "Epoch: 5, Step: 1396/2949, Loss: 0.7498\n",
      "Epoch: 5, Step: 1397/2949, Loss: 0.7475\n",
      "Epoch: 5, Step: 1398/2949, Loss: 0.8029\n",
      "Epoch: 5, Step: 1399/2949, Loss: 0.6883\n",
      "Epoch: 5, Step: 1400/2949, Loss: 0.7760\n",
      "Epoch: 5, Step: 1401/2949, Loss: 0.7161\n",
      "Epoch: 5, Step: 1402/2949, Loss: 0.6876\n",
      "Epoch: 5, Step: 1403/2949, Loss: 0.6915\n",
      "Epoch: 5, Step: 1404/2949, Loss: 0.7730\n",
      "Epoch: 5, Step: 1405/2949, Loss: 0.7911\n",
      "Epoch: 5, Step: 1406/2949, Loss: 0.7362\n",
      "Epoch: 5, Step: 1407/2949, Loss: 0.7383\n",
      "Epoch: 5, Step: 1408/2949, Loss: 0.7840\n",
      "Epoch: 5, Step: 1409/2949, Loss: 0.7352\n",
      "Epoch: 5, Step: 1410/2949, Loss: 0.7165\n",
      "Epoch: 5, Step: 1411/2949, Loss: 0.7289\n",
      "Epoch: 5, Step: 1412/2949, Loss: 0.7618\n",
      "Epoch: 5, Step: 1413/2949, Loss: 0.7304\n",
      "Epoch: 5, Step: 1414/2949, Loss: 0.7426\n",
      "Epoch: 5, Step: 1415/2949, Loss: 0.7565\n",
      "Epoch: 5, Step: 1416/2949, Loss: 0.7788\n",
      "Epoch: 5, Step: 1417/2949, Loss: 0.7359\n",
      "Epoch: 5, Step: 1418/2949, Loss: 0.7112\n",
      "Epoch: 5, Step: 1419/2949, Loss: 0.7687\n",
      "Epoch: 5, Step: 1420/2949, Loss: 0.7607\n",
      "Epoch: 5, Step: 1421/2949, Loss: 0.7299\n",
      "Epoch: 5, Step: 1422/2949, Loss: 0.7132\n",
      "Epoch: 5, Step: 1423/2949, Loss: 0.6966\n",
      "Epoch: 5, Step: 1424/2949, Loss: 0.7422\n",
      "Epoch: 5, Step: 1425/2949, Loss: 0.7320\n",
      "Epoch: 5, Step: 1426/2949, Loss: 0.6482\n",
      "Epoch: 5, Step: 1427/2949, Loss: 0.7342\n",
      "Epoch: 5, Step: 1428/2949, Loss: 0.6908\n",
      "Epoch: 5, Step: 1429/2949, Loss: 0.7241\n",
      "Epoch: 5, Step: 1430/2949, Loss: 0.7632\n",
      "Epoch: 5, Step: 1431/2949, Loss: 0.7129\n",
      "Epoch: 5, Step: 1432/2949, Loss: 0.7104\n",
      "Epoch: 5, Step: 1433/2949, Loss: 0.7185\n",
      "Epoch: 5, Step: 1434/2949, Loss: 0.7618\n",
      "Epoch: 5, Step: 1435/2949, Loss: 0.7226\n",
      "Epoch: 5, Step: 1436/2949, Loss: 0.7453\n",
      "Epoch: 5, Step: 1437/2949, Loss: 0.7060\n",
      "Epoch: 5, Step: 1438/2949, Loss: 0.7364\n",
      "Epoch: 5, Step: 1439/2949, Loss: 0.7381\n",
      "Epoch: 5, Step: 1440/2949, Loss: 0.7467\n",
      "Epoch: 5, Step: 1441/2949, Loss: 0.7604\n",
      "Epoch: 5, Step: 1442/2949, Loss: 0.7521\n",
      "Epoch: 5, Step: 1443/2949, Loss: 0.7546\n",
      "Epoch: 5, Step: 1444/2949, Loss: 0.7653\n",
      "Epoch: 5, Step: 1445/2949, Loss: 0.7533\n",
      "Epoch: 5, Step: 1446/2949, Loss: 0.7506\n",
      "Epoch: 5, Step: 1447/2949, Loss: 0.7399\n",
      "Epoch: 5, Step: 1448/2949, Loss: 0.7456\n",
      "Epoch: 5, Step: 1449/2949, Loss: 0.7412\n",
      "Epoch: 5, Step: 1450/2949, Loss: 0.7586\n",
      "Epoch: 5, Step: 1451/2949, Loss: 0.8077\n",
      "Epoch: 5, Step: 1452/2949, Loss: 0.7624\n",
      "Epoch: 5, Step: 1453/2949, Loss: 0.6797\n",
      "Epoch: 5, Step: 1454/2949, Loss: 0.7310\n",
      "Epoch: 5, Step: 1455/2949, Loss: 0.7966\n",
      "Epoch: 5, Step: 1456/2949, Loss: 0.7489\n",
      "Epoch: 5, Step: 1457/2949, Loss: 0.7207\n",
      "Epoch: 5, Step: 1458/2949, Loss: 0.7192\n",
      "Epoch: 5, Step: 1459/2949, Loss: 0.7466\n",
      "Epoch: 5, Step: 1460/2949, Loss: 0.7395\n",
      "Epoch: 5, Step: 1461/2949, Loss: 0.7522\n",
      "Epoch: 5, Step: 1462/2949, Loss: 0.7301\n",
      "Epoch: 5, Step: 1463/2949, Loss: 0.7815\n",
      "Epoch: 5, Step: 1464/2949, Loss: 0.7291\n",
      "Epoch: 5, Step: 1465/2949, Loss: 0.7351\n",
      "Epoch: 5, Step: 1466/2949, Loss: 0.7644\n",
      "Epoch: 5, Step: 1467/2949, Loss: 0.7479\n",
      "Epoch: 5, Step: 1468/2949, Loss: 0.7071\n",
      "Epoch: 5, Step: 1469/2949, Loss: 0.6937\n",
      "Epoch: 5, Step: 1470/2949, Loss: 0.7303\n",
      "Epoch: 5, Step: 1471/2949, Loss: 0.7385\n",
      "Epoch: 5, Step: 1472/2949, Loss: 0.7298\n",
      "Epoch: 5, Step: 1473/2949, Loss: 0.7675\n",
      "Epoch: 5, Step: 1474/2949, Loss: 0.7656\n",
      "Epoch: 5, Step: 1475/2949, Loss: 0.6807\n",
      "Epoch: 5, Step: 1476/2949, Loss: 0.7516\n",
      "Epoch: 5, Step: 1477/2949, Loss: 0.7587\n",
      "Epoch: 5, Step: 1478/2949, Loss: 0.7569\n",
      "Epoch: 5, Step: 1479/2949, Loss: 0.7776\n",
      "Epoch: 5, Step: 1480/2949, Loss: 0.7051\n",
      "Epoch: 5, Step: 1481/2949, Loss: 0.7118\n",
      "Epoch: 5, Step: 1482/2949, Loss: 0.7247\n",
      "Epoch: 5, Step: 1483/2949, Loss: 0.7711\n",
      "Epoch: 5, Step: 1484/2949, Loss: 0.7169\n",
      "Epoch: 5, Step: 1485/2949, Loss: 0.7044\n",
      "Epoch: 5, Step: 1486/2949, Loss: 0.6996\n",
      "Epoch: 5, Step: 1487/2949, Loss: 0.6995\n",
      "Epoch: 5, Step: 1488/2949, Loss: 0.7856\n",
      "Epoch: 5, Step: 1489/2949, Loss: 0.7454\n",
      "Epoch: 5, Step: 1490/2949, Loss: 0.7408\n",
      "Epoch: 5, Step: 1491/2949, Loss: 0.7555\n",
      "Epoch: 5, Step: 1492/2949, Loss: 0.6824\n",
      "Epoch: 5, Step: 1493/2949, Loss: 0.7393\n",
      "Epoch: 5, Step: 1494/2949, Loss: 0.8007\n",
      "Epoch: 5, Step: 1495/2949, Loss: 0.6791\n",
      "Epoch: 5, Step: 1496/2949, Loss: 0.7925\n",
      "Epoch: 5, Step: 1497/2949, Loss: 0.7474\n",
      "Epoch: 5, Step: 1498/2949, Loss: 0.7486\n",
      "Epoch: 5, Step: 1499/2949, Loss: 0.7235\n",
      "Epoch: 5, Step: 1500/2949, Loss: 0.7483\n",
      "Epoch: 5, Step: 1501/2949, Loss: 0.7629\n",
      "Epoch: 5, Step: 1502/2949, Loss: 0.6560\n",
      "Epoch: 5, Step: 1503/2949, Loss: 0.7387\n",
      "Epoch: 5, Step: 1504/2949, Loss: 0.7381\n",
      "Epoch: 5, Step: 1505/2949, Loss: 0.7729\n",
      "Epoch: 5, Step: 1506/2949, Loss: 0.7501\n",
      "Epoch: 5, Step: 1507/2949, Loss: 0.7203\n",
      "Epoch: 5, Step: 1508/2949, Loss: 0.7166\n",
      "Epoch: 5, Step: 1509/2949, Loss: 0.7080\n",
      "Epoch: 5, Step: 1510/2949, Loss: 0.7345\n",
      "Epoch: 5, Step: 1511/2949, Loss: 0.7705\n",
      "Epoch: 5, Step: 1512/2949, Loss: 0.7303\n",
      "Epoch: 5, Step: 1513/2949, Loss: 0.7028\n",
      "Epoch: 5, Step: 1514/2949, Loss: 0.6673\n",
      "Epoch: 5, Step: 1515/2949, Loss: 0.7579\n",
      "Epoch: 5, Step: 1516/2949, Loss: 0.6847\n",
      "Epoch: 5, Step: 1517/2949, Loss: 0.7397\n",
      "Epoch: 5, Step: 1518/2949, Loss: 0.7212\n",
      "Epoch: 5, Step: 1519/2949, Loss: 0.7173\n",
      "Epoch: 5, Step: 1520/2949, Loss: 0.7322\n",
      "Epoch: 5, Step: 1521/2949, Loss: 0.7304\n",
      "Epoch: 5, Step: 1522/2949, Loss: 0.7816\n",
      "Epoch: 5, Step: 1523/2949, Loss: 0.6947\n",
      "Epoch: 5, Step: 1524/2949, Loss: 0.6872\n",
      "Epoch: 5, Step: 1525/2949, Loss: 0.7081\n",
      "Epoch: 5, Step: 1526/2949, Loss: 0.7797\n",
      "Epoch: 5, Step: 1527/2949, Loss: 0.7711\n",
      "Epoch: 5, Step: 1528/2949, Loss: 0.7386\n",
      "Epoch: 5, Step: 1529/2949, Loss: 0.7985\n",
      "Epoch: 5, Step: 1530/2949, Loss: 0.6952\n",
      "Epoch: 5, Step: 1531/2949, Loss: 0.7129\n",
      "Epoch: 5, Step: 1532/2949, Loss: 0.7352\n",
      "Epoch: 5, Step: 1533/2949, Loss: 0.7149\n",
      "Epoch: 5, Step: 1534/2949, Loss: 0.7604\n",
      "Epoch: 5, Step: 1535/2949, Loss: 0.6879\n",
      "Epoch: 5, Step: 1536/2949, Loss: 0.7258\n",
      "Epoch: 5, Step: 1537/2949, Loss: 0.7464\n",
      "Epoch: 5, Step: 1538/2949, Loss: 0.7395\n",
      "Epoch: 5, Step: 1539/2949, Loss: 0.7061\n",
      "Epoch: 5, Step: 1540/2949, Loss: 0.7784\n",
      "Epoch: 5, Step: 1541/2949, Loss: 0.7465\n",
      "Epoch: 5, Step: 1542/2949, Loss: 0.7600\n",
      "Epoch: 5, Step: 1543/2949, Loss: 0.7386\n",
      "Epoch: 5, Step: 1544/2949, Loss: 0.7455\n",
      "Epoch: 5, Step: 1545/2949, Loss: 0.7008\n",
      "Epoch: 5, Step: 1546/2949, Loss: 0.7068\n",
      "Epoch: 5, Step: 1547/2949, Loss: 0.7249\n",
      "Epoch: 5, Step: 1548/2949, Loss: 0.7343\n",
      "Epoch: 5, Step: 1549/2949, Loss: 0.7673\n",
      "Epoch: 5, Step: 1550/2949, Loss: 0.7431\n",
      "Epoch: 5, Step: 1551/2949, Loss: 0.7380\n",
      "Epoch: 5, Step: 1552/2949, Loss: 0.7258\n",
      "Epoch: 5, Step: 1553/2949, Loss: 0.7167\n",
      "Epoch: 5, Step: 1554/2949, Loss: 0.7708\n",
      "Epoch: 5, Step: 1555/2949, Loss: 0.7312\n",
      "Epoch: 5, Step: 1556/2949, Loss: 0.7983\n",
      "Epoch: 5, Step: 1557/2949, Loss: 0.7734\n",
      "Epoch: 5, Step: 1558/2949, Loss: 0.7406\n",
      "Epoch: 5, Step: 1559/2949, Loss: 0.7208\n",
      "Epoch: 5, Step: 1560/2949, Loss: 0.6793\n",
      "Epoch: 5, Step: 1561/2949, Loss: 0.7188\n",
      "Epoch: 5, Step: 1562/2949, Loss: 0.7474\n",
      "Epoch: 5, Step: 1563/2949, Loss: 0.7238\n",
      "Epoch: 5, Step: 1564/2949, Loss: 0.7738\n",
      "Epoch: 5, Step: 1565/2949, Loss: 0.7146\n",
      "Epoch: 5, Step: 1566/2949, Loss: 0.6515\n",
      "Epoch: 5, Step: 1567/2949, Loss: 0.7021\n",
      "Epoch: 5, Step: 1568/2949, Loss: 0.7000\n",
      "Epoch: 5, Step: 1569/2949, Loss: 0.7478\n",
      "Epoch: 5, Step: 1570/2949, Loss: 0.7439\n",
      "Epoch: 5, Step: 1571/2949, Loss: 0.7148\n",
      "Epoch: 5, Step: 1572/2949, Loss: 0.7696\n",
      "Epoch: 5, Step: 1573/2949, Loss: 0.7596\n",
      "Epoch: 5, Step: 1574/2949, Loss: 0.7572\n",
      "Epoch: 5, Step: 1575/2949, Loss: 0.7323\n",
      "Epoch: 5, Step: 1576/2949, Loss: 0.7919\n",
      "Epoch: 5, Step: 1577/2949, Loss: 0.7199\n",
      "Epoch: 5, Step: 1578/2949, Loss: 0.7547\n",
      "Epoch: 5, Step: 1579/2949, Loss: 0.7837\n",
      "Epoch: 5, Step: 1580/2949, Loss: 0.7103\n",
      "Epoch: 5, Step: 1581/2949, Loss: 0.7217\n",
      "Epoch: 5, Step: 1582/2949, Loss: 0.7380\n",
      "Epoch: 5, Step: 1583/2949, Loss: 0.7575\n",
      "Epoch: 5, Step: 1584/2949, Loss: 0.7333\n",
      "Epoch: 5, Step: 1585/2949, Loss: 0.7579\n",
      "Epoch: 5, Step: 1586/2949, Loss: 0.7682\n",
      "Epoch: 5, Step: 1587/2949, Loss: 0.7639\n",
      "Epoch: 5, Step: 1588/2949, Loss: 0.7014\n",
      "Epoch: 5, Step: 1589/2949, Loss: 0.7340\n",
      "Epoch: 5, Step: 1590/2949, Loss: 0.7311\n",
      "Epoch: 5, Step: 1591/2949, Loss: 0.7389\n",
      "Epoch: 5, Step: 1592/2949, Loss: 0.7247\n",
      "Epoch: 5, Step: 1593/2949, Loss: 0.7625\n",
      "Epoch: 5, Step: 1594/2949, Loss: 0.7403\n",
      "Epoch: 5, Step: 1595/2949, Loss: 0.7369\n",
      "Epoch: 5, Step: 1596/2949, Loss: 0.7200\n",
      "Epoch: 5, Step: 1597/2949, Loss: 0.7360\n",
      "Epoch: 5, Step: 1598/2949, Loss: 0.7214\n",
      "Epoch: 5, Step: 1599/2949, Loss: 0.7616\n",
      "Epoch: 5, Step: 1600/2949, Loss: 0.7459\n",
      "Epoch: 5, Step: 1601/2949, Loss: 0.7883\n",
      "Epoch: 5, Step: 1602/2949, Loss: 0.7450\n",
      "Epoch: 5, Step: 1603/2949, Loss: 0.7116\n",
      "Epoch: 5, Step: 1604/2949, Loss: 0.6962\n",
      "Epoch: 5, Step: 1605/2949, Loss: 0.7475\n",
      "Epoch: 5, Step: 1606/2949, Loss: 0.7436\n",
      "Epoch: 5, Step: 1607/2949, Loss: 0.7373\n",
      "Epoch: 5, Step: 1608/2949, Loss: 0.7403\n",
      "Epoch: 5, Step: 1609/2949, Loss: 0.7393\n",
      "Epoch: 5, Step: 1610/2949, Loss: 0.7123\n",
      "Epoch: 5, Step: 1611/2949, Loss: 0.6968\n",
      "Epoch: 5, Step: 1612/2949, Loss: 0.7310\n",
      "Epoch: 5, Step: 1613/2949, Loss: 0.7501\n",
      "Epoch: 5, Step: 1614/2949, Loss: 0.6788\n",
      "Epoch: 5, Step: 1615/2949, Loss: 0.7396\n",
      "Epoch: 5, Step: 1616/2949, Loss: 0.7681\n",
      "Epoch: 5, Step: 1617/2949, Loss: 0.6991\n",
      "Epoch: 5, Step: 1618/2949, Loss: 0.7439\n",
      "Epoch: 5, Step: 1619/2949, Loss: 0.7651\n",
      "Epoch: 5, Step: 1620/2949, Loss: 0.7536\n",
      "Epoch: 5, Step: 1621/2949, Loss: 0.7068\n",
      "Epoch: 5, Step: 1622/2949, Loss: 0.7322\n",
      "Epoch: 5, Step: 1623/2949, Loss: 0.7211\n",
      "Epoch: 5, Step: 1624/2949, Loss: 0.7378\n",
      "Epoch: 5, Step: 1625/2949, Loss: 0.7286\n",
      "Epoch: 5, Step: 1626/2949, Loss: 0.7686\n",
      "Epoch: 5, Step: 1627/2949, Loss: 0.6834\n",
      "Epoch: 5, Step: 1628/2949, Loss: 0.7396\n",
      "Epoch: 5, Step: 1629/2949, Loss: 0.7079\n",
      "Epoch: 5, Step: 1630/2949, Loss: 0.7725\n",
      "Epoch: 5, Step: 1631/2949, Loss: 0.6913\n",
      "Epoch: 5, Step: 1632/2949, Loss: 0.7357\n",
      "Epoch: 5, Step: 1633/2949, Loss: 0.6911\n",
      "Epoch: 5, Step: 1634/2949, Loss: 0.7191\n",
      "Epoch: 5, Step: 1635/2949, Loss: 0.7375\n",
      "Epoch: 5, Step: 1636/2949, Loss: 0.7305\n",
      "Epoch: 5, Step: 1637/2949, Loss: 0.7161\n",
      "Epoch: 5, Step: 1638/2949, Loss: 0.7392\n",
      "Epoch: 5, Step: 1639/2949, Loss: 0.7183\n",
      "Epoch: 5, Step: 1640/2949, Loss: 0.7049\n",
      "Epoch: 5, Step: 1641/2949, Loss: 0.7400\n",
      "Epoch: 5, Step: 1642/2949, Loss: 0.7586\n",
      "Epoch: 5, Step: 1643/2949, Loss: 0.7239\n",
      "Epoch: 5, Step: 1644/2949, Loss: 0.7551\n",
      "Epoch: 5, Step: 1645/2949, Loss: 0.7396\n",
      "Epoch: 5, Step: 1646/2949, Loss: 0.7006\n",
      "Epoch: 5, Step: 1647/2949, Loss: 0.7791\n",
      "Epoch: 5, Step: 1648/2949, Loss: 0.6991\n",
      "Epoch: 5, Step: 1649/2949, Loss: 0.7554\n",
      "Epoch: 5, Step: 1650/2949, Loss: 0.8245\n",
      "Epoch: 5, Step: 1651/2949, Loss: 0.7624\n",
      "Epoch: 5, Step: 1652/2949, Loss: 0.8230\n",
      "Epoch: 5, Step: 1653/2949, Loss: 0.7434\n",
      "Epoch: 5, Step: 1654/2949, Loss: 0.7293\n",
      "Epoch: 5, Step: 1655/2949, Loss: 0.7140\n",
      "Epoch: 5, Step: 1656/2949, Loss: 0.7442\n",
      "Epoch: 5, Step: 1657/2949, Loss: 0.7338\n",
      "Epoch: 5, Step: 1658/2949, Loss: 0.7345\n",
      "Epoch: 5, Step: 1659/2949, Loss: 0.7457\n",
      "Epoch: 5, Step: 1660/2949, Loss: 0.7378\n",
      "Epoch: 5, Step: 1661/2949, Loss: 0.7468\n",
      "Epoch: 5, Step: 1662/2949, Loss: 0.7388\n",
      "Epoch: 5, Step: 1663/2949, Loss: 0.7795\n",
      "Epoch: 5, Step: 1664/2949, Loss: 0.7416\n",
      "Epoch: 5, Step: 1665/2949, Loss: 0.7201\n",
      "Epoch: 5, Step: 1666/2949, Loss: 0.7406\n",
      "Epoch: 5, Step: 1667/2949, Loss: 0.7318\n",
      "Epoch: 5, Step: 1668/2949, Loss: 0.7829\n",
      "Epoch: 5, Step: 1669/2949, Loss: 0.7222\n",
      "Epoch: 5, Step: 1670/2949, Loss: 0.7617\n",
      "Epoch: 5, Step: 1671/2949, Loss: 0.7106\n",
      "Epoch: 5, Step: 1672/2949, Loss: 0.7296\n",
      "Epoch: 5, Step: 1673/2949, Loss: 0.7398\n",
      "Epoch: 5, Step: 1674/2949, Loss: 0.7456\n",
      "Epoch: 5, Step: 1675/2949, Loss: 0.7665\n",
      "Epoch: 5, Step: 1676/2949, Loss: 0.7891\n",
      "Epoch: 5, Step: 1677/2949, Loss: 0.7593\n",
      "Epoch: 5, Step: 1678/2949, Loss: 0.7699\n",
      "Epoch: 5, Step: 1679/2949, Loss: 0.6784\n",
      "Epoch: 5, Step: 1680/2949, Loss: 0.7531\n",
      "Epoch: 5, Step: 1681/2949, Loss: 0.7028\n",
      "Epoch: 5, Step: 1682/2949, Loss: 0.7526\n",
      "Epoch: 5, Step: 1683/2949, Loss: 0.7167\n",
      "Epoch: 5, Step: 1684/2949, Loss: 0.7466\n",
      "Epoch: 5, Step: 1685/2949, Loss: 0.7378\n",
      "Epoch: 5, Step: 1686/2949, Loss: 0.7328\n",
      "Epoch: 5, Step: 1687/2949, Loss: 0.7286\n",
      "Epoch: 5, Step: 1688/2949, Loss: 0.7560\n",
      "Epoch: 5, Step: 1689/2949, Loss: 0.7882\n",
      "Epoch: 5, Step: 1690/2949, Loss: 0.6906\n",
      "Epoch: 5, Step: 1691/2949, Loss: 0.7531\n",
      "Epoch: 5, Step: 1692/2949, Loss: 0.7512\n",
      "Epoch: 5, Step: 1693/2949, Loss: 0.7501\n",
      "Epoch: 5, Step: 1694/2949, Loss: 0.7511\n",
      "Epoch: 5, Step: 1695/2949, Loss: 0.7819\n",
      "Epoch: 5, Step: 1696/2949, Loss: 0.7141\n",
      "Epoch: 5, Step: 1697/2949, Loss: 0.6820\n",
      "Epoch: 5, Step: 1698/2949, Loss: 0.7435\n",
      "Epoch: 5, Step: 1699/2949, Loss: 0.7596\n",
      "Epoch: 5, Step: 1700/2949, Loss: 0.7246\n",
      "Epoch: 5, Step: 1701/2949, Loss: 0.7011\n",
      "Epoch: 5, Step: 1702/2949, Loss: 0.7567\n",
      "Epoch: 5, Step: 1703/2949, Loss: 0.6809\n",
      "Epoch: 5, Step: 1704/2949, Loss: 0.7243\n",
      "Epoch: 5, Step: 1705/2949, Loss: 0.7547\n",
      "Epoch: 5, Step: 1706/2949, Loss: 0.7365\n",
      "Epoch: 5, Step: 1707/2949, Loss: 0.7082\n",
      "Epoch: 5, Step: 1708/2949, Loss: 0.8011\n",
      "Epoch: 5, Step: 1709/2949, Loss: 0.7718\n",
      "Epoch: 5, Step: 1710/2949, Loss: 0.7164\n",
      "Epoch: 5, Step: 1711/2949, Loss: 0.7053\n",
      "Epoch: 5, Step: 1712/2949, Loss: 0.7022\n",
      "Epoch: 5, Step: 1713/2949, Loss: 0.6796\n",
      "Epoch: 5, Step: 1714/2949, Loss: 0.7588\n",
      "Epoch: 5, Step: 1715/2949, Loss: 0.7553\n",
      "Epoch: 5, Step: 1716/2949, Loss: 0.7817\n",
      "Epoch: 5, Step: 1717/2949, Loss: 0.7962\n",
      "Epoch: 5, Step: 1718/2949, Loss: 0.7379\n",
      "Epoch: 5, Step: 1719/2949, Loss: 0.7365\n",
      "Epoch: 5, Step: 1720/2949, Loss: 0.7451\n",
      "Epoch: 5, Step: 1721/2949, Loss: 0.7215\n",
      "Epoch: 5, Step: 1722/2949, Loss: 0.7068\n",
      "Epoch: 5, Step: 1723/2949, Loss: 0.7241\n",
      "Epoch: 5, Step: 1724/2949, Loss: 0.6998\n",
      "Epoch: 5, Step: 1725/2949, Loss: 0.7229\n",
      "Epoch: 5, Step: 1726/2949, Loss: 0.7737\n",
      "Epoch: 5, Step: 1727/2949, Loss: 0.7462\n",
      "Epoch: 5, Step: 1728/2949, Loss: 0.7444\n",
      "Epoch: 5, Step: 1729/2949, Loss: 0.7439\n",
      "Epoch: 5, Step: 1730/2949, Loss: 0.7469\n",
      "Epoch: 5, Step: 1731/2949, Loss: 0.7001\n",
      "Epoch: 5, Step: 1732/2949, Loss: 0.7228\n",
      "Epoch: 5, Step: 1733/2949, Loss: 0.7247\n",
      "Epoch: 5, Step: 1734/2949, Loss: 0.7472\n",
      "Epoch: 5, Step: 1735/2949, Loss: 0.7519\n",
      "Epoch: 5, Step: 1736/2949, Loss: 0.7645\n",
      "Epoch: 5, Step: 1737/2949, Loss: 0.7383\n",
      "Epoch: 5, Step: 1738/2949, Loss: 0.7837\n",
      "Epoch: 5, Step: 1739/2949, Loss: 0.7039\n",
      "Epoch: 5, Step: 1740/2949, Loss: 0.6999\n",
      "Epoch: 5, Step: 1741/2949, Loss: 0.7151\n",
      "Epoch: 5, Step: 1742/2949, Loss: 0.7285\n",
      "Epoch: 5, Step: 1743/2949, Loss: 0.7464\n",
      "Epoch: 5, Step: 1744/2949, Loss: 0.7414\n",
      "Epoch: 5, Step: 1745/2949, Loss: 0.7195\n",
      "Epoch: 5, Step: 1746/2949, Loss: 0.7538\n",
      "Epoch: 5, Step: 1747/2949, Loss: 0.7739\n",
      "Epoch: 5, Step: 1748/2949, Loss: 0.7518\n",
      "Epoch: 5, Step: 1749/2949, Loss: 0.7402\n",
      "Epoch: 5, Step: 1750/2949, Loss: 0.6877\n",
      "Epoch: 5, Step: 1751/2949, Loss: 0.7224\n",
      "Epoch: 5, Step: 1752/2949, Loss: 0.7733\n",
      "Epoch: 5, Step: 1753/2949, Loss: 0.6875\n",
      "Epoch: 5, Step: 1754/2949, Loss: 0.7786\n",
      "Epoch: 5, Step: 1755/2949, Loss: 0.7667\n",
      "Epoch: 5, Step: 1756/2949, Loss: 0.6744\n",
      "Epoch: 5, Step: 1757/2949, Loss: 0.7360\n",
      "Epoch: 5, Step: 1758/2949, Loss: 0.7297\n",
      "Epoch: 5, Step: 1759/2949, Loss: 0.7117\n",
      "Epoch: 5, Step: 1760/2949, Loss: 0.7597\n",
      "Epoch: 5, Step: 1761/2949, Loss: 0.7287\n",
      "Epoch: 5, Step: 1762/2949, Loss: 0.7560\n",
      "Epoch: 5, Step: 1763/2949, Loss: 0.7488\n",
      "Epoch: 5, Step: 1764/2949, Loss: 0.7864\n",
      "Epoch: 5, Step: 1765/2949, Loss: 0.7486\n",
      "Epoch: 5, Step: 1766/2949, Loss: 0.7529\n",
      "Epoch: 5, Step: 1767/2949, Loss: 0.7530\n",
      "Epoch: 5, Step: 1768/2949, Loss: 0.7032\n",
      "Epoch: 5, Step: 1769/2949, Loss: 0.7221\n",
      "Epoch: 5, Step: 1770/2949, Loss: 0.6965\n",
      "Epoch: 5, Step: 1771/2949, Loss: 0.7648\n",
      "Epoch: 5, Step: 1772/2949, Loss: 0.7330\n",
      "Epoch: 5, Step: 1773/2949, Loss: 0.7565\n",
      "Epoch: 5, Step: 1774/2949, Loss: 0.7354\n",
      "Epoch: 5, Step: 1775/2949, Loss: 0.7397\n",
      "Epoch: 5, Step: 1776/2949, Loss: 0.7218\n",
      "Epoch: 5, Step: 1777/2949, Loss: 0.7484\n",
      "Epoch: 5, Step: 1778/2949, Loss: 0.7258\n",
      "Epoch: 5, Step: 1779/2949, Loss: 0.7640\n",
      "Epoch: 5, Step: 1780/2949, Loss: 0.7371\n",
      "Epoch: 5, Step: 1781/2949, Loss: 0.7045\n",
      "Epoch: 5, Step: 1782/2949, Loss: 0.6882\n",
      "Epoch: 5, Step: 1783/2949, Loss: 0.7797\n",
      "Epoch: 5, Step: 1784/2949, Loss: 0.7582\n",
      "Epoch: 5, Step: 1785/2949, Loss: 0.7106\n",
      "Epoch: 5, Step: 1786/2949, Loss: 0.7399\n",
      "Epoch: 5, Step: 1787/2949, Loss: 0.7238\n",
      "Epoch: 5, Step: 1788/2949, Loss: 0.6826\n",
      "Epoch: 5, Step: 1789/2949, Loss: 0.7583\n",
      "Epoch: 5, Step: 1790/2949, Loss: 0.7167\n",
      "Epoch: 5, Step: 1791/2949, Loss: 0.7578\n",
      "Epoch: 5, Step: 1792/2949, Loss: 0.7247\n",
      "Epoch: 5, Step: 1793/2949, Loss: 0.7402\n",
      "Epoch: 5, Step: 1794/2949, Loss: 0.7490\n",
      "Epoch: 5, Step: 1795/2949, Loss: 0.7420\n",
      "Epoch: 5, Step: 1796/2949, Loss: 0.7712\n",
      "Epoch: 5, Step: 1797/2949, Loss: 0.7166\n",
      "Epoch: 5, Step: 1798/2949, Loss: 0.7973\n",
      "Epoch: 5, Step: 1799/2949, Loss: 0.7822\n",
      "Epoch: 5, Step: 1800/2949, Loss: 0.7226\n",
      "Epoch: 5, Step: 1801/2949, Loss: 0.7567\n",
      "Epoch: 5, Step: 1802/2949, Loss: 0.7861\n",
      "Epoch: 5, Step: 1803/2949, Loss: 0.7533\n",
      "Epoch: 5, Step: 1804/2949, Loss: 0.7470\n",
      "Epoch: 5, Step: 1805/2949, Loss: 0.7369\n",
      "Epoch: 5, Step: 1806/2949, Loss: 0.6979\n",
      "Epoch: 5, Step: 1807/2949, Loss: 0.7180\n",
      "Epoch: 5, Step: 1808/2949, Loss: 0.7409\n",
      "Epoch: 5, Step: 1809/2949, Loss: 0.7268\n",
      "Epoch: 5, Step: 1810/2949, Loss: 0.7617\n",
      "Epoch: 5, Step: 1811/2949, Loss: 0.7301\n",
      "Epoch: 5, Step: 1812/2949, Loss: 0.7126\n",
      "Epoch: 5, Step: 1813/2949, Loss: 0.7551\n",
      "Epoch: 5, Step: 1814/2949, Loss: 0.7531\n",
      "Epoch: 5, Step: 1815/2949, Loss: 0.6913\n",
      "Epoch: 5, Step: 1816/2949, Loss: 0.7825\n",
      "Epoch: 5, Step: 1817/2949, Loss: 0.7526\n",
      "Epoch: 5, Step: 1818/2949, Loss: 0.7565\n",
      "Epoch: 5, Step: 1819/2949, Loss: 0.7428\n",
      "Epoch: 5, Step: 1820/2949, Loss: 0.7243\n",
      "Epoch: 5, Step: 1821/2949, Loss: 0.7143\n",
      "Epoch: 5, Step: 1822/2949, Loss: 0.7173\n",
      "Epoch: 5, Step: 1823/2949, Loss: 0.7315\n",
      "Epoch: 5, Step: 1824/2949, Loss: 0.7824\n",
      "Epoch: 5, Step: 1825/2949, Loss: 0.7184\n",
      "Epoch: 5, Step: 1826/2949, Loss: 0.7414\n",
      "Epoch: 5, Step: 1827/2949, Loss: 0.6832\n",
      "Epoch: 5, Step: 1828/2949, Loss: 0.7180\n",
      "Epoch: 5, Step: 1829/2949, Loss: 0.7539\n",
      "Epoch: 5, Step: 1830/2949, Loss: 0.7665\n",
      "Epoch: 5, Step: 1831/2949, Loss: 0.7893\n",
      "Epoch: 5, Step: 1832/2949, Loss: 0.7780\n",
      "Epoch: 5, Step: 1833/2949, Loss: 0.7075\n",
      "Epoch: 5, Step: 1834/2949, Loss: 0.6803\n",
      "Epoch: 5, Step: 1835/2949, Loss: 0.6730\n",
      "Epoch: 5, Step: 1836/2949, Loss: 0.7531\n",
      "Epoch: 5, Step: 1837/2949, Loss: 0.7517\n",
      "Epoch: 5, Step: 1838/2949, Loss: 0.8094\n",
      "Epoch: 5, Step: 1839/2949, Loss: 0.7193\n",
      "Epoch: 5, Step: 1840/2949, Loss: 0.7282\n",
      "Epoch: 5, Step: 1841/2949, Loss: 0.7450\n",
      "Epoch: 5, Step: 1842/2949, Loss: 0.7351\n",
      "Epoch: 5, Step: 1843/2949, Loss: 0.7277\n",
      "Epoch: 5, Step: 1844/2949, Loss: 0.7404\n",
      "Epoch: 5, Step: 1845/2949, Loss: 0.7500\n",
      "Epoch: 5, Step: 1846/2949, Loss: 0.7207\n",
      "Epoch: 5, Step: 1847/2949, Loss: 0.7659\n",
      "Epoch: 5, Step: 1848/2949, Loss: 0.7370\n",
      "Epoch: 5, Step: 1849/2949, Loss: 0.7468\n",
      "Epoch: 5, Step: 1850/2949, Loss: 0.7336\n",
      "Epoch: 5, Step: 1851/2949, Loss: 0.7045\n",
      "Epoch: 5, Step: 1852/2949, Loss: 0.7478\n",
      "Epoch: 5, Step: 1853/2949, Loss: 0.7457\n",
      "Epoch: 5, Step: 1854/2949, Loss: 0.7217\n",
      "Epoch: 5, Step: 1855/2949, Loss: 0.6933\n",
      "Epoch: 5, Step: 1856/2949, Loss: 0.7420\n",
      "Epoch: 5, Step: 1857/2949, Loss: 0.7527\n",
      "Epoch: 5, Step: 1858/2949, Loss: 0.7170\n",
      "Epoch: 5, Step: 1859/2949, Loss: 0.7368\n",
      "Epoch: 5, Step: 1860/2949, Loss: 0.7299\n",
      "Epoch: 5, Step: 1861/2949, Loss: 0.7082\n",
      "Epoch: 5, Step: 1862/2949, Loss: 0.7647\n",
      "Epoch: 5, Step: 1863/2949, Loss: 0.7199\n",
      "Epoch: 5, Step: 1864/2949, Loss: 0.7300\n",
      "Epoch: 5, Step: 1865/2949, Loss: 0.7041\n",
      "Epoch: 5, Step: 1866/2949, Loss: 0.7273\n",
      "Epoch: 5, Step: 1867/2949, Loss: 0.7353\n",
      "Epoch: 5, Step: 1868/2949, Loss: 0.7485\n",
      "Epoch: 5, Step: 1869/2949, Loss: 0.7348\n",
      "Epoch: 5, Step: 1870/2949, Loss: 0.7453\n",
      "Epoch: 5, Step: 1871/2949, Loss: 0.7121\n",
      "Epoch: 5, Step: 1872/2949, Loss: 0.7411\n",
      "Epoch: 5, Step: 1873/2949, Loss: 0.7482\n",
      "Epoch: 5, Step: 1874/2949, Loss: 0.7223\n",
      "Epoch: 5, Step: 1875/2949, Loss: 0.7686\n",
      "Epoch: 5, Step: 1876/2949, Loss: 0.7219\n",
      "Epoch: 5, Step: 1877/2949, Loss: 0.7268\n",
      "Epoch: 5, Step: 1878/2949, Loss: 0.7199\n",
      "Epoch: 5, Step: 1879/2949, Loss: 0.7378\n",
      "Epoch: 5, Step: 1880/2949, Loss: 0.7291\n",
      "Epoch: 5, Step: 1881/2949, Loss: 0.7120\n",
      "Epoch: 5, Step: 1882/2949, Loss: 0.7692\n",
      "Epoch: 5, Step: 1883/2949, Loss: 0.7562\n",
      "Epoch: 5, Step: 1884/2949, Loss: 0.7859\n",
      "Epoch: 5, Step: 1885/2949, Loss: 0.7129\n",
      "Epoch: 5, Step: 1886/2949, Loss: 0.7044\n",
      "Epoch: 5, Step: 1887/2949, Loss: 0.7071\n",
      "Epoch: 5, Step: 1888/2949, Loss: 0.6951\n",
      "Epoch: 5, Step: 1889/2949, Loss: 0.7002\n",
      "Epoch: 5, Step: 1890/2949, Loss: 0.7237\n",
      "Epoch: 5, Step: 1891/2949, Loss: 0.7250\n",
      "Epoch: 5, Step: 1892/2949, Loss: 0.7360\n",
      "Epoch: 5, Step: 1893/2949, Loss: 0.6889\n",
      "Epoch: 5, Step: 1894/2949, Loss: 0.6987\n",
      "Epoch: 5, Step: 1895/2949, Loss: 0.7570\n",
      "Epoch: 5, Step: 1896/2949, Loss: 0.7297\n",
      "Epoch: 5, Step: 1897/2949, Loss: 0.7491\n",
      "Epoch: 5, Step: 1898/2949, Loss: 0.7131\n",
      "Epoch: 5, Step: 1899/2949, Loss: 0.7213\n",
      "Epoch: 5, Step: 1900/2949, Loss: 0.7738\n",
      "Epoch: 5, Step: 1901/2949, Loss: 0.7458\n",
      "Epoch: 5, Step: 1902/2949, Loss: 0.7623\n",
      "Epoch: 5, Step: 1903/2949, Loss: 0.7329\n",
      "Epoch: 5, Step: 1904/2949, Loss: 0.7111\n",
      "Epoch: 5, Step: 1905/2949, Loss: 0.7449\n",
      "Epoch: 5, Step: 1906/2949, Loss: 0.7176\n",
      "Epoch: 5, Step: 1907/2949, Loss: 0.7453\n",
      "Epoch: 5, Step: 1908/2949, Loss: 0.7442\n",
      "Epoch: 5, Step: 1909/2949, Loss: 0.7112\n",
      "Epoch: 5, Step: 1910/2949, Loss: 0.7137\n",
      "Epoch: 5, Step: 1911/2949, Loss: 0.6903\n",
      "Epoch: 5, Step: 1912/2949, Loss: 0.7517\n",
      "Epoch: 5, Step: 1913/2949, Loss: 0.7152\n",
      "Epoch: 5, Step: 1914/2949, Loss: 0.6965\n",
      "Epoch: 5, Step: 1915/2949, Loss: 0.7929\n",
      "Epoch: 5, Step: 1916/2949, Loss: 0.7763\n",
      "Epoch: 5, Step: 1917/2949, Loss: 0.7429\n",
      "Epoch: 5, Step: 1918/2949, Loss: 0.7081\n",
      "Epoch: 5, Step: 1919/2949, Loss: 0.7449\n",
      "Epoch: 5, Step: 1920/2949, Loss: 0.6950\n",
      "Epoch: 5, Step: 1921/2949, Loss: 0.7534\n",
      "Epoch: 5, Step: 1922/2949, Loss: 0.7306\n",
      "Epoch: 5, Step: 1923/2949, Loss: 0.7561\n",
      "Epoch: 5, Step: 1924/2949, Loss: 0.7435\n",
      "Epoch: 5, Step: 1925/2949, Loss: 0.7518\n",
      "Epoch: 5, Step: 1926/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 1927/2949, Loss: 0.7378\n",
      "Epoch: 5, Step: 1928/2949, Loss: 0.7311\n",
      "Epoch: 5, Step: 1929/2949, Loss: 0.7348\n",
      "Epoch: 5, Step: 1930/2949, Loss: 0.7088\n",
      "Epoch: 5, Step: 1931/2949, Loss: 0.7749\n",
      "Epoch: 5, Step: 1932/2949, Loss: 0.7569\n",
      "Epoch: 5, Step: 1933/2949, Loss: 0.7790\n",
      "Epoch: 5, Step: 1934/2949, Loss: 0.7582\n",
      "Epoch: 5, Step: 1935/2949, Loss: 0.7344\n",
      "Epoch: 5, Step: 1936/2949, Loss: 0.7637\n",
      "Epoch: 5, Step: 1937/2949, Loss: 0.6995\n",
      "Epoch: 5, Step: 1938/2949, Loss: 0.7347\n",
      "Epoch: 5, Step: 1939/2949, Loss: 0.7331\n",
      "Epoch: 5, Step: 1940/2949, Loss: 0.7479\n",
      "Epoch: 5, Step: 1941/2949, Loss: 0.6984\n",
      "Epoch: 5, Step: 1942/2949, Loss: 0.7158\n",
      "Epoch: 5, Step: 1943/2949, Loss: 0.7358\n",
      "Epoch: 5, Step: 1944/2949, Loss: 0.7963\n",
      "Epoch: 5, Step: 1945/2949, Loss: 0.7467\n",
      "Epoch: 5, Step: 1946/2949, Loss: 0.7711\n",
      "Epoch: 5, Step: 1947/2949, Loss: 0.7434\n",
      "Epoch: 5, Step: 1948/2949, Loss: 0.7579\n",
      "Epoch: 5, Step: 1949/2949, Loss: 0.6993\n",
      "Epoch: 5, Step: 1950/2949, Loss: 0.6980\n",
      "Epoch: 5, Step: 1951/2949, Loss: 0.7960\n",
      "Epoch: 5, Step: 1952/2949, Loss: 0.7276\n",
      "Epoch: 5, Step: 1953/2949, Loss: 0.7686\n",
      "Epoch: 5, Step: 1954/2949, Loss: 0.7539\n",
      "Epoch: 5, Step: 1955/2949, Loss: 0.7728\n",
      "Epoch: 5, Step: 1956/2949, Loss: 0.7013\n",
      "Epoch: 5, Step: 1957/2949, Loss: 0.6886\n",
      "Epoch: 5, Step: 1958/2949, Loss: 0.7287\n",
      "Epoch: 5, Step: 1959/2949, Loss: 0.7639\n",
      "Epoch: 5, Step: 1960/2949, Loss: 0.7090\n",
      "Epoch: 5, Step: 1961/2949, Loss: 0.7287\n",
      "Epoch: 5, Step: 1962/2949, Loss: 0.7377\n",
      "Epoch: 5, Step: 1963/2949, Loss: 0.7922\n",
      "Epoch: 5, Step: 1964/2949, Loss: 0.6317\n",
      "Epoch: 5, Step: 1965/2949, Loss: 0.7443\n",
      "Epoch: 5, Step: 1966/2949, Loss: 0.7396\n",
      "Epoch: 5, Step: 1967/2949, Loss: 0.7820\n",
      "Epoch: 5, Step: 1968/2949, Loss: 0.7707\n",
      "Epoch: 5, Step: 1969/2949, Loss: 0.7267\n",
      "Epoch: 5, Step: 1970/2949, Loss: 0.7582\n",
      "Epoch: 5, Step: 1971/2949, Loss: 0.7622\n",
      "Epoch: 5, Step: 1972/2949, Loss: 0.7369\n",
      "Epoch: 5, Step: 1973/2949, Loss: 0.7149\n",
      "Epoch: 5, Step: 1974/2949, Loss: 0.7378\n",
      "Epoch: 5, Step: 1975/2949, Loss: 0.7600\n",
      "Epoch: 5, Step: 1976/2949, Loss: 0.7591\n",
      "Epoch: 5, Step: 1977/2949, Loss: 0.7616\n",
      "Epoch: 5, Step: 1978/2949, Loss: 0.7990\n",
      "Epoch: 5, Step: 1979/2949, Loss: 0.7016\n",
      "Epoch: 5, Step: 1980/2949, Loss: 0.7053\n",
      "Epoch: 5, Step: 1981/2949, Loss: 0.7511\n",
      "Epoch: 5, Step: 1982/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 1983/2949, Loss: 0.7688\n",
      "Epoch: 5, Step: 1984/2949, Loss: 0.7538\n",
      "Epoch: 5, Step: 1985/2949, Loss: 0.7189\n",
      "Epoch: 5, Step: 1986/2949, Loss: 0.7895\n",
      "Epoch: 5, Step: 1987/2949, Loss: 0.6951\n",
      "Epoch: 5, Step: 1988/2949, Loss: 0.7416\n",
      "Epoch: 5, Step: 1989/2949, Loss: 0.7165\n",
      "Epoch: 5, Step: 1990/2949, Loss: 0.7379\n",
      "Epoch: 5, Step: 1991/2949, Loss: 0.7375\n",
      "Epoch: 5, Step: 1992/2949, Loss: 0.7130\n",
      "Epoch: 5, Step: 1993/2949, Loss: 0.7520\n",
      "Epoch: 5, Step: 1994/2949, Loss: 0.7367\n",
      "Epoch: 5, Step: 1995/2949, Loss: 0.7444\n",
      "Epoch: 5, Step: 1996/2949, Loss: 0.7418\n",
      "Epoch: 5, Step: 1997/2949, Loss: 0.7590\n",
      "Epoch: 5, Step: 1998/2949, Loss: 0.7174\n",
      "Epoch: 5, Step: 1999/2949, Loss: 0.7806\n",
      "Epoch: 5, Step: 2000/2949, Loss: 0.7270\n",
      "Epoch: 5, Step: 2001/2949, Loss: 0.7962\n",
      "Epoch: 5, Step: 2002/2949, Loss: 0.7170\n",
      "Epoch: 5, Step: 2003/2949, Loss: 0.7604\n",
      "Epoch: 5, Step: 2004/2949, Loss: 0.7143\n",
      "Epoch: 5, Step: 2005/2949, Loss: 0.7524\n",
      "Epoch: 5, Step: 2006/2949, Loss: 0.7101\n",
      "Epoch: 5, Step: 2007/2949, Loss: 0.7237\n",
      "Epoch: 5, Step: 2008/2949, Loss: 0.7581\n",
      "Epoch: 5, Step: 2009/2949, Loss: 0.7307\n",
      "Epoch: 5, Step: 2010/2949, Loss: 0.7074\n",
      "Epoch: 5, Step: 2011/2949, Loss: 0.7663\n",
      "Epoch: 5, Step: 2012/2949, Loss: 0.6865\n",
      "Epoch: 5, Step: 2013/2949, Loss: 0.7334\n",
      "Epoch: 5, Step: 2014/2949, Loss: 0.7309\n",
      "Epoch: 5, Step: 2015/2949, Loss: 0.6985\n",
      "Epoch: 5, Step: 2016/2949, Loss: 0.6895\n",
      "Epoch: 5, Step: 2017/2949, Loss: 0.8336\n",
      "Epoch: 5, Step: 2018/2949, Loss: 0.7103\n",
      "Epoch: 5, Step: 2019/2949, Loss: 0.7123\n",
      "Epoch: 5, Step: 2020/2949, Loss: 0.7213\n",
      "Epoch: 5, Step: 2021/2949, Loss: 0.7213\n",
      "Epoch: 5, Step: 2022/2949, Loss: 0.7134\n",
      "Epoch: 5, Step: 2023/2949, Loss: 0.6885\n",
      "Epoch: 5, Step: 2024/2949, Loss: 0.7512\n",
      "Epoch: 5, Step: 2025/2949, Loss: 0.7095\n",
      "Epoch: 5, Step: 2026/2949, Loss: 0.7779\n",
      "Epoch: 5, Step: 2027/2949, Loss: 0.7052\n",
      "Epoch: 5, Step: 2028/2949, Loss: 0.6791\n",
      "Epoch: 5, Step: 2029/2949, Loss: 0.7491\n",
      "Epoch: 5, Step: 2030/2949, Loss: 0.7267\n",
      "Epoch: 5, Step: 2031/2949, Loss: 0.7346\n",
      "Epoch: 5, Step: 2032/2949, Loss: 0.7380\n",
      "Epoch: 5, Step: 2033/2949, Loss: 0.7649\n",
      "Epoch: 5, Step: 2034/2949, Loss: 0.7009\n",
      "Epoch: 5, Step: 2035/2949, Loss: 0.7489\n",
      "Epoch: 5, Step: 2036/2949, Loss: 0.6894\n",
      "Epoch: 5, Step: 2037/2949, Loss: 0.7689\n",
      "Epoch: 5, Step: 2038/2949, Loss: 0.7210\n",
      "Epoch: 5, Step: 2039/2949, Loss: 0.7273\n",
      "Epoch: 5, Step: 2040/2949, Loss: 0.7030\n",
      "Epoch: 5, Step: 2041/2949, Loss: 0.7142\n",
      "Epoch: 5, Step: 2042/2949, Loss: 0.7480\n",
      "Epoch: 5, Step: 2043/2949, Loss: 0.8060\n",
      "Epoch: 5, Step: 2044/2949, Loss: 0.7135\n",
      "Epoch: 5, Step: 2045/2949, Loss: 0.7969\n",
      "Epoch: 5, Step: 2046/2949, Loss: 0.7219\n",
      "Epoch: 5, Step: 2047/2949, Loss: 0.7284\n",
      "Epoch: 5, Step: 2048/2949, Loss: 0.7723\n",
      "Epoch: 5, Step: 2049/2949, Loss: 0.7545\n",
      "Epoch: 5, Step: 2050/2949, Loss: 0.7304\n",
      "Epoch: 5, Step: 2051/2949, Loss: 0.7024\n",
      "Epoch: 5, Step: 2052/2949, Loss: 0.6747\n",
      "Epoch: 5, Step: 2053/2949, Loss: 0.7170\n",
      "Epoch: 5, Step: 2054/2949, Loss: 0.7500\n",
      "Epoch: 5, Step: 2055/2949, Loss: 0.7618\n",
      "Epoch: 5, Step: 2056/2949, Loss: 0.7199\n",
      "Epoch: 5, Step: 2057/2949, Loss: 0.6921\n",
      "Epoch: 5, Step: 2058/2949, Loss: 0.7174\n",
      "Epoch: 5, Step: 2059/2949, Loss: 0.7573\n",
      "Epoch: 5, Step: 2060/2949, Loss: 0.7251\n",
      "Epoch: 5, Step: 2061/2949, Loss: 0.7544\n",
      "Epoch: 5, Step: 2062/2949, Loss: 0.7678\n",
      "Epoch: 5, Step: 2063/2949, Loss: 0.8033\n",
      "Epoch: 5, Step: 2064/2949, Loss: 0.7424\n",
      "Epoch: 5, Step: 2065/2949, Loss: 0.7265\n",
      "Epoch: 5, Step: 2066/2949, Loss: 0.7107\n",
      "Epoch: 5, Step: 2067/2949, Loss: 0.7615\n",
      "Epoch: 5, Step: 2068/2949, Loss: 0.7143\n",
      "Epoch: 5, Step: 2069/2949, Loss: 0.7222\n",
      "Epoch: 5, Step: 2070/2949, Loss: 0.7772\n",
      "Epoch: 5, Step: 2071/2949, Loss: 0.7223\n",
      "Epoch: 5, Step: 2072/2949, Loss: 0.7554\n",
      "Epoch: 5, Step: 2073/2949, Loss: 0.7592\n",
      "Epoch: 5, Step: 2074/2949, Loss: 0.7471\n",
      "Epoch: 5, Step: 2075/2949, Loss: 0.7698\n",
      "Epoch: 5, Step: 2076/2949, Loss: 0.7194\n",
      "Epoch: 5, Step: 2077/2949, Loss: 0.6645\n",
      "Epoch: 5, Step: 2078/2949, Loss: 0.7361\n",
      "Epoch: 5, Step: 2079/2949, Loss: 0.7188\n",
      "Epoch: 5, Step: 2080/2949, Loss: 0.7355\n",
      "Epoch: 5, Step: 2081/2949, Loss: 0.6678\n",
      "Epoch: 5, Step: 2082/2949, Loss: 0.7634\n",
      "Epoch: 5, Step: 2083/2949, Loss: 0.7758\n",
      "Epoch: 5, Step: 2084/2949, Loss: 0.7576\n",
      "Epoch: 5, Step: 2085/2949, Loss: 0.7639\n",
      "Epoch: 5, Step: 2086/2949, Loss: 0.7541\n",
      "Epoch: 5, Step: 2087/2949, Loss: 0.7169\n",
      "Epoch: 5, Step: 2088/2949, Loss: 0.6789\n",
      "Epoch: 5, Step: 2089/2949, Loss: 0.7170\n",
      "Epoch: 5, Step: 2090/2949, Loss: 0.7281\n",
      "Epoch: 5, Step: 2091/2949, Loss: 0.7358\n",
      "Epoch: 5, Step: 2092/2949, Loss: 0.7094\n",
      "Epoch: 5, Step: 2093/2949, Loss: 0.7284\n",
      "Epoch: 5, Step: 2094/2949, Loss: 0.7721\n",
      "Epoch: 5, Step: 2095/2949, Loss: 0.7571\n",
      "Epoch: 5, Step: 2096/2949, Loss: 0.7218\n",
      "Epoch: 5, Step: 2097/2949, Loss: 0.7694\n",
      "Epoch: 5, Step: 2098/2949, Loss: 0.6761\n",
      "Epoch: 5, Step: 2099/2949, Loss: 0.7650\n",
      "Epoch: 5, Step: 2100/2949, Loss: 0.6989\n",
      "Epoch: 5, Step: 2101/2949, Loss: 0.7341\n",
      "Epoch: 5, Step: 2102/2949, Loss: 0.7583\n",
      "Epoch: 5, Step: 2103/2949, Loss: 0.7038\n",
      "Epoch: 5, Step: 2104/2949, Loss: 0.7817\n",
      "Epoch: 5, Step: 2105/2949, Loss: 0.7444\n",
      "Epoch: 5, Step: 2106/2949, Loss: 0.7218\n",
      "Epoch: 5, Step: 2107/2949, Loss: 0.7276\n",
      "Epoch: 5, Step: 2108/2949, Loss: 0.7093\n",
      "Epoch: 5, Step: 2109/2949, Loss: 0.7186\n",
      "Epoch: 5, Step: 2110/2949, Loss: 0.6805\n",
      "Epoch: 5, Step: 2111/2949, Loss: 0.7377\n",
      "Epoch: 5, Step: 2112/2949, Loss: 0.7446\n",
      "Epoch: 5, Step: 2113/2949, Loss: 0.7132\n",
      "Epoch: 5, Step: 2114/2949, Loss: 0.7228\n",
      "Epoch: 5, Step: 2115/2949, Loss: 0.7018\n",
      "Epoch: 5, Step: 2116/2949, Loss: 0.7155\n",
      "Epoch: 5, Step: 2117/2949, Loss: 0.7325\n",
      "Epoch: 5, Step: 2118/2949, Loss: 0.7230\n",
      "Epoch: 5, Step: 2119/2949, Loss: 0.7021\n",
      "Epoch: 5, Step: 2120/2949, Loss: 0.7139\n",
      "Epoch: 5, Step: 2121/2949, Loss: 0.7415\n",
      "Epoch: 5, Step: 2122/2949, Loss: 0.7328\n",
      "Epoch: 5, Step: 2123/2949, Loss: 0.7438\n",
      "Epoch: 5, Step: 2124/2949, Loss: 0.7279\n",
      "Epoch: 5, Step: 2125/2949, Loss: 0.7010\n",
      "Epoch: 5, Step: 2126/2949, Loss: 0.7758\n",
      "Epoch: 5, Step: 2127/2949, Loss: 0.7374\n",
      "Epoch: 5, Step: 2128/2949, Loss: 0.7724\n",
      "Epoch: 5, Step: 2129/2949, Loss: 0.7218\n",
      "Epoch: 5, Step: 2130/2949, Loss: 0.7365\n",
      "Epoch: 5, Step: 2131/2949, Loss: 0.7504\n",
      "Epoch: 5, Step: 2132/2949, Loss: 0.7580\n",
      "Epoch: 5, Step: 2133/2949, Loss: 0.7188\n",
      "Epoch: 5, Step: 2134/2949, Loss: 0.7464\n",
      "Epoch: 5, Step: 2135/2949, Loss: 0.7500\n",
      "Epoch: 5, Step: 2136/2949, Loss: 0.7893\n",
      "Epoch: 5, Step: 2137/2949, Loss: 0.7317\n",
      "Epoch: 5, Step: 2138/2949, Loss: 0.7125\n",
      "Epoch: 5, Step: 2139/2949, Loss: 0.7576\n",
      "Epoch: 5, Step: 2140/2949, Loss: 0.7390\n",
      "Epoch: 5, Step: 2141/2949, Loss: 0.7064\n",
      "Epoch: 5, Step: 2142/2949, Loss: 0.6973\n",
      "Epoch: 5, Step: 2143/2949, Loss: 0.7383\n",
      "Epoch: 5, Step: 2144/2949, Loss: 0.7607\n",
      "Epoch: 5, Step: 2145/2949, Loss: 0.7613\n",
      "Epoch: 5, Step: 2146/2949, Loss: 0.7359\n",
      "Epoch: 5, Step: 2147/2949, Loss: 0.7314\n",
      "Epoch: 5, Step: 2148/2949, Loss: 0.7513\n",
      "Epoch: 5, Step: 2149/2949, Loss: 0.7297\n",
      "Epoch: 5, Step: 2150/2949, Loss: 0.7628\n",
      "Epoch: 5, Step: 2151/2949, Loss: 0.7544\n",
      "Epoch: 5, Step: 2152/2949, Loss: 0.7682\n",
      "Epoch: 5, Step: 2153/2949, Loss: 0.7263\n",
      "Epoch: 5, Step: 2154/2949, Loss: 0.7003\n",
      "Epoch: 5, Step: 2155/2949, Loss: 0.7584\n",
      "Epoch: 5, Step: 2156/2949, Loss: 0.7067\n",
      "Epoch: 5, Step: 2157/2949, Loss: 0.7669\n",
      "Epoch: 5, Step: 2158/2949, Loss: 0.7918\n",
      "Epoch: 5, Step: 2159/2949, Loss: 0.7415\n",
      "Epoch: 5, Step: 2160/2949, Loss: 0.7039\n",
      "Epoch: 5, Step: 2161/2949, Loss: 0.7334\n",
      "Epoch: 5, Step: 2162/2949, Loss: 0.7612\n",
      "Epoch: 5, Step: 2163/2949, Loss: 0.7349\n",
      "Epoch: 5, Step: 2164/2949, Loss: 0.7351\n",
      "Epoch: 5, Step: 2165/2949, Loss: 0.7304\n",
      "Epoch: 5, Step: 2166/2949, Loss: 0.7050\n",
      "Epoch: 5, Step: 2167/2949, Loss: 0.7159\n",
      "Epoch: 5, Step: 2168/2949, Loss: 0.7506\n",
      "Epoch: 5, Step: 2169/2949, Loss: 0.7366\n",
      "Epoch: 5, Step: 2170/2949, Loss: 0.7431\n",
      "Epoch: 5, Step: 2171/2949, Loss: 0.7195\n",
      "Epoch: 5, Step: 2172/2949, Loss: 0.7523\n",
      "Epoch: 5, Step: 2173/2949, Loss: 0.7569\n",
      "Epoch: 5, Step: 2174/2949, Loss: 0.7007\n",
      "Epoch: 5, Step: 2175/2949, Loss: 0.7427\n",
      "Epoch: 5, Step: 2176/2949, Loss: 0.7164\n",
      "Epoch: 5, Step: 2177/2949, Loss: 0.7001\n",
      "Epoch: 5, Step: 2178/2949, Loss: 0.7191\n",
      "Epoch: 5, Step: 2179/2949, Loss: 0.7029\n",
      "Epoch: 5, Step: 2180/2949, Loss: 0.7797\n",
      "Epoch: 5, Step: 2181/2949, Loss: 0.7557\n",
      "Epoch: 5, Step: 2182/2949, Loss: 0.7115\n",
      "Epoch: 5, Step: 2183/2949, Loss: 0.7079\n",
      "Epoch: 5, Step: 2184/2949, Loss: 0.7672\n",
      "Epoch: 5, Step: 2185/2949, Loss: 0.7435\n",
      "Epoch: 5, Step: 2186/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 2187/2949, Loss: 0.7310\n",
      "Epoch: 5, Step: 2188/2949, Loss: 0.7644\n",
      "Epoch: 5, Step: 2189/2949, Loss: 0.7529\n",
      "Epoch: 5, Step: 2190/2949, Loss: 0.6949\n",
      "Epoch: 5, Step: 2191/2949, Loss: 0.7268\n",
      "Epoch: 5, Step: 2192/2949, Loss: 0.7650\n",
      "Epoch: 5, Step: 2193/2949, Loss: 0.7253\n",
      "Epoch: 5, Step: 2194/2949, Loss: 0.7522\n",
      "Epoch: 5, Step: 2195/2949, Loss: 0.7485\n",
      "Epoch: 5, Step: 2196/2949, Loss: 0.7123\n",
      "Epoch: 5, Step: 2197/2949, Loss: 0.7556\n",
      "Epoch: 5, Step: 2198/2949, Loss: 0.7448\n",
      "Epoch: 5, Step: 2199/2949, Loss: 0.6936\n",
      "Epoch: 5, Step: 2200/2949, Loss: 0.7614\n",
      "Epoch: 5, Step: 2201/2949, Loss: 0.7372\n",
      "Epoch: 5, Step: 2202/2949, Loss: 0.7432\n",
      "Epoch: 5, Step: 2203/2949, Loss: 0.7069\n",
      "Epoch: 5, Step: 2204/2949, Loss: 0.7252\n",
      "Epoch: 5, Step: 2205/2949, Loss: 0.6882\n",
      "Epoch: 5, Step: 2206/2949, Loss: 0.7441\n",
      "Epoch: 5, Step: 2207/2949, Loss: 0.7690\n",
      "Epoch: 5, Step: 2208/2949, Loss: 0.7503\n",
      "Epoch: 5, Step: 2209/2949, Loss: 0.7202\n",
      "Epoch: 5, Step: 2210/2949, Loss: 0.7021\n",
      "Epoch: 5, Step: 2211/2949, Loss: 0.7756\n",
      "Epoch: 5, Step: 2212/2949, Loss: 0.7009\n",
      "Epoch: 5, Step: 2213/2949, Loss: 0.7385\n",
      "Epoch: 5, Step: 2214/2949, Loss: 0.7597\n",
      "Epoch: 5, Step: 2215/2949, Loss: 0.7903\n",
      "Epoch: 5, Step: 2216/2949, Loss: 0.7235\n",
      "Epoch: 5, Step: 2217/2949, Loss: 0.7789\n",
      "Epoch: 5, Step: 2218/2949, Loss: 0.7503\n",
      "Epoch: 5, Step: 2219/2949, Loss: 0.7787\n",
      "Epoch: 5, Step: 2220/2949, Loss: 0.7389\n",
      "Epoch: 5, Step: 2221/2949, Loss: 0.7468\n",
      "Epoch: 5, Step: 2222/2949, Loss: 0.7658\n",
      "Epoch: 5, Step: 2223/2949, Loss: 0.7134\n",
      "Epoch: 5, Step: 2224/2949, Loss: 0.6776\n",
      "Epoch: 5, Step: 2225/2949, Loss: 0.7788\n",
      "Epoch: 5, Step: 2226/2949, Loss: 0.7130\n",
      "Epoch: 5, Step: 2227/2949, Loss: 0.7862\n",
      "Epoch: 5, Step: 2228/2949, Loss: 0.7086\n",
      "Epoch: 5, Step: 2229/2949, Loss: 0.7418\n",
      "Epoch: 5, Step: 2230/2949, Loss: 0.7272\n",
      "Epoch: 5, Step: 2231/2949, Loss: 0.7468\n",
      "Epoch: 5, Step: 2232/2949, Loss: 0.7477\n",
      "Epoch: 5, Step: 2233/2949, Loss: 0.7448\n",
      "Epoch: 5, Step: 2234/2949, Loss: 0.7370\n",
      "Epoch: 5, Step: 2235/2949, Loss: 0.7245\n",
      "Epoch: 5, Step: 2236/2949, Loss: 0.7235\n",
      "Epoch: 5, Step: 2237/2949, Loss: 0.6810\n",
      "Epoch: 5, Step: 2238/2949, Loss: 0.7583\n",
      "Epoch: 5, Step: 2239/2949, Loss: 0.7406\n",
      "Epoch: 5, Step: 2240/2949, Loss: 0.7469\n",
      "Epoch: 5, Step: 2241/2949, Loss: 0.7205\n",
      "Epoch: 5, Step: 2242/2949, Loss: 0.7677\n",
      "Epoch: 5, Step: 2243/2949, Loss: 0.7224\n",
      "Epoch: 5, Step: 2244/2949, Loss: 0.7357\n",
      "Epoch: 5, Step: 2245/2949, Loss: 0.7180\n",
      "Epoch: 5, Step: 2246/2949, Loss: 0.7395\n",
      "Epoch: 5, Step: 2247/2949, Loss: 0.7779\n",
      "Epoch: 5, Step: 2248/2949, Loss: 0.7019\n",
      "Epoch: 5, Step: 2249/2949, Loss: 0.7871\n",
      "Epoch: 5, Step: 2250/2949, Loss: 0.7513\n",
      "Epoch: 5, Step: 2251/2949, Loss: 0.7131\n",
      "Epoch: 5, Step: 2252/2949, Loss: 0.6994\n",
      "Epoch: 5, Step: 2253/2949, Loss: 0.7375\n",
      "Epoch: 5, Step: 2254/2949, Loss: 0.7736\n",
      "Epoch: 5, Step: 2255/2949, Loss: 0.7300\n",
      "Epoch: 5, Step: 2256/2949, Loss: 0.7716\n",
      "Epoch: 5, Step: 2257/2949, Loss: 0.7166\n",
      "Epoch: 5, Step: 2258/2949, Loss: 0.7151\n",
      "Epoch: 5, Step: 2259/2949, Loss: 0.7082\n",
      "Epoch: 5, Step: 2260/2949, Loss: 0.6913\n",
      "Epoch: 5, Step: 2261/2949, Loss: 0.7759\n",
      "Epoch: 5, Step: 2262/2949, Loss: 0.6868\n",
      "Epoch: 5, Step: 2263/2949, Loss: 0.7593\n",
      "Epoch: 5, Step: 2264/2949, Loss: 0.7755\n",
      "Epoch: 5, Step: 2265/2949, Loss: 0.7324\n",
      "Epoch: 5, Step: 2266/2949, Loss: 0.7760\n",
      "Epoch: 5, Step: 2267/2949, Loss: 0.7070\n",
      "Epoch: 5, Step: 2268/2949, Loss: 0.7490\n",
      "Epoch: 5, Step: 2269/2949, Loss: 0.7012\n",
      "Epoch: 5, Step: 2270/2949, Loss: 0.7280\n",
      "Epoch: 5, Step: 2271/2949, Loss: 0.7435\n",
      "Epoch: 5, Step: 2272/2949, Loss: 0.7390\n",
      "Epoch: 5, Step: 2273/2949, Loss: 0.7287\n",
      "Epoch: 5, Step: 2274/2949, Loss: 0.7280\n",
      "Epoch: 5, Step: 2275/2949, Loss: 0.7444\n",
      "Epoch: 5, Step: 2276/2949, Loss: 0.6553\n",
      "Epoch: 5, Step: 2277/2949, Loss: 0.7250\n",
      "Epoch: 5, Step: 2278/2949, Loss: 0.7173\n",
      "Epoch: 5, Step: 2279/2949, Loss: 0.7414\n",
      "Epoch: 5, Step: 2280/2949, Loss: 0.7531\n",
      "Epoch: 5, Step: 2281/2949, Loss: 0.7149\n",
      "Epoch: 5, Step: 2282/2949, Loss: 0.7512\n",
      "Epoch: 5, Step: 2283/2949, Loss: 0.7132\n",
      "Epoch: 5, Step: 2284/2949, Loss: 0.7639\n",
      "Epoch: 5, Step: 2285/2949, Loss: 0.7508\n",
      "Epoch: 5, Step: 2286/2949, Loss: 0.7348\n",
      "Epoch: 5, Step: 2287/2949, Loss: 0.7513\n",
      "Epoch: 5, Step: 2288/2949, Loss: 0.6763\n",
      "Epoch: 5, Step: 2289/2949, Loss: 0.7239\n",
      "Epoch: 5, Step: 2290/2949, Loss: 0.7177\n",
      "Epoch: 5, Step: 2291/2949, Loss: 0.7414\n",
      "Epoch: 5, Step: 2292/2949, Loss: 0.7616\n",
      "Epoch: 5, Step: 2293/2949, Loss: 0.7400\n",
      "Epoch: 5, Step: 2294/2949, Loss: 0.7178\n",
      "Epoch: 5, Step: 2295/2949, Loss: 0.7968\n",
      "Epoch: 5, Step: 2296/2949, Loss: 0.7625\n",
      "Epoch: 5, Step: 2297/2949, Loss: 0.7652\n",
      "Epoch: 5, Step: 2298/2949, Loss: 0.7352\n",
      "Epoch: 5, Step: 2299/2949, Loss: 0.7557\n",
      "Epoch: 5, Step: 2300/2949, Loss: 0.7666\n",
      "Epoch: 5, Step: 2301/2949, Loss: 0.7312\n",
      "Epoch: 5, Step: 2302/2949, Loss: 0.7999\n",
      "Epoch: 5, Step: 2303/2949, Loss: 0.7433\n",
      "Epoch: 5, Step: 2304/2949, Loss: 0.7736\n",
      "Epoch: 5, Step: 2305/2949, Loss: 0.7234\n",
      "Epoch: 5, Step: 2306/2949, Loss: 0.7242\n",
      "Epoch: 5, Step: 2307/2949, Loss: 0.7854\n",
      "Epoch: 5, Step: 2308/2949, Loss: 0.7370\n",
      "Epoch: 5, Step: 2309/2949, Loss: 0.7776\n",
      "Epoch: 5, Step: 2310/2949, Loss: 0.7207\n",
      "Epoch: 5, Step: 2311/2949, Loss: 0.7308\n",
      "Epoch: 5, Step: 2312/2949, Loss: 0.7398\n",
      "Epoch: 5, Step: 2313/2949, Loss: 0.7095\n",
      "Epoch: 5, Step: 2314/2949, Loss: 0.7126\n",
      "Epoch: 5, Step: 2315/2949, Loss: 0.7014\n",
      "Epoch: 5, Step: 2316/2949, Loss: 0.6994\n",
      "Epoch: 5, Step: 2317/2949, Loss: 0.7083\n",
      "Epoch: 5, Step: 2318/2949, Loss: 0.7462\n",
      "Epoch: 5, Step: 2319/2949, Loss: 0.7378\n",
      "Epoch: 5, Step: 2320/2949, Loss: 0.7186\n",
      "Epoch: 5, Step: 2321/2949, Loss: 0.6932\n",
      "Epoch: 5, Step: 2322/2949, Loss: 0.7957\n",
      "Epoch: 5, Step: 2323/2949, Loss: 0.7441\n",
      "Epoch: 5, Step: 2324/2949, Loss: 0.7417\n",
      "Epoch: 5, Step: 2325/2949, Loss: 0.6957\n",
      "Epoch: 5, Step: 2326/2949, Loss: 0.7530\n",
      "Epoch: 5, Step: 2327/2949, Loss: 0.7452\n",
      "Epoch: 5, Step: 2328/2949, Loss: 0.7482\n",
      "Epoch: 5, Step: 2329/2949, Loss: 0.7971\n",
      "Epoch: 5, Step: 2330/2949, Loss: 0.7688\n",
      "Epoch: 5, Step: 2331/2949, Loss: 0.7919\n",
      "Epoch: 5, Step: 2332/2949, Loss: 0.7955\n",
      "Epoch: 5, Step: 2333/2949, Loss: 0.7574\n",
      "Epoch: 5, Step: 2334/2949, Loss: 0.7096\n",
      "Epoch: 5, Step: 2335/2949, Loss: 0.7380\n",
      "Epoch: 5, Step: 2336/2949, Loss: 0.7942\n",
      "Epoch: 5, Step: 2337/2949, Loss: 0.7238\n",
      "Epoch: 5, Step: 2338/2949, Loss: 0.7171\n",
      "Epoch: 5, Step: 2339/2949, Loss: 0.7632\n",
      "Epoch: 5, Step: 2340/2949, Loss: 0.7611\n",
      "Epoch: 5, Step: 2341/2949, Loss: 0.7607\n",
      "Epoch: 5, Step: 2342/2949, Loss: 0.6820\n",
      "Epoch: 5, Step: 2343/2949, Loss: 0.7510\n",
      "Epoch: 5, Step: 2344/2949, Loss: 0.7334\n",
      "Epoch: 5, Step: 2345/2949, Loss: 0.7370\n",
      "Epoch: 5, Step: 2346/2949, Loss: 0.7453\n",
      "Epoch: 5, Step: 2347/2949, Loss: 0.7126\n",
      "Epoch: 5, Step: 2348/2949, Loss: 0.7438\n",
      "Epoch: 5, Step: 2349/2949, Loss: 0.7532\n",
      "Epoch: 5, Step: 2350/2949, Loss: 0.6990\n",
      "Epoch: 5, Step: 2351/2949, Loss: 0.7041\n",
      "Epoch: 5, Step: 2352/2949, Loss: 0.7372\n",
      "Epoch: 5, Step: 2353/2949, Loss: 0.7566\n",
      "Epoch: 5, Step: 2354/2949, Loss: 0.7432\n",
      "Epoch: 5, Step: 2355/2949, Loss: 0.7401\n",
      "Epoch: 5, Step: 2356/2949, Loss: 0.7328\n",
      "Epoch: 5, Step: 2357/2949, Loss: 0.7193\n",
      "Epoch: 5, Step: 2358/2949, Loss: 0.7365\n",
      "Epoch: 5, Step: 2359/2949, Loss: 0.7602\n",
      "Epoch: 5, Step: 2360/2949, Loss: 0.7323\n",
      "Epoch: 5, Step: 2361/2949, Loss: 0.7077\n",
      "Epoch: 5, Step: 2362/2949, Loss: 0.6995\n",
      "Epoch: 5, Step: 2363/2949, Loss: 0.7538\n",
      "Epoch: 5, Step: 2364/2949, Loss: 0.7430\n",
      "Epoch: 5, Step: 2365/2949, Loss: 0.7712\n",
      "Epoch: 5, Step: 2366/2949, Loss: 0.7074\n",
      "Epoch: 5, Step: 2367/2949, Loss: 0.7681\n",
      "Epoch: 5, Step: 2368/2949, Loss: 0.7556\n",
      "Epoch: 5, Step: 2369/2949, Loss: 0.7324\n",
      "Epoch: 5, Step: 2370/2949, Loss: 0.7478\n",
      "Epoch: 5, Step: 2371/2949, Loss: 0.8061\n",
      "Epoch: 5, Step: 2372/2949, Loss: 0.7433\n",
      "Epoch: 5, Step: 2373/2949, Loss: 0.7248\n",
      "Epoch: 5, Step: 2374/2949, Loss: 0.7068\n",
      "Epoch: 5, Step: 2375/2949, Loss: 0.7473\n",
      "Epoch: 5, Step: 2376/2949, Loss: 0.6852\n",
      "Epoch: 5, Step: 2377/2949, Loss: 0.7699\n",
      "Epoch: 5, Step: 2378/2949, Loss: 0.7215\n",
      "Epoch: 5, Step: 2379/2949, Loss: 0.7583\n",
      "Epoch: 5, Step: 2380/2949, Loss: 0.7500\n",
      "Epoch: 5, Step: 2381/2949, Loss: 0.6865\n",
      "Epoch: 5, Step: 2382/2949, Loss: 0.7512\n",
      "Epoch: 5, Step: 2383/2949, Loss: 0.7472\n",
      "Epoch: 5, Step: 2384/2949, Loss: 0.7391\n",
      "Epoch: 5, Step: 2385/2949, Loss: 0.7028\n",
      "Epoch: 5, Step: 2386/2949, Loss: 0.7562\n",
      "Epoch: 5, Step: 2387/2949, Loss: 0.7594\n",
      "Epoch: 5, Step: 2388/2949, Loss: 0.7050\n",
      "Epoch: 5, Step: 2389/2949, Loss: 0.6977\n",
      "Epoch: 5, Step: 2390/2949, Loss: 0.7340\n",
      "Epoch: 5, Step: 2391/2949, Loss: 0.7703\n",
      "Epoch: 5, Step: 2392/2949, Loss: 0.6976\n",
      "Epoch: 5, Step: 2393/2949, Loss: 0.7382\n",
      "Epoch: 5, Step: 2394/2949, Loss: 0.7117\n",
      "Epoch: 5, Step: 2395/2949, Loss: 0.7188\n",
      "Epoch: 5, Step: 2396/2949, Loss: 0.7102\n",
      "Epoch: 5, Step: 2397/2949, Loss: 0.7129\n",
      "Epoch: 5, Step: 2398/2949, Loss: 0.7212\n",
      "Epoch: 5, Step: 2399/2949, Loss: 0.7397\n",
      "Epoch: 5, Step: 2400/2949, Loss: 0.7375\n",
      "Epoch: 5, Step: 2401/2949, Loss: 0.7001\n",
      "Epoch: 5, Step: 2402/2949, Loss: 0.7107\n",
      "Epoch: 5, Step: 2403/2949, Loss: 0.7306\n",
      "Epoch: 5, Step: 2404/2949, Loss: 0.7552\n",
      "Epoch: 5, Step: 2405/2949, Loss: 0.7372\n",
      "Epoch: 5, Step: 2406/2949, Loss: 0.6755\n",
      "Epoch: 5, Step: 2407/2949, Loss: 0.7694\n",
      "Epoch: 5, Step: 2408/2949, Loss: 0.7476\n",
      "Epoch: 5, Step: 2409/2949, Loss: 0.7422\n",
      "Epoch: 5, Step: 2410/2949, Loss: 0.7263\n",
      "Epoch: 5, Step: 2411/2949, Loss: 0.7416\n",
      "Epoch: 5, Step: 2412/2949, Loss: 0.7516\n",
      "Epoch: 5, Step: 2413/2949, Loss: 0.7180\n",
      "Epoch: 5, Step: 2414/2949, Loss: 0.7572\n",
      "Epoch: 5, Step: 2415/2949, Loss: 0.7494\n",
      "Epoch: 5, Step: 2416/2949, Loss: 0.7308\n",
      "Epoch: 5, Step: 2417/2949, Loss: 0.7882\n",
      "Epoch: 5, Step: 2418/2949, Loss: 0.7346\n",
      "Epoch: 5, Step: 2419/2949, Loss: 0.7459\n",
      "Epoch: 5, Step: 2420/2949, Loss: 0.7675\n",
      "Epoch: 5, Step: 2421/2949, Loss: 0.7211\n",
      "Epoch: 5, Step: 2422/2949, Loss: 0.7360\n",
      "Epoch: 5, Step: 2423/2949, Loss: 0.7344\n",
      "Epoch: 5, Step: 2424/2949, Loss: 0.7062\n",
      "Epoch: 5, Step: 2425/2949, Loss: 0.7573\n",
      "Epoch: 5, Step: 2426/2949, Loss: 0.7418\n",
      "Epoch: 5, Step: 2427/2949, Loss: 0.7660\n",
      "Epoch: 5, Step: 2428/2949, Loss: 0.7336\n",
      "Epoch: 5, Step: 2429/2949, Loss: 0.7576\n",
      "Epoch: 5, Step: 2430/2949, Loss: 0.7265\n",
      "Epoch: 5, Step: 2431/2949, Loss: 0.7243\n",
      "Epoch: 5, Step: 2432/2949, Loss: 0.7467\n",
      "Epoch: 5, Step: 2433/2949, Loss: 0.6990\n",
      "Epoch: 5, Step: 2434/2949, Loss: 0.6979\n",
      "Epoch: 5, Step: 2435/2949, Loss: 0.7139\n",
      "Epoch: 5, Step: 2436/2949, Loss: 0.7760\n",
      "Epoch: 5, Step: 2437/2949, Loss: 0.7126\n",
      "Epoch: 5, Step: 2438/2949, Loss: 0.6858\n",
      "Epoch: 5, Step: 2439/2949, Loss: 0.7493\n",
      "Epoch: 5, Step: 2440/2949, Loss: 0.7107\n",
      "Epoch: 5, Step: 2441/2949, Loss: 0.7144\n",
      "Epoch: 5, Step: 2442/2949, Loss: 0.7198\n",
      "Epoch: 5, Step: 2443/2949, Loss: 0.6626\n",
      "Epoch: 5, Step: 2444/2949, Loss: 0.6847\n",
      "Epoch: 5, Step: 2445/2949, Loss: 0.7548\n",
      "Epoch: 5, Step: 2446/2949, Loss: 0.7083\n",
      "Epoch: 5, Step: 2447/2949, Loss: 0.7405\n",
      "Epoch: 5, Step: 2448/2949, Loss: 0.7576\n",
      "Epoch: 5, Step: 2449/2949, Loss: 0.7496\n",
      "Epoch: 5, Step: 2450/2949, Loss: 0.7740\n",
      "Epoch: 5, Step: 2451/2949, Loss: 0.7719\n",
      "Epoch: 5, Step: 2452/2949, Loss: 0.7737\n",
      "Epoch: 5, Step: 2453/2949, Loss: 0.7548\n",
      "Epoch: 5, Step: 2454/2949, Loss: 0.7396\n",
      "Epoch: 5, Step: 2455/2949, Loss: 0.7270\n",
      "Epoch: 5, Step: 2456/2949, Loss: 0.6833\n",
      "Epoch: 5, Step: 2457/2949, Loss: 0.7183\n",
      "Epoch: 5, Step: 2458/2949, Loss: 0.6956\n",
      "Epoch: 5, Step: 2459/2949, Loss: 0.7285\n",
      "Epoch: 5, Step: 2460/2949, Loss: 0.7225\n",
      "Epoch: 5, Step: 2461/2949, Loss: 0.7855\n",
      "Epoch: 5, Step: 2462/2949, Loss: 0.7678\n",
      "Epoch: 5, Step: 2463/2949, Loss: 0.7628\n",
      "Epoch: 5, Step: 2464/2949, Loss: 0.7207\n",
      "Epoch: 5, Step: 2465/2949, Loss: 0.7320\n",
      "Epoch: 5, Step: 2466/2949, Loss: 0.7358\n",
      "Epoch: 5, Step: 2467/2949, Loss: 0.7885\n",
      "Epoch: 5, Step: 2468/2949, Loss: 0.7325\n",
      "Epoch: 5, Step: 2469/2949, Loss: 0.7010\n",
      "Epoch: 5, Step: 2470/2949, Loss: 0.7131\n",
      "Epoch: 5, Step: 2471/2949, Loss: 0.7748\n",
      "Epoch: 5, Step: 2472/2949, Loss: 0.6891\n",
      "Epoch: 5, Step: 2473/2949, Loss: 0.7146\n",
      "Epoch: 5, Step: 2474/2949, Loss: 0.7431\n",
      "Epoch: 5, Step: 2475/2949, Loss: 0.7258\n",
      "Epoch: 5, Step: 2476/2949, Loss: 0.7077\n",
      "Epoch: 5, Step: 2477/2949, Loss: 0.7751\n",
      "Epoch: 5, Step: 2478/2949, Loss: 0.7248\n",
      "Epoch: 5, Step: 2479/2949, Loss: 0.7690\n",
      "Epoch: 5, Step: 2480/2949, Loss: 0.7582\n",
      "Epoch: 5, Step: 2481/2949, Loss: 0.7269\n",
      "Epoch: 5, Step: 2482/2949, Loss: 0.7200\n",
      "Epoch: 5, Step: 2483/2949, Loss: 0.7076\n",
      "Epoch: 5, Step: 2484/2949, Loss: 0.7083\n",
      "Epoch: 5, Step: 2485/2949, Loss: 0.7429\n",
      "Epoch: 5, Step: 2486/2949, Loss: 0.7201\n",
      "Epoch: 5, Step: 2487/2949, Loss: 0.7627\n",
      "Epoch: 5, Step: 2488/2949, Loss: 0.7256\n",
      "Epoch: 5, Step: 2489/2949, Loss: 0.7397\n",
      "Epoch: 5, Step: 2490/2949, Loss: 0.7449\n",
      "Epoch: 5, Step: 2491/2949, Loss: 0.7366\n",
      "Epoch: 5, Step: 2492/2949, Loss: 0.7217\n",
      "Epoch: 5, Step: 2493/2949, Loss: 0.7271\n",
      "Epoch: 5, Step: 2494/2949, Loss: 0.7112\n",
      "Epoch: 5, Step: 2495/2949, Loss: 0.7228\n",
      "Epoch: 5, Step: 2496/2949, Loss: 0.7330\n",
      "Epoch: 5, Step: 2497/2949, Loss: 0.7084\n",
      "Epoch: 5, Step: 2498/2949, Loss: 0.7467\n",
      "Epoch: 5, Step: 2499/2949, Loss: 0.7594\n",
      "Epoch: 5, Step: 2500/2949, Loss: 0.7814\n",
      "Epoch: 5, Step: 2501/2949, Loss: 0.7296\n",
      "Epoch: 5, Step: 2502/2949, Loss: 0.7436\n",
      "Epoch: 5, Step: 2503/2949, Loss: 0.7469\n",
      "Epoch: 5, Step: 2504/2949, Loss: 0.7524\n",
      "Epoch: 5, Step: 2505/2949, Loss: 0.7256\n",
      "Epoch: 5, Step: 2506/2949, Loss: 0.7177\n",
      "Epoch: 5, Step: 2507/2949, Loss: 0.7366\n",
      "Epoch: 5, Step: 2508/2949, Loss: 0.7104\n",
      "Epoch: 5, Step: 2509/2949, Loss: 0.7597\n",
      "Epoch: 5, Step: 2510/2949, Loss: 0.7214\n",
      "Epoch: 5, Step: 2511/2949, Loss: 0.7070\n",
      "Epoch: 5, Step: 2512/2949, Loss: 0.7711\n",
      "Epoch: 5, Step: 2513/2949, Loss: 0.7348\n",
      "Epoch: 5, Step: 2514/2949, Loss: 0.7066\n",
      "Epoch: 5, Step: 2515/2949, Loss: 0.7481\n",
      "Epoch: 5, Step: 2516/2949, Loss: 0.7262\n",
      "Epoch: 5, Step: 2517/2949, Loss: 0.7406\n",
      "Epoch: 5, Step: 2518/2949, Loss: 0.7227\n",
      "Epoch: 5, Step: 2519/2949, Loss: 0.7544\n",
      "Epoch: 5, Step: 2520/2949, Loss: 0.7366\n",
      "Epoch: 5, Step: 2521/2949, Loss: 0.7329\n",
      "Epoch: 5, Step: 2522/2949, Loss: 0.6963\n",
      "Epoch: 5, Step: 2523/2949, Loss: 0.7362\n",
      "Epoch: 5, Step: 2524/2949, Loss: 0.7480\n",
      "Epoch: 5, Step: 2525/2949, Loss: 0.7024\n",
      "Epoch: 5, Step: 2526/2949, Loss: 0.7635\n",
      "Epoch: 5, Step: 2527/2949, Loss: 0.7009\n",
      "Epoch: 5, Step: 2528/2949, Loss: 0.7644\n",
      "Epoch: 5, Step: 2529/2949, Loss: 0.7575\n",
      "Epoch: 5, Step: 2530/2949, Loss: 0.7003\n",
      "Epoch: 5, Step: 2531/2949, Loss: 0.7342\n",
      "Epoch: 5, Step: 2532/2949, Loss: 0.6744\n",
      "Epoch: 5, Step: 2533/2949, Loss: 0.7694\n",
      "Epoch: 5, Step: 2534/2949, Loss: 0.7318\n",
      "Epoch: 5, Step: 2535/2949, Loss: 0.7521\n",
      "Epoch: 5, Step: 2536/2949, Loss: 0.7653\n",
      "Epoch: 5, Step: 2537/2949, Loss: 0.7427\n",
      "Epoch: 5, Step: 2538/2949, Loss: 0.7239\n",
      "Epoch: 5, Step: 2539/2949, Loss: 0.7391\n",
      "Epoch: 5, Step: 2540/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 2541/2949, Loss: 0.7686\n",
      "Epoch: 5, Step: 2542/2949, Loss: 0.7114\n",
      "Epoch: 5, Step: 2543/2949, Loss: 0.7131\n",
      "Epoch: 5, Step: 2544/2949, Loss: 0.7565\n",
      "Epoch: 5, Step: 2545/2949, Loss: 0.7705\n",
      "Epoch: 5, Step: 2546/2949, Loss: 0.7188\n",
      "Epoch: 5, Step: 2547/2949, Loss: 0.6863\n",
      "Epoch: 5, Step: 2548/2949, Loss: 0.7751\n",
      "Epoch: 5, Step: 2549/2949, Loss: 0.7250\n",
      "Epoch: 5, Step: 2550/2949, Loss: 0.7597\n",
      "Epoch: 5, Step: 2551/2949, Loss: 0.7359\n",
      "Epoch: 5, Step: 2552/2949, Loss: 0.7395\n",
      "Epoch: 5, Step: 2553/2949, Loss: 0.7042\n",
      "Epoch: 5, Step: 2554/2949, Loss: 0.6997\n",
      "Epoch: 5, Step: 2555/2949, Loss: 0.7038\n",
      "Epoch: 5, Step: 2556/2949, Loss: 0.6834\n",
      "Epoch: 5, Step: 2557/2949, Loss: 0.7578\n",
      "Epoch: 5, Step: 2558/2949, Loss: 0.7208\n",
      "Epoch: 5, Step: 2559/2949, Loss: 0.7033\n",
      "Epoch: 5, Step: 2560/2949, Loss: 0.7179\n",
      "Epoch: 5, Step: 2561/2949, Loss: 0.7322\n",
      "Epoch: 5, Step: 2562/2949, Loss: 0.7267\n",
      "Epoch: 5, Step: 2563/2949, Loss: 0.6254\n",
      "Epoch: 5, Step: 2564/2949, Loss: 0.7078\n",
      "Epoch: 5, Step: 2565/2949, Loss: 0.7923\n",
      "Epoch: 5, Step: 2566/2949, Loss: 0.7766\n",
      "Epoch: 5, Step: 2567/2949, Loss: 0.7152\n",
      "Epoch: 5, Step: 2568/2949, Loss: 0.7429\n",
      "Epoch: 5, Step: 2569/2949, Loss: 0.7398\n",
      "Epoch: 5, Step: 2570/2949, Loss: 0.6848\n",
      "Epoch: 5, Step: 2571/2949, Loss: 0.7263\n",
      "Epoch: 5, Step: 2572/2949, Loss: 0.7056\n",
      "Epoch: 5, Step: 2573/2949, Loss: 0.6661\n",
      "Epoch: 5, Step: 2574/2949, Loss: 0.7287\n",
      "Epoch: 5, Step: 2575/2949, Loss: 0.7030\n",
      "Epoch: 5, Step: 2576/2949, Loss: 0.7659\n",
      "Epoch: 5, Step: 2577/2949, Loss: 0.7250\n",
      "Epoch: 5, Step: 2578/2949, Loss: 0.7334\n",
      "Epoch: 5, Step: 2579/2949, Loss: 0.7509\n",
      "Epoch: 5, Step: 2580/2949, Loss: 0.7276\n",
      "Epoch: 5, Step: 2581/2949, Loss: 0.7760\n",
      "Epoch: 5, Step: 2582/2949, Loss: 0.7796\n",
      "Epoch: 5, Step: 2583/2949, Loss: 0.7555\n",
      "Epoch: 5, Step: 2584/2949, Loss: 0.7549\n",
      "Epoch: 5, Step: 2585/2949, Loss: 0.7699\n",
      "Epoch: 5, Step: 2586/2949, Loss: 0.6981\n",
      "Epoch: 5, Step: 2587/2949, Loss: 0.7199\n",
      "Epoch: 5, Step: 2588/2949, Loss: 0.7705\n",
      "Epoch: 5, Step: 2589/2949, Loss: 0.7606\n",
      "Epoch: 5, Step: 2590/2949, Loss: 0.7773\n",
      "Epoch: 5, Step: 2591/2949, Loss: 0.7637\n",
      "Epoch: 5, Step: 2592/2949, Loss: 0.7157\n",
      "Epoch: 5, Step: 2593/2949, Loss: 0.7168\n",
      "Epoch: 5, Step: 2594/2949, Loss: 0.7146\n",
      "Epoch: 5, Step: 2595/2949, Loss: 0.7272\n",
      "Epoch: 5, Step: 2596/2949, Loss: 0.7487\n",
      "Epoch: 5, Step: 2597/2949, Loss: 0.7602\n",
      "Epoch: 5, Step: 2598/2949, Loss: 0.7551\n",
      "Epoch: 5, Step: 2599/2949, Loss: 0.7407\n",
      "Epoch: 5, Step: 2600/2949, Loss: 0.6909\n",
      "Epoch: 5, Step: 2601/2949, Loss: 0.7471\n",
      "Epoch: 5, Step: 2602/2949, Loss: 0.7482\n",
      "Epoch: 5, Step: 2603/2949, Loss: 0.7448\n",
      "Epoch: 5, Step: 2604/2949, Loss: 0.7624\n",
      "Epoch: 5, Step: 2605/2949, Loss: 0.7774\n",
      "Epoch: 5, Step: 2606/2949, Loss: 0.7359\n",
      "Epoch: 5, Step: 2607/2949, Loss: 0.7859\n",
      "Epoch: 5, Step: 2608/2949, Loss: 0.7368\n",
      "Epoch: 5, Step: 2609/2949, Loss: 0.7879\n",
      "Epoch: 5, Step: 2610/2949, Loss: 0.7670\n",
      "Epoch: 5, Step: 2611/2949, Loss: 0.7681\n",
      "Epoch: 5, Step: 2612/2949, Loss: 0.7504\n",
      "Epoch: 5, Step: 2613/2949, Loss: 0.7594\n",
      "Epoch: 5, Step: 2614/2949, Loss: 0.7467\n",
      "Epoch: 5, Step: 2615/2949, Loss: 0.7685\n",
      "Epoch: 5, Step: 2616/2949, Loss: 0.7288\n",
      "Epoch: 5, Step: 2617/2949, Loss: 0.7191\n",
      "Epoch: 5, Step: 2618/2949, Loss: 0.7985\n",
      "Epoch: 5, Step: 2619/2949, Loss: 0.6940\n",
      "Epoch: 5, Step: 2620/2949, Loss: 0.7789\n",
      "Epoch: 5, Step: 2621/2949, Loss: 0.7306\n",
      "Epoch: 5, Step: 2622/2949, Loss: 0.7369\n",
      "Epoch: 5, Step: 2623/2949, Loss: 0.7568\n",
      "Epoch: 5, Step: 2624/2949, Loss: 0.7888\n",
      "Epoch: 5, Step: 2625/2949, Loss: 0.6777\n",
      "Epoch: 5, Step: 2626/2949, Loss: 0.7206\n",
      "Epoch: 5, Step: 2627/2949, Loss: 0.7758\n",
      "Epoch: 5, Step: 2628/2949, Loss: 0.7424\n",
      "Epoch: 5, Step: 2629/2949, Loss: 0.7214\n",
      "Epoch: 5, Step: 2630/2949, Loss: 0.7542\n",
      "Epoch: 5, Step: 2631/2949, Loss: 0.7225\n",
      "Epoch: 5, Step: 2632/2949, Loss: 0.7734\n",
      "Epoch: 5, Step: 2633/2949, Loss: 0.7617\n",
      "Epoch: 5, Step: 2634/2949, Loss: 0.7531\n",
      "Epoch: 5, Step: 2635/2949, Loss: 0.7655\n",
      "Epoch: 5, Step: 2636/2949, Loss: 0.7214\n",
      "Epoch: 5, Step: 2637/2949, Loss: 0.6678\n",
      "Epoch: 5, Step: 2638/2949, Loss: 0.7405\n",
      "Epoch: 5, Step: 2639/2949, Loss: 0.6641\n",
      "Epoch: 5, Step: 2640/2949, Loss: 0.7386\n",
      "Epoch: 5, Step: 2641/2949, Loss: 0.7586\n",
      "Epoch: 5, Step: 2642/2949, Loss: 0.7000\n",
      "Epoch: 5, Step: 2643/2949, Loss: 0.6699\n",
      "Epoch: 5, Step: 2644/2949, Loss: 0.7245\n",
      "Epoch: 5, Step: 2645/2949, Loss: 0.7190\n",
      "Epoch: 5, Step: 2646/2949, Loss: 0.7074\n",
      "Epoch: 5, Step: 2647/2949, Loss: 0.7931\n",
      "Epoch: 5, Step: 2648/2949, Loss: 0.7221\n",
      "Epoch: 5, Step: 2649/2949, Loss: 0.7236\n",
      "Epoch: 5, Step: 2650/2949, Loss: 0.7313\n",
      "Epoch: 5, Step: 2651/2949, Loss: 0.7728\n",
      "Epoch: 5, Step: 2652/2949, Loss: 0.7469\n",
      "Epoch: 5, Step: 2653/2949, Loss: 0.7227\n",
      "Epoch: 5, Step: 2654/2949, Loss: 0.7056\n",
      "Epoch: 5, Step: 2655/2949, Loss: 0.7773\n",
      "Epoch: 5, Step: 2656/2949, Loss: 0.7730\n",
      "Epoch: 5, Step: 2657/2949, Loss: 0.7346\n",
      "Epoch: 5, Step: 2658/2949, Loss: 0.7294\n",
      "Epoch: 5, Step: 2659/2949, Loss: 0.6629\n",
      "Epoch: 5, Step: 2660/2949, Loss: 0.7575\n",
      "Epoch: 5, Step: 2661/2949, Loss: 0.7438\n",
      "Epoch: 5, Step: 2662/2949, Loss: 0.7669\n",
      "Epoch: 5, Step: 2663/2949, Loss: 0.7056\n",
      "Epoch: 5, Step: 2664/2949, Loss: 0.7070\n",
      "Epoch: 5, Step: 2665/2949, Loss: 0.7548\n",
      "Epoch: 5, Step: 2666/2949, Loss: 0.7074\n",
      "Epoch: 5, Step: 2667/2949, Loss: 0.7192\n",
      "Epoch: 5, Step: 2668/2949, Loss: 0.8467\n",
      "Epoch: 5, Step: 2669/2949, Loss: 0.6877\n",
      "Epoch: 5, Step: 2670/2949, Loss: 0.7387\n",
      "Epoch: 5, Step: 2671/2949, Loss: 0.7611\n",
      "Epoch: 5, Step: 2672/2949, Loss: 0.7801\n",
      "Epoch: 5, Step: 2673/2949, Loss: 0.7239\n",
      "Epoch: 5, Step: 2674/2949, Loss: 0.7472\n",
      "Epoch: 5, Step: 2675/2949, Loss: 0.7165\n",
      "Epoch: 5, Step: 2676/2949, Loss: 0.7490\n",
      "Epoch: 5, Step: 2677/2949, Loss: 0.6745\n",
      "Epoch: 5, Step: 2678/2949, Loss: 0.7267\n",
      "Epoch: 5, Step: 2679/2949, Loss: 0.6863\n",
      "Epoch: 5, Step: 2680/2949, Loss: 0.7607\n",
      "Epoch: 5, Step: 2681/2949, Loss: 0.7436\n",
      "Epoch: 5, Step: 2682/2949, Loss: 0.7626\n",
      "Epoch: 5, Step: 2683/2949, Loss: 0.7384\n",
      "Epoch: 5, Step: 2684/2949, Loss: 0.7444\n",
      "Epoch: 5, Step: 2685/2949, Loss: 0.7471\n",
      "Epoch: 5, Step: 2686/2949, Loss: 0.7867\n",
      "Epoch: 5, Step: 2687/2949, Loss: 0.7405\n",
      "Epoch: 5, Step: 2688/2949, Loss: 0.7093\n",
      "Epoch: 5, Step: 2689/2949, Loss: 0.7769\n",
      "Epoch: 5, Step: 2690/2949, Loss: 0.6939\n",
      "Epoch: 5, Step: 2691/2949, Loss: 0.7397\n",
      "Epoch: 5, Step: 2692/2949, Loss: 0.7724\n",
      "Epoch: 5, Step: 2693/2949, Loss: 0.7029\n",
      "Epoch: 5, Step: 2694/2949, Loss: 0.7624\n",
      "Epoch: 5, Step: 2695/2949, Loss: 0.7043\n",
      "Epoch: 5, Step: 2696/2949, Loss: 0.6981\n",
      "Epoch: 5, Step: 2697/2949, Loss: 0.7443\n",
      "Epoch: 5, Step: 2698/2949, Loss: 0.7145\n",
      "Epoch: 5, Step: 2699/2949, Loss: 0.7986\n",
      "Epoch: 5, Step: 2700/2949, Loss: 0.6816\n",
      "Epoch: 5, Step: 2701/2949, Loss: 0.7166\n",
      "Epoch: 5, Step: 2702/2949, Loss: 0.7098\n",
      "Epoch: 5, Step: 2703/2949, Loss: 0.7067\n",
      "Epoch: 5, Step: 2704/2949, Loss: 0.6905\n",
      "Epoch: 5, Step: 2705/2949, Loss: 0.6860\n",
      "Epoch: 5, Step: 2706/2949, Loss: 0.7016\n",
      "Epoch: 5, Step: 2707/2949, Loss: 0.7236\n",
      "Epoch: 5, Step: 2708/2949, Loss: 0.7660\n",
      "Epoch: 5, Step: 2709/2949, Loss: 0.7303\n",
      "Epoch: 5, Step: 2710/2949, Loss: 0.7684\n",
      "Epoch: 5, Step: 2711/2949, Loss: 0.7226\n",
      "Epoch: 5, Step: 2712/2949, Loss: 0.7553\n",
      "Epoch: 5, Step: 2713/2949, Loss: 0.7771\n",
      "Epoch: 5, Step: 2714/2949, Loss: 0.7894\n",
      "Epoch: 5, Step: 2715/2949, Loss: 0.7304\n",
      "Epoch: 5, Step: 2716/2949, Loss: 0.7551\n",
      "Epoch: 5, Step: 2717/2949, Loss: 0.6979\n",
      "Epoch: 5, Step: 2718/2949, Loss: 0.7785\n",
      "Epoch: 5, Step: 2719/2949, Loss: 0.7405\n",
      "Epoch: 5, Step: 2720/2949, Loss: 0.7357\n",
      "Epoch: 5, Step: 2721/2949, Loss: 0.7072\n",
      "Epoch: 5, Step: 2722/2949, Loss: 0.7546\n",
      "Epoch: 5, Step: 2723/2949, Loss: 0.7302\n",
      "Epoch: 5, Step: 2724/2949, Loss: 0.7298\n",
      "Epoch: 5, Step: 2725/2949, Loss: 0.6835\n",
      "Epoch: 5, Step: 2726/2949, Loss: 0.7450\n",
      "Epoch: 5, Step: 2727/2949, Loss: 0.7176\n",
      "Epoch: 5, Step: 2728/2949, Loss: 0.6915\n",
      "Epoch: 5, Step: 2729/2949, Loss: 0.7810\n",
      "Epoch: 5, Step: 2730/2949, Loss: 0.6940\n",
      "Epoch: 5, Step: 2731/2949, Loss: 0.7762\n",
      "Epoch: 5, Step: 2732/2949, Loss: 0.7178\n",
      "Epoch: 5, Step: 2733/2949, Loss: 0.7748\n",
      "Epoch: 5, Step: 2734/2949, Loss: 0.7735\n",
      "Epoch: 5, Step: 2735/2949, Loss: 0.7191\n",
      "Epoch: 5, Step: 2736/2949, Loss: 0.6655\n",
      "Epoch: 5, Step: 2737/2949, Loss: 0.7342\n",
      "Epoch: 5, Step: 2738/2949, Loss: 0.7029\n",
      "Epoch: 5, Step: 2739/2949, Loss: 0.6721\n",
      "Epoch: 5, Step: 2740/2949, Loss: 0.7802\n",
      "Epoch: 5, Step: 2741/2949, Loss: 0.7497\n",
      "Epoch: 5, Step: 2742/2949, Loss: 0.7429\n",
      "Epoch: 5, Step: 2743/2949, Loss: 0.7483\n",
      "Epoch: 5, Step: 2744/2949, Loss: 0.7533\n",
      "Epoch: 5, Step: 2745/2949, Loss: 0.7358\n",
      "Epoch: 5, Step: 2746/2949, Loss: 0.7719\n",
      "Epoch: 5, Step: 2747/2949, Loss: 0.7229\n",
      "Epoch: 5, Step: 2748/2949, Loss: 0.7462\n",
      "Epoch: 5, Step: 2749/2949, Loss: 0.7196\n",
      "Epoch: 5, Step: 2750/2949, Loss: 0.7651\n",
      "Epoch: 5, Step: 2751/2949, Loss: 0.7414\n",
      "Epoch: 5, Step: 2752/2949, Loss: 0.7508\n",
      "Epoch: 5, Step: 2753/2949, Loss: 0.7452\n",
      "Epoch: 5, Step: 2754/2949, Loss: 0.7375\n",
      "Epoch: 5, Step: 2755/2949, Loss: 0.7158\n",
      "Epoch: 5, Step: 2756/2949, Loss: 0.7615\n",
      "Epoch: 5, Step: 2757/2949, Loss: 0.7674\n",
      "Epoch: 5, Step: 2758/2949, Loss: 0.7769\n",
      "Epoch: 5, Step: 2759/2949, Loss: 0.7507\n",
      "Epoch: 5, Step: 2760/2949, Loss: 0.7440\n",
      "Epoch: 5, Step: 2761/2949, Loss: 0.6939\n",
      "Epoch: 5, Step: 2762/2949, Loss: 0.6822\n",
      "Epoch: 5, Step: 2763/2949, Loss: 0.7270\n",
      "Epoch: 5, Step: 2764/2949, Loss: 0.7466\n",
      "Epoch: 5, Step: 2765/2949, Loss: 0.6744\n",
      "Epoch: 5, Step: 2766/2949, Loss: 0.6935\n",
      "Epoch: 5, Step: 2767/2949, Loss: 0.7759\n",
      "Epoch: 5, Step: 2768/2949, Loss: 0.7679\n",
      "Epoch: 5, Step: 2769/2949, Loss: 0.7118\n",
      "Epoch: 5, Step: 2770/2949, Loss: 0.7770\n",
      "Epoch: 5, Step: 2771/2949, Loss: 0.7290\n",
      "Epoch: 5, Step: 2772/2949, Loss: 0.7188\n",
      "Epoch: 5, Step: 2773/2949, Loss: 0.7306\n",
      "Epoch: 5, Step: 2774/2949, Loss: 0.7668\n",
      "Epoch: 5, Step: 2775/2949, Loss: 0.7540\n",
      "Epoch: 5, Step: 2776/2949, Loss: 0.6845\n",
      "Epoch: 5, Step: 2777/2949, Loss: 0.7502\n",
      "Epoch: 5, Step: 2778/2949, Loss: 0.7323\n",
      "Epoch: 5, Step: 2779/2949, Loss: 0.7198\n",
      "Epoch: 5, Step: 2780/2949, Loss: 0.7698\n",
      "Epoch: 5, Step: 2781/2949, Loss: 0.6929\n",
      "Epoch: 5, Step: 2782/2949, Loss: 0.7453\n",
      "Epoch: 5, Step: 2783/2949, Loss: 0.7657\n",
      "Epoch: 5, Step: 2784/2949, Loss: 0.7415\n",
      "Epoch: 5, Step: 2785/2949, Loss: 0.7238\n",
      "Epoch: 5, Step: 2786/2949, Loss: 0.7703\n",
      "Epoch: 5, Step: 2787/2949, Loss: 0.7735\n",
      "Epoch: 5, Step: 2788/2949, Loss: 0.7121\n",
      "Epoch: 5, Step: 2789/2949, Loss: 0.7545\n",
      "Epoch: 5, Step: 2790/2949, Loss: 0.7658\n",
      "Epoch: 5, Step: 2791/2949, Loss: 0.7405\n",
      "Epoch: 5, Step: 2792/2949, Loss: 0.7103\n",
      "Epoch: 5, Step: 2793/2949, Loss: 0.7139\n",
      "Epoch: 5, Step: 2794/2949, Loss: 0.6991\n",
      "Epoch: 5, Step: 2795/2949, Loss: 0.7489\n",
      "Epoch: 5, Step: 2796/2949, Loss: 0.7517\n",
      "Epoch: 5, Step: 2797/2949, Loss: 0.7559\n",
      "Epoch: 5, Step: 2798/2949, Loss: 0.6918\n",
      "Epoch: 5, Step: 2799/2949, Loss: 0.6836\n",
      "Epoch: 5, Step: 2800/2949, Loss: 0.7006\n",
      "Epoch: 5, Step: 2801/2949, Loss: 0.7621\n",
      "Epoch: 5, Step: 2802/2949, Loss: 0.7622\n",
      "Epoch: 5, Step: 2803/2949, Loss: 0.7512\n",
      "Epoch: 5, Step: 2804/2949, Loss: 0.7202\n",
      "Epoch: 5, Step: 2805/2949, Loss: 0.6769\n",
      "Epoch: 5, Step: 2806/2949, Loss: 0.7520\n",
      "Epoch: 5, Step: 2807/2949, Loss: 0.6907\n",
      "Epoch: 5, Step: 2808/2949, Loss: 0.7464\n",
      "Epoch: 5, Step: 2809/2949, Loss: 0.7720\n",
      "Epoch: 5, Step: 2810/2949, Loss: 0.7292\n",
      "Epoch: 5, Step: 2811/2949, Loss: 0.7538\n",
      "Epoch: 5, Step: 2812/2949, Loss: 0.7276\n",
      "Epoch: 5, Step: 2813/2949, Loss: 0.7067\n",
      "Epoch: 5, Step: 2814/2949, Loss: 0.7143\n",
      "Epoch: 5, Step: 2815/2949, Loss: 0.7639\n",
      "Epoch: 5, Step: 2816/2949, Loss: 0.7195\n",
      "Epoch: 5, Step: 2817/2949, Loss: 0.8066\n",
      "Epoch: 5, Step: 2818/2949, Loss: 0.7921\n",
      "Epoch: 5, Step: 2819/2949, Loss: 0.7676\n",
      "Epoch: 5, Step: 2820/2949, Loss: 0.7592\n",
      "Epoch: 5, Step: 2821/2949, Loss: 0.7387\n",
      "Epoch: 5, Step: 2822/2949, Loss: 0.7373\n",
      "Epoch: 5, Step: 2823/2949, Loss: 0.7377\n",
      "Epoch: 5, Step: 2824/2949, Loss: 0.6974\n",
      "Epoch: 5, Step: 2825/2949, Loss: 0.7110\n",
      "Epoch: 5, Step: 2826/2949, Loss: 0.6970\n",
      "Epoch: 5, Step: 2827/2949, Loss: 0.7614\n",
      "Epoch: 5, Step: 2828/2949, Loss: 0.7288\n",
      "Epoch: 5, Step: 2829/2949, Loss: 0.7184\n",
      "Epoch: 5, Step: 2830/2949, Loss: 0.7764\n",
      "Epoch: 5, Step: 2831/2949, Loss: 0.7529\n",
      "Epoch: 5, Step: 2832/2949, Loss: 0.7424\n",
      "Epoch: 5, Step: 2833/2949, Loss: 0.7439\n",
      "Epoch: 5, Step: 2834/2949, Loss: 0.7264\n",
      "Epoch: 5, Step: 2835/2949, Loss: 0.7929\n",
      "Epoch: 5, Step: 2836/2949, Loss: 0.7603\n",
      "Epoch: 5, Step: 2837/2949, Loss: 0.7393\n",
      "Epoch: 5, Step: 2838/2949, Loss: 0.7465\n",
      "Epoch: 5, Step: 2839/2949, Loss: 0.7333\n",
      "Epoch: 5, Step: 2840/2949, Loss: 0.6869\n",
      "Epoch: 5, Step: 2841/2949, Loss: 0.7450\n",
      "Epoch: 5, Step: 2842/2949, Loss: 0.7435\n",
      "Epoch: 5, Step: 2843/2949, Loss: 0.7040\n",
      "Epoch: 5, Step: 2844/2949, Loss: 0.7399\n",
      "Epoch: 5, Step: 2845/2949, Loss: 0.8064\n",
      "Epoch: 5, Step: 2846/2949, Loss: 0.7270\n",
      "Epoch: 5, Step: 2847/2949, Loss: 0.7234\n",
      "Epoch: 5, Step: 2848/2949, Loss: 0.7011\n",
      "Epoch: 5, Step: 2849/2949, Loss: 0.7597\n",
      "Epoch: 5, Step: 2850/2949, Loss: 0.7497\n",
      "Epoch: 5, Step: 2851/2949, Loss: 0.7310\n",
      "Epoch: 5, Step: 2852/2949, Loss: 0.7109\n",
      "Epoch: 5, Step: 2853/2949, Loss: 0.7650\n",
      "Epoch: 5, Step: 2854/2949, Loss: 0.7252\n",
      "Epoch: 5, Step: 2855/2949, Loss: 0.7192\n",
      "Epoch: 5, Step: 2856/2949, Loss: 0.7372\n",
      "Epoch: 5, Step: 2857/2949, Loss: 0.7216\n",
      "Epoch: 5, Step: 2858/2949, Loss: 0.7405\n",
      "Epoch: 5, Step: 2859/2949, Loss: 0.7316\n",
      "Epoch: 5, Step: 2860/2949, Loss: 0.7752\n",
      "Epoch: 5, Step: 2861/2949, Loss: 0.7252\n",
      "Epoch: 5, Step: 2862/2949, Loss: 0.7454\n",
      "Epoch: 5, Step: 2863/2949, Loss: 0.7683\n",
      "Epoch: 5, Step: 2864/2949, Loss: 0.7688\n",
      "Epoch: 5, Step: 2865/2949, Loss: 0.7309\n",
      "Epoch: 5, Step: 2866/2949, Loss: 0.6860\n",
      "Epoch: 5, Step: 2867/2949, Loss: 0.7370\n",
      "Epoch: 5, Step: 2868/2949, Loss: 0.7710\n",
      "Epoch: 5, Step: 2869/2949, Loss: 0.6858\n",
      "Epoch: 5, Step: 2870/2949, Loss: 0.7781\n",
      "Epoch: 5, Step: 2871/2949, Loss: 0.7764\n",
      "Epoch: 5, Step: 2872/2949, Loss: 0.7786\n",
      "Epoch: 5, Step: 2873/2949, Loss: 0.7043\n",
      "Epoch: 5, Step: 2874/2949, Loss: 0.7326\n",
      "Epoch: 5, Step: 2875/2949, Loss: 0.7787\n",
      "Epoch: 5, Step: 2876/2949, Loss: 0.7339\n",
      "Epoch: 5, Step: 2877/2949, Loss: 0.7659\n",
      "Epoch: 5, Step: 2878/2949, Loss: 0.7466\n",
      "Epoch: 5, Step: 2879/2949, Loss: 0.7383\n",
      "Epoch: 5, Step: 2880/2949, Loss: 0.7200\n",
      "Epoch: 5, Step: 2881/2949, Loss: 0.7438\n",
      "Epoch: 5, Step: 2882/2949, Loss: 0.7451\n",
      "Epoch: 5, Step: 2883/2949, Loss: 0.7457\n",
      "Epoch: 5, Step: 2884/2949, Loss: 0.7466\n",
      "Epoch: 5, Step: 2885/2949, Loss: 0.7264\n",
      "Epoch: 5, Step: 2886/2949, Loss: 0.7520\n",
      "Epoch: 5, Step: 2887/2949, Loss: 0.7728\n",
      "Epoch: 5, Step: 2888/2949, Loss: 0.7146\n",
      "Epoch: 5, Step: 2889/2949, Loss: 0.7398\n",
      "Epoch: 5, Step: 2890/2949, Loss: 0.6887\n",
      "Epoch: 5, Step: 2891/2949, Loss: 0.6988\n",
      "Epoch: 5, Step: 2892/2949, Loss: 0.7243\n",
      "Epoch: 5, Step: 2893/2949, Loss: 0.7275\n",
      "Epoch: 5, Step: 2894/2949, Loss: 0.7444\n",
      "Epoch: 5, Step: 2895/2949, Loss: 0.7391\n",
      "Epoch: 5, Step: 2896/2949, Loss: 0.6955\n",
      "Epoch: 5, Step: 2897/2949, Loss: 0.7251\n",
      "Epoch: 5, Step: 2898/2949, Loss: 0.7352\n",
      "Epoch: 5, Step: 2899/2949, Loss: 0.6825\n",
      "Epoch: 5, Step: 2900/2949, Loss: 0.7554\n",
      "Epoch: 5, Step: 2901/2949, Loss: 0.7411\n",
      "Epoch: 5, Step: 2902/2949, Loss: 0.6731\n",
      "Epoch: 5, Step: 2903/2949, Loss: 0.7617\n",
      "Epoch: 5, Step: 2904/2949, Loss: 0.7531\n",
      "Epoch: 5, Step: 2905/2949, Loss: 0.7575\n",
      "Epoch: 5, Step: 2906/2949, Loss: 0.7666\n",
      "Epoch: 5, Step: 2907/2949, Loss: 0.7590\n",
      "Epoch: 5, Step: 2908/2949, Loss: 0.7589\n",
      "Epoch: 5, Step: 2909/2949, Loss: 0.7408\n",
      "Epoch: 5, Step: 2910/2949, Loss: 0.7020\n",
      "Epoch: 5, Step: 2911/2949, Loss: 0.7010\n",
      "Epoch: 5, Step: 2912/2949, Loss: 0.7623\n",
      "Epoch: 5, Step: 2913/2949, Loss: 0.7876\n",
      "Epoch: 5, Step: 2914/2949, Loss: 0.7395\n",
      "Epoch: 5, Step: 2915/2949, Loss: 0.7459\n",
      "Epoch: 5, Step: 2916/2949, Loss: 0.6897\n",
      "Epoch: 5, Step: 2917/2949, Loss: 0.7208\n",
      "Epoch: 5, Step: 2918/2949, Loss: 0.7513\n",
      "Epoch: 5, Step: 2919/2949, Loss: 0.8008\n",
      "Epoch: 5, Step: 2920/2949, Loss: 0.7458\n",
      "Epoch: 5, Step: 2921/2949, Loss: 0.7124\n",
      "Epoch: 5, Step: 2922/2949, Loss: 0.7801\n",
      "Epoch: 5, Step: 2923/2949, Loss: 0.7462\n",
      "Epoch: 5, Step: 2924/2949, Loss: 0.6389\n",
      "Epoch: 5, Step: 2925/2949, Loss: 0.6900\n",
      "Epoch: 5, Step: 2926/2949, Loss: 0.7428\n",
      "Epoch: 5, Step: 2927/2949, Loss: 0.7560\n",
      "Epoch: 5, Step: 2928/2949, Loss: 0.7376\n",
      "Epoch: 5, Step: 2929/2949, Loss: 0.7332\n",
      "Epoch: 5, Step: 2930/2949, Loss: 0.7194\n",
      "Epoch: 5, Step: 2931/2949, Loss: 0.7128\n",
      "Epoch: 5, Step: 2932/2949, Loss: 0.7437\n",
      "Epoch: 5, Step: 2933/2949, Loss: 0.7089\n",
      "Epoch: 5, Step: 2934/2949, Loss: 0.7054\n",
      "Epoch: 5, Step: 2935/2949, Loss: 0.7484\n",
      "Epoch: 5, Step: 2936/2949, Loss: 0.7236\n",
      "Epoch: 5, Step: 2937/2949, Loss: 0.7123\n",
      "Epoch: 5, Step: 2938/2949, Loss: 0.7426\n",
      "Epoch: 5, Step: 2939/2949, Loss: 0.6950\n",
      "Epoch: 5, Step: 2940/2949, Loss: 0.7577\n",
      "Epoch: 5, Step: 2941/2949, Loss: 0.7240\n",
      "Epoch: 5, Step: 2942/2949, Loss: 0.7225\n",
      "Epoch: 5, Step: 2943/2949, Loss: 0.7592\n",
      "Epoch: 5, Step: 2944/2949, Loss: 0.6935\n",
      "Epoch: 5, Step: 2945/2949, Loss: 0.7167\n",
      "Epoch: 5, Step: 2946/2949, Loss: 0.7198\n",
      "Epoch: 5, Step: 2947/2949, Loss: 0.7314\n",
      "Epoch: 5, Step: 2948/2949, Loss: 0.7395\n",
      "Epoch: 5, Step: 2949/2949, Loss: 0.8011\n",
      "Test Accuracy (xgboost): 0.3683\n",
      "Epoch: 5, Accuracy: 0.3683\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b36079339986eb08"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
